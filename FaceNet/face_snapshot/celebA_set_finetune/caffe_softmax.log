I0826 15:26:38.198761 25446 caffe.cpp:217] Using GPUs 0
I0826 15:26:38.240788 25446 caffe.cpp:222] GPU 0: GeForce RTX 2080
I0826 15:26:38.511544 25446 solver.cpp:63] Initializing solver from parameters: 
base_lr: 0.001
display: 10
max_iter: 28000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 1000
snapshot_prefix: "face_snapshot/face_train_test"
solver_mode: GPU
device_id: 0
net: "face_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 16000
stepvalue: 24000
stepvalue: 28000
I0826 15:26:38.511720 25446 solver.cpp:106] Creating training net from net file: face_train_test.prototxt
I0826 15:26:38.512199 25446 net.cpp:58] Initializing net from parameters: 
name: "Face-ResNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0078125
    mirror: true
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
  }
  data_param {
    source: "/media/ly/data/facenet/facenet_caffe-master/face_recog_celebA_set_lmdb"
    batch_size: 16
    backend: LMDB
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "PReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1b"
  type: "PReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1b"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1b"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1b"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "res2_2"
  type: "Eltwise"
  bottom: "pool1b"
  bottom: "conv2_2"
  top: "res2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "res2_2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "res3_2"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "conv3_2"
  top: "res3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "res3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "res3_4"
  type: "Eltwise"
  bottom: "res3_2"
  bottom: "conv3_4"
  top: "res3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "res3_4"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "res4_2"
  type: "Eltwise"
  bottom: "pool3"
  bottom: "conv4_2"
  top: "res4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "res4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_4"
  type: "PReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "res4_4"
  type: "Eltwise"
  bottom: "res4_2"
  bottom: "conv4_4"
  top: "res4_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_5"
  type: "Convolution"
  bottom: "res4_4"
  top: "conv4_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_5"
  type: "PReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_6"
  type: "PReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
layer {
  name: "res4_6"
  type: "Eltwise"
  bottom: "res4_4"
  bottom: "conv4_6"
  top: "res4_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_7"
  type: "Convolution"
  bottom: "res4_6"
  top: "conv4_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_7"
  type: "PReLU"
  bottom: "conv4_7"
  top: "conv4_7"
}
layer {
  name: "conv4_8"
  type: "Convolution"
  bottom: "conv4_7"
  top: "conv4_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_8"
  type: "PReLU"
  bottom: "conv4_8"
  top: "conv4_8"
}
layer {
  name: "res4_8"
  type: "Eltwise"
  bottom: "res4_6"
  bottom: "conv4_8"
  top: "res4_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_9"
  type: "Convolution"
  bottom: "res4_8"
  top: "conv4_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_9"
  type: "PReLU"
  bottom: "conv4_9"
  top: "conv4_9"
}
layer {
  name: "conv4_10"
  type: "Convolution"
  bottom: "conv4_9"
  top: "conv4_10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_10"
  type: "PReLU"
  bottom: "conv4_10"
  top: "conv4_10"
}
layer {
  name: "res4_10"
  type: "Eltwise"
  bottom: "res4_8"
  bottom: "conv4_10"
  top: "res4_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "res4_10"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "PReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "PReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "res5_2"
  type: "Eltwise"
  bottom: "pool4"
  bottom: "conv5_2"
  top: "res5_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "res5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "PReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_4"
  type: "PReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "res5_4"
  type: "Eltwise"
  bottom: "res5_2"
  bottom: "conv5_4"
  top: "res5_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_5"
  type: "Convolution"
  bottom: "res5_4"
  top: "conv5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_5"
  type: "PReLU"
  bottom: "conv5_5"
  top: "conv5_5"
}
layer {
  name: "conv5_6"
  type: "Convolution"
  bottom: "conv5_5"
  top: "conv5_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_6"
  type: "PReLU"
  bottom: "conv5_6"
  top: "conv5_6"
}
layer {
  name: "res5_6"
  type: "Eltwise"
  bottom: "res5_4"
  bottom: "conv5_6"
  top: "res5_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc_5"
  type: "InnerProduct"
  bottom: "res5_6"
  top: "fc_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc_6"
  type: "InnerProduct"
  bottom: "fc_5"
  top: "fc_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10177
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_6"
  bottom: "label"
  top: "softmax_loss"
}
layer {
  name: "center_loss"
  type: "CenterLoss"
  bottom: "fc_5"
  bottom: "label"
  top: "center_loss"
  loss_weight: 0.008
  param {
    lr_mult: 1
    decay_mult: 2
  }
  center_loss_param {
    num_output: 10177
    center_filler {
      type: "xavier"
    }
  }
}
I0826 15:26:38.512702 25446 layer_factory.hpp:77] Creating layer data
I0826 15:26:38.512887 25446 net.cpp:100] Creating Layer data
I0826 15:26:38.512897 25446 net.cpp:408] data -> data
I0826 15:26:38.512915 25446 net.cpp:408] data -> label
I0826 15:26:38.513540 25465 db_lmdb.cpp:35] Opened lmdb /media/ly/data/facenet/facenet_caffe-master/face_recog_celebA_set_lmdb
I0826 15:26:38.526090 25446 data_layer.cpp:41] output data size: 16,3,224,224
I0826 15:26:38.535876 25446 net.cpp:150] Setting up data
I0826 15:26:38.535897 25446 net.cpp:157] Top shape: 16 3 224 224 (2408448)
I0826 15:26:38.535904 25446 net.cpp:157] Top shape: 16 (16)
I0826 15:26:38.535907 25446 net.cpp:165] Memory required for data: 9633856
I0826 15:26:38.535913 25446 layer_factory.hpp:77] Creating layer label_data_1_split
I0826 15:26:38.535924 25446 net.cpp:100] Creating Layer label_data_1_split
I0826 15:26:38.535929 25446 net.cpp:434] label_data_1_split <- label
I0826 15:26:38.535939 25446 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0826 15:26:38.535948 25446 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0826 15:26:38.535984 25446 net.cpp:150] Setting up label_data_1_split
I0826 15:26:38.535990 25446 net.cpp:157] Top shape: 16 (16)
I0826 15:26:38.535995 25446 net.cpp:157] Top shape: 16 (16)
I0826 15:26:38.536000 25446 net.cpp:165] Memory required for data: 9633984
I0826 15:26:38.536015 25446 layer_factory.hpp:77] Creating layer conv1a
I0826 15:26:38.536043 25446 net.cpp:100] Creating Layer conv1a
I0826 15:26:38.536046 25446 net.cpp:434] conv1a <- data
I0826 15:26:38.536049 25446 net.cpp:408] conv1a -> conv1a
I0826 15:26:39.267613 25446 net.cpp:150] Setting up conv1a
I0826 15:26:39.267629 25446 net.cpp:157] Top shape: 16 32 222 222 (25233408)
I0826 15:26:39.267652 25446 net.cpp:165] Memory required for data: 110567616
I0826 15:26:39.267668 25446 layer_factory.hpp:77] Creating layer relu1a
I0826 15:26:39.267676 25446 net.cpp:100] Creating Layer relu1a
I0826 15:26:39.267694 25446 net.cpp:434] relu1a <- conv1a
I0826 15:26:39.267700 25446 net.cpp:395] relu1a -> conv1a (in-place)
I0826 15:26:39.269476 25446 net.cpp:150] Setting up relu1a
I0826 15:26:39.269485 25446 net.cpp:157] Top shape: 16 32 222 222 (25233408)
I0826 15:26:39.269490 25446 net.cpp:165] Memory required for data: 211501248
I0826 15:26:39.269496 25446 layer_factory.hpp:77] Creating layer conv1b
I0826 15:26:39.269505 25446 net.cpp:100] Creating Layer conv1b
I0826 15:26:39.269508 25446 net.cpp:434] conv1b <- conv1a
I0826 15:26:39.269512 25446 net.cpp:408] conv1b -> conv1b
I0826 15:26:39.270937 25446 net.cpp:150] Setting up conv1b
I0826 15:26:39.270946 25446 net.cpp:157] Top shape: 16 64 220 220 (49561600)
I0826 15:26:39.270951 25446 net.cpp:165] Memory required for data: 409747648
I0826 15:26:39.270956 25446 layer_factory.hpp:77] Creating layer relu1b
I0826 15:26:39.270959 25446 net.cpp:100] Creating Layer relu1b
I0826 15:26:39.270962 25446 net.cpp:434] relu1b <- conv1b
I0826 15:26:39.270965 25446 net.cpp:395] relu1b -> conv1b (in-place)
I0826 15:26:39.274452 25446 net.cpp:150] Setting up relu1b
I0826 15:26:39.274468 25446 net.cpp:157] Top shape: 16 64 220 220 (49561600)
I0826 15:26:39.274474 25446 net.cpp:165] Memory required for data: 607994048
I0826 15:26:39.274482 25446 layer_factory.hpp:77] Creating layer pool1b
I0826 15:26:39.274488 25446 net.cpp:100] Creating Layer pool1b
I0826 15:26:39.274492 25446 net.cpp:434] pool1b <- conv1b
I0826 15:26:39.274497 25446 net.cpp:408] pool1b -> pool1b
I0826 15:26:39.274619 25446 net.cpp:150] Setting up pool1b
I0826 15:26:39.274624 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.274628 25446 net.cpp:165] Memory required for data: 657555648
I0826 15:26:39.274631 25446 layer_factory.hpp:77] Creating layer pool1b_pool1b_0_split
I0826 15:26:39.274636 25446 net.cpp:100] Creating Layer pool1b_pool1b_0_split
I0826 15:26:39.274637 25446 net.cpp:434] pool1b_pool1b_0_split <- pool1b
I0826 15:26:39.274641 25446 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_0
I0826 15:26:39.274646 25446 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_1
I0826 15:26:39.274670 25446 net.cpp:150] Setting up pool1b_pool1b_0_split
I0826 15:26:39.274674 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.274677 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.274679 25446 net.cpp:165] Memory required for data: 756678848
I0826 15:26:39.274682 25446 layer_factory.hpp:77] Creating layer conv2_1
I0826 15:26:39.274693 25446 net.cpp:100] Creating Layer conv2_1
I0826 15:26:39.274698 25446 net.cpp:434] conv2_1 <- pool1b_pool1b_0_split_0
I0826 15:26:39.274703 25446 net.cpp:408] conv2_1 -> conv2_1
I0826 15:26:39.276949 25446 net.cpp:150] Setting up conv2_1
I0826 15:26:39.276957 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.276960 25446 net.cpp:165] Memory required for data: 806240448
I0826 15:26:39.276965 25446 layer_factory.hpp:77] Creating layer relu2_1
I0826 15:26:39.276969 25446 net.cpp:100] Creating Layer relu2_1
I0826 15:26:39.276973 25446 net.cpp:434] relu2_1 <- conv2_1
I0826 15:26:39.276975 25446 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0826 15:26:39.277941 25446 net.cpp:150] Setting up relu2_1
I0826 15:26:39.277948 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.277952 25446 net.cpp:165] Memory required for data: 855802048
I0826 15:26:39.277957 25446 layer_factory.hpp:77] Creating layer conv2_2
I0826 15:26:39.277964 25446 net.cpp:100] Creating Layer conv2_2
I0826 15:26:39.277967 25446 net.cpp:434] conv2_2 <- conv2_1
I0826 15:26:39.277971 25446 net.cpp:408] conv2_2 -> conv2_2
I0826 15:26:39.280758 25446 net.cpp:150] Setting up conv2_2
I0826 15:26:39.280767 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.280771 25446 net.cpp:165] Memory required for data: 905363648
I0826 15:26:39.280776 25446 layer_factory.hpp:77] Creating layer relu2_2
I0826 15:26:39.280781 25446 net.cpp:100] Creating Layer relu2_2
I0826 15:26:39.280786 25446 net.cpp:434] relu2_2 <- conv2_2
I0826 15:26:39.280788 25446 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0826 15:26:39.281759 25446 net.cpp:150] Setting up relu2_2
I0826 15:26:39.281767 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.281771 25446 net.cpp:165] Memory required for data: 954925248
I0826 15:26:39.281775 25446 layer_factory.hpp:77] Creating layer res2_2
I0826 15:26:39.281786 25446 net.cpp:100] Creating Layer res2_2
I0826 15:26:39.281790 25446 net.cpp:434] res2_2 <- pool1b_pool1b_0_split_1
I0826 15:26:39.281792 25446 net.cpp:434] res2_2 <- conv2_2
I0826 15:26:39.281795 25446 net.cpp:408] res2_2 -> res2_2
I0826 15:26:39.281819 25446 net.cpp:150] Setting up res2_2
I0826 15:26:39.281823 25446 net.cpp:157] Top shape: 16 64 110 110 (12390400)
I0826 15:26:39.281826 25446 net.cpp:165] Memory required for data: 1004486848
I0826 15:26:39.281828 25446 layer_factory.hpp:77] Creating layer conv2
I0826 15:26:39.281834 25446 net.cpp:100] Creating Layer conv2
I0826 15:26:39.281837 25446 net.cpp:434] conv2 <- res2_2
I0826 15:26:39.281841 25446 net.cpp:408] conv2 -> conv2
I0826 15:26:39.284255 25446 net.cpp:150] Setting up conv2
I0826 15:26:39.284265 25446 net.cpp:157] Top shape: 16 128 108 108 (23887872)
I0826 15:26:39.284284 25446 net.cpp:165] Memory required for data: 1100038336
I0826 15:26:39.284289 25446 layer_factory.hpp:77] Creating layer relu2
I0826 15:26:39.284294 25446 net.cpp:100] Creating Layer relu2
I0826 15:26:39.284298 25446 net.cpp:434] relu2 <- conv2
I0826 15:26:39.284304 25446 net.cpp:395] relu2 -> conv2 (in-place)
I0826 15:26:39.286046 25446 net.cpp:150] Setting up relu2
I0826 15:26:39.286056 25446 net.cpp:157] Top shape: 16 128 108 108 (23887872)
I0826 15:26:39.286062 25446 net.cpp:165] Memory required for data: 1195589824
I0826 15:26:39.286067 25446 layer_factory.hpp:77] Creating layer pool2
I0826 15:26:39.286072 25446 net.cpp:100] Creating Layer pool2
I0826 15:26:39.286074 25446 net.cpp:434] pool2 <- conv2
I0826 15:26:39.286078 25446 net.cpp:408] pool2 -> pool2
I0826 15:26:39.286129 25446 net.cpp:150] Setting up pool2
I0826 15:26:39.286135 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.286154 25446 net.cpp:165] Memory required for data: 1219477696
I0826 15:26:39.286156 25446 layer_factory.hpp:77] Creating layer pool2_pool2_0_split
I0826 15:26:39.286164 25446 net.cpp:100] Creating Layer pool2_pool2_0_split
I0826 15:26:39.286166 25446 net.cpp:434] pool2_pool2_0_split <- pool2
I0826 15:26:39.286170 25446 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_0
I0826 15:26:39.286173 25446 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_1
I0826 15:26:39.286237 25446 net.cpp:150] Setting up pool2_pool2_0_split
I0826 15:26:39.286242 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.286244 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.286247 25446 net.cpp:165] Memory required for data: 1267253440
I0826 15:26:39.286249 25446 layer_factory.hpp:77] Creating layer conv3_1
I0826 15:26:39.286257 25446 net.cpp:100] Creating Layer conv3_1
I0826 15:26:39.286258 25446 net.cpp:434] conv3_1 <- pool2_pool2_0_split_0
I0826 15:26:39.286262 25446 net.cpp:408] conv3_1 -> conv3_1
I0826 15:26:39.289098 25446 net.cpp:150] Setting up conv3_1
I0826 15:26:39.289105 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.289124 25446 net.cpp:165] Memory required for data: 1291141312
I0826 15:26:39.289131 25446 layer_factory.hpp:77] Creating layer relu3_1
I0826 15:26:39.289137 25446 net.cpp:100] Creating Layer relu3_1
I0826 15:26:39.289144 25446 net.cpp:434] relu3_1 <- conv3_1
I0826 15:26:39.289149 25446 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0826 15:26:39.289837 25446 net.cpp:150] Setting up relu3_1
I0826 15:26:39.289845 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.289849 25446 net.cpp:165] Memory required for data: 1315029184
I0826 15:26:39.289867 25446 layer_factory.hpp:77] Creating layer conv3_2
I0826 15:26:39.289875 25446 net.cpp:100] Creating Layer conv3_2
I0826 15:26:39.289877 25446 net.cpp:434] conv3_2 <- conv3_1
I0826 15:26:39.289881 25446 net.cpp:408] conv3_2 -> conv3_2
I0826 15:26:39.292876 25446 net.cpp:150] Setting up conv3_2
I0826 15:26:39.292884 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.292903 25446 net.cpp:165] Memory required for data: 1338917056
I0826 15:26:39.292908 25446 layer_factory.hpp:77] Creating layer relu3_2
I0826 15:26:39.292912 25446 net.cpp:100] Creating Layer relu3_2
I0826 15:26:39.292915 25446 net.cpp:434] relu3_2 <- conv3_2
I0826 15:26:39.292918 25446 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0826 15:26:39.293629 25446 net.cpp:150] Setting up relu3_2
I0826 15:26:39.293637 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.293655 25446 net.cpp:165] Memory required for data: 1362804928
I0826 15:26:39.293659 25446 layer_factory.hpp:77] Creating layer res3_2
I0826 15:26:39.293664 25446 net.cpp:100] Creating Layer res3_2
I0826 15:26:39.293668 25446 net.cpp:434] res3_2 <- pool2_pool2_0_split_1
I0826 15:26:39.293670 25446 net.cpp:434] res3_2 <- conv3_2
I0826 15:26:39.293674 25446 net.cpp:408] res3_2 -> res3_2
I0826 15:26:39.293695 25446 net.cpp:150] Setting up res3_2
I0826 15:26:39.293699 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.293702 25446 net.cpp:165] Memory required for data: 1386692800
I0826 15:26:39.293705 25446 layer_factory.hpp:77] Creating layer res3_2_res3_2_0_split
I0826 15:26:39.293711 25446 net.cpp:100] Creating Layer res3_2_res3_2_0_split
I0826 15:26:39.293715 25446 net.cpp:434] res3_2_res3_2_0_split <- res3_2
I0826 15:26:39.293735 25446 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_0
I0826 15:26:39.293741 25446 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_1
I0826 15:26:39.293779 25446 net.cpp:150] Setting up res3_2_res3_2_0_split
I0826 15:26:39.293785 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.293803 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.293807 25446 net.cpp:165] Memory required for data: 1434468544
I0826 15:26:39.293825 25446 layer_factory.hpp:77] Creating layer conv3_3
I0826 15:26:39.293833 25446 net.cpp:100] Creating Layer conv3_3
I0826 15:26:39.293838 25446 net.cpp:434] conv3_3 <- res3_2_res3_2_0_split_0
I0826 15:26:39.293843 25446 net.cpp:408] conv3_3 -> conv3_3
I0826 15:26:39.296653 25446 net.cpp:150] Setting up conv3_3
I0826 15:26:39.296661 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.296680 25446 net.cpp:165] Memory required for data: 1458356416
I0826 15:26:39.296685 25446 layer_factory.hpp:77] Creating layer relu3_3
I0826 15:26:39.296690 25446 net.cpp:100] Creating Layer relu3_3
I0826 15:26:39.296694 25446 net.cpp:434] relu3_3 <- conv3_3
I0826 15:26:39.296696 25446 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0826 15:26:39.297415 25446 net.cpp:150] Setting up relu3_3
I0826 15:26:39.297422 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.297441 25446 net.cpp:165] Memory required for data: 1482244288
I0826 15:26:39.297446 25446 layer_factory.hpp:77] Creating layer conv3_4
I0826 15:26:39.297451 25446 net.cpp:100] Creating Layer conv3_4
I0826 15:26:39.297454 25446 net.cpp:434] conv3_4 <- conv3_3
I0826 15:26:39.297458 25446 net.cpp:408] conv3_4 -> conv3_4
I0826 15:26:39.299810 25446 net.cpp:150] Setting up conv3_4
I0826 15:26:39.299818 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.299821 25446 net.cpp:165] Memory required for data: 1506132160
I0826 15:26:39.299825 25446 layer_factory.hpp:77] Creating layer relu3_4
I0826 15:26:39.299829 25446 net.cpp:100] Creating Layer relu3_4
I0826 15:26:39.299832 25446 net.cpp:434] relu3_4 <- conv3_4
I0826 15:26:39.299835 25446 net.cpp:395] relu3_4 -> conv3_4 (in-place)
I0826 15:26:39.300583 25446 net.cpp:150] Setting up relu3_4
I0826 15:26:39.300591 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.300595 25446 net.cpp:165] Memory required for data: 1530020032
I0826 15:26:39.300599 25446 layer_factory.hpp:77] Creating layer res3_4
I0826 15:26:39.300606 25446 net.cpp:100] Creating Layer res3_4
I0826 15:26:39.300608 25446 net.cpp:434] res3_4 <- res3_2_res3_2_0_split_1
I0826 15:26:39.300611 25446 net.cpp:434] res3_4 <- conv3_4
I0826 15:26:39.300616 25446 net.cpp:408] res3_4 -> res3_4
I0826 15:26:39.300637 25446 net.cpp:150] Setting up res3_4
I0826 15:26:39.300643 25446 net.cpp:157] Top shape: 16 128 54 54 (5971968)
I0826 15:26:39.300648 25446 net.cpp:165] Memory required for data: 1553907904
I0826 15:26:39.300652 25446 layer_factory.hpp:77] Creating layer conv3
I0826 15:26:39.300659 25446 net.cpp:100] Creating Layer conv3
I0826 15:26:39.300662 25446 net.cpp:434] conv3 <- res3_4
I0826 15:26:39.300667 25446 net.cpp:408] conv3 -> conv3
I0826 15:26:39.303905 25446 net.cpp:150] Setting up conv3
I0826 15:26:39.303915 25446 net.cpp:157] Top shape: 16 256 52 52 (11075584)
I0826 15:26:39.303934 25446 net.cpp:165] Memory required for data: 1598210240
I0826 15:26:39.303939 25446 layer_factory.hpp:77] Creating layer relu3
I0826 15:26:39.303944 25446 net.cpp:100] Creating Layer relu3
I0826 15:26:39.303947 25446 net.cpp:434] relu3 <- conv3
I0826 15:26:39.303951 25446 net.cpp:395] relu3 -> conv3 (in-place)
I0826 15:26:39.304862 25446 net.cpp:150] Setting up relu3
I0826 15:26:39.304869 25446 net.cpp:157] Top shape: 16 256 52 52 (11075584)
I0826 15:26:39.304888 25446 net.cpp:165] Memory required for data: 1642512576
I0826 15:26:39.304891 25446 layer_factory.hpp:77] Creating layer pool3
I0826 15:26:39.304896 25446 net.cpp:100] Creating Layer pool3
I0826 15:26:39.304899 25446 net.cpp:434] pool3 <- conv3
I0826 15:26:39.304903 25446 net.cpp:408] pool3 -> pool3
I0826 15:26:39.304971 25446 net.cpp:150] Setting up pool3
I0826 15:26:39.304975 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.304980 25446 net.cpp:165] Memory required for data: 1653588160
I0826 15:26:39.304981 25446 layer_factory.hpp:77] Creating layer pool3_pool3_0_split
I0826 15:26:39.304986 25446 net.cpp:100] Creating Layer pool3_pool3_0_split
I0826 15:26:39.304987 25446 net.cpp:434] pool3_pool3_0_split <- pool3
I0826 15:26:39.304991 25446 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_0
I0826 15:26:39.304996 25446 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_1
I0826 15:26:39.305042 25446 net.cpp:150] Setting up pool3_pool3_0_split
I0826 15:26:39.305047 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.305065 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.305068 25446 net.cpp:165] Memory required for data: 1675739328
I0826 15:26:39.305070 25446 layer_factory.hpp:77] Creating layer conv4_1
I0826 15:26:39.305078 25446 net.cpp:100] Creating Layer conv4_1
I0826 15:26:39.305080 25446 net.cpp:434] conv4_1 <- pool3_pool3_0_split_0
I0826 15:26:39.305084 25446 net.cpp:408] conv4_1 -> conv4_1
I0826 15:26:39.310443 25446 net.cpp:150] Setting up conv4_1
I0826 15:26:39.310452 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.310456 25446 net.cpp:165] Memory required for data: 1686814912
I0826 15:26:39.310461 25446 layer_factory.hpp:77] Creating layer relu4_1
I0826 15:26:39.310465 25446 net.cpp:100] Creating Layer relu4_1
I0826 15:26:39.310468 25446 net.cpp:434] relu4_1 <- conv4_1
I0826 15:26:39.310472 25446 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0826 15:26:39.311100 25446 net.cpp:150] Setting up relu4_1
I0826 15:26:39.311106 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.311110 25446 net.cpp:165] Memory required for data: 1697890496
I0826 15:26:39.311115 25446 layer_factory.hpp:77] Creating layer conv4_2
I0826 15:26:39.311122 25446 net.cpp:100] Creating Layer conv4_2
I0826 15:26:39.311125 25446 net.cpp:434] conv4_2 <- conv4_1
I0826 15:26:39.311128 25446 net.cpp:408] conv4_2 -> conv4_2
I0826 15:26:39.316540 25446 net.cpp:150] Setting up conv4_2
I0826 15:26:39.316548 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.316568 25446 net.cpp:165] Memory required for data: 1708966080
I0826 15:26:39.316573 25446 layer_factory.hpp:77] Creating layer relu4_2
I0826 15:26:39.316577 25446 net.cpp:100] Creating Layer relu4_2
I0826 15:26:39.316581 25446 net.cpp:434] relu4_2 <- conv4_2
I0826 15:26:39.316586 25446 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0826 15:26:39.316751 25446 net.cpp:150] Setting up relu4_2
I0826 15:26:39.316756 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.316773 25446 net.cpp:165] Memory required for data: 1720041664
I0826 15:26:39.316777 25446 layer_factory.hpp:77] Creating layer res4_2
I0826 15:26:39.316782 25446 net.cpp:100] Creating Layer res4_2
I0826 15:26:39.316785 25446 net.cpp:434] res4_2 <- pool3_pool3_0_split_1
I0826 15:26:39.316789 25446 net.cpp:434] res4_2 <- conv4_2
I0826 15:26:39.316794 25446 net.cpp:408] res4_2 -> res4_2
I0826 15:26:39.316820 25446 net.cpp:150] Setting up res4_2
I0826 15:26:39.316843 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.316848 25446 net.cpp:165] Memory required for data: 1731117248
I0826 15:26:39.316869 25446 layer_factory.hpp:77] Creating layer res4_2_res4_2_0_split
I0826 15:26:39.316874 25446 net.cpp:100] Creating Layer res4_2_res4_2_0_split
I0826 15:26:39.316879 25446 net.cpp:434] res4_2_res4_2_0_split <- res4_2
I0826 15:26:39.316884 25446 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_0
I0826 15:26:39.316890 25446 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_1
I0826 15:26:39.316932 25446 net.cpp:150] Setting up res4_2_res4_2_0_split
I0826 15:26:39.316937 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.316941 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.316956 25446 net.cpp:165] Memory required for data: 1753268416
I0826 15:26:39.316987 25446 layer_factory.hpp:77] Creating layer conv4_3
I0826 15:26:39.316994 25446 net.cpp:100] Creating Layer conv4_3
I0826 15:26:39.316998 25446 net.cpp:434] conv4_3 <- res4_2_res4_2_0_split_0
I0826 15:26:39.317000 25446 net.cpp:408] conv4_3 -> conv4_3
I0826 15:26:39.323352 25446 net.cpp:150] Setting up conv4_3
I0826 15:26:39.323364 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.323369 25446 net.cpp:165] Memory required for data: 1764344000
I0826 15:26:39.323375 25446 layer_factory.hpp:77] Creating layer relu4_3
I0826 15:26:39.323380 25446 net.cpp:100] Creating Layer relu4_3
I0826 15:26:39.323384 25446 net.cpp:434] relu4_3 <- conv4_3
I0826 15:26:39.323387 25446 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0826 15:26:39.323572 25446 net.cpp:150] Setting up relu4_3
I0826 15:26:39.323577 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.323581 25446 net.cpp:165] Memory required for data: 1775419584
I0826 15:26:39.323585 25446 layer_factory.hpp:77] Creating layer conv4_4
I0826 15:26:39.323590 25446 net.cpp:100] Creating Layer conv4_4
I0826 15:26:39.323593 25446 net.cpp:434] conv4_4 <- conv4_3
I0826 15:26:39.323596 25446 net.cpp:408] conv4_4 -> conv4_4
I0826 15:26:39.329852 25446 net.cpp:150] Setting up conv4_4
I0826 15:26:39.329862 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.329866 25446 net.cpp:165] Memory required for data: 1786495168
I0826 15:26:39.329874 25446 layer_factory.hpp:77] Creating layer relu4_4
I0826 15:26:39.329879 25446 net.cpp:100] Creating Layer relu4_4
I0826 15:26:39.329881 25446 net.cpp:434] relu4_4 <- conv4_4
I0826 15:26:39.329885 25446 net.cpp:395] relu4_4 -> conv4_4 (in-place)
I0826 15:26:39.330531 25446 net.cpp:150] Setting up relu4_4
I0826 15:26:39.330539 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.330543 25446 net.cpp:165] Memory required for data: 1797570752
I0826 15:26:39.330548 25446 layer_factory.hpp:77] Creating layer res4_4
I0826 15:26:39.330552 25446 net.cpp:100] Creating Layer res4_4
I0826 15:26:39.330556 25446 net.cpp:434] res4_4 <- res4_2_res4_2_0_split_1
I0826 15:26:39.330559 25446 net.cpp:434] res4_4 <- conv4_4
I0826 15:26:39.330562 25446 net.cpp:408] res4_4 -> res4_4
I0826 15:26:39.330598 25446 net.cpp:150] Setting up res4_4
I0826 15:26:39.330602 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.330607 25446 net.cpp:165] Memory required for data: 1808646336
I0826 15:26:39.330610 25446 layer_factory.hpp:77] Creating layer res4_4_res4_4_0_split
I0826 15:26:39.330631 25446 net.cpp:100] Creating Layer res4_4_res4_4_0_split
I0826 15:26:39.330634 25446 net.cpp:434] res4_4_res4_4_0_split <- res4_4
I0826 15:26:39.330639 25446 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_0
I0826 15:26:39.330644 25446 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_1
I0826 15:26:39.330711 25446 net.cpp:150] Setting up res4_4_res4_4_0_split
I0826 15:26:39.330716 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.330719 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.330721 25446 net.cpp:165] Memory required for data: 1830797504
I0826 15:26:39.330724 25446 layer_factory.hpp:77] Creating layer conv4_5
I0826 15:26:39.330729 25446 net.cpp:100] Creating Layer conv4_5
I0826 15:26:39.330732 25446 net.cpp:434] conv4_5 <- res4_4_res4_4_0_split_0
I0826 15:26:39.330736 25446 net.cpp:408] conv4_5 -> conv4_5
I0826 15:26:39.336604 25446 net.cpp:150] Setting up conv4_5
I0826 15:26:39.336614 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.336619 25446 net.cpp:165] Memory required for data: 1841873088
I0826 15:26:39.336627 25446 layer_factory.hpp:77] Creating layer relu4_5
I0826 15:26:39.336630 25446 net.cpp:100] Creating Layer relu4_5
I0826 15:26:39.336634 25446 net.cpp:434] relu4_5 <- conv4_5
I0826 15:26:39.336638 25446 net.cpp:395] relu4_5 -> conv4_5 (in-place)
I0826 15:26:39.336822 25446 net.cpp:150] Setting up relu4_5
I0826 15:26:39.336828 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.336832 25446 net.cpp:165] Memory required for data: 1852948672
I0826 15:26:39.336848 25446 layer_factory.hpp:77] Creating layer conv4_6
I0826 15:26:39.336854 25446 net.cpp:100] Creating Layer conv4_6
I0826 15:26:39.336858 25446 net.cpp:434] conv4_6 <- conv4_5
I0826 15:26:39.336861 25446 net.cpp:408] conv4_6 -> conv4_6
I0826 15:26:39.342471 25446 net.cpp:150] Setting up conv4_6
I0826 15:26:39.342479 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.342483 25446 net.cpp:165] Memory required for data: 1864024256
I0826 15:26:39.342489 25446 layer_factory.hpp:77] Creating layer relu4_6
I0826 15:26:39.342494 25446 net.cpp:100] Creating Layer relu4_6
I0826 15:26:39.342496 25446 net.cpp:434] relu4_6 <- conv4_6
I0826 15:26:39.342500 25446 net.cpp:395] relu4_6 -> conv4_6 (in-place)
I0826 15:26:39.342658 25446 net.cpp:150] Setting up relu4_6
I0826 15:26:39.342662 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.342665 25446 net.cpp:165] Memory required for data: 1875099840
I0826 15:26:39.342669 25446 layer_factory.hpp:77] Creating layer res4_6
I0826 15:26:39.342674 25446 net.cpp:100] Creating Layer res4_6
I0826 15:26:39.342676 25446 net.cpp:434] res4_6 <- res4_4_res4_4_0_split_1
I0826 15:26:39.342679 25446 net.cpp:434] res4_6 <- conv4_6
I0826 15:26:39.342682 25446 net.cpp:408] res4_6 -> res4_6
I0826 15:26:39.342703 25446 net.cpp:150] Setting up res4_6
I0826 15:26:39.342707 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.342710 25446 net.cpp:165] Memory required for data: 1886175424
I0826 15:26:39.342712 25446 layer_factory.hpp:77] Creating layer res4_6_res4_6_0_split
I0826 15:26:39.342716 25446 net.cpp:100] Creating Layer res4_6_res4_6_0_split
I0826 15:26:39.342718 25446 net.cpp:434] res4_6_res4_6_0_split <- res4_6
I0826 15:26:39.342722 25446 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_0
I0826 15:26:39.342744 25446 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_1
I0826 15:26:39.342797 25446 net.cpp:150] Setting up res4_6_res4_6_0_split
I0826 15:26:39.342800 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.342803 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.342806 25446 net.cpp:165] Memory required for data: 1908326592
I0826 15:26:39.342808 25446 layer_factory.hpp:77] Creating layer conv4_7
I0826 15:26:39.342818 25446 net.cpp:100] Creating Layer conv4_7
I0826 15:26:39.342821 25446 net.cpp:434] conv4_7 <- res4_6_res4_6_0_split_0
I0826 15:26:39.342828 25446 net.cpp:408] conv4_7 -> conv4_7
I0826 15:26:39.349617 25446 net.cpp:150] Setting up conv4_7
I0826 15:26:39.349627 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.349632 25446 net.cpp:165] Memory required for data: 1919402176
I0826 15:26:39.349638 25446 layer_factory.hpp:77] Creating layer relu4_7
I0826 15:26:39.349644 25446 net.cpp:100] Creating Layer relu4_7
I0826 15:26:39.349647 25446 net.cpp:434] relu4_7 <- conv4_7
I0826 15:26:39.349650 25446 net.cpp:395] relu4_7 -> conv4_7 (in-place)
I0826 15:26:39.350262 25446 net.cpp:150] Setting up relu4_7
I0826 15:26:39.350270 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.350289 25446 net.cpp:165] Memory required for data: 1930477760
I0826 15:26:39.350293 25446 layer_factory.hpp:77] Creating layer conv4_8
I0826 15:26:39.350301 25446 net.cpp:100] Creating Layer conv4_8
I0826 15:26:39.350302 25446 net.cpp:434] conv4_8 <- conv4_7
I0826 15:26:39.350307 25446 net.cpp:408] conv4_8 -> conv4_8
I0826 15:26:39.356006 25446 net.cpp:150] Setting up conv4_8
I0826 15:26:39.356019 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.356022 25446 net.cpp:165] Memory required for data: 1941553344
I0826 15:26:39.356029 25446 layer_factory.hpp:77] Creating layer relu4_8
I0826 15:26:39.356034 25446 net.cpp:100] Creating Layer relu4_8
I0826 15:26:39.356039 25446 net.cpp:434] relu4_8 <- conv4_8
I0826 15:26:39.356042 25446 net.cpp:395] relu4_8 -> conv4_8 (in-place)
I0826 15:26:39.356243 25446 net.cpp:150] Setting up relu4_8
I0826 15:26:39.356251 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.356269 25446 net.cpp:165] Memory required for data: 1952628928
I0826 15:26:39.356274 25446 layer_factory.hpp:77] Creating layer res4_8
I0826 15:26:39.356282 25446 net.cpp:100] Creating Layer res4_8
I0826 15:26:39.356287 25446 net.cpp:434] res4_8 <- res4_6_res4_6_0_split_1
I0826 15:26:39.356292 25446 net.cpp:434] res4_8 <- conv4_8
I0826 15:26:39.356297 25446 net.cpp:408] res4_8 -> res4_8
I0826 15:26:39.356323 25446 net.cpp:150] Setting up res4_8
I0826 15:26:39.356328 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.356333 25446 net.cpp:165] Memory required for data: 1963704512
I0826 15:26:39.356335 25446 layer_factory.hpp:77] Creating layer res4_8_res4_8_0_split
I0826 15:26:39.356343 25446 net.cpp:100] Creating Layer res4_8_res4_8_0_split
I0826 15:26:39.356345 25446 net.cpp:434] res4_8_res4_8_0_split <- res4_8
I0826 15:26:39.356350 25446 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_0
I0826 15:26:39.356356 25446 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_1
I0826 15:26:39.356398 25446 net.cpp:150] Setting up res4_8_res4_8_0_split
I0826 15:26:39.356402 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.356407 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.356411 25446 net.cpp:165] Memory required for data: 1985855680
I0826 15:26:39.356415 25446 layer_factory.hpp:77] Creating layer conv4_9
I0826 15:26:39.356422 25446 net.cpp:100] Creating Layer conv4_9
I0826 15:26:39.356426 25446 net.cpp:434] conv4_9 <- res4_8_res4_8_0_split_0
I0826 15:26:39.356432 25446 net.cpp:408] conv4_9 -> conv4_9
I0826 15:26:39.362468 25446 net.cpp:150] Setting up conv4_9
I0826 15:26:39.362478 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.362483 25446 net.cpp:165] Memory required for data: 1996931264
I0826 15:26:39.362488 25446 layer_factory.hpp:77] Creating layer relu4_9
I0826 15:26:39.362494 25446 net.cpp:100] Creating Layer relu4_9
I0826 15:26:39.362498 25446 net.cpp:434] relu4_9 <- conv4_9
I0826 15:26:39.362501 25446 net.cpp:395] relu4_9 -> conv4_9 (in-place)
I0826 15:26:39.362661 25446 net.cpp:150] Setting up relu4_9
I0826 15:26:39.362668 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.362670 25446 net.cpp:165] Memory required for data: 2008006848
I0826 15:26:39.362673 25446 layer_factory.hpp:77] Creating layer conv4_10
I0826 15:26:39.362680 25446 net.cpp:100] Creating Layer conv4_10
I0826 15:26:39.362684 25446 net.cpp:434] conv4_10 <- conv4_9
I0826 15:26:39.362687 25446 net.cpp:408] conv4_10 -> conv4_10
I0826 15:26:39.369567 25446 net.cpp:150] Setting up conv4_10
I0826 15:26:39.369580 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.369585 25446 net.cpp:165] Memory required for data: 2019082432
I0826 15:26:39.369593 25446 layer_factory.hpp:77] Creating layer relu4_10
I0826 15:26:39.369599 25446 net.cpp:100] Creating Layer relu4_10
I0826 15:26:39.369602 25446 net.cpp:434] relu4_10 <- conv4_10
I0826 15:26:39.369607 25446 net.cpp:395] relu4_10 -> conv4_10 (in-place)
I0826 15:26:39.370260 25446 net.cpp:150] Setting up relu4_10
I0826 15:26:39.370267 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.370270 25446 net.cpp:165] Memory required for data: 2030158016
I0826 15:26:39.370275 25446 layer_factory.hpp:77] Creating layer res4_10
I0826 15:26:39.370280 25446 net.cpp:100] Creating Layer res4_10
I0826 15:26:39.370282 25446 net.cpp:434] res4_10 <- res4_8_res4_8_0_split_1
I0826 15:26:39.370285 25446 net.cpp:434] res4_10 <- conv4_10
I0826 15:26:39.370290 25446 net.cpp:408] res4_10 -> res4_10
I0826 15:26:39.370332 25446 net.cpp:150] Setting up res4_10
I0826 15:26:39.370337 25446 net.cpp:157] Top shape: 16 256 26 26 (2768896)
I0826 15:26:39.370355 25446 net.cpp:165] Memory required for data: 2041233600
I0826 15:26:39.370358 25446 layer_factory.hpp:77] Creating layer conv4
I0826 15:26:39.370364 25446 net.cpp:100] Creating Layer conv4
I0826 15:26:39.370368 25446 net.cpp:434] conv4 <- res4_10
I0826 15:26:39.370373 25446 net.cpp:408] conv4 -> conv4
I0826 15:26:39.376845 25446 net.cpp:150] Setting up conv4
I0826 15:26:39.376868 25446 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0826 15:26:39.376873 25446 net.cpp:165] Memory required for data: 2060107968
I0826 15:26:39.376878 25446 layer_factory.hpp:77] Creating layer relu4
I0826 15:26:39.376883 25446 net.cpp:100] Creating Layer relu4
I0826 15:26:39.376885 25446 net.cpp:434] relu4 <- conv4
I0826 15:26:39.376889 25446 net.cpp:395] relu4 -> conv4 (in-place)
I0826 15:26:39.377162 25446 net.cpp:150] Setting up relu4
I0826 15:26:39.377167 25446 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0826 15:26:39.377171 25446 net.cpp:165] Memory required for data: 2078982336
I0826 15:26:39.377174 25446 layer_factory.hpp:77] Creating layer pool4
I0826 15:26:39.377180 25446 net.cpp:100] Creating Layer pool4
I0826 15:26:39.377183 25446 net.cpp:434] pool4 <- conv4
I0826 15:26:39.377187 25446 net.cpp:408] pool4 -> pool4
I0826 15:26:39.377267 25446 net.cpp:150] Setting up pool4
I0826 15:26:39.377272 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.377275 25446 net.cpp:165] Memory required for data: 2083700928
I0826 15:26:39.377279 25446 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I0826 15:26:39.377285 25446 net.cpp:100] Creating Layer pool4_pool4_0_split
I0826 15:26:39.377287 25446 net.cpp:434] pool4_pool4_0_split <- pool4
I0826 15:26:39.377291 25446 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_0
I0826 15:26:39.377295 25446 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_1
I0826 15:26:39.377363 25446 net.cpp:150] Setting up pool4_pool4_0_split
I0826 15:26:39.377367 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.377372 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.377373 25446 net.cpp:165] Memory required for data: 2093138112
I0826 15:26:39.377377 25446 layer_factory.hpp:77] Creating layer conv5_1
I0826 15:26:39.377382 25446 net.cpp:100] Creating Layer conv5_1
I0826 15:26:39.377384 25446 net.cpp:434] conv5_1 <- pool4_pool4_0_split_0
I0826 15:26:39.377388 25446 net.cpp:408] conv5_1 -> conv5_1
I0826 15:26:39.395036 25446 net.cpp:150] Setting up conv5_1
I0826 15:26:39.395053 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.395058 25446 net.cpp:165] Memory required for data: 2097856704
I0826 15:26:39.395071 25446 layer_factory.hpp:77] Creating layer relu5_1
I0826 15:26:39.395076 25446 net.cpp:100] Creating Layer relu5_1
I0826 15:26:39.395081 25446 net.cpp:434] relu5_1 <- conv5_1
I0826 15:26:39.395085 25446 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0826 15:26:39.395221 25446 net.cpp:150] Setting up relu5_1
I0826 15:26:39.395227 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.395231 25446 net.cpp:165] Memory required for data: 2102575296
I0826 15:26:39.395233 25446 layer_factory.hpp:77] Creating layer conv5_2
I0826 15:26:39.395242 25446 net.cpp:100] Creating Layer conv5_2
I0826 15:26:39.395246 25446 net.cpp:434] conv5_2 <- conv5_1
I0826 15:26:39.395249 25446 net.cpp:408] conv5_2 -> conv5_2
I0826 15:26:39.412992 25446 net.cpp:150] Setting up conv5_2
I0826 15:26:39.413007 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.413013 25446 net.cpp:165] Memory required for data: 2107293888
I0826 15:26:39.413019 25446 layer_factory.hpp:77] Creating layer relu5_2
I0826 15:26:39.413025 25446 net.cpp:100] Creating Layer relu5_2
I0826 15:26:39.413028 25446 net.cpp:434] relu5_2 <- conv5_2
I0826 15:26:39.413033 25446 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0826 15:26:39.413202 25446 net.cpp:150] Setting up relu5_2
I0826 15:26:39.413208 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.413225 25446 net.cpp:165] Memory required for data: 2112012480
I0826 15:26:39.413229 25446 layer_factory.hpp:77] Creating layer res5_2
I0826 15:26:39.413236 25446 net.cpp:100] Creating Layer res5_2
I0826 15:26:39.413241 25446 net.cpp:434] res5_2 <- pool4_pool4_0_split_1
I0826 15:26:39.413250 25446 net.cpp:434] res5_2 <- conv5_2
I0826 15:26:39.413257 25446 net.cpp:408] res5_2 -> res5_2
I0826 15:26:39.413282 25446 net.cpp:150] Setting up res5_2
I0826 15:26:39.413314 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.413319 25446 net.cpp:165] Memory required for data: 2116731072
I0826 15:26:39.413321 25446 layer_factory.hpp:77] Creating layer res5_2_res5_2_0_split
I0826 15:26:39.413326 25446 net.cpp:100] Creating Layer res5_2_res5_2_0_split
I0826 15:26:39.413329 25446 net.cpp:434] res5_2_res5_2_0_split <- res5_2
I0826 15:26:39.413332 25446 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_0
I0826 15:26:39.413336 25446 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_1
I0826 15:26:39.413393 25446 net.cpp:150] Setting up res5_2_res5_2_0_split
I0826 15:26:39.413410 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.413414 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.413416 25446 net.cpp:165] Memory required for data: 2126168256
I0826 15:26:39.413419 25446 layer_factory.hpp:77] Creating layer conv5_3
I0826 15:26:39.413424 25446 net.cpp:100] Creating Layer conv5_3
I0826 15:26:39.413427 25446 net.cpp:434] conv5_3 <- res5_2_res5_2_0_split_0
I0826 15:26:39.413432 25446 net.cpp:408] conv5_3 -> conv5_3
I0826 15:26:39.431022 25446 net.cpp:150] Setting up conv5_3
I0826 15:26:39.431038 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.431044 25446 net.cpp:165] Memory required for data: 2130886848
I0826 15:26:39.431067 25446 layer_factory.hpp:77] Creating layer relu5_3
I0826 15:26:39.431075 25446 net.cpp:100] Creating Layer relu5_3
I0826 15:26:39.431082 25446 net.cpp:434] relu5_3 <- conv5_3
I0826 15:26:39.431089 25446 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0826 15:26:39.431723 25446 net.cpp:150] Setting up relu5_3
I0826 15:26:39.431730 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.431735 25446 net.cpp:165] Memory required for data: 2135605440
I0826 15:26:39.431738 25446 layer_factory.hpp:77] Creating layer conv5_4
I0826 15:26:39.431747 25446 net.cpp:100] Creating Layer conv5_4
I0826 15:26:39.431751 25446 net.cpp:434] conv5_4 <- conv5_3
I0826 15:26:39.431754 25446 net.cpp:408] conv5_4 -> conv5_4
I0826 15:26:39.448890 25446 net.cpp:150] Setting up conv5_4
I0826 15:26:39.448905 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.448911 25446 net.cpp:165] Memory required for data: 2140324032
I0826 15:26:39.448917 25446 layer_factory.hpp:77] Creating layer relu5_4
I0826 15:26:39.448925 25446 net.cpp:100] Creating Layer relu5_4
I0826 15:26:39.448930 25446 net.cpp:434] relu5_4 <- conv5_4
I0826 15:26:39.448935 25446 net.cpp:395] relu5_4 -> conv5_4 (in-place)
I0826 15:26:39.449071 25446 net.cpp:150] Setting up relu5_4
I0826 15:26:39.449076 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.449079 25446 net.cpp:165] Memory required for data: 2145042624
I0826 15:26:39.449082 25446 layer_factory.hpp:77] Creating layer res5_4
I0826 15:26:39.449088 25446 net.cpp:100] Creating Layer res5_4
I0826 15:26:39.449091 25446 net.cpp:434] res5_4 <- res5_2_res5_2_0_split_1
I0826 15:26:39.449095 25446 net.cpp:434] res5_4 <- conv5_4
I0826 15:26:39.449098 25446 net.cpp:408] res5_4 -> res5_4
I0826 15:26:39.449120 25446 net.cpp:150] Setting up res5_4
I0826 15:26:39.449123 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.449126 25446 net.cpp:165] Memory required for data: 2149761216
I0826 15:26:39.449128 25446 layer_factory.hpp:77] Creating layer res5_4_res5_4_0_split
I0826 15:26:39.449131 25446 net.cpp:100] Creating Layer res5_4_res5_4_0_split
I0826 15:26:39.449134 25446 net.cpp:434] res5_4_res5_4_0_split <- res5_4
I0826 15:26:39.449139 25446 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_0
I0826 15:26:39.449143 25446 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_1
I0826 15:26:39.449193 25446 net.cpp:150] Setting up res5_4_res5_4_0_split
I0826 15:26:39.449198 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.449203 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.449208 25446 net.cpp:165] Memory required for data: 2159198400
I0826 15:26:39.449210 25446 layer_factory.hpp:77] Creating layer conv5_5
I0826 15:26:39.449234 25446 net.cpp:100] Creating Layer conv5_5
I0826 15:26:39.449239 25446 net.cpp:434] conv5_5 <- res5_4_res5_4_0_split_0
I0826 15:26:39.449244 25446 net.cpp:408] conv5_5 -> conv5_5
I0826 15:26:39.466624 25446 net.cpp:150] Setting up conv5_5
I0826 15:26:39.466640 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.466645 25446 net.cpp:165] Memory required for data: 2163916992
I0826 15:26:39.466652 25446 layer_factory.hpp:77] Creating layer relu5_5
I0826 15:26:39.466658 25446 net.cpp:100] Creating Layer relu5_5
I0826 15:26:39.466662 25446 net.cpp:434] relu5_5 <- conv5_5
I0826 15:26:39.466666 25446 net.cpp:395] relu5_5 -> conv5_5 (in-place)
I0826 15:26:39.466835 25446 net.cpp:150] Setting up relu5_5
I0826 15:26:39.466841 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.466859 25446 net.cpp:165] Memory required for data: 2168635584
I0826 15:26:39.466863 25446 layer_factory.hpp:77] Creating layer conv5_6
I0826 15:26:39.466872 25446 net.cpp:100] Creating Layer conv5_6
I0826 15:26:39.466876 25446 net.cpp:434] conv5_6 <- conv5_5
I0826 15:26:39.466879 25446 net.cpp:408] conv5_6 -> conv5_6
I0826 15:26:39.486151 25446 net.cpp:150] Setting up conv5_6
I0826 15:26:39.486166 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.486171 25446 net.cpp:165] Memory required for data: 2173354176
I0826 15:26:39.486178 25446 layer_factory.hpp:77] Creating layer relu5_6
I0826 15:26:39.486186 25446 net.cpp:100] Creating Layer relu5_6
I0826 15:26:39.486189 25446 net.cpp:434] relu5_6 <- conv5_6
I0826 15:26:39.486193 25446 net.cpp:395] relu5_6 -> conv5_6 (in-place)
I0826 15:26:39.486336 25446 net.cpp:150] Setting up relu5_6
I0826 15:26:39.486341 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.486344 25446 net.cpp:165] Memory required for data: 2178072768
I0826 15:26:39.486348 25446 layer_factory.hpp:77] Creating layer res5_6
I0826 15:26:39.486354 25446 net.cpp:100] Creating Layer res5_6
I0826 15:26:39.486357 25446 net.cpp:434] res5_6 <- res5_4_res5_4_0_split_1
I0826 15:26:39.486361 25446 net.cpp:434] res5_6 <- conv5_6
I0826 15:26:39.486363 25446 net.cpp:408] res5_6 -> res5_6
I0826 15:26:39.486387 25446 net.cpp:150] Setting up res5_6
I0826 15:26:39.486390 25446 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0826 15:26:39.486393 25446 net.cpp:165] Memory required for data: 2182791360
I0826 15:26:39.486395 25446 layer_factory.hpp:77] Creating layer fc_5
I0826 15:26:39.486400 25446 net.cpp:100] Creating Layer fc_5
I0826 15:26:39.486402 25446 net.cpp:434] fc_5 <- res5_6
I0826 15:26:39.486407 25446 net.cpp:408] fc_5 -> fc_5
I0826 15:26:39.636106 25446 net.cpp:150] Setting up fc_5
I0826 15:26:39.636124 25446 net.cpp:157] Top shape: 16 512 (8192)
I0826 15:26:39.636128 25446 net.cpp:165] Memory required for data: 2182824128
I0826 15:26:39.636137 25446 layer_factory.hpp:77] Creating layer fc_5_fc_5_0_split
I0826 15:26:39.636143 25446 net.cpp:100] Creating Layer fc_5_fc_5_0_split
I0826 15:26:39.636147 25446 net.cpp:434] fc_5_fc_5_0_split <- fc_5
I0826 15:26:39.636152 25446 net.cpp:408] fc_5_fc_5_0_split -> fc_5_fc_5_0_split_0
I0826 15:26:39.636159 25446 net.cpp:408] fc_5_fc_5_0_split -> fc_5_fc_5_0_split_1
I0826 15:26:39.636199 25446 net.cpp:150] Setting up fc_5_fc_5_0_split
I0826 15:26:39.636204 25446 net.cpp:157] Top shape: 16 512 (8192)
I0826 15:26:39.636209 25446 net.cpp:157] Top shape: 16 512 (8192)
I0826 15:26:39.636212 25446 net.cpp:165] Memory required for data: 2182889664
I0826 15:26:39.636216 25446 layer_factory.hpp:77] Creating layer fc_6
I0826 15:26:39.636224 25446 net.cpp:100] Creating Layer fc_6
I0826 15:26:39.636227 25446 net.cpp:434] fc_6 <- fc_5_fc_5_0_split_0
I0826 15:26:39.636231 25446 net.cpp:408] fc_6 -> fc_6
I0826 15:26:39.657500 25446 net.cpp:150] Setting up fc_6
I0826 15:26:39.657516 25446 net.cpp:157] Top shape: 16 10177 (162832)
I0826 15:26:39.657522 25446 net.cpp:165] Memory required for data: 2183540992
I0826 15:26:39.657531 25446 layer_factory.hpp:77] Creating layer softmax_loss
I0826 15:26:39.657537 25446 net.cpp:100] Creating Layer softmax_loss
I0826 15:26:39.657580 25446 net.cpp:434] softmax_loss <- fc_6
I0826 15:26:39.657586 25446 net.cpp:434] softmax_loss <- label_data_1_split_0
I0826 15:26:39.657598 25446 net.cpp:408] softmax_loss -> softmax_loss
I0826 15:26:39.657609 25446 layer_factory.hpp:77] Creating layer softmax_loss
I0826 15:26:39.658293 25446 net.cpp:150] Setting up softmax_loss
I0826 15:26:39.658300 25446 net.cpp:157] Top shape: (1)
I0826 15:26:39.658303 25446 net.cpp:160]     with loss weight 1
I0826 15:26:39.658318 25446 net.cpp:165] Memory required for data: 2183540996
I0826 15:26:39.658321 25446 layer_factory.hpp:77] Creating layer center_loss
I0826 15:26:39.658326 25446 net.cpp:100] Creating Layer center_loss
I0826 15:26:39.658329 25446 net.cpp:434] center_loss <- fc_5_fc_5_0_split_1
I0826 15:26:39.658332 25446 net.cpp:434] center_loss <- label_data_1_split_1
I0826 15:26:39.658352 25446 net.cpp:408] center_loss -> center_loss
I0826 15:26:39.679679 25446 net.cpp:150] Setting up center_loss
I0826 15:26:39.679695 25446 net.cpp:157] Top shape: (1)
I0826 15:26:39.679700 25446 net.cpp:160]     with loss weight 0.008
I0826 15:26:39.679709 25446 net.cpp:165] Memory required for data: 2183541000
I0826 15:26:39.679718 25446 net.cpp:226] center_loss needs backward computation.
I0826 15:26:39.679728 25446 net.cpp:226] softmax_loss needs backward computation.
I0826 15:26:39.679731 25446 net.cpp:226] fc_6 needs backward computation.
I0826 15:26:39.679734 25446 net.cpp:226] fc_5_fc_5_0_split needs backward computation.
I0826 15:26:39.679738 25446 net.cpp:226] fc_5 needs backward computation.
I0826 15:26:39.679739 25446 net.cpp:226] res5_6 needs backward computation.
I0826 15:26:39.679742 25446 net.cpp:226] relu5_6 needs backward computation.
I0826 15:26:39.679745 25446 net.cpp:226] conv5_6 needs backward computation.
I0826 15:26:39.679749 25446 net.cpp:226] relu5_5 needs backward computation.
I0826 15:26:39.679750 25446 net.cpp:226] conv5_5 needs backward computation.
I0826 15:26:39.679752 25446 net.cpp:226] res5_4_res5_4_0_split needs backward computation.
I0826 15:26:39.679755 25446 net.cpp:226] res5_4 needs backward computation.
I0826 15:26:39.679759 25446 net.cpp:226] relu5_4 needs backward computation.
I0826 15:26:39.679760 25446 net.cpp:226] conv5_4 needs backward computation.
I0826 15:26:39.679764 25446 net.cpp:226] relu5_3 needs backward computation.
I0826 15:26:39.679765 25446 net.cpp:226] conv5_3 needs backward computation.
I0826 15:26:39.679769 25446 net.cpp:226] res5_2_res5_2_0_split needs backward computation.
I0826 15:26:39.679787 25446 net.cpp:226] res5_2 needs backward computation.
I0826 15:26:39.679792 25446 net.cpp:226] relu5_2 needs backward computation.
I0826 15:26:39.679797 25446 net.cpp:226] conv5_2 needs backward computation.
I0826 15:26:39.679801 25446 net.cpp:226] relu5_1 needs backward computation.
I0826 15:26:39.679807 25446 net.cpp:226] conv5_1 needs backward computation.
I0826 15:26:39.679826 25446 net.cpp:226] pool4_pool4_0_split needs backward computation.
I0826 15:26:39.679829 25446 net.cpp:226] pool4 needs backward computation.
I0826 15:26:39.679833 25446 net.cpp:226] relu4 needs backward computation.
I0826 15:26:39.679859 25446 net.cpp:226] conv4 needs backward computation.
I0826 15:26:39.679863 25446 net.cpp:226] res4_10 needs backward computation.
I0826 15:26:39.679868 25446 net.cpp:226] relu4_10 needs backward computation.
I0826 15:26:39.679873 25446 net.cpp:226] conv4_10 needs backward computation.
I0826 15:26:39.679877 25446 net.cpp:226] relu4_9 needs backward computation.
I0826 15:26:39.679879 25446 net.cpp:226] conv4_9 needs backward computation.
I0826 15:26:39.679883 25446 net.cpp:226] res4_8_res4_8_0_split needs backward computation.
I0826 15:26:39.679898 25446 net.cpp:226] res4_8 needs backward computation.
I0826 15:26:39.679903 25446 net.cpp:226] relu4_8 needs backward computation.
I0826 15:26:39.679904 25446 net.cpp:226] conv4_8 needs backward computation.
I0826 15:26:39.679908 25446 net.cpp:226] relu4_7 needs backward computation.
I0826 15:26:39.679909 25446 net.cpp:226] conv4_7 needs backward computation.
I0826 15:26:39.679927 25446 net.cpp:226] res4_6_res4_6_0_split needs backward computation.
I0826 15:26:39.679931 25446 net.cpp:226] res4_6 needs backward computation.
I0826 15:26:39.679936 25446 net.cpp:226] relu4_6 needs backward computation.
I0826 15:26:39.679941 25446 net.cpp:226] conv4_6 needs backward computation.
I0826 15:26:39.679944 25446 net.cpp:226] relu4_5 needs backward computation.
I0826 15:26:39.679946 25446 net.cpp:226] conv4_5 needs backward computation.
I0826 15:26:39.679949 25446 net.cpp:226] res4_4_res4_4_0_split needs backward computation.
I0826 15:26:39.679951 25446 net.cpp:226] res4_4 needs backward computation.
I0826 15:26:39.679953 25446 net.cpp:226] relu4_4 needs backward computation.
I0826 15:26:39.679956 25446 net.cpp:226] conv4_4 needs backward computation.
I0826 15:26:39.679958 25446 net.cpp:226] relu4_3 needs backward computation.
I0826 15:26:39.679960 25446 net.cpp:226] conv4_3 needs backward computation.
I0826 15:26:39.679963 25446 net.cpp:226] res4_2_res4_2_0_split needs backward computation.
I0826 15:26:39.679965 25446 net.cpp:226] res4_2 needs backward computation.
I0826 15:26:39.679971 25446 net.cpp:226] relu4_2 needs backward computation.
I0826 15:26:39.679973 25446 net.cpp:226] conv4_2 needs backward computation.
I0826 15:26:39.679975 25446 net.cpp:226] relu4_1 needs backward computation.
I0826 15:26:39.679978 25446 net.cpp:226] conv4_1 needs backward computation.
I0826 15:26:39.679980 25446 net.cpp:226] pool3_pool3_0_split needs backward computation.
I0826 15:26:39.679983 25446 net.cpp:226] pool3 needs backward computation.
I0826 15:26:39.679986 25446 net.cpp:226] relu3 needs backward computation.
I0826 15:26:39.679988 25446 net.cpp:226] conv3 needs backward computation.
I0826 15:26:39.679991 25446 net.cpp:226] res3_4 needs backward computation.
I0826 15:26:39.679993 25446 net.cpp:226] relu3_4 needs backward computation.
I0826 15:26:39.679996 25446 net.cpp:226] conv3_4 needs backward computation.
I0826 15:26:39.679998 25446 net.cpp:226] relu3_3 needs backward computation.
I0826 15:26:39.680016 25446 net.cpp:226] conv3_3 needs backward computation.
I0826 15:26:39.680023 25446 net.cpp:226] res3_2_res3_2_0_split needs backward computation.
I0826 15:26:39.680027 25446 net.cpp:226] res3_2 needs backward computation.
I0826 15:26:39.680032 25446 net.cpp:226] relu3_2 needs backward computation.
I0826 15:26:39.680037 25446 net.cpp:226] conv3_2 needs backward computation.
I0826 15:26:39.680042 25446 net.cpp:226] relu3_1 needs backward computation.
I0826 15:26:39.680045 25446 net.cpp:226] conv3_1 needs backward computation.
I0826 15:26:39.680048 25446 net.cpp:226] pool2_pool2_0_split needs backward computation.
I0826 15:26:39.680053 25446 net.cpp:226] pool2 needs backward computation.
I0826 15:26:39.680059 25446 net.cpp:226] relu2 needs backward computation.
I0826 15:26:39.680064 25446 net.cpp:226] conv2 needs backward computation.
I0826 15:26:39.680068 25446 net.cpp:226] res2_2 needs backward computation.
I0826 15:26:39.680073 25446 net.cpp:226] relu2_2 needs backward computation.
I0826 15:26:39.680080 25446 net.cpp:226] conv2_2 needs backward computation.
I0826 15:26:39.680083 25446 net.cpp:226] relu2_1 needs backward computation.
I0826 15:26:39.680088 25446 net.cpp:226] conv2_1 needs backward computation.
I0826 15:26:39.680092 25446 net.cpp:226] pool1b_pool1b_0_split needs backward computation.
I0826 15:26:39.680099 25446 net.cpp:226] pool1b needs backward computation.
I0826 15:26:39.680104 25446 net.cpp:226] relu1b needs backward computation.
I0826 15:26:39.680106 25446 net.cpp:226] conv1b needs backward computation.
I0826 15:26:39.680111 25446 net.cpp:226] relu1a needs backward computation.
I0826 15:26:39.680117 25446 net.cpp:226] conv1a needs backward computation.
I0826 15:26:39.680122 25446 net.cpp:228] label_data_1_split does not need backward computation.
I0826 15:26:39.680128 25446 net.cpp:228] data does not need backward computation.
I0826 15:26:39.680133 25446 net.cpp:270] This network produces output center_loss
I0826 15:26:39.680138 25446 net.cpp:270] This network produces output softmax_loss
I0826 15:26:39.680181 25446 net.cpp:283] Network initialization done.
I0826 15:26:39.680299 25446 solver.cpp:75] Solver scaffolding done.
I0826 15:26:39.683463 25446 caffe.cpp:155] Finetuning from /media/ly/data/caffe-face/face_example/face_model.caffemodel
I0826 15:26:39.751595 25446 net.cpp:761] Ignoring source layer input
I0826 15:26:39.764125 25446 net.cpp:761] Ignoring source layer fc5
I0826 15:26:39.766311 25446 caffe.cpp:251] Starting Optimization
I0826 15:26:39.766321 25446 solver.cpp:294] Solving Face-ResNet
I0826 15:26:39.766324 25446 solver.cpp:295] Learning Rate Policy: multistep
I0826 15:26:40.054852 25446 solver.cpp:243] Iteration 0, loss = 11.0922
I0826 15:26:40.054878 25446 solver.cpp:259]     Train net output #0: center_loss = 164.549 (* 0.008 = 1.31639 loss)
I0826 15:26:40.054885 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.77582 (* 1 = 9.77582 loss)
I0826 15:26:40.054898 25446 sgd_solver.cpp:138] Iteration 0, lr = 0.001
I0826 15:26:41.955703 25446 solver.cpp:243] Iteration 10, loss = 9.32073
I0826 15:26:41.955739 25446 solver.cpp:259]     Train net output #0: center_loss = 19.2523 (* 0.008 = 0.154018 loss)
I0826 15:26:41.955745 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16671 (* 1 = 9.16671 loss)
I0826 15:26:41.955749 25446 sgd_solver.cpp:138] Iteration 10, lr = 0.001
I0826 15:26:43.980556 25446 solver.cpp:243] Iteration 20, loss = 9.36109
I0826 15:26:43.980593 25446 solver.cpp:259]     Train net output #0: center_loss = 18.3937 (* 0.008 = 0.147149 loss)
I0826 15:26:43.980599 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21395 (* 1 = 9.21395 loss)
I0826 15:26:43.980603 25446 sgd_solver.cpp:138] Iteration 20, lr = 0.001
I0826 15:26:46.010161 25446 solver.cpp:243] Iteration 30, loss = 9.43828
I0826 15:26:46.010198 25446 solver.cpp:259]     Train net output #0: center_loss = 18.2452 (* 0.008 = 0.145962 loss)
I0826 15:26:46.010205 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.29232 (* 1 = 9.29232 loss)
I0826 15:26:46.010207 25446 sgd_solver.cpp:138] Iteration 30, lr = 0.001
I0826 15:26:48.044106 25446 solver.cpp:243] Iteration 40, loss = 9.36748
I0826 15:26:48.044127 25446 solver.cpp:259]     Train net output #0: center_loss = 11.1993 (* 0.008 = 0.0895942 loss)
I0826 15:26:48.044148 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.27788 (* 1 = 9.27788 loss)
I0826 15:26:48.044152 25446 sgd_solver.cpp:138] Iteration 40, lr = 0.001
I0826 15:26:50.078200 25446 solver.cpp:243] Iteration 50, loss = 9.31298
I0826 15:26:50.078238 25446 solver.cpp:259]     Train net output #0: center_loss = 8.68454 (* 0.008 = 0.0694763 loss)
I0826 15:26:50.078243 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2435 (* 1 = 9.2435 loss)
I0826 15:26:50.078246 25446 sgd_solver.cpp:138] Iteration 50, lr = 0.001
I0826 15:26:52.120259 25446 solver.cpp:243] Iteration 60, loss = 9.29452
I0826 15:26:52.120295 25446 solver.cpp:259]     Train net output #0: center_loss = 8.26152 (* 0.008 = 0.0660922 loss)
I0826 15:26:52.120301 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22843 (* 1 = 9.22843 loss)
I0826 15:26:52.120303 25446 sgd_solver.cpp:138] Iteration 60, lr = 0.001
I0826 15:26:54.234117 25446 solver.cpp:243] Iteration 70, loss = 9.32493
I0826 15:26:54.234153 25446 solver.cpp:259]     Train net output #0: center_loss = 7.21615 (* 0.008 = 0.0577292 loss)
I0826 15:26:54.234159 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2672 (* 1 = 9.2672 loss)
I0826 15:26:54.234163 25446 sgd_solver.cpp:138] Iteration 70, lr = 0.001
I0826 15:26:56.336496 25446 solver.cpp:243] Iteration 80, loss = 9.26507
I0826 15:26:56.336534 25446 solver.cpp:259]     Train net output #0: center_loss = 6.04555 (* 0.008 = 0.0483644 loss)
I0826 15:26:56.336539 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2167 (* 1 = 9.2167 loss)
I0826 15:26:56.336541 25446 sgd_solver.cpp:138] Iteration 80, lr = 0.001
I0826 15:26:58.520948 25446 solver.cpp:243] Iteration 90, loss = 9.27495
I0826 15:26:58.520994 25446 solver.cpp:259]     Train net output #0: center_loss = 5.13651 (* 0.008 = 0.0410921 loss)
I0826 15:26:58.521001 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23385 (* 1 = 9.23385 loss)
I0826 15:26:58.521005 25446 sgd_solver.cpp:138] Iteration 90, lr = 0.001
I0826 15:27:00.588598 25446 solver.cpp:243] Iteration 100, loss = 9.32909
I0826 15:27:00.588621 25446 solver.cpp:259]     Train net output #0: center_loss = 5.0269 (* 0.008 = 0.0402152 loss)
I0826 15:27:00.588626 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.28888 (* 1 = 9.28888 loss)
I0826 15:27:00.588631 25446 sgd_solver.cpp:138] Iteration 100, lr = 0.001
I0826 15:27:02.703830 25446 solver.cpp:243] Iteration 110, loss = 9.33427
I0826 15:27:02.703860 25446 solver.cpp:259]     Train net output #0: center_loss = 4.57057 (* 0.008 = 0.0365645 loss)
I0826 15:27:02.703868 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.29771 (* 1 = 9.29771 loss)
I0826 15:27:02.703876 25446 sgd_solver.cpp:138] Iteration 110, lr = 0.001
I0826 15:27:04.806097 25446 solver.cpp:243] Iteration 120, loss = 9.29712
I0826 15:27:04.806120 25446 solver.cpp:259]     Train net output #0: center_loss = 4.82599 (* 0.008 = 0.0386079 loss)
I0826 15:27:04.806126 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.25852 (* 1 = 9.25852 loss)
I0826 15:27:04.806130 25446 sgd_solver.cpp:138] Iteration 120, lr = 0.001
I0826 15:27:06.885810 25446 solver.cpp:243] Iteration 130, loss = 9.25663
I0826 15:27:06.885848 25446 solver.cpp:259]     Train net output #0: center_loss = 3.97591 (* 0.008 = 0.0318072 loss)
I0826 15:27:06.885854 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22482 (* 1 = 9.22482 loss)
I0826 15:27:06.885859 25446 sgd_solver.cpp:138] Iteration 130, lr = 0.001
I0826 15:27:08.993057 25446 solver.cpp:243] Iteration 140, loss = 9.23497
I0826 15:27:08.993149 25446 solver.cpp:259]     Train net output #0: center_loss = 4.08649 (* 0.008 = 0.0326919 loss)
I0826 15:27:08.993155 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20228 (* 1 = 9.20228 loss)
I0826 15:27:08.993160 25446 sgd_solver.cpp:138] Iteration 140, lr = 0.001
I0826 15:27:11.115192 25446 solver.cpp:243] Iteration 150, loss = 9.27872
I0826 15:27:11.115231 25446 solver.cpp:259]     Train net output #0: center_loss = 3.56069 (* 0.008 = 0.0284855 loss)
I0826 15:27:11.115237 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.25024 (* 1 = 9.25024 loss)
I0826 15:27:11.115242 25446 sgd_solver.cpp:138] Iteration 150, lr = 0.001
I0826 15:27:13.177947 25446 solver.cpp:243] Iteration 160, loss = 9.17425
I0826 15:27:13.177984 25446 solver.cpp:259]     Train net output #0: center_loss = 4.24483 (* 0.008 = 0.0339587 loss)
I0826 15:27:13.177989 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1403 (* 1 = 9.1403 loss)
I0826 15:27:13.177994 25446 sgd_solver.cpp:138] Iteration 160, lr = 0.001
I0826 15:27:15.216532 25446 solver.cpp:243] Iteration 170, loss = 9.25889
I0826 15:27:15.216569 25446 solver.cpp:259]     Train net output #0: center_loss = 4.01141 (* 0.008 = 0.0320912 loss)
I0826 15:27:15.216574 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2268 (* 1 = 9.2268 loss)
I0826 15:27:15.216578 25446 sgd_solver.cpp:138] Iteration 170, lr = 0.001
I0826 15:27:17.268836 25446 solver.cpp:243] Iteration 180, loss = 9.23602
I0826 15:27:17.268862 25446 solver.cpp:259]     Train net output #0: center_loss = 3.60112 (* 0.008 = 0.028809 loss)
I0826 15:27:17.268867 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20721 (* 1 = 9.20721 loss)
I0826 15:27:17.268872 25446 sgd_solver.cpp:138] Iteration 180, lr = 0.001
I0826 15:27:19.306457 25446 solver.cpp:243] Iteration 190, loss = 9.29667
I0826 15:27:19.306494 25446 solver.cpp:259]     Train net output #0: center_loss = 3.20689 (* 0.008 = 0.0256551 loss)
I0826 15:27:19.306500 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.27102 (* 1 = 9.27102 loss)
I0826 15:27:19.306504 25446 sgd_solver.cpp:138] Iteration 190, lr = 0.001
I0826 15:27:21.347424 25446 solver.cpp:243] Iteration 200, loss = 9.29176
I0826 15:27:21.347447 25446 solver.cpp:259]     Train net output #0: center_loss = 2.66825 (* 0.008 = 0.021346 loss)
I0826 15:27:21.347467 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.27041 (* 1 = 9.27041 loss)
I0826 15:27:21.347471 25446 sgd_solver.cpp:138] Iteration 200, lr = 0.001
I0826 15:27:23.385581 25446 solver.cpp:243] Iteration 210, loss = 9.26378
I0826 15:27:23.385618 25446 solver.cpp:259]     Train net output #0: center_loss = 3.39465 (* 0.008 = 0.0271572 loss)
I0826 15:27:23.385624 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23663 (* 1 = 9.23663 loss)
I0826 15:27:23.385627 25446 sgd_solver.cpp:138] Iteration 210, lr = 0.001
I0826 15:27:25.424818 25446 solver.cpp:243] Iteration 220, loss = 9.21692
I0826 15:27:25.424855 25446 solver.cpp:259]     Train net output #0: center_loss = 2.86754 (* 0.008 = 0.0229403 loss)
I0826 15:27:25.424860 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19397 (* 1 = 9.19397 loss)
I0826 15:27:25.424863 25446 sgd_solver.cpp:138] Iteration 220, lr = 0.001
I0826 15:27:27.461851 25446 solver.cpp:243] Iteration 230, loss = 9.24168
I0826 15:27:27.461874 25446 solver.cpp:259]     Train net output #0: center_loss = 2.70246 (* 0.008 = 0.0216196 loss)
I0826 15:27:27.461894 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22006 (* 1 = 9.22006 loss)
I0826 15:27:27.461899 25446 sgd_solver.cpp:138] Iteration 230, lr = 0.001
I0826 15:27:29.502007 25446 solver.cpp:243] Iteration 240, loss = 9.24426
I0826 15:27:29.502028 25446 solver.cpp:259]     Train net output #0: center_loss = 2.53769 (* 0.008 = 0.0203015 loss)
I0826 15:27:29.502033 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22396 (* 1 = 9.22396 loss)
I0826 15:27:29.502038 25446 sgd_solver.cpp:138] Iteration 240, lr = 0.001
I0826 15:27:31.543737 25446 solver.cpp:243] Iteration 250, loss = 9.22246
I0826 15:27:31.543798 25446 solver.cpp:259]     Train net output #0: center_loss = 2.55866 (* 0.008 = 0.0204693 loss)
I0826 15:27:31.543819 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20199 (* 1 = 9.20199 loss)
I0826 15:27:31.543823 25446 sgd_solver.cpp:138] Iteration 250, lr = 0.001
I0826 15:27:33.583827 25446 solver.cpp:243] Iteration 260, loss = 9.26191
I0826 15:27:33.583864 25446 solver.cpp:259]     Train net output #0: center_loss = 2.45203 (* 0.008 = 0.0196162 loss)
I0826 15:27:33.583869 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24229 (* 1 = 9.24229 loss)
I0826 15:27:33.583873 25446 sgd_solver.cpp:138] Iteration 260, lr = 0.001
I0826 15:27:35.623255 25446 solver.cpp:243] Iteration 270, loss = 9.26588
I0826 15:27:35.623292 25446 solver.cpp:259]     Train net output #0: center_loss = 2.46425 (* 0.008 = 0.019714 loss)
I0826 15:27:35.623297 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24616 (* 1 = 9.24616 loss)
I0826 15:27:35.623301 25446 sgd_solver.cpp:138] Iteration 270, lr = 0.001
I0826 15:27:37.664638 25446 solver.cpp:243] Iteration 280, loss = 9.25434
I0826 15:27:37.664677 25446 solver.cpp:259]     Train net output #0: center_loss = 2.50331 (* 0.008 = 0.0200265 loss)
I0826 15:27:37.664682 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23432 (* 1 = 9.23432 loss)
I0826 15:27:37.664686 25446 sgd_solver.cpp:138] Iteration 280, lr = 0.001
I0826 15:27:39.707104 25446 solver.cpp:243] Iteration 290, loss = 9.24857
I0826 15:27:39.707217 25446 solver.cpp:259]     Train net output #0: center_loss = 2.53229 (* 0.008 = 0.0202583 loss)
I0826 15:27:39.707223 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22832 (* 1 = 9.22832 loss)
I0826 15:27:39.707240 25446 sgd_solver.cpp:138] Iteration 290, lr = 0.001
I0826 15:27:41.749200 25446 solver.cpp:243] Iteration 300, loss = 9.23632
I0826 15:27:41.749238 25446 solver.cpp:259]     Train net output #0: center_loss = 2.67885 (* 0.008 = 0.0214308 loss)
I0826 15:27:41.749243 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21489 (* 1 = 9.21489 loss)
I0826 15:27:41.749250 25446 sgd_solver.cpp:138] Iteration 300, lr = 0.001
I0826 15:27:43.794355 25446 solver.cpp:243] Iteration 310, loss = 9.23856
I0826 15:27:43.794392 25446 solver.cpp:259]     Train net output #0: center_loss = 2.17072 (* 0.008 = 0.0173657 loss)
I0826 15:27:43.794399 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22119 (* 1 = 9.22119 loss)
I0826 15:27:43.794401 25446 sgd_solver.cpp:138] Iteration 310, lr = 0.001
I0826 15:27:45.835716 25446 solver.cpp:243] Iteration 320, loss = 9.27777
I0826 15:27:45.835753 25446 solver.cpp:259]     Train net output #0: center_loss = 2.20867 (* 0.008 = 0.0176693 loss)
I0826 15:27:45.835758 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2601 (* 1 = 9.2601 loss)
I0826 15:27:45.835762 25446 sgd_solver.cpp:138] Iteration 320, lr = 0.001
I0826 15:27:47.878811 25446 solver.cpp:243] Iteration 330, loss = 9.26059
I0826 15:27:47.878849 25446 solver.cpp:259]     Train net output #0: center_loss = 2.40577 (* 0.008 = 0.0192462 loss)
I0826 15:27:47.878854 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24134 (* 1 = 9.24134 loss)
I0826 15:27:47.878857 25446 sgd_solver.cpp:138] Iteration 330, lr = 0.001
I0826 15:27:49.923214 25446 solver.cpp:243] Iteration 340, loss = 9.21641
I0826 15:27:49.923252 25446 solver.cpp:259]     Train net output #0: center_loss = 2.16487 (* 0.008 = 0.0173189 loss)
I0826 15:27:49.923257 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19909 (* 1 = 9.19909 loss)
I0826 15:27:49.923261 25446 sgd_solver.cpp:138] Iteration 340, lr = 0.001
I0826 15:27:51.966967 25446 solver.cpp:243] Iteration 350, loss = 9.24238
I0826 15:27:51.967005 25446 solver.cpp:259]     Train net output #0: center_loss = 2.08085 (* 0.008 = 0.0166468 loss)
I0826 15:27:51.967010 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22574 (* 1 = 9.22574 loss)
I0826 15:27:51.967013 25446 sgd_solver.cpp:138] Iteration 350, lr = 0.001
I0826 15:27:54.009433 25446 solver.cpp:243] Iteration 360, loss = 9.23829
I0826 15:27:54.009469 25446 solver.cpp:259]     Train net output #0: center_loss = 2.12667 (* 0.008 = 0.0170134 loss)
I0826 15:27:54.009474 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22128 (* 1 = 9.22128 loss)
I0826 15:27:54.009476 25446 sgd_solver.cpp:138] Iteration 360, lr = 0.001
I0826 15:27:56.052682 25446 solver.cpp:243] Iteration 370, loss = 9.2452
I0826 15:27:56.052719 25446 solver.cpp:259]     Train net output #0: center_loss = 2.12523 (* 0.008 = 0.0170018 loss)
I0826 15:27:56.052724 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22819 (* 1 = 9.22819 loss)
I0826 15:27:56.052727 25446 sgd_solver.cpp:138] Iteration 370, lr = 0.001
I0826 15:27:58.095943 25446 solver.cpp:243] Iteration 380, loss = 9.22451
I0826 15:27:58.095981 25446 solver.cpp:259]     Train net output #0: center_loss = 2.12224 (* 0.008 = 0.0169779 loss)
I0826 15:27:58.095986 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20754 (* 1 = 9.20754 loss)
I0826 15:27:58.095989 25446 sgd_solver.cpp:138] Iteration 380, lr = 0.001
I0826 15:28:00.143409 25446 solver.cpp:243] Iteration 390, loss = 9.23185
I0826 15:28:00.143446 25446 solver.cpp:259]     Train net output #0: center_loss = 2.21186 (* 0.008 = 0.0176949 loss)
I0826 15:28:00.143451 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21415 (* 1 = 9.21415 loss)
I0826 15:28:00.143455 25446 sgd_solver.cpp:138] Iteration 390, lr = 0.001
I0826 15:28:02.191777 25446 solver.cpp:243] Iteration 400, loss = 9.26713
I0826 15:28:02.191834 25446 solver.cpp:259]     Train net output #0: center_loss = 2.53759 (* 0.008 = 0.0203007 loss)
I0826 15:28:02.191840 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24683 (* 1 = 9.24683 loss)
I0826 15:28:02.191859 25446 sgd_solver.cpp:138] Iteration 400, lr = 0.001
I0826 15:28:04.240561 25446 solver.cpp:243] Iteration 410, loss = 9.22208
I0826 15:28:04.240598 25446 solver.cpp:259]     Train net output #0: center_loss = 2.1004 (* 0.008 = 0.0168032 loss)
I0826 15:28:04.240603 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20528 (* 1 = 9.20528 loss)
I0826 15:28:04.240607 25446 sgd_solver.cpp:138] Iteration 410, lr = 0.001
I0826 15:28:06.288094 25446 solver.cpp:243] Iteration 420, loss = 9.22628
I0826 15:28:06.288130 25446 solver.cpp:259]     Train net output #0: center_loss = 1.95269 (* 0.008 = 0.0156215 loss)
I0826 15:28:06.288136 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21065 (* 1 = 9.21065 loss)
I0826 15:28:06.288139 25446 sgd_solver.cpp:138] Iteration 420, lr = 0.001
I0826 15:28:08.338268 25446 solver.cpp:243] Iteration 430, loss = 9.2619
I0826 15:28:08.338305 25446 solver.cpp:259]     Train net output #0: center_loss = 2.1334 (* 0.008 = 0.0170672 loss)
I0826 15:28:08.338310 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24483 (* 1 = 9.24483 loss)
I0826 15:28:08.338315 25446 sgd_solver.cpp:138] Iteration 430, lr = 0.001
I0826 15:28:10.390177 25446 solver.cpp:243] Iteration 440, loss = 9.21433
I0826 15:28:10.390336 25446 solver.cpp:259]     Train net output #0: center_loss = 2.32843 (* 0.008 = 0.0186275 loss)
I0826 15:28:10.390342 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1957 (* 1 = 9.1957 loss)
I0826 15:28:10.390359 25446 sgd_solver.cpp:138] Iteration 440, lr = 0.001
I0826 15:28:12.441866 25446 solver.cpp:243] Iteration 450, loss = 9.22117
I0826 15:28:12.441905 25446 solver.cpp:259]     Train net output #0: center_loss = 2.17037 (* 0.008 = 0.017363 loss)
I0826 15:28:12.441910 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20381 (* 1 = 9.20381 loss)
I0826 15:28:12.441912 25446 sgd_solver.cpp:138] Iteration 450, lr = 0.001
I0826 15:28:14.489586 25446 solver.cpp:243] Iteration 460, loss = 9.22518
I0826 15:28:14.489624 25446 solver.cpp:259]     Train net output #0: center_loss = 2.15357 (* 0.008 = 0.0172285 loss)
I0826 15:28:14.489629 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20795 (* 1 = 9.20795 loss)
I0826 15:28:14.489632 25446 sgd_solver.cpp:138] Iteration 460, lr = 0.001
I0826 15:28:16.541036 25446 solver.cpp:243] Iteration 470, loss = 9.23823
I0826 15:28:16.541074 25446 solver.cpp:259]     Train net output #0: center_loss = 1.98466 (* 0.008 = 0.0158773 loss)
I0826 15:28:16.541079 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22235 (* 1 = 9.22235 loss)
I0826 15:28:16.541082 25446 sgd_solver.cpp:138] Iteration 470, lr = 0.001
I0826 15:28:18.590165 25446 solver.cpp:243] Iteration 480, loss = 9.2329
I0826 15:28:18.590201 25446 solver.cpp:259]     Train net output #0: center_loss = 1.86923 (* 0.008 = 0.0149538 loss)
I0826 15:28:18.590207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21795 (* 1 = 9.21795 loss)
I0826 15:28:18.590210 25446 sgd_solver.cpp:138] Iteration 480, lr = 0.001
I0826 15:28:20.643507 25446 solver.cpp:243] Iteration 490, loss = 9.2683
I0826 15:28:20.643544 25446 solver.cpp:259]     Train net output #0: center_loss = 1.94221 (* 0.008 = 0.0155377 loss)
I0826 15:28:20.643549 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.25276 (* 1 = 9.25276 loss)
I0826 15:28:20.643553 25446 sgd_solver.cpp:138] Iteration 490, lr = 0.001
I0826 15:28:22.694386 25446 solver.cpp:243] Iteration 500, loss = 9.22213
I0826 15:28:22.694423 25446 solver.cpp:259]     Train net output #0: center_loss = 2.02644 (* 0.008 = 0.0162115 loss)
I0826 15:28:22.694429 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20592 (* 1 = 9.20592 loss)
I0826 15:28:22.694432 25446 sgd_solver.cpp:138] Iteration 500, lr = 0.001
I0826 15:28:24.746165 25446 solver.cpp:243] Iteration 510, loss = 9.21082
I0826 15:28:24.746186 25446 solver.cpp:259]     Train net output #0: center_loss = 2.11018 (* 0.008 = 0.0168815 loss)
I0826 15:28:24.746206 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19394 (* 1 = 9.19394 loss)
I0826 15:28:24.746210 25446 sgd_solver.cpp:138] Iteration 510, lr = 0.001
I0826 15:28:26.800112 25446 solver.cpp:243] Iteration 520, loss = 9.22549
I0826 15:28:26.800150 25446 solver.cpp:259]     Train net output #0: center_loss = 2.05821 (* 0.008 = 0.0164657 loss)
I0826 15:28:26.800155 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20902 (* 1 = 9.20902 loss)
I0826 15:28:26.800158 25446 sgd_solver.cpp:138] Iteration 520, lr = 0.001
I0826 15:28:28.855720 25446 solver.cpp:243] Iteration 530, loss = 9.22803
I0826 15:28:28.855741 25446 solver.cpp:259]     Train net output #0: center_loss = 2.05523 (* 0.008 = 0.0164418 loss)
I0826 15:28:28.855762 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21159 (* 1 = 9.21159 loss)
I0826 15:28:28.855765 25446 sgd_solver.cpp:138] Iteration 530, lr = 0.001
I0826 15:28:30.908852 25446 solver.cpp:243] Iteration 540, loss = 9.24802
I0826 15:28:30.908890 25446 solver.cpp:259]     Train net output #0: center_loss = 1.93319 (* 0.008 = 0.0154655 loss)
I0826 15:28:30.908895 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23256 (* 1 = 9.23256 loss)
I0826 15:28:30.908898 25446 sgd_solver.cpp:138] Iteration 540, lr = 0.001
I0826 15:28:32.955621 25446 solver.cpp:243] Iteration 550, loss = 9.24596
I0826 15:28:32.955680 25446 solver.cpp:259]     Train net output #0: center_loss = 1.86671 (* 0.008 = 0.0149337 loss)
I0826 15:28:32.955701 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23103 (* 1 = 9.23103 loss)
I0826 15:28:32.955704 25446 sgd_solver.cpp:138] Iteration 550, lr = 0.001
I0826 15:28:35.008225 25446 solver.cpp:243] Iteration 560, loss = 9.21803
I0826 15:28:35.008261 25446 solver.cpp:259]     Train net output #0: center_loss = 1.89941 (* 0.008 = 0.0151953 loss)
I0826 15:28:35.008266 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20283 (* 1 = 9.20283 loss)
I0826 15:28:35.008270 25446 sgd_solver.cpp:138] Iteration 560, lr = 0.001
I0826 15:28:37.063653 25446 solver.cpp:243] Iteration 570, loss = 9.25105
I0826 15:28:37.063690 25446 solver.cpp:259]     Train net output #0: center_loss = 1.88171 (* 0.008 = 0.0150537 loss)
I0826 15:28:37.063696 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23599 (* 1 = 9.23599 loss)
I0826 15:28:37.063699 25446 sgd_solver.cpp:138] Iteration 570, lr = 0.001
I0826 15:28:39.113914 25446 solver.cpp:243] Iteration 580, loss = 9.23699
I0826 15:28:39.113951 25446 solver.cpp:259]     Train net output #0: center_loss = 2.02515 (* 0.008 = 0.0162012 loss)
I0826 15:28:39.113956 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22079 (* 1 = 9.22079 loss)
I0826 15:28:39.113960 25446 sgd_solver.cpp:138] Iteration 580, lr = 0.001
I0826 15:28:41.164767 25446 solver.cpp:243] Iteration 590, loss = 9.22945
I0826 15:28:41.164885 25446 solver.cpp:259]     Train net output #0: center_loss = 1.97586 (* 0.008 = 0.0158069 loss)
I0826 15:28:41.164891 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21365 (* 1 = 9.21365 loss)
I0826 15:28:41.164894 25446 sgd_solver.cpp:138] Iteration 590, lr = 0.001
I0826 15:28:43.216209 25446 solver.cpp:243] Iteration 600, loss = 9.22956
I0826 15:28:43.216245 25446 solver.cpp:259]     Train net output #0: center_loss = 1.9572 (* 0.008 = 0.0156576 loss)
I0826 15:28:43.216250 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2139 (* 1 = 9.2139 loss)
I0826 15:28:43.216254 25446 sgd_solver.cpp:138] Iteration 600, lr = 0.001
I0826 15:28:45.268935 25446 solver.cpp:243] Iteration 610, loss = 9.22464
I0826 15:28:45.268972 25446 solver.cpp:259]     Train net output #0: center_loss = 1.91232 (* 0.008 = 0.0152986 loss)
I0826 15:28:45.268977 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20934 (* 1 = 9.20934 loss)
I0826 15:28:45.268981 25446 sgd_solver.cpp:138] Iteration 610, lr = 0.001
I0826 15:28:47.323863 25446 solver.cpp:243] Iteration 620, loss = 9.24192
I0826 15:28:47.323884 25446 solver.cpp:259]     Train net output #0: center_loss = 2.019 (* 0.008 = 0.016152 loss)
I0826 15:28:47.323904 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22577 (* 1 = 9.22577 loss)
I0826 15:28:47.323907 25446 sgd_solver.cpp:138] Iteration 620, lr = 0.001
I0826 15:28:49.375002 25446 solver.cpp:243] Iteration 630, loss = 9.25843
I0826 15:28:49.375041 25446 solver.cpp:259]     Train net output #0: center_loss = 1.88698 (* 0.008 = 0.0150959 loss)
I0826 15:28:49.375046 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24334 (* 1 = 9.24334 loss)
I0826 15:28:49.375048 25446 sgd_solver.cpp:138] Iteration 630, lr = 0.001
I0826 15:28:51.430047 25446 solver.cpp:243] Iteration 640, loss = 9.25472
I0826 15:28:51.430084 25446 solver.cpp:259]     Train net output #0: center_loss = 1.83292 (* 0.008 = 0.0146633 loss)
I0826 15:28:51.430089 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24006 (* 1 = 9.24006 loss)
I0826 15:28:51.430092 25446 sgd_solver.cpp:138] Iteration 640, lr = 0.001
I0826 15:28:53.478585 25446 solver.cpp:243] Iteration 650, loss = 9.23512
I0826 15:28:53.478622 25446 solver.cpp:259]     Train net output #0: center_loss = 1.82947 (* 0.008 = 0.0146357 loss)
I0826 15:28:53.478627 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22048 (* 1 = 9.22048 loss)
I0826 15:28:53.478631 25446 sgd_solver.cpp:138] Iteration 650, lr = 0.001
I0826 15:28:55.530880 25446 solver.cpp:243] Iteration 660, loss = 9.22093
I0826 15:28:55.530916 25446 solver.cpp:259]     Train net output #0: center_loss = 1.85438 (* 0.008 = 0.014835 loss)
I0826 15:28:55.530921 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2061 (* 1 = 9.2061 loss)
I0826 15:28:55.530925 25446 sgd_solver.cpp:138] Iteration 660, lr = 0.001
I0826 15:28:57.582561 25446 solver.cpp:243] Iteration 670, loss = 9.28157
I0826 15:28:57.582599 25446 solver.cpp:259]     Train net output #0: center_loss = 1.787 (* 0.008 = 0.014296 loss)
I0826 15:28:57.582604 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.26727 (* 1 = 9.26727 loss)
I0826 15:28:57.582607 25446 sgd_solver.cpp:138] Iteration 670, lr = 0.001
I0826 15:28:59.637145 25446 solver.cpp:243] Iteration 680, loss = 9.23194
I0826 15:28:59.637183 25446 solver.cpp:259]     Train net output #0: center_loss = 1.85175 (* 0.008 = 0.014814 loss)
I0826 15:28:59.637188 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21713 (* 1 = 9.21713 loss)
I0826 15:28:59.637192 25446 sgd_solver.cpp:138] Iteration 680, lr = 0.001
I0826 15:29:01.694104 25446 solver.cpp:243] Iteration 690, loss = 9.24456
I0826 15:29:01.694144 25446 solver.cpp:259]     Train net output #0: center_loss = 1.92045 (* 0.008 = 0.0153636 loss)
I0826 15:29:01.694149 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22919 (* 1 = 9.22919 loss)
I0826 15:29:01.694151 25446 sgd_solver.cpp:138] Iteration 690, lr = 0.001
I0826 15:29:03.744714 25446 solver.cpp:243] Iteration 700, loss = 9.25434
I0826 15:29:03.744773 25446 solver.cpp:259]     Train net output #0: center_loss = 1.76783 (* 0.008 = 0.0141427 loss)
I0826 15:29:03.744794 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2402 (* 1 = 9.2402 loss)
I0826 15:29:03.744797 25446 sgd_solver.cpp:138] Iteration 700, lr = 0.001
I0826 15:29:05.796123 25446 solver.cpp:243] Iteration 710, loss = 9.26399
I0826 15:29:05.796161 25446 solver.cpp:259]     Train net output #0: center_loss = 1.96514 (* 0.008 = 0.0157211 loss)
I0826 15:29:05.796166 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24826 (* 1 = 9.24826 loss)
I0826 15:29:05.796170 25446 sgd_solver.cpp:138] Iteration 710, lr = 0.001
I0826 15:29:07.848587 25446 solver.cpp:243] Iteration 720, loss = 9.21653
I0826 15:29:07.848623 25446 solver.cpp:259]     Train net output #0: center_loss = 1.94635 (* 0.008 = 0.0155708 loss)
I0826 15:29:07.848628 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20095 (* 1 = 9.20095 loss)
I0826 15:29:07.848631 25446 sgd_solver.cpp:138] Iteration 720, lr = 0.001
I0826 15:29:09.902851 25446 solver.cpp:243] Iteration 730, loss = 9.19946
I0826 15:29:09.902874 25446 solver.cpp:259]     Train net output #0: center_loss = 1.92739 (* 0.008 = 0.0154191 loss)
I0826 15:29:09.902894 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18404 (* 1 = 9.18404 loss)
I0826 15:29:09.902897 25446 sgd_solver.cpp:138] Iteration 730, lr = 0.001
I0826 15:29:11.952013 25446 solver.cpp:243] Iteration 740, loss = 9.24766
I0826 15:29:11.952122 25446 solver.cpp:259]     Train net output #0: center_loss = 1.80606 (* 0.008 = 0.0144485 loss)
I0826 15:29:11.952129 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23321 (* 1 = 9.23321 loss)
I0826 15:29:11.952132 25446 sgd_solver.cpp:138] Iteration 740, lr = 0.001
I0826 15:29:14.006717 25446 solver.cpp:243] Iteration 750, loss = 9.24521
I0826 15:29:14.006754 25446 solver.cpp:259]     Train net output #0: center_loss = 1.87509 (* 0.008 = 0.0150007 loss)
I0826 15:29:14.006760 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23021 (* 1 = 9.23021 loss)
I0826 15:29:14.006763 25446 sgd_solver.cpp:138] Iteration 750, lr = 0.001
I0826 15:29:16.059293 25446 solver.cpp:243] Iteration 760, loss = 9.22014
I0826 15:29:16.059330 25446 solver.cpp:259]     Train net output #0: center_loss = 1.68805 (* 0.008 = 0.0135044 loss)
I0826 15:29:16.059336 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20664 (* 1 = 9.20664 loss)
I0826 15:29:16.059340 25446 sgd_solver.cpp:138] Iteration 760, lr = 0.001
I0826 15:29:18.115427 25446 solver.cpp:243] Iteration 770, loss = 9.22949
I0826 15:29:18.115465 25446 solver.cpp:259]     Train net output #0: center_loss = 2.05002 (* 0.008 = 0.0164002 loss)
I0826 15:29:18.115470 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21309 (* 1 = 9.21309 loss)
I0826 15:29:18.115473 25446 sgd_solver.cpp:138] Iteration 770, lr = 0.001
I0826 15:29:20.171039 25446 solver.cpp:243] Iteration 780, loss = 9.23268
I0826 15:29:20.171077 25446 solver.cpp:259]     Train net output #0: center_loss = 1.8738 (* 0.008 = 0.0149904 loss)
I0826 15:29:20.171082 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21769 (* 1 = 9.21769 loss)
I0826 15:29:20.171085 25446 sgd_solver.cpp:138] Iteration 780, lr = 0.001
I0826 15:29:22.226722 25446 solver.cpp:243] Iteration 790, loss = 9.22731
I0826 15:29:22.226758 25446 solver.cpp:259]     Train net output #0: center_loss = 1.68575 (* 0.008 = 0.013486 loss)
I0826 15:29:22.226764 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21383 (* 1 = 9.21383 loss)
I0826 15:29:22.226768 25446 sgd_solver.cpp:138] Iteration 790, lr = 0.001
I0826 15:29:24.281165 25446 solver.cpp:243] Iteration 800, loss = 9.19792
I0826 15:29:24.281203 25446 solver.cpp:259]     Train net output #0: center_loss = 1.67917 (* 0.008 = 0.0134334 loss)
I0826 15:29:24.281208 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18449 (* 1 = 9.18449 loss)
I0826 15:29:24.281211 25446 sgd_solver.cpp:138] Iteration 800, lr = 0.001
I0826 15:29:26.332620 25446 solver.cpp:243] Iteration 810, loss = 9.23062
I0826 15:29:26.332657 25446 solver.cpp:259]     Train net output #0: center_loss = 1.70649 (* 0.008 = 0.0136519 loss)
I0826 15:29:26.332662 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21697 (* 1 = 9.21697 loss)
I0826 15:29:26.332666 25446 sgd_solver.cpp:138] Iteration 810, lr = 0.001
I0826 15:29:28.393687 25446 solver.cpp:243] Iteration 820, loss = 9.27038
I0826 15:29:28.393723 25446 solver.cpp:259]     Train net output #0: center_loss = 1.82851 (* 0.008 = 0.0146281 loss)
I0826 15:29:28.393728 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.25575 (* 1 = 9.25575 loss)
I0826 15:29:28.393733 25446 sgd_solver.cpp:138] Iteration 820, lr = 0.001
I0826 15:29:30.447383 25446 solver.cpp:243] Iteration 830, loss = 9.25725
I0826 15:29:30.447420 25446 solver.cpp:259]     Train net output #0: center_loss = 1.83615 (* 0.008 = 0.0146892 loss)
I0826 15:29:30.447427 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24256 (* 1 = 9.24256 loss)
I0826 15:29:30.447429 25446 sgd_solver.cpp:138] Iteration 830, lr = 0.001
I0826 15:29:32.500152 25446 solver.cpp:243] Iteration 840, loss = 9.22774
I0826 15:29:32.500190 25446 solver.cpp:259]     Train net output #0: center_loss = 1.74895 (* 0.008 = 0.0139916 loss)
I0826 15:29:32.500196 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21375 (* 1 = 9.21375 loss)
I0826 15:29:32.500200 25446 sgd_solver.cpp:138] Iteration 840, lr = 0.001
I0826 15:29:34.550148 25446 solver.cpp:243] Iteration 850, loss = 9.25691
I0826 15:29:34.550205 25446 solver.cpp:259]     Train net output #0: center_loss = 1.85361 (* 0.008 = 0.0148289 loss)
I0826 15:29:34.550225 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24208 (* 1 = 9.24208 loss)
I0826 15:29:34.550230 25446 sgd_solver.cpp:138] Iteration 850, lr = 0.001
I0826 15:29:36.605095 25446 solver.cpp:243] Iteration 860, loss = 9.23192
I0826 15:29:36.605134 25446 solver.cpp:259]     Train net output #0: center_loss = 1.78507 (* 0.008 = 0.0142805 loss)
I0826 15:29:36.605139 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21764 (* 1 = 9.21764 loss)
I0826 15:29:36.605142 25446 sgd_solver.cpp:138] Iteration 860, lr = 0.001
I0826 15:29:38.661195 25446 solver.cpp:243] Iteration 870, loss = 9.24725
I0826 15:29:38.661231 25446 solver.cpp:259]     Train net output #0: center_loss = 1.74481 (* 0.008 = 0.0139585 loss)
I0826 15:29:38.661237 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23329 (* 1 = 9.23329 loss)
I0826 15:29:38.661239 25446 sgd_solver.cpp:138] Iteration 870, lr = 0.001
I0826 15:29:40.716414 25446 solver.cpp:243] Iteration 880, loss = 9.23852
I0826 15:29:40.716454 25446 solver.cpp:259]     Train net output #0: center_loss = 1.75604 (* 0.008 = 0.0140483 loss)
I0826 15:29:40.716459 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22447 (* 1 = 9.22447 loss)
I0826 15:29:40.716461 25446 sgd_solver.cpp:138] Iteration 880, lr = 0.001
I0826 15:29:42.774679 25446 solver.cpp:243] Iteration 890, loss = 9.22649
I0826 15:29:42.774780 25446 solver.cpp:259]     Train net output #0: center_loss = 1.53394 (* 0.008 = 0.0122715 loss)
I0826 15:29:42.774786 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21422 (* 1 = 9.21422 loss)
I0826 15:29:42.774803 25446 sgd_solver.cpp:138] Iteration 890, lr = 0.001
I0826 15:29:44.830415 25446 solver.cpp:243] Iteration 900, loss = 9.22152
I0826 15:29:44.830453 25446 solver.cpp:259]     Train net output #0: center_loss = 1.78338 (* 0.008 = 0.0142671 loss)
I0826 15:29:44.830458 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20726 (* 1 = 9.20726 loss)
I0826 15:29:44.830461 25446 sgd_solver.cpp:138] Iteration 900, lr = 0.001
I0826 15:29:46.882558 25446 solver.cpp:243] Iteration 910, loss = 9.26888
I0826 15:29:46.882581 25446 solver.cpp:259]     Train net output #0: center_loss = 1.74312 (* 0.008 = 0.013945 loss)
I0826 15:29:46.882601 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.25493 (* 1 = 9.25493 loss)
I0826 15:29:46.882606 25446 sgd_solver.cpp:138] Iteration 910, lr = 0.001
I0826 15:29:48.938688 25446 solver.cpp:243] Iteration 920, loss = 9.21184
I0826 15:29:48.938709 25446 solver.cpp:259]     Train net output #0: center_loss = 1.78235 (* 0.008 = 0.0142588 loss)
I0826 15:29:48.938730 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19758 (* 1 = 9.19758 loss)
I0826 15:29:48.938732 25446 sgd_solver.cpp:138] Iteration 920, lr = 0.001
I0826 15:29:50.996444 25446 solver.cpp:243] Iteration 930, loss = 9.20416
I0826 15:29:50.996481 25446 solver.cpp:259]     Train net output #0: center_loss = 1.90421 (* 0.008 = 0.0152337 loss)
I0826 15:29:50.996486 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18893 (* 1 = 9.18893 loss)
I0826 15:29:50.996490 25446 sgd_solver.cpp:138] Iteration 930, lr = 0.001
I0826 15:29:53.056071 25446 solver.cpp:243] Iteration 940, loss = 9.21981
I0826 15:29:53.056108 25446 solver.cpp:259]     Train net output #0: center_loss = 2.13914 (* 0.008 = 0.0171131 loss)
I0826 15:29:53.056114 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2027 (* 1 = 9.2027 loss)
I0826 15:29:53.056118 25446 sgd_solver.cpp:138] Iteration 940, lr = 0.001
I0826 15:29:55.112375 25446 solver.cpp:243] Iteration 950, loss = 9.22886
I0826 15:29:55.112411 25446 solver.cpp:259]     Train net output #0: center_loss = 1.79069 (* 0.008 = 0.0143255 loss)
I0826 15:29:55.112416 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21453 (* 1 = 9.21453 loss)
I0826 15:29:55.112418 25446 sgd_solver.cpp:138] Iteration 950, lr = 0.001
I0826 15:29:57.165894 25446 solver.cpp:243] Iteration 960, loss = 9.23237
I0826 15:29:57.165916 25446 solver.cpp:259]     Train net output #0: center_loss = 1.865 (* 0.008 = 0.01492 loss)
I0826 15:29:57.165936 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21745 (* 1 = 9.21745 loss)
I0826 15:29:57.165940 25446 sgd_solver.cpp:138] Iteration 960, lr = 0.001
I0826 15:29:59.220607 25446 solver.cpp:243] Iteration 970, loss = 9.18364
I0826 15:29:59.220643 25446 solver.cpp:259]     Train net output #0: center_loss = 2.09775 (* 0.008 = 0.016782 loss)
I0826 15:29:59.220649 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16686 (* 1 = 9.16686 loss)
I0826 15:29:59.220651 25446 sgd_solver.cpp:138] Iteration 970, lr = 0.001
I0826 15:30:01.274798 25446 solver.cpp:243] Iteration 980, loss = 9.22382
I0826 15:30:01.274835 25446 solver.cpp:259]     Train net output #0: center_loss = 2.09248 (* 0.008 = 0.0167399 loss)
I0826 15:30:01.274840 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20708 (* 1 = 9.20708 loss)
I0826 15:30:01.274843 25446 sgd_solver.cpp:138] Iteration 980, lr = 0.001
I0826 15:30:03.329833 25446 solver.cpp:243] Iteration 990, loss = 9.21906
I0826 15:30:03.329869 25446 solver.cpp:259]     Train net output #0: center_loss = 1.98726 (* 0.008 = 0.0158981 loss)
I0826 15:30:03.329874 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20316 (* 1 = 9.20316 loss)
I0826 15:30:03.329879 25446 sgd_solver.cpp:138] Iteration 990, lr = 0.001
I0826 15:30:05.176192 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_1000.caffemodel
I0826 15:30:06.313283 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_1000.solverstate
I0826 15:30:06.634263 25446 solver.cpp:243] Iteration 1000, loss = 9.23424
I0826 15:30:06.634305 25446 solver.cpp:259]     Train net output #0: center_loss = 2.14127 (* 0.008 = 0.0171302 loss)
I0826 15:30:06.634310 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21711 (* 1 = 9.21711 loss)
I0826 15:30:06.634315 25446 sgd_solver.cpp:138] Iteration 1000, lr = 0.001
I0826 15:30:08.689642 25446 solver.cpp:243] Iteration 1010, loss = 9.2294
I0826 15:30:08.689680 25446 solver.cpp:259]     Train net output #0: center_loss = 2.16772 (* 0.008 = 0.0173417 loss)
I0826 15:30:08.689685 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21206 (* 1 = 9.21206 loss)
I0826 15:30:08.689688 25446 sgd_solver.cpp:138] Iteration 1010, lr = 0.001
I0826 15:30:10.740768 25446 solver.cpp:243] Iteration 1020, loss = 9.22378
I0826 15:30:10.740806 25446 solver.cpp:259]     Train net output #0: center_loss = 2.35174 (* 0.008 = 0.0188139 loss)
I0826 15:30:10.740811 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20497 (* 1 = 9.20497 loss)
I0826 15:30:10.740814 25446 sgd_solver.cpp:138] Iteration 1020, lr = 0.001
I0826 15:30:12.799417 25446 solver.cpp:243] Iteration 1030, loss = 9.21835
I0826 15:30:12.799561 25446 solver.cpp:259]     Train net output #0: center_loss = 2.06169 (* 0.008 = 0.0164935 loss)
I0826 15:30:12.799566 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20186 (* 1 = 9.20186 loss)
I0826 15:30:12.799584 25446 sgd_solver.cpp:138] Iteration 1030, lr = 0.001
I0826 15:30:14.852077 25446 solver.cpp:243] Iteration 1040, loss = 9.25365
I0826 15:30:14.852115 25446 solver.cpp:259]     Train net output #0: center_loss = 2.14823 (* 0.008 = 0.0171858 loss)
I0826 15:30:14.852120 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23646 (* 1 = 9.23646 loss)
I0826 15:30:14.852123 25446 sgd_solver.cpp:138] Iteration 1040, lr = 0.001
I0826 15:30:16.909080 25446 solver.cpp:243] Iteration 1050, loss = 9.21862
I0826 15:30:16.909117 25446 solver.cpp:259]     Train net output #0: center_loss = 2.05583 (* 0.008 = 0.0164466 loss)
I0826 15:30:16.909123 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20218 (* 1 = 9.20218 loss)
I0826 15:30:16.909126 25446 sgd_solver.cpp:138] Iteration 1050, lr = 0.001
I0826 15:30:18.962452 25446 solver.cpp:243] Iteration 1060, loss = 9.2445
I0826 15:30:18.962489 25446 solver.cpp:259]     Train net output #0: center_loss = 2.04333 (* 0.008 = 0.0163466 loss)
I0826 15:30:18.962496 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22816 (* 1 = 9.22816 loss)
I0826 15:30:18.962498 25446 sgd_solver.cpp:138] Iteration 1060, lr = 0.001
I0826 15:30:21.016991 25446 solver.cpp:243] Iteration 1070, loss = 9.19185
I0826 15:30:21.017030 25446 solver.cpp:259]     Train net output #0: center_loss = 2.29415 (* 0.008 = 0.0183532 loss)
I0826 15:30:21.017035 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17349 (* 1 = 9.17349 loss)
I0826 15:30:21.017037 25446 sgd_solver.cpp:138] Iteration 1070, lr = 0.001
I0826 15:30:23.073277 25446 solver.cpp:243] Iteration 1080, loss = 9.2513
I0826 15:30:23.073314 25446 solver.cpp:259]     Train net output #0: center_loss = 2.08301 (* 0.008 = 0.016664 loss)
I0826 15:30:23.073319 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23463 (* 1 = 9.23463 loss)
I0826 15:30:23.073323 25446 sgd_solver.cpp:138] Iteration 1080, lr = 0.001
I0826 15:30:25.126490 25446 solver.cpp:243] Iteration 1090, loss = 9.21686
I0826 15:30:25.126528 25446 solver.cpp:259]     Train net output #0: center_loss = 1.99517 (* 0.008 = 0.0159614 loss)
I0826 15:30:25.126533 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2009 (* 1 = 9.2009 loss)
I0826 15:30:25.126536 25446 sgd_solver.cpp:138] Iteration 1090, lr = 0.001
I0826 15:30:27.182250 25446 solver.cpp:243] Iteration 1100, loss = 9.26156
I0826 15:30:27.182286 25446 solver.cpp:259]     Train net output #0: center_loss = 2.15805 (* 0.008 = 0.0172644 loss)
I0826 15:30:27.182291 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2443 (* 1 = 9.2443 loss)
I0826 15:30:27.182293 25446 sgd_solver.cpp:138] Iteration 1100, lr = 0.001
I0826 15:30:29.238423 25446 solver.cpp:243] Iteration 1110, loss = 9.26166
I0826 15:30:29.238461 25446 solver.cpp:259]     Train net output #0: center_loss = 2.01522 (* 0.008 = 0.0161218 loss)
I0826 15:30:29.238466 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24554 (* 1 = 9.24554 loss)
I0826 15:30:29.238469 25446 sgd_solver.cpp:138] Iteration 1110, lr = 0.001
I0826 15:30:31.294587 25446 solver.cpp:243] Iteration 1120, loss = 9.25216
I0826 15:30:31.294625 25446 solver.cpp:259]     Train net output #0: center_loss = 2.14685 (* 0.008 = 0.0171748 loss)
I0826 15:30:31.294629 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23499 (* 1 = 9.23499 loss)
I0826 15:30:31.294632 25446 sgd_solver.cpp:138] Iteration 1120, lr = 0.001
I0826 15:30:33.351164 25446 solver.cpp:243] Iteration 1130, loss = 9.22169
I0826 15:30:33.351202 25446 solver.cpp:259]     Train net output #0: center_loss = 2.24089 (* 0.008 = 0.0179271 loss)
I0826 15:30:33.351207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20377 (* 1 = 9.20377 loss)
I0826 15:30:33.351210 25446 sgd_solver.cpp:138] Iteration 1130, lr = 0.001
I0826 15:30:35.403556 25446 solver.cpp:243] Iteration 1140, loss = 9.19949
I0826 15:30:35.403594 25446 solver.cpp:259]     Train net output #0: center_loss = 2.2968 (* 0.008 = 0.0183744 loss)
I0826 15:30:35.403599 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18111 (* 1 = 9.18111 loss)
I0826 15:30:35.403602 25446 sgd_solver.cpp:138] Iteration 1140, lr = 0.001
I0826 15:30:37.462849 25446 solver.cpp:243] Iteration 1150, loss = 9.20469
I0826 15:30:37.462890 25446 solver.cpp:259]     Train net output #0: center_loss = 2.07441 (* 0.008 = 0.0165953 loss)
I0826 15:30:37.462896 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1881 (* 1 = 9.1881 loss)
I0826 15:30:37.462900 25446 sgd_solver.cpp:138] Iteration 1150, lr = 0.001
I0826 15:30:39.518272 25446 solver.cpp:243] Iteration 1160, loss = 9.20968
I0826 15:30:39.518308 25446 solver.cpp:259]     Train net output #0: center_loss = 2.10698 (* 0.008 = 0.0168558 loss)
I0826 15:30:39.518313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19282 (* 1 = 9.19282 loss)
I0826 15:30:39.518317 25446 sgd_solver.cpp:138] Iteration 1160, lr = 0.001
I0826 15:30:41.575261 25446 solver.cpp:243] Iteration 1170, loss = 9.19103
I0826 15:30:41.575299 25446 solver.cpp:259]     Train net output #0: center_loss = 2.0742 (* 0.008 = 0.0165936 loss)
I0826 15:30:41.575304 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17444 (* 1 = 9.17444 loss)
I0826 15:30:41.575307 25446 sgd_solver.cpp:138] Iteration 1170, lr = 0.001
I0826 15:30:43.632977 25446 solver.cpp:243] Iteration 1180, loss = 9.20192
I0826 15:30:43.633133 25446 solver.cpp:259]     Train net output #0: center_loss = 2.12368 (* 0.008 = 0.0169895 loss)
I0826 15:30:43.633139 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18493 (* 1 = 9.18493 loss)
I0826 15:30:43.633157 25446 sgd_solver.cpp:138] Iteration 1180, lr = 0.001
I0826 15:30:45.683676 25446 solver.cpp:243] Iteration 1190, loss = 9.20846
I0826 15:30:45.683717 25446 solver.cpp:259]     Train net output #0: center_loss = 2.07864 (* 0.008 = 0.0166291 loss)
I0826 15:30:45.683724 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19183 (* 1 = 9.19183 loss)
I0826 15:30:45.683729 25446 sgd_solver.cpp:138] Iteration 1190, lr = 0.001
I0826 15:30:47.741291 25446 solver.cpp:243] Iteration 1200, loss = 9.20885
I0826 15:30:47.741328 25446 solver.cpp:259]     Train net output #0: center_loss = 2.24913 (* 0.008 = 0.0179931 loss)
I0826 15:30:47.741333 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19086 (* 1 = 9.19086 loss)
I0826 15:30:47.741338 25446 sgd_solver.cpp:138] Iteration 1200, lr = 0.001
I0826 15:30:49.794061 25446 solver.cpp:243] Iteration 1210, loss = 9.24367
I0826 15:30:49.794097 25446 solver.cpp:259]     Train net output #0: center_loss = 2.13671 (* 0.008 = 0.0170937 loss)
I0826 15:30:49.794102 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22658 (* 1 = 9.22658 loss)
I0826 15:30:49.794106 25446 sgd_solver.cpp:138] Iteration 1210, lr = 0.001
I0826 15:30:51.849129 25446 solver.cpp:243] Iteration 1220, loss = 9.23607
I0826 15:30:51.849166 25446 solver.cpp:259]     Train net output #0: center_loss = 2.29603 (* 0.008 = 0.0183683 loss)
I0826 15:30:51.849172 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21771 (* 1 = 9.21771 loss)
I0826 15:30:51.849175 25446 sgd_solver.cpp:138] Iteration 1220, lr = 0.001
I0826 15:30:53.899801 25446 solver.cpp:243] Iteration 1230, loss = 9.22407
I0826 15:30:53.899839 25446 solver.cpp:259]     Train net output #0: center_loss = 2.19363 (* 0.008 = 0.017549 loss)
I0826 15:30:53.899844 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20652 (* 1 = 9.20652 loss)
I0826 15:30:53.899847 25446 sgd_solver.cpp:138] Iteration 1230, lr = 0.001
I0826 15:30:55.957156 25446 solver.cpp:243] Iteration 1240, loss = 9.19645
I0826 15:30:55.957195 25446 solver.cpp:259]     Train net output #0: center_loss = 2.34022 (* 0.008 = 0.0187218 loss)
I0826 15:30:55.957199 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17773 (* 1 = 9.17773 loss)
I0826 15:30:55.957202 25446 sgd_solver.cpp:138] Iteration 1240, lr = 0.001
I0826 15:30:58.012853 25446 solver.cpp:243] Iteration 1250, loss = 9.22369
I0826 15:30:58.012876 25446 solver.cpp:259]     Train net output #0: center_loss = 2.23009 (* 0.008 = 0.0178407 loss)
I0826 15:30:58.012897 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20585 (* 1 = 9.20585 loss)
I0826 15:30:58.012899 25446 sgd_solver.cpp:138] Iteration 1250, lr = 0.001
I0826 15:31:00.073390 25446 solver.cpp:243] Iteration 1260, loss = 9.19791
I0826 15:31:00.073427 25446 solver.cpp:259]     Train net output #0: center_loss = 2.37516 (* 0.008 = 0.0190012 loss)
I0826 15:31:00.073433 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17891 (* 1 = 9.17891 loss)
I0826 15:31:00.073437 25446 sgd_solver.cpp:138] Iteration 1260, lr = 0.001
I0826 15:31:02.133996 25446 solver.cpp:243] Iteration 1270, loss = 9.17239
I0826 15:31:02.134017 25446 solver.cpp:259]     Train net output #0: center_loss = 2.5696 (* 0.008 = 0.0205568 loss)
I0826 15:31:02.134037 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15183 (* 1 = 9.15183 loss)
I0826 15:31:02.134040 25446 sgd_solver.cpp:138] Iteration 1270, lr = 0.001
I0826 15:31:04.185451 25446 solver.cpp:243] Iteration 1280, loss = 9.22657
I0826 15:31:04.185488 25446 solver.cpp:259]     Train net output #0: center_loss = 2.56713 (* 0.008 = 0.020537 loss)
I0826 15:31:04.185494 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20603 (* 1 = 9.20603 loss)
I0826 15:31:04.185497 25446 sgd_solver.cpp:138] Iteration 1280, lr = 0.001
I0826 15:31:06.243366 25446 solver.cpp:243] Iteration 1290, loss = 9.23827
I0826 15:31:06.243402 25446 solver.cpp:259]     Train net output #0: center_loss = 2.41445 (* 0.008 = 0.0193156 loss)
I0826 15:31:06.243407 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21896 (* 1 = 9.21896 loss)
I0826 15:31:06.243410 25446 sgd_solver.cpp:138] Iteration 1290, lr = 0.001
I0826 15:31:08.300416 25446 solver.cpp:243] Iteration 1300, loss = 9.22822
I0826 15:31:08.300453 25446 solver.cpp:259]     Train net output #0: center_loss = 2.20116 (* 0.008 = 0.0176093 loss)
I0826 15:31:08.300459 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21061 (* 1 = 9.21061 loss)
I0826 15:31:08.300462 25446 sgd_solver.cpp:138] Iteration 1300, lr = 0.001
I0826 15:31:10.356220 25446 solver.cpp:243] Iteration 1310, loss = 9.2564
I0826 15:31:10.356243 25446 solver.cpp:259]     Train net output #0: center_loss = 1.93541 (* 0.008 = 0.0154833 loss)
I0826 15:31:10.356263 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24092 (* 1 = 9.24092 loss)
I0826 15:31:10.356268 25446 sgd_solver.cpp:138] Iteration 1310, lr = 0.001
I0826 15:31:12.415767 25446 solver.cpp:243] Iteration 1320, loss = 9.23732
I0826 15:31:12.415805 25446 solver.cpp:259]     Train net output #0: center_loss = 2.09979 (* 0.008 = 0.0167983 loss)
I0826 15:31:12.415812 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22052 (* 1 = 9.22052 loss)
I0826 15:31:12.415814 25446 sgd_solver.cpp:138] Iteration 1320, lr = 0.001
I0826 15:31:14.473224 25446 solver.cpp:243] Iteration 1330, loss = 9.20485
I0826 15:31:14.473363 25446 solver.cpp:259]     Train net output #0: center_loss = 2.2309 (* 0.008 = 0.0178472 loss)
I0826 15:31:14.473369 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.187 (* 1 = 9.187 loss)
I0826 15:31:14.473387 25446 sgd_solver.cpp:138] Iteration 1330, lr = 0.001
I0826 15:31:16.529541 25446 solver.cpp:243] Iteration 1340, loss = 9.20698
I0826 15:31:16.529577 25446 solver.cpp:259]     Train net output #0: center_loss = 1.92606 (* 0.008 = 0.0154085 loss)
I0826 15:31:16.529582 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19157 (* 1 = 9.19157 loss)
I0826 15:31:16.529587 25446 sgd_solver.cpp:138] Iteration 1340, lr = 0.001
I0826 15:31:18.590378 25446 solver.cpp:243] Iteration 1350, loss = 9.22339
I0826 15:31:18.590415 25446 solver.cpp:259]     Train net output #0: center_loss = 1.96752 (* 0.008 = 0.0157401 loss)
I0826 15:31:18.590421 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20765 (* 1 = 9.20765 loss)
I0826 15:31:18.590425 25446 sgd_solver.cpp:138] Iteration 1350, lr = 0.001
I0826 15:31:20.647738 25446 solver.cpp:243] Iteration 1360, loss = 9.2262
I0826 15:31:20.647775 25446 solver.cpp:259]     Train net output #0: center_loss = 1.94259 (* 0.008 = 0.0155407 loss)
I0826 15:31:20.647781 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21065 (* 1 = 9.21065 loss)
I0826 15:31:20.647784 25446 sgd_solver.cpp:138] Iteration 1360, lr = 0.001
I0826 15:31:22.702878 25446 solver.cpp:243] Iteration 1370, loss = 9.21343
I0826 15:31:22.702917 25446 solver.cpp:259]     Train net output #0: center_loss = 2.14994 (* 0.008 = 0.0171995 loss)
I0826 15:31:22.702922 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19623 (* 1 = 9.19623 loss)
I0826 15:31:22.702925 25446 sgd_solver.cpp:138] Iteration 1370, lr = 0.001
I0826 15:31:24.759953 25446 solver.cpp:243] Iteration 1380, loss = 9.22718
I0826 15:31:24.759989 25446 solver.cpp:259]     Train net output #0: center_loss = 2.17969 (* 0.008 = 0.0174375 loss)
I0826 15:31:24.759994 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20974 (* 1 = 9.20974 loss)
I0826 15:31:24.759999 25446 sgd_solver.cpp:138] Iteration 1380, lr = 0.001
I0826 15:31:26.814338 25446 solver.cpp:243] Iteration 1390, loss = 9.24622
I0826 15:31:26.814376 25446 solver.cpp:259]     Train net output #0: center_loss = 2.25281 (* 0.008 = 0.0180225 loss)
I0826 15:31:26.814381 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2282 (* 1 = 9.2282 loss)
I0826 15:31:26.814384 25446 sgd_solver.cpp:138] Iteration 1390, lr = 0.001
I0826 15:31:28.871376 25446 solver.cpp:243] Iteration 1400, loss = 9.19206
I0826 15:31:28.871413 25446 solver.cpp:259]     Train net output #0: center_loss = 2.18926 (* 0.008 = 0.0175141 loss)
I0826 15:31:28.871418 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17455 (* 1 = 9.17455 loss)
I0826 15:31:28.871421 25446 sgd_solver.cpp:138] Iteration 1400, lr = 0.001
I0826 15:31:30.928269 25446 solver.cpp:243] Iteration 1410, loss = 9.21744
I0826 15:31:30.928308 25446 solver.cpp:259]     Train net output #0: center_loss = 2.26896 (* 0.008 = 0.0181517 loss)
I0826 15:31:30.928313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19929 (* 1 = 9.19929 loss)
I0826 15:31:30.928315 25446 sgd_solver.cpp:138] Iteration 1410, lr = 0.001
I0826 15:31:32.988879 25446 solver.cpp:243] Iteration 1420, loss = 9.23269
I0826 15:31:32.988916 25446 solver.cpp:259]     Train net output #0: center_loss = 2.40837 (* 0.008 = 0.0192669 loss)
I0826 15:31:32.988921 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21342 (* 1 = 9.21342 loss)
I0826 15:31:32.988925 25446 sgd_solver.cpp:138] Iteration 1420, lr = 0.001
I0826 15:31:35.042361 25446 solver.cpp:243] Iteration 1430, loss = 9.19514
I0826 15:31:35.042397 25446 solver.cpp:259]     Train net output #0: center_loss = 2.33008 (* 0.008 = 0.0186407 loss)
I0826 15:31:35.042402 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1765 (* 1 = 9.1765 loss)
I0826 15:31:35.042405 25446 sgd_solver.cpp:138] Iteration 1430, lr = 0.001
I0826 15:31:37.099071 25446 solver.cpp:243] Iteration 1440, loss = 9.231
I0826 15:31:37.099109 25446 solver.cpp:259]     Train net output #0: center_loss = 2.36636 (* 0.008 = 0.0189308 loss)
I0826 15:31:37.099114 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21207 (* 1 = 9.21207 loss)
I0826 15:31:37.099117 25446 sgd_solver.cpp:138] Iteration 1440, lr = 0.001
I0826 15:31:39.156875 25446 solver.cpp:243] Iteration 1450, loss = 9.20944
I0826 15:31:39.156910 25446 solver.cpp:259]     Train net output #0: center_loss = 2.35281 (* 0.008 = 0.0188225 loss)
I0826 15:31:39.156915 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19061 (* 1 = 9.19061 loss)
I0826 15:31:39.156919 25446 sgd_solver.cpp:138] Iteration 1450, lr = 0.001
I0826 15:31:41.209910 25446 solver.cpp:243] Iteration 1460, loss = 9.2413
I0826 15:31:41.209947 25446 solver.cpp:259]     Train net output #0: center_loss = 2.55547 (* 0.008 = 0.0204437 loss)
I0826 15:31:41.209952 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22086 (* 1 = 9.22086 loss)
I0826 15:31:41.209955 25446 sgd_solver.cpp:138] Iteration 1460, lr = 0.001
I0826 15:31:43.264582 25446 solver.cpp:243] Iteration 1470, loss = 9.17453
I0826 15:31:43.264618 25446 solver.cpp:259]     Train net output #0: center_loss = 2.38764 (* 0.008 = 0.0191011 loss)
I0826 15:31:43.264624 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15543 (* 1 = 9.15543 loss)
I0826 15:31:43.264627 25446 sgd_solver.cpp:138] Iteration 1470, lr = 0.001
I0826 15:31:45.320521 25446 solver.cpp:243] Iteration 1480, loss = 9.22933
I0826 15:31:45.320638 25446 solver.cpp:259]     Train net output #0: center_loss = 2.2937 (* 0.008 = 0.0183496 loss)
I0826 15:31:45.320657 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21098 (* 1 = 9.21098 loss)
I0826 15:31:45.320660 25446 sgd_solver.cpp:138] Iteration 1480, lr = 0.001
I0826 15:31:47.376945 25446 solver.cpp:243] Iteration 1490, loss = 9.22829
I0826 15:31:47.376981 25446 solver.cpp:259]     Train net output #0: center_loss = 2.3271 (* 0.008 = 0.0186168 loss)
I0826 15:31:47.376986 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20967 (* 1 = 9.20967 loss)
I0826 15:31:47.376991 25446 sgd_solver.cpp:138] Iteration 1490, lr = 0.001
I0826 15:31:49.434340 25446 solver.cpp:243] Iteration 1500, loss = 9.20821
I0826 15:31:49.434377 25446 solver.cpp:259]     Train net output #0: center_loss = 2.5342 (* 0.008 = 0.0202736 loss)
I0826 15:31:49.434382 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18793 (* 1 = 9.18793 loss)
I0826 15:31:49.434386 25446 sgd_solver.cpp:138] Iteration 1500, lr = 0.001
I0826 15:31:51.493965 25446 solver.cpp:243] Iteration 1510, loss = 9.23313
I0826 15:31:51.494002 25446 solver.cpp:259]     Train net output #0: center_loss = 2.57849 (* 0.008 = 0.0206279 loss)
I0826 15:31:51.494007 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2125 (* 1 = 9.2125 loss)
I0826 15:31:51.494010 25446 sgd_solver.cpp:138] Iteration 1510, lr = 0.001
I0826 15:31:53.553452 25446 solver.cpp:243] Iteration 1520, loss = 9.21848
I0826 15:31:53.553474 25446 solver.cpp:259]     Train net output #0: center_loss = 2.59673 (* 0.008 = 0.0207739 loss)
I0826 15:31:53.553494 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1977 (* 1 = 9.1977 loss)
I0826 15:31:53.553498 25446 sgd_solver.cpp:138] Iteration 1520, lr = 0.001
I0826 15:31:55.608232 25446 solver.cpp:243] Iteration 1530, loss = 9.1917
I0826 15:31:55.608269 25446 solver.cpp:259]     Train net output #0: center_loss = 2.37574 (* 0.008 = 0.0190059 loss)
I0826 15:31:55.608275 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1727 (* 1 = 9.1727 loss)
I0826 15:31:55.608278 25446 sgd_solver.cpp:138] Iteration 1530, lr = 0.001
I0826 15:31:57.662549 25446 solver.cpp:243] Iteration 1540, loss = 9.18622
I0826 15:31:57.662588 25446 solver.cpp:259]     Train net output #0: center_loss = 2.55082 (* 0.008 = 0.0204066 loss)
I0826 15:31:57.662593 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16581 (* 1 = 9.16581 loss)
I0826 15:31:57.662596 25446 sgd_solver.cpp:138] Iteration 1540, lr = 0.001
I0826 15:31:59.718472 25446 solver.cpp:243] Iteration 1550, loss = 9.152
I0826 15:31:59.718509 25446 solver.cpp:259]     Train net output #0: center_loss = 2.74366 (* 0.008 = 0.0219493 loss)
I0826 15:31:59.718514 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13005 (* 1 = 9.13005 loss)
I0826 15:31:59.718518 25446 sgd_solver.cpp:138] Iteration 1550, lr = 0.001
I0826 15:32:01.774379 25446 solver.cpp:243] Iteration 1560, loss = 9.26306
I0826 15:32:01.774416 25446 solver.cpp:259]     Train net output #0: center_loss = 2.60355 (* 0.008 = 0.0208284 loss)
I0826 15:32:01.774421 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.24223 (* 1 = 9.24223 loss)
I0826 15:32:01.774425 25446 sgd_solver.cpp:138] Iteration 1560, lr = 0.001
I0826 15:32:03.831071 25446 solver.cpp:243] Iteration 1570, loss = 9.23233
I0826 15:32:03.831107 25446 solver.cpp:259]     Train net output #0: center_loss = 2.70831 (* 0.008 = 0.0216665 loss)
I0826 15:32:03.831113 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21067 (* 1 = 9.21067 loss)
I0826 15:32:03.831116 25446 sgd_solver.cpp:138] Iteration 1570, lr = 0.001
I0826 15:32:05.887697 25446 solver.cpp:243] Iteration 1580, loss = 9.22492
I0826 15:32:05.887734 25446 solver.cpp:259]     Train net output #0: center_loss = 2.64535 (* 0.008 = 0.0211628 loss)
I0826 15:32:05.887739 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20376 (* 1 = 9.20376 loss)
I0826 15:32:05.887742 25446 sgd_solver.cpp:138] Iteration 1580, lr = 0.001
I0826 15:32:07.943346 25446 solver.cpp:243] Iteration 1590, loss = 9.20352
I0826 15:32:07.943383 25446 solver.cpp:259]     Train net output #0: center_loss = 2.73085 (* 0.008 = 0.0218468 loss)
I0826 15:32:07.943389 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18167 (* 1 = 9.18167 loss)
I0826 15:32:07.943392 25446 sgd_solver.cpp:138] Iteration 1590, lr = 0.001
I0826 15:32:09.998324 25446 solver.cpp:243] Iteration 1600, loss = 9.20781
I0826 15:32:09.998363 25446 solver.cpp:259]     Train net output #0: center_loss = 2.82886 (* 0.008 = 0.0226308 loss)
I0826 15:32:09.998368 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18518 (* 1 = 9.18518 loss)
I0826 15:32:09.998371 25446 sgd_solver.cpp:138] Iteration 1600, lr = 0.001
I0826 15:32:12.053128 25446 solver.cpp:243] Iteration 1610, loss = 9.20243
I0826 15:32:12.053165 25446 solver.cpp:259]     Train net output #0: center_loss = 2.67806 (* 0.008 = 0.0214245 loss)
I0826 15:32:12.053171 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18101 (* 1 = 9.18101 loss)
I0826 15:32:12.053174 25446 sgd_solver.cpp:138] Iteration 1610, lr = 0.001
I0826 15:32:14.110638 25446 solver.cpp:243] Iteration 1620, loss = 9.15232
I0826 15:32:14.110674 25446 solver.cpp:259]     Train net output #0: center_loss = 3.07802 (* 0.008 = 0.0246241 loss)
I0826 15:32:14.110679 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1277 (* 1 = 9.1277 loss)
I0826 15:32:14.110683 25446 sgd_solver.cpp:138] Iteration 1620, lr = 0.001
I0826 15:32:16.169605 25446 solver.cpp:243] Iteration 1630, loss = 9.19711
I0826 15:32:16.169747 25446 solver.cpp:259]     Train net output #0: center_loss = 2.72846 (* 0.008 = 0.0218277 loss)
I0826 15:32:16.169755 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17528 (* 1 = 9.17528 loss)
I0826 15:32:16.169759 25446 sgd_solver.cpp:138] Iteration 1630, lr = 0.001
I0826 15:32:18.226317 25446 solver.cpp:243] Iteration 1640, loss = 9.21393
I0826 15:32:18.226353 25446 solver.cpp:259]     Train net output #0: center_loss = 2.97118 (* 0.008 = 0.0237694 loss)
I0826 15:32:18.226358 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19016 (* 1 = 9.19016 loss)
I0826 15:32:18.226361 25446 sgd_solver.cpp:138] Iteration 1640, lr = 0.001
I0826 15:32:20.285529 25446 solver.cpp:243] Iteration 1650, loss = 9.21327
I0826 15:32:20.285567 25446 solver.cpp:259]     Train net output #0: center_loss = 2.66845 (* 0.008 = 0.0213476 loss)
I0826 15:32:20.285573 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19193 (* 1 = 9.19193 loss)
I0826 15:32:20.285575 25446 sgd_solver.cpp:138] Iteration 1650, lr = 0.001
I0826 15:32:22.343374 25446 solver.cpp:243] Iteration 1660, loss = 9.23696
I0826 15:32:22.343410 25446 solver.cpp:259]     Train net output #0: center_loss = 3.06816 (* 0.008 = 0.0245453 loss)
I0826 15:32:22.343415 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21242 (* 1 = 9.21242 loss)
I0826 15:32:22.343418 25446 sgd_solver.cpp:138] Iteration 1660, lr = 0.001
I0826 15:32:24.398504 25446 solver.cpp:243] Iteration 1670, loss = 9.17685
I0826 15:32:24.398541 25446 solver.cpp:259]     Train net output #0: center_loss = 2.62165 (* 0.008 = 0.0209732 loss)
I0826 15:32:24.398547 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15588 (* 1 = 9.15588 loss)
I0826 15:32:24.398550 25446 sgd_solver.cpp:138] Iteration 1670, lr = 0.001
I0826 15:32:26.455595 25446 solver.cpp:243] Iteration 1680, loss = 9.2574
I0826 15:32:26.455633 25446 solver.cpp:259]     Train net output #0: center_loss = 3.02855 (* 0.008 = 0.0242284 loss)
I0826 15:32:26.455639 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23317 (* 1 = 9.23317 loss)
I0826 15:32:26.455642 25446 sgd_solver.cpp:138] Iteration 1680, lr = 0.001
I0826 15:32:28.507753 25446 solver.cpp:243] Iteration 1690, loss = 9.26321
I0826 15:32:28.507791 25446 solver.cpp:259]     Train net output #0: center_loss = 3.09111 (* 0.008 = 0.0247289 loss)
I0826 15:32:28.507797 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23849 (* 1 = 9.23849 loss)
I0826 15:32:28.507799 25446 sgd_solver.cpp:138] Iteration 1690, lr = 0.001
I0826 15:32:30.568455 25446 solver.cpp:243] Iteration 1700, loss = 9.21015
I0826 15:32:30.568493 25446 solver.cpp:259]     Train net output #0: center_loss = 2.9724 (* 0.008 = 0.0237792 loss)
I0826 15:32:30.568498 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18637 (* 1 = 9.18637 loss)
I0826 15:32:30.568501 25446 sgd_solver.cpp:138] Iteration 1700, lr = 0.001
I0826 15:32:32.627645 25446 solver.cpp:243] Iteration 1710, loss = 9.25401
I0826 15:32:32.627681 25446 solver.cpp:259]     Train net output #0: center_loss = 2.67487 (* 0.008 = 0.0213989 loss)
I0826 15:32:32.627687 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23261 (* 1 = 9.23261 loss)
I0826 15:32:32.627691 25446 sgd_solver.cpp:138] Iteration 1710, lr = 0.001
I0826 15:32:34.687158 25446 solver.cpp:243] Iteration 1720, loss = 9.24747
I0826 15:32:34.687196 25446 solver.cpp:259]     Train net output #0: center_loss = 2.90603 (* 0.008 = 0.0232482 loss)
I0826 15:32:34.687201 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22422 (* 1 = 9.22422 loss)
I0826 15:32:34.687203 25446 sgd_solver.cpp:138] Iteration 1720, lr = 0.001
I0826 15:32:36.748313 25446 solver.cpp:243] Iteration 1730, loss = 9.2586
I0826 15:32:36.748351 25446 solver.cpp:259]     Train net output #0: center_loss = 3.20368 (* 0.008 = 0.0256295 loss)
I0826 15:32:36.748356 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.23297 (* 1 = 9.23297 loss)
I0826 15:32:36.748359 25446 sgd_solver.cpp:138] Iteration 1730, lr = 0.001
I0826 15:32:38.803890 25446 solver.cpp:243] Iteration 1740, loss = 9.23119
I0826 15:32:38.803927 25446 solver.cpp:259]     Train net output #0: center_loss = 3.23423 (* 0.008 = 0.0258739 loss)
I0826 15:32:38.803933 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20531 (* 1 = 9.20531 loss)
I0826 15:32:38.803936 25446 sgd_solver.cpp:138] Iteration 1740, lr = 0.001
I0826 15:32:40.861551 25446 solver.cpp:243] Iteration 1750, loss = 9.23197
I0826 15:32:40.861588 25446 solver.cpp:259]     Train net output #0: center_loss = 3.49619 (* 0.008 = 0.0279695 loss)
I0826 15:32:40.861593 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20401 (* 1 = 9.20401 loss)
I0826 15:32:40.861596 25446 sgd_solver.cpp:138] Iteration 1750, lr = 0.001
I0826 15:32:42.917708 25446 solver.cpp:243] Iteration 1760, loss = 9.1556
I0826 15:32:42.917747 25446 solver.cpp:259]     Train net output #0: center_loss = 3.36576 (* 0.008 = 0.0269261 loss)
I0826 15:32:42.917752 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.12867 (* 1 = 9.12867 loss)
I0826 15:32:42.917754 25446 sgd_solver.cpp:138] Iteration 1760, lr = 0.001
I0826 15:32:44.975980 25446 solver.cpp:243] Iteration 1770, loss = 9.20632
I0826 15:32:44.976017 25446 solver.cpp:259]     Train net output #0: center_loss = 3.03328 (* 0.008 = 0.0242663 loss)
I0826 15:32:44.976022 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18205 (* 1 = 9.18205 loss)
I0826 15:32:44.976027 25446 sgd_solver.cpp:138] Iteration 1770, lr = 0.001
I0826 15:32:47.032299 25446 solver.cpp:243] Iteration 1780, loss = 9.22965
I0826 15:32:47.032416 25446 solver.cpp:259]     Train net output #0: center_loss = 3.28455 (* 0.008 = 0.0262764 loss)
I0826 15:32:47.032423 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20337 (* 1 = 9.20337 loss)
I0826 15:32:47.032425 25446 sgd_solver.cpp:138] Iteration 1780, lr = 0.001
I0826 15:32:49.088723 25446 solver.cpp:243] Iteration 1790, loss = 9.18521
I0826 15:32:49.088760 25446 solver.cpp:259]     Train net output #0: center_loss = 2.92758 (* 0.008 = 0.0234206 loss)
I0826 15:32:49.088765 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16179 (* 1 = 9.16179 loss)
I0826 15:32:49.088768 25446 sgd_solver.cpp:138] Iteration 1790, lr = 0.001
I0826 15:32:51.148157 25446 solver.cpp:243] Iteration 1800, loss = 9.21677
I0826 15:32:51.148195 25446 solver.cpp:259]     Train net output #0: center_loss = 3.25094 (* 0.008 = 0.0260075 loss)
I0826 15:32:51.148200 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19077 (* 1 = 9.19077 loss)
I0826 15:32:51.148203 25446 sgd_solver.cpp:138] Iteration 1800, lr = 0.001
I0826 15:32:53.204401 25446 solver.cpp:243] Iteration 1810, loss = 9.17245
I0826 15:32:53.204424 25446 solver.cpp:259]     Train net output #0: center_loss = 3.06008 (* 0.008 = 0.0244806 loss)
I0826 15:32:53.204444 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14797 (* 1 = 9.14797 loss)
I0826 15:32:53.204447 25446 sgd_solver.cpp:138] Iteration 1810, lr = 0.001
I0826 15:32:55.264335 25446 solver.cpp:243] Iteration 1820, loss = 9.16803
I0826 15:32:55.264372 25446 solver.cpp:259]     Train net output #0: center_loss = 2.934 (* 0.008 = 0.023472 loss)
I0826 15:32:55.264379 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14456 (* 1 = 9.14456 loss)
I0826 15:32:55.264381 25446 sgd_solver.cpp:138] Iteration 1820, lr = 0.001
I0826 15:32:57.319543 25446 solver.cpp:243] Iteration 1830, loss = 9.22472
I0826 15:32:57.319581 25446 solver.cpp:259]     Train net output #0: center_loss = 3.34711 (* 0.008 = 0.0267769 loss)
I0826 15:32:57.319586 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19795 (* 1 = 9.19795 loss)
I0826 15:32:57.319589 25446 sgd_solver.cpp:138] Iteration 1830, lr = 0.001
I0826 15:32:59.375641 25446 solver.cpp:243] Iteration 1840, loss = 9.20776
I0826 15:32:59.375679 25446 solver.cpp:259]     Train net output #0: center_loss = 3.08532 (* 0.008 = 0.0246826 loss)
I0826 15:32:59.375684 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18307 (* 1 = 9.18307 loss)
I0826 15:32:59.375686 25446 sgd_solver.cpp:138] Iteration 1840, lr = 0.001
I0826 15:33:01.437299 25446 solver.cpp:243] Iteration 1850, loss = 9.22518
I0826 15:33:01.437335 25446 solver.cpp:259]     Train net output #0: center_loss = 2.8202 (* 0.008 = 0.0225616 loss)
I0826 15:33:01.437341 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20262 (* 1 = 9.20262 loss)
I0826 15:33:01.437345 25446 sgd_solver.cpp:138] Iteration 1850, lr = 0.001
I0826 15:33:03.491541 25446 solver.cpp:243] Iteration 1860, loss = 9.19487
I0826 15:33:03.491576 25446 solver.cpp:259]     Train net output #0: center_loss = 2.90852 (* 0.008 = 0.0232682 loss)
I0826 15:33:03.491582 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1716 (* 1 = 9.1716 loss)
I0826 15:33:03.491585 25446 sgd_solver.cpp:138] Iteration 1860, lr = 0.001
I0826 15:33:05.551021 25446 solver.cpp:243] Iteration 1870, loss = 9.19573
I0826 15:33:05.551059 25446 solver.cpp:259]     Train net output #0: center_loss = 3.22995 (* 0.008 = 0.0258396 loss)
I0826 15:33:05.551064 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16989 (* 1 = 9.16989 loss)
I0826 15:33:05.551066 25446 sgd_solver.cpp:138] Iteration 1870, lr = 0.001
I0826 15:33:07.603739 25446 solver.cpp:243] Iteration 1880, loss = 9.25259
I0826 15:33:07.603775 25446 solver.cpp:259]     Train net output #0: center_loss = 3.08314 (* 0.008 = 0.0246651 loss)
I0826 15:33:07.603781 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22793 (* 1 = 9.22793 loss)
I0826 15:33:07.603785 25446 sgd_solver.cpp:138] Iteration 1880, lr = 0.001
I0826 15:33:09.665716 25446 solver.cpp:243] Iteration 1890, loss = 9.20548
I0826 15:33:09.665753 25446 solver.cpp:259]     Train net output #0: center_loss = 3.06163 (* 0.008 = 0.0244931 loss)
I0826 15:33:09.665758 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18099 (* 1 = 9.18099 loss)
I0826 15:33:09.665761 25446 sgd_solver.cpp:138] Iteration 1890, lr = 0.001
I0826 15:33:11.721774 25446 solver.cpp:243] Iteration 1900, loss = 9.21925
I0826 15:33:11.721812 25446 solver.cpp:259]     Train net output #0: center_loss = 3.2996 (* 0.008 = 0.0263968 loss)
I0826 15:33:11.721817 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19285 (* 1 = 9.19285 loss)
I0826 15:33:11.721820 25446 sgd_solver.cpp:138] Iteration 1900, lr = 0.001
I0826 15:33:13.774718 25446 solver.cpp:243] Iteration 1910, loss = 9.23957
I0826 15:33:13.774755 25446 solver.cpp:259]     Train net output #0: center_loss = 3.13174 (* 0.008 = 0.0250539 loss)
I0826 15:33:13.774760 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21451 (* 1 = 9.21451 loss)
I0826 15:33:13.774763 25446 sgd_solver.cpp:138] Iteration 1910, lr = 0.001
I0826 15:33:15.833498 25446 solver.cpp:243] Iteration 1920, loss = 9.24398
I0826 15:33:15.833534 25446 solver.cpp:259]     Train net output #0: center_loss = 3.40997 (* 0.008 = 0.0272797 loss)
I0826 15:33:15.833539 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.2167 (* 1 = 9.2167 loss)
I0826 15:33:15.833542 25446 sgd_solver.cpp:138] Iteration 1920, lr = 0.001
I0826 15:33:17.892926 25446 solver.cpp:243] Iteration 1930, loss = 9.2003
I0826 15:33:17.893055 25446 solver.cpp:259]     Train net output #0: center_loss = 3.21463 (* 0.008 = 0.0257171 loss)
I0826 15:33:17.893061 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17458 (* 1 = 9.17458 loss)
I0826 15:33:17.893079 25446 sgd_solver.cpp:138] Iteration 1930, lr = 0.001
I0826 15:33:19.947402 25446 solver.cpp:243] Iteration 1940, loss = 9.22962
I0826 15:33:19.947438 25446 solver.cpp:259]     Train net output #0: center_loss = 3.31061 (* 0.008 = 0.0264848 loss)
I0826 15:33:19.947444 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20313 (* 1 = 9.20313 loss)
I0826 15:33:19.947448 25446 sgd_solver.cpp:138] Iteration 1940, lr = 0.001
I0826 15:33:22.003000 25446 solver.cpp:243] Iteration 1950, loss = 9.21074
I0826 15:33:22.003036 25446 solver.cpp:259]     Train net output #0: center_loss = 3.37489 (* 0.008 = 0.0269991 loss)
I0826 15:33:22.003041 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18374 (* 1 = 9.18374 loss)
I0826 15:33:22.003044 25446 sgd_solver.cpp:138] Iteration 1950, lr = 0.001
I0826 15:33:24.056722 25446 solver.cpp:243] Iteration 1960, loss = 9.19932
I0826 15:33:24.056761 25446 solver.cpp:259]     Train net output #0: center_loss = 3.34803 (* 0.008 = 0.0267842 loss)
I0826 15:33:24.056766 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17253 (* 1 = 9.17253 loss)
I0826 15:33:24.056768 25446 sgd_solver.cpp:138] Iteration 1960, lr = 0.001
I0826 15:33:26.111302 25446 solver.cpp:243] Iteration 1970, loss = 9.18278
I0826 15:33:26.111338 25446 solver.cpp:259]     Train net output #0: center_loss = 3.50324 (* 0.008 = 0.0280259 loss)
I0826 15:33:26.111344 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15476 (* 1 = 9.15476 loss)
I0826 15:33:26.111347 25446 sgd_solver.cpp:138] Iteration 1970, lr = 0.001
I0826 15:33:28.165313 25446 solver.cpp:243] Iteration 1980, loss = 9.22859
I0826 15:33:28.165335 25446 solver.cpp:259]     Train net output #0: center_loss = 3.25764 (* 0.008 = 0.0260611 loss)
I0826 15:33:28.165355 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20253 (* 1 = 9.20253 loss)
I0826 15:33:28.165359 25446 sgd_solver.cpp:138] Iteration 1980, lr = 0.001
I0826 15:33:30.220033 25446 solver.cpp:243] Iteration 1990, loss = 9.17485
I0826 15:33:30.220070 25446 solver.cpp:259]     Train net output #0: center_loss = 3.52806 (* 0.008 = 0.0282245 loss)
I0826 15:33:30.220075 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14662 (* 1 = 9.14662 loss)
I0826 15:33:30.220079 25446 sgd_solver.cpp:138] Iteration 1990, lr = 0.001
I0826 15:33:32.068998 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_2000.caffemodel
I0826 15:33:33.181301 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_2000.solverstate
I0826 15:33:33.507865 25446 solver.cpp:243] Iteration 2000, loss = 9.19501
I0826 15:33:33.507906 25446 solver.cpp:259]     Train net output #0: center_loss = 3.21382 (* 0.008 = 0.0257106 loss)
I0826 15:33:33.507912 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1693 (* 1 = 9.1693 loss)
I0826 15:33:33.507916 25446 sgd_solver.cpp:138] Iteration 2000, lr = 0.001
I0826 15:33:35.562165 25446 solver.cpp:243] Iteration 2010, loss = 9.25051
I0826 15:33:35.562203 25446 solver.cpp:259]     Train net output #0: center_loss = 3.03476 (* 0.008 = 0.0242781 loss)
I0826 15:33:35.562208 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.22623 (* 1 = 9.22623 loss)
I0826 15:33:35.562212 25446 sgd_solver.cpp:138] Iteration 2010, lr = 0.001
I0826 15:33:37.620240 25446 solver.cpp:243] Iteration 2020, loss = 9.22654
I0826 15:33:37.620280 25446 solver.cpp:259]     Train net output #0: center_loss = 3.49072 (* 0.008 = 0.0279257 loss)
I0826 15:33:37.620285 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19861 (* 1 = 9.19861 loss)
I0826 15:33:37.620288 25446 sgd_solver.cpp:138] Iteration 2020, lr = 0.001
I0826 15:33:39.679241 25446 solver.cpp:243] Iteration 2030, loss = 9.18014
I0826 15:33:39.679280 25446 solver.cpp:259]     Train net output #0: center_loss = 4.17141 (* 0.008 = 0.0333713 loss)
I0826 15:33:39.679337 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14677 (* 1 = 9.14677 loss)
I0826 15:33:39.679342 25446 sgd_solver.cpp:138] Iteration 2030, lr = 0.001
I0826 15:33:41.739167 25446 solver.cpp:243] Iteration 2040, loss = 9.12089
I0826 15:33:41.739204 25446 solver.cpp:259]     Train net output #0: center_loss = 3.10729 (* 0.008 = 0.0248583 loss)
I0826 15:33:41.739210 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09603 (* 1 = 9.09603 loss)
I0826 15:33:41.739213 25446 sgd_solver.cpp:138] Iteration 2040, lr = 0.001
I0826 15:33:43.796701 25446 solver.cpp:243] Iteration 2050, loss = 9.23083
I0826 15:33:43.796737 25446 solver.cpp:259]     Train net output #0: center_loss = 3.13094 (* 0.008 = 0.0250475 loss)
I0826 15:33:43.796743 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.20578 (* 1 = 9.20578 loss)
I0826 15:33:43.796746 25446 sgd_solver.cpp:138] Iteration 2050, lr = 0.001
I0826 15:33:45.851078 25446 solver.cpp:243] Iteration 2060, loss = 9.13549
I0826 15:33:45.851116 25446 solver.cpp:259]     Train net output #0: center_loss = 4.30158 (* 0.008 = 0.0344127 loss)
I0826 15:33:45.851121 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10107 (* 1 = 9.10107 loss)
I0826 15:33:45.851125 25446 sgd_solver.cpp:138] Iteration 2060, lr = 0.001
I0826 15:33:47.911108 25446 solver.cpp:243] Iteration 2070, loss = 9.19422
I0826 15:33:47.911269 25446 solver.cpp:259]     Train net output #0: center_loss = 4.22231 (* 0.008 = 0.0337785 loss)
I0826 15:33:47.911288 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16044 (* 1 = 9.16044 loss)
I0826 15:33:47.911293 25446 sgd_solver.cpp:138] Iteration 2070, lr = 0.001
I0826 15:33:49.970599 25446 solver.cpp:243] Iteration 2080, loss = 9.18802
I0826 15:33:49.970636 25446 solver.cpp:259]     Train net output #0: center_loss = 4.29147 (* 0.008 = 0.0343318 loss)
I0826 15:33:49.970641 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15369 (* 1 = 9.15369 loss)
I0826 15:33:49.970645 25446 sgd_solver.cpp:138] Iteration 2080, lr = 0.001
I0826 15:33:52.027624 25446 solver.cpp:243] Iteration 2090, loss = 9.14295
I0826 15:33:52.027662 25446 solver.cpp:259]     Train net output #0: center_loss = 3.63321 (* 0.008 = 0.0290657 loss)
I0826 15:33:52.027667 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11389 (* 1 = 9.11389 loss)
I0826 15:33:52.027670 25446 sgd_solver.cpp:138] Iteration 2090, lr = 0.001
I0826 15:33:54.083542 25446 solver.cpp:243] Iteration 2100, loss = 9.24272
I0826 15:33:54.083580 25446 solver.cpp:259]     Train net output #0: center_loss = 3.88003 (* 0.008 = 0.0310402 loss)
I0826 15:33:54.083585 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21168 (* 1 = 9.21168 loss)
I0826 15:33:54.083588 25446 sgd_solver.cpp:138] Iteration 2100, lr = 0.001
I0826 15:33:56.140879 25446 solver.cpp:243] Iteration 2110, loss = 9.19634
I0826 15:33:56.140916 25446 solver.cpp:259]     Train net output #0: center_loss = 3.96738 (* 0.008 = 0.031739 loss)
I0826 15:33:56.140921 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1646 (* 1 = 9.1646 loss)
I0826 15:33:56.140925 25446 sgd_solver.cpp:138] Iteration 2110, lr = 0.001
I0826 15:33:58.224267 25446 solver.cpp:243] Iteration 2120, loss = 9.24603
I0826 15:33:58.224290 25446 solver.cpp:259]     Train net output #0: center_loss = 3.94103 (* 0.008 = 0.0315282 loss)
I0826 15:33:58.224295 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21451 (* 1 = 9.21451 loss)
I0826 15:33:58.224299 25446 sgd_solver.cpp:138] Iteration 2120, lr = 0.001
I0826 15:34:00.295747 25446 solver.cpp:243] Iteration 2130, loss = 9.19273
I0826 15:34:00.295784 25446 solver.cpp:259]     Train net output #0: center_loss = 3.94321 (* 0.008 = 0.0315457 loss)
I0826 15:34:00.295790 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16119 (* 1 = 9.16119 loss)
I0826 15:34:00.295794 25446 sgd_solver.cpp:138] Iteration 2130, lr = 0.001
I0826 15:34:02.371105 25446 solver.cpp:243] Iteration 2140, loss = 9.19778
I0826 15:34:02.371142 25446 solver.cpp:259]     Train net output #0: center_loss = 4.23232 (* 0.008 = 0.0338586 loss)
I0826 15:34:02.371148 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16393 (* 1 = 9.16393 loss)
I0826 15:34:02.371151 25446 sgd_solver.cpp:138] Iteration 2140, lr = 0.001
I0826 15:34:04.458220 25446 solver.cpp:243] Iteration 2150, loss = 9.2058
I0826 15:34:04.458245 25446 solver.cpp:259]     Train net output #0: center_loss = 4.41688 (* 0.008 = 0.035335 loss)
I0826 15:34:04.458250 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17047 (* 1 = 9.17047 loss)
I0826 15:34:04.458254 25446 sgd_solver.cpp:138] Iteration 2150, lr = 0.001
I0826 15:34:06.528141 25446 solver.cpp:243] Iteration 2160, loss = 9.1881
I0826 15:34:06.528165 25446 solver.cpp:259]     Train net output #0: center_loss = 4.93115 (* 0.008 = 0.0394492 loss)
I0826 15:34:06.528170 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14865 (* 1 = 9.14865 loss)
I0826 15:34:06.528174 25446 sgd_solver.cpp:138] Iteration 2160, lr = 0.001
I0826 15:34:08.604661 25446 solver.cpp:243] Iteration 2170, loss = 9.21313
I0826 15:34:08.604701 25446 solver.cpp:259]     Train net output #0: center_loss = 4.42112 (* 0.008 = 0.035369 loss)
I0826 15:34:08.604707 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17776 (* 1 = 9.17776 loss)
I0826 15:34:08.604710 25446 sgd_solver.cpp:138] Iteration 2170, lr = 0.001
I0826 15:34:10.709661 25446 solver.cpp:243] Iteration 2180, loss = 9.1626
I0826 15:34:10.709691 25446 solver.cpp:259]     Train net output #0: center_loss = 4.76039 (* 0.008 = 0.0380832 loss)
I0826 15:34:10.709697 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.12452 (* 1 = 9.12452 loss)
I0826 15:34:10.709702 25446 sgd_solver.cpp:138] Iteration 2180, lr = 0.001
I0826 15:34:12.830760 25446 solver.cpp:243] Iteration 2190, loss = 9.198
I0826 15:34:12.830798 25446 solver.cpp:259]     Train net output #0: center_loss = 4.21059 (* 0.008 = 0.0336847 loss)
I0826 15:34:12.830804 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16432 (* 1 = 9.16432 loss)
I0826 15:34:12.830808 25446 sgd_solver.cpp:138] Iteration 2190, lr = 0.001
I0826 15:34:14.989202 25446 solver.cpp:243] Iteration 2200, loss = 9.1353
I0826 15:34:14.989229 25446 solver.cpp:259]     Train net output #0: center_loss = 3.74608 (* 0.008 = 0.0299686 loss)
I0826 15:34:14.989235 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10533 (* 1 = 9.10533 loss)
I0826 15:34:14.989240 25446 sgd_solver.cpp:138] Iteration 2200, lr = 0.001
I0826 15:34:17.054504 25446 solver.cpp:243] Iteration 2210, loss = 9.2195
I0826 15:34:17.054541 25446 solver.cpp:259]     Train net output #0: center_loss = 4.86023 (* 0.008 = 0.0388818 loss)
I0826 15:34:17.054548 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18061 (* 1 = 9.18061 loss)
I0826 15:34:17.054550 25446 sgd_solver.cpp:138] Iteration 2210, lr = 0.001
I0826 15:34:19.116734 25446 solver.cpp:243] Iteration 2220, loss = 9.22079
I0826 15:34:19.116852 25446 solver.cpp:259]     Train net output #0: center_loss = 4.42615 (* 0.008 = 0.0354092 loss)
I0826 15:34:19.116871 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18538 (* 1 = 9.18538 loss)
I0826 15:34:19.116874 25446 sgd_solver.cpp:138] Iteration 2220, lr = 0.001
I0826 15:34:21.188239 25446 solver.cpp:243] Iteration 2230, loss = 9.21839
I0826 15:34:21.188277 25446 solver.cpp:259]     Train net output #0: center_loss = 4.43628 (* 0.008 = 0.0354903 loss)
I0826 15:34:21.188282 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1829 (* 1 = 9.1829 loss)
I0826 15:34:21.188285 25446 sgd_solver.cpp:138] Iteration 2230, lr = 0.001
I0826 15:34:23.265863 25446 solver.cpp:243] Iteration 2240, loss = 9.19509
I0826 15:34:23.265899 25446 solver.cpp:259]     Train net output #0: center_loss = 4.06839 (* 0.008 = 0.0325472 loss)
I0826 15:34:23.265904 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16254 (* 1 = 9.16254 loss)
I0826 15:34:23.265908 25446 sgd_solver.cpp:138] Iteration 2240, lr = 0.001
I0826 15:34:25.322214 25446 solver.cpp:243] Iteration 2250, loss = 9.16938
I0826 15:34:25.322250 25446 solver.cpp:259]     Train net output #0: center_loss = 4.3514 (* 0.008 = 0.0348112 loss)
I0826 15:34:25.322257 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13457 (* 1 = 9.13457 loss)
I0826 15:34:25.322259 25446 sgd_solver.cpp:138] Iteration 2250, lr = 0.001
I0826 15:34:27.395764 25446 solver.cpp:243] Iteration 2260, loss = 9.17926
I0826 15:34:27.395800 25446 solver.cpp:259]     Train net output #0: center_loss = 4.47986 (* 0.008 = 0.0358389 loss)
I0826 15:34:27.395805 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14342 (* 1 = 9.14342 loss)
I0826 15:34:27.395809 25446 sgd_solver.cpp:138] Iteration 2260, lr = 0.001
I0826 15:34:29.492828 25446 solver.cpp:243] Iteration 2270, loss = 9.21222
I0826 15:34:29.492851 25446 solver.cpp:259]     Train net output #0: center_loss = 4.82595 (* 0.008 = 0.0386076 loss)
I0826 15:34:29.492856 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17362 (* 1 = 9.17362 loss)
I0826 15:34:29.492859 25446 sgd_solver.cpp:138] Iteration 2270, lr = 0.001
I0826 15:34:31.573940 25446 solver.cpp:243] Iteration 2280, loss = 9.20437
I0826 15:34:31.573964 25446 solver.cpp:259]     Train net output #0: center_loss = 3.87282 (* 0.008 = 0.0309825 loss)
I0826 15:34:31.573969 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17339 (* 1 = 9.17339 loss)
I0826 15:34:31.573973 25446 sgd_solver.cpp:138] Iteration 2280, lr = 0.001
I0826 15:34:33.664036 25446 solver.cpp:243] Iteration 2290, loss = 9.21107
I0826 15:34:33.664073 25446 solver.cpp:259]     Train net output #0: center_loss = 4.18935 (* 0.008 = 0.0335148 loss)
I0826 15:34:33.664079 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17755 (* 1 = 9.17755 loss)
I0826 15:34:33.664083 25446 sgd_solver.cpp:138] Iteration 2290, lr = 0.001
I0826 15:34:35.750013 25446 solver.cpp:243] Iteration 2300, loss = 9.19121
I0826 15:34:35.750038 25446 solver.cpp:259]     Train net output #0: center_loss = 5.0185 (* 0.008 = 0.040148 loss)
I0826 15:34:35.750044 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15106 (* 1 = 9.15106 loss)
I0826 15:34:35.750048 25446 sgd_solver.cpp:138] Iteration 2300, lr = 0.001
I0826 15:34:37.828575 25446 solver.cpp:243] Iteration 2310, loss = 9.06765
I0826 15:34:37.828614 25446 solver.cpp:259]     Train net output #0: center_loss = 4.98144 (* 0.008 = 0.0398515 loss)
I0826 15:34:37.828619 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.0278 (* 1 = 9.0278 loss)
I0826 15:34:37.828624 25446 sgd_solver.cpp:138] Iteration 2310, lr = 0.001
I0826 15:34:39.915302 25446 solver.cpp:243] Iteration 2320, loss = 9.23258
I0826 15:34:39.915340 25446 solver.cpp:259]     Train net output #0: center_loss = 4.86488 (* 0.008 = 0.0389191 loss)
I0826 15:34:39.915345 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.19366 (* 1 = 9.19366 loss)
I0826 15:34:39.915349 25446 sgd_solver.cpp:138] Iteration 2320, lr = 0.001
I0826 15:34:41.997501 25446 solver.cpp:243] Iteration 2330, loss = 9.21835
I0826 15:34:41.997524 25446 solver.cpp:259]     Train net output #0: center_loss = 4.76025 (* 0.008 = 0.038082 loss)
I0826 15:34:41.997543 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.18027 (* 1 = 9.18027 loss)
I0826 15:34:41.997547 25446 sgd_solver.cpp:138] Iteration 2330, lr = 0.001
I0826 15:34:44.067049 25446 solver.cpp:243] Iteration 2340, loss = 9.25342
I0826 15:34:44.067086 25446 solver.cpp:259]     Train net output #0: center_loss = 4.72862 (* 0.008 = 0.037829 loss)
I0826 15:34:44.067092 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21559 (* 1 = 9.21559 loss)
I0826 15:34:44.067095 25446 sgd_solver.cpp:138] Iteration 2340, lr = 0.001
I0826 15:34:46.130574 25446 solver.cpp:243] Iteration 2350, loss = 9.17327
I0826 15:34:46.130599 25446 solver.cpp:259]     Train net output #0: center_loss = 5.1227 (* 0.008 = 0.0409816 loss)
I0826 15:34:46.130604 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13229 (* 1 = 9.13229 loss)
I0826 15:34:46.130606 25446 sgd_solver.cpp:138] Iteration 2350, lr = 0.001
I0826 15:34:48.225755 25446 solver.cpp:243] Iteration 2360, loss = 9.21095
I0826 15:34:48.225793 25446 solver.cpp:259]     Train net output #0: center_loss = 5.52919 (* 0.008 = 0.0442335 loss)
I0826 15:34:48.225798 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16672 (* 1 = 9.16672 loss)
I0826 15:34:48.225802 25446 sgd_solver.cpp:138] Iteration 2360, lr = 0.001
I0826 15:34:50.312027 25446 solver.cpp:243] Iteration 2370, loss = 9.1853
I0826 15:34:50.312166 25446 solver.cpp:259]     Train net output #0: center_loss = 5.45197 (* 0.008 = 0.0436158 loss)
I0826 15:34:50.312186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14168 (* 1 = 9.14168 loss)
I0826 15:34:50.312189 25446 sgd_solver.cpp:138] Iteration 2370, lr = 0.001
I0826 15:34:52.416043 25446 solver.cpp:243] Iteration 2380, loss = 9.15017
I0826 15:34:52.416065 25446 solver.cpp:259]     Train net output #0: center_loss = 5.19904 (* 0.008 = 0.0415923 loss)
I0826 15:34:52.416071 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10858 (* 1 = 9.10858 loss)
I0826 15:34:52.416074 25446 sgd_solver.cpp:138] Iteration 2380, lr = 0.001
I0826 15:34:54.508004 25446 solver.cpp:243] Iteration 2390, loss = 9.1933
I0826 15:34:54.508042 25446 solver.cpp:259]     Train net output #0: center_loss = 4.49991 (* 0.008 = 0.0359993 loss)
I0826 15:34:54.508049 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1573 (* 1 = 9.1573 loss)
I0826 15:34:54.508052 25446 sgd_solver.cpp:138] Iteration 2390, lr = 0.001
I0826 15:34:56.631908 25446 solver.cpp:243] Iteration 2400, loss = 9.15386
I0826 15:34:56.631932 25446 solver.cpp:259]     Train net output #0: center_loss = 4.20702 (* 0.008 = 0.0336562 loss)
I0826 15:34:56.631937 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1202 (* 1 = 9.1202 loss)
I0826 15:34:56.631942 25446 sgd_solver.cpp:138] Iteration 2400, lr = 0.001
I0826 15:34:58.701596 25446 solver.cpp:243] Iteration 2410, loss = 9.14918
I0826 15:34:58.701632 25446 solver.cpp:259]     Train net output #0: center_loss = 4.46192 (* 0.008 = 0.0356954 loss)
I0826 15:34:58.701638 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11348 (* 1 = 9.11348 loss)
I0826 15:34:58.701642 25446 sgd_solver.cpp:138] Iteration 2410, lr = 0.001
I0826 15:35:00.770339 25446 solver.cpp:243] Iteration 2420, loss = 9.14089
I0826 15:35:00.770380 25446 solver.cpp:259]     Train net output #0: center_loss = 4.93855 (* 0.008 = 0.0395084 loss)
I0826 15:35:00.770385 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10138 (* 1 = 9.10138 loss)
I0826 15:35:00.770390 25446 sgd_solver.cpp:138] Iteration 2420, lr = 0.001
I0826 15:35:02.850517 25446 solver.cpp:243] Iteration 2430, loss = 9.14117
I0826 15:35:02.850539 25446 solver.cpp:259]     Train net output #0: center_loss = 5.12658 (* 0.008 = 0.0410126 loss)
I0826 15:35:02.850544 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10015 (* 1 = 9.10015 loss)
I0826 15:35:02.850548 25446 sgd_solver.cpp:138] Iteration 2430, lr = 0.001
I0826 15:35:04.919011 25446 solver.cpp:243] Iteration 2440, loss = 9.15889
I0826 15:35:04.919034 25446 solver.cpp:259]     Train net output #0: center_loss = 5.60011 (* 0.008 = 0.0448009 loss)
I0826 15:35:04.919054 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11409 (* 1 = 9.11409 loss)
I0826 15:35:04.919059 25446 sgd_solver.cpp:138] Iteration 2440, lr = 0.001
I0826 15:35:07.005033 25446 solver.cpp:243] Iteration 2450, loss = 9.1409
I0826 15:35:07.005057 25446 solver.cpp:259]     Train net output #0: center_loss = 5.0654 (* 0.008 = 0.0405232 loss)
I0826 15:35:07.005064 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10037 (* 1 = 9.10037 loss)
I0826 15:35:07.005067 25446 sgd_solver.cpp:138] Iteration 2450, lr = 0.001
I0826 15:35:09.197386 25446 solver.cpp:243] Iteration 2460, loss = 9.21345
I0826 15:35:09.197427 25446 solver.cpp:259]     Train net output #0: center_loss = 6.22316 (* 0.008 = 0.0497853 loss)
I0826 15:35:09.197433 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16366 (* 1 = 9.16366 loss)
I0826 15:35:09.197438 25446 sgd_solver.cpp:138] Iteration 2460, lr = 0.001
I0826 15:35:11.338641 25446 solver.cpp:243] Iteration 2470, loss = 9.11923
I0826 15:35:11.338677 25446 solver.cpp:259]     Train net output #0: center_loss = 5.56976 (* 0.008 = 0.0445581 loss)
I0826 15:35:11.338683 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07467 (* 1 = 9.07467 loss)
I0826 15:35:11.338687 25446 sgd_solver.cpp:138] Iteration 2470, lr = 0.001
I0826 15:35:13.406704 25446 solver.cpp:243] Iteration 2480, loss = 9.10958
I0826 15:35:13.406742 25446 solver.cpp:259]     Train net output #0: center_loss = 5.4569 (* 0.008 = 0.0436552 loss)
I0826 15:35:13.406747 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06593 (* 1 = 9.06593 loss)
I0826 15:35:13.406751 25446 sgd_solver.cpp:138] Iteration 2480, lr = 0.001
I0826 15:35:15.465301 25446 solver.cpp:243] Iteration 2490, loss = 9.19058
I0826 15:35:15.465348 25446 solver.cpp:259]     Train net output #0: center_loss = 4.87636 (* 0.008 = 0.0390109 loss)
I0826 15:35:15.465354 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15157 (* 1 = 9.15157 loss)
I0826 15:35:15.465358 25446 sgd_solver.cpp:138] Iteration 2490, lr = 0.001
I0826 15:35:17.530822 25446 solver.cpp:243] Iteration 2500, loss = 9.1157
I0826 15:35:17.530859 25446 solver.cpp:259]     Train net output #0: center_loss = 5.19857 (* 0.008 = 0.0415886 loss)
I0826 15:35:17.530865 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07411 (* 1 = 9.07411 loss)
I0826 15:35:17.530869 25446 sgd_solver.cpp:138] Iteration 2500, lr = 0.001
I0826 15:35:19.591820 25446 solver.cpp:243] Iteration 2510, loss = 9.18332
I0826 15:35:19.591856 25446 solver.cpp:259]     Train net output #0: center_loss = 5.91817 (* 0.008 = 0.0473454 loss)
I0826 15:35:19.591861 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13597 (* 1 = 9.13597 loss)
I0826 15:35:19.591864 25446 sgd_solver.cpp:138] Iteration 2510, lr = 0.001
I0826 15:35:21.652307 25446 solver.cpp:243] Iteration 2520, loss = 9.18497
I0826 15:35:21.652436 25446 solver.cpp:259]     Train net output #0: center_loss = 5.73224 (* 0.008 = 0.0458579 loss)
I0826 15:35:21.652441 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13912 (* 1 = 9.13912 loss)
I0826 15:35:21.652446 25446 sgd_solver.cpp:138] Iteration 2520, lr = 0.001
I0826 15:35:23.718734 25446 solver.cpp:243] Iteration 2530, loss = 9.16837
I0826 15:35:23.718772 25446 solver.cpp:259]     Train net output #0: center_loss = 6.55415 (* 0.008 = 0.0524332 loss)
I0826 15:35:23.718777 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11593 (* 1 = 9.11593 loss)
I0826 15:35:23.718781 25446 sgd_solver.cpp:138] Iteration 2530, lr = 0.001
I0826 15:35:25.788595 25446 solver.cpp:243] Iteration 2540, loss = 9.2637
I0826 15:35:25.788635 25446 solver.cpp:259]     Train net output #0: center_loss = 5.65111 (* 0.008 = 0.0452089 loss)
I0826 15:35:25.788640 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21849 (* 1 = 9.21849 loss)
I0826 15:35:25.788642 25446 sgd_solver.cpp:138] Iteration 2540, lr = 0.001
I0826 15:35:27.852283 25446 solver.cpp:243] Iteration 2550, loss = 9.22814
I0826 15:35:27.852306 25446 solver.cpp:259]     Train net output #0: center_loss = 5.32989 (* 0.008 = 0.0426391 loss)
I0826 15:35:27.852311 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1855 (* 1 = 9.1855 loss)
I0826 15:35:27.852315 25446 sgd_solver.cpp:138] Iteration 2550, lr = 0.001
I0826 15:35:29.917335 25446 solver.cpp:243] Iteration 2560, loss = 9.13241
I0826 15:35:29.917371 25446 solver.cpp:259]     Train net output #0: center_loss = 5.93106 (* 0.008 = 0.0474485 loss)
I0826 15:35:29.917377 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.08496 (* 1 = 9.08496 loss)
I0826 15:35:29.917381 25446 sgd_solver.cpp:138] Iteration 2560, lr = 0.001
I0826 15:35:31.979115 25446 solver.cpp:243] Iteration 2570, loss = 9.18901
I0826 15:35:31.979153 25446 solver.cpp:259]     Train net output #0: center_loss = 5.93282 (* 0.008 = 0.0474625 loss)
I0826 15:35:31.979159 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14155 (* 1 = 9.14155 loss)
I0826 15:35:31.979163 25446 sgd_solver.cpp:138] Iteration 2570, lr = 0.001
I0826 15:35:34.075131 25446 solver.cpp:243] Iteration 2580, loss = 9.21324
I0826 15:35:34.075158 25446 solver.cpp:259]     Train net output #0: center_loss = 7.08277 (* 0.008 = 0.0566622 loss)
I0826 15:35:34.075165 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15657 (* 1 = 9.15657 loss)
I0826 15:35:34.075168 25446 sgd_solver.cpp:138] Iteration 2580, lr = 0.001
I0826 15:35:36.163689 25446 solver.cpp:243] Iteration 2590, loss = 9.20575
I0826 15:35:36.163727 25446 solver.cpp:259]     Train net output #0: center_loss = 6.12859 (* 0.008 = 0.0490287 loss)
I0826 15:35:36.163733 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15672 (* 1 = 9.15672 loss)
I0826 15:35:36.163735 25446 sgd_solver.cpp:138] Iteration 2590, lr = 0.001
I0826 15:35:38.239920 25446 solver.cpp:243] Iteration 2600, loss = 9.17591
I0826 15:35:38.239959 25446 solver.cpp:259]     Train net output #0: center_loss = 5.90853 (* 0.008 = 0.0472683 loss)
I0826 15:35:38.239965 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.12864 (* 1 = 9.12864 loss)
I0826 15:35:38.239969 25446 sgd_solver.cpp:138] Iteration 2600, lr = 0.001
I0826 15:35:40.309810 25446 solver.cpp:243] Iteration 2610, loss = 9.16173
I0826 15:35:40.309834 25446 solver.cpp:259]     Train net output #0: center_loss = 6.13471 (* 0.008 = 0.0490777 loss)
I0826 15:35:40.309839 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11265 (* 1 = 9.11265 loss)
I0826 15:35:40.309842 25446 sgd_solver.cpp:138] Iteration 2610, lr = 0.001
I0826 15:35:42.379667 25446 solver.cpp:243] Iteration 2620, loss = 9.195
I0826 15:35:42.379705 25446 solver.cpp:259]     Train net output #0: center_loss = 6.02599 (* 0.008 = 0.0482079 loss)
I0826 15:35:42.379711 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1468 (* 1 = 9.1468 loss)
I0826 15:35:42.379715 25446 sgd_solver.cpp:138] Iteration 2620, lr = 0.001
I0826 15:35:44.445611 25446 solver.cpp:243] Iteration 2630, loss = 9.14752
I0826 15:35:44.445636 25446 solver.cpp:259]     Train net output #0: center_loss = 6.76345 (* 0.008 = 0.0541076 loss)
I0826 15:35:44.445642 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09341 (* 1 = 9.09341 loss)
I0826 15:35:44.445647 25446 sgd_solver.cpp:138] Iteration 2630, lr = 0.001
I0826 15:35:46.528921 25446 solver.cpp:243] Iteration 2640, loss = 9.15403
I0826 15:35:46.528961 25446 solver.cpp:259]     Train net output #0: center_loss = 7.5103 (* 0.008 = 0.0600824 loss)
I0826 15:35:46.528966 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09394 (* 1 = 9.09394 loss)
I0826 15:35:46.528970 25446 sgd_solver.cpp:138] Iteration 2640, lr = 0.001
I0826 15:35:48.591843 25446 solver.cpp:243] Iteration 2650, loss = 9.11849
I0826 15:35:48.591879 25446 solver.cpp:259]     Train net output #0: center_loss = 6.55269 (* 0.008 = 0.0524216 loss)
I0826 15:35:48.591886 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06607 (* 1 = 9.06607 loss)
I0826 15:35:48.591888 25446 sgd_solver.cpp:138] Iteration 2650, lr = 0.001
I0826 15:35:50.651954 25446 solver.cpp:243] Iteration 2660, loss = 9.16863
I0826 15:35:50.651978 25446 solver.cpp:259]     Train net output #0: center_loss = 5.60546 (* 0.008 = 0.0448436 loss)
I0826 15:35:50.651983 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.12379 (* 1 = 9.12379 loss)
I0826 15:35:50.651988 25446 sgd_solver.cpp:138] Iteration 2660, lr = 0.001
I0826 15:35:52.712126 25446 solver.cpp:243] Iteration 2670, loss = 9.0866
I0826 15:35:52.712262 25446 solver.cpp:259]     Train net output #0: center_loss = 6.2333 (* 0.008 = 0.0498664 loss)
I0826 15:35:52.712270 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.03674 (* 1 = 9.03674 loss)
I0826 15:35:52.712286 25446 sgd_solver.cpp:138] Iteration 2670, lr = 0.001
I0826 15:35:54.776563 25446 solver.cpp:243] Iteration 2680, loss = 9.04071
I0826 15:35:54.776600 25446 solver.cpp:259]     Train net output #0: center_loss = 6.57971 (* 0.008 = 0.0526377 loss)
I0826 15:35:54.776607 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98807 (* 1 = 8.98807 loss)
I0826 15:35:54.776609 25446 sgd_solver.cpp:138] Iteration 2680, lr = 0.001
I0826 15:35:56.836566 25446 solver.cpp:243] Iteration 2690, loss = 9.2215
I0826 15:35:56.836591 25446 solver.cpp:259]     Train net output #0: center_loss = 6.47414 (* 0.008 = 0.0517931 loss)
I0826 15:35:56.836596 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16971 (* 1 = 9.16971 loss)
I0826 15:35:56.836599 25446 sgd_solver.cpp:138] Iteration 2690, lr = 0.001
I0826 15:35:58.906046 25446 solver.cpp:243] Iteration 2700, loss = 9.15856
I0826 15:35:58.906085 25446 solver.cpp:259]     Train net output #0: center_loss = 6.13707 (* 0.008 = 0.0490966 loss)
I0826 15:35:58.906090 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10947 (* 1 = 9.10947 loss)
I0826 15:35:58.906093 25446 sgd_solver.cpp:138] Iteration 2700, lr = 0.001
I0826 15:36:01.002768 25446 solver.cpp:243] Iteration 2710, loss = 9.10337
I0826 15:36:01.002806 25446 solver.cpp:259]     Train net output #0: center_loss = 7.11435 (* 0.008 = 0.0569148 loss)
I0826 15:36:01.002812 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.04646 (* 1 = 9.04646 loss)
I0826 15:36:01.002815 25446 sgd_solver.cpp:138] Iteration 2710, lr = 0.001
I0826 15:36:03.097180 25446 solver.cpp:243] Iteration 2720, loss = 9.08332
I0826 15:36:03.097203 25446 solver.cpp:259]     Train net output #0: center_loss = 5.88243 (* 0.008 = 0.0470595 loss)
I0826 15:36:03.097223 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.03626 (* 1 = 9.03626 loss)
I0826 15:36:03.097226 25446 sgd_solver.cpp:138] Iteration 2720, lr = 0.001
I0826 15:36:05.157093 25446 solver.cpp:243] Iteration 2730, loss = 9.18205
I0826 15:36:05.157132 25446 solver.cpp:259]     Train net output #0: center_loss = 5.98816 (* 0.008 = 0.0479053 loss)
I0826 15:36:05.157138 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13414 (* 1 = 9.13414 loss)
I0826 15:36:05.157142 25446 sgd_solver.cpp:138] Iteration 2730, lr = 0.001
I0826 15:36:07.304934 25446 solver.cpp:243] Iteration 2740, loss = 9.13252
I0826 15:36:07.304971 25446 solver.cpp:259]     Train net output #0: center_loss = 6.98391 (* 0.008 = 0.0558713 loss)
I0826 15:36:07.304976 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07665 (* 1 = 9.07665 loss)
I0826 15:36:07.304980 25446 sgd_solver.cpp:138] Iteration 2740, lr = 0.001
I0826 15:36:09.373211 25446 solver.cpp:243] Iteration 2750, loss = 9.23528
I0826 15:36:09.373272 25446 solver.cpp:259]     Train net output #0: center_loss = 7.52925 (* 0.008 = 0.060234 loss)
I0826 15:36:09.373279 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.17505 (* 1 = 9.17505 loss)
I0826 15:36:09.373304 25446 sgd_solver.cpp:138] Iteration 2750, lr = 0.001
I0826 15:36:11.467788 25446 solver.cpp:243] Iteration 2760, loss = 9.15818
I0826 15:36:11.467810 25446 solver.cpp:259]     Train net output #0: center_loss = 6.67496 (* 0.008 = 0.0533997 loss)
I0826 15:36:11.467830 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10478 (* 1 = 9.10478 loss)
I0826 15:36:11.467834 25446 sgd_solver.cpp:138] Iteration 2760, lr = 0.001
I0826 15:36:13.533664 25446 solver.cpp:243] Iteration 2770, loss = 9.16426
I0826 15:36:13.533689 25446 solver.cpp:259]     Train net output #0: center_loss = 7.12123 (* 0.008 = 0.0569699 loss)
I0826 15:36:13.533694 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10729 (* 1 = 9.10729 loss)
I0826 15:36:13.533697 25446 sgd_solver.cpp:138] Iteration 2770, lr = 0.001
I0826 15:36:15.618602 25446 solver.cpp:243] Iteration 2780, loss = 9.20224
I0826 15:36:15.618625 25446 solver.cpp:259]     Train net output #0: center_loss = 5.64676 (* 0.008 = 0.0451741 loss)
I0826 15:36:15.618643 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15707 (* 1 = 9.15707 loss)
I0826 15:36:15.618646 25446 sgd_solver.cpp:138] Iteration 2780, lr = 0.001
I0826 15:36:17.700386 25446 solver.cpp:243] Iteration 2790, loss = 9.13905
I0826 15:36:17.700408 25446 solver.cpp:259]     Train net output #0: center_loss = 6.68606 (* 0.008 = 0.0534885 loss)
I0826 15:36:17.700414 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.08556 (* 1 = 9.08556 loss)
I0826 15:36:17.700418 25446 sgd_solver.cpp:138] Iteration 2790, lr = 0.001
I0826 15:36:19.765594 25446 solver.cpp:243] Iteration 2800, loss = 9.11161
I0826 15:36:19.765615 25446 solver.cpp:259]     Train net output #0: center_loss = 7.65212 (* 0.008 = 0.061217 loss)
I0826 15:36:19.765620 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.0504 (* 1 = 9.0504 loss)
I0826 15:36:19.765625 25446 sgd_solver.cpp:138] Iteration 2800, lr = 0.001
I0826 15:36:21.853767 25446 solver.cpp:243] Iteration 2810, loss = 9.16773
I0826 15:36:21.853792 25446 solver.cpp:259]     Train net output #0: center_loss = 6.93042 (* 0.008 = 0.0554433 loss)
I0826 15:36:21.853797 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11228 (* 1 = 9.11228 loss)
I0826 15:36:21.853801 25446 sgd_solver.cpp:138] Iteration 2810, lr = 0.001
I0826 15:36:23.987212 25446 solver.cpp:243] Iteration 2820, loss = 9.14822
I0826 15:36:23.987329 25446 solver.cpp:259]     Train net output #0: center_loss = 6.27936 (* 0.008 = 0.0502349 loss)
I0826 15:36:23.987335 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09799 (* 1 = 9.09799 loss)
I0826 15:36:23.987354 25446 sgd_solver.cpp:138] Iteration 2820, lr = 0.001
I0826 15:36:26.074481 25446 solver.cpp:243] Iteration 2830, loss = 9.1688
I0826 15:36:26.074532 25446 solver.cpp:259]     Train net output #0: center_loss = 7.20701 (* 0.008 = 0.0576561 loss)
I0826 15:36:26.074542 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11115 (* 1 = 9.11115 loss)
I0826 15:36:26.074548 25446 sgd_solver.cpp:138] Iteration 2830, lr = 0.001
I0826 15:36:28.151911 25446 solver.cpp:243] Iteration 2840, loss = 9.17373
I0826 15:36:28.151950 25446 solver.cpp:259]     Train net output #0: center_loss = 6.61004 (* 0.008 = 0.0528804 loss)
I0826 15:36:28.151955 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.12085 (* 1 = 9.12085 loss)
I0826 15:36:28.151959 25446 sgd_solver.cpp:138] Iteration 2840, lr = 0.001
I0826 15:36:30.230613 25446 solver.cpp:243] Iteration 2850, loss = 9.15988
I0826 15:36:30.230651 25446 solver.cpp:259]     Train net output #0: center_loss = 6.56609 (* 0.008 = 0.0525287 loss)
I0826 15:36:30.230657 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10735 (* 1 = 9.10735 loss)
I0826 15:36:30.230660 25446 sgd_solver.cpp:138] Iteration 2850, lr = 0.001
I0826 15:36:32.325131 25446 solver.cpp:243] Iteration 2860, loss = 9.07367
I0826 15:36:32.325170 25446 solver.cpp:259]     Train net output #0: center_loss = 7.11816 (* 0.008 = 0.0569453 loss)
I0826 15:36:32.325176 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.01673 (* 1 = 9.01673 loss)
I0826 15:36:32.325181 25446 sgd_solver.cpp:138] Iteration 2860, lr = 0.001
I0826 15:36:34.418211 25446 solver.cpp:243] Iteration 2870, loss = 9.16971
I0826 15:36:34.418251 25446 solver.cpp:259]     Train net output #0: center_loss = 7.44237 (* 0.008 = 0.059539 loss)
I0826 15:36:34.418257 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11017 (* 1 = 9.11017 loss)
I0826 15:36:34.418262 25446 sgd_solver.cpp:138] Iteration 2870, lr = 0.001
I0826 15:36:36.518115 25446 solver.cpp:243] Iteration 2880, loss = 9.14353
I0826 15:36:36.518138 25446 solver.cpp:259]     Train net output #0: center_loss = 5.2421 (* 0.008 = 0.0419368 loss)
I0826 15:36:36.518143 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1016 (* 1 = 9.1016 loss)
I0826 15:36:36.518148 25446 sgd_solver.cpp:138] Iteration 2880, lr = 0.001
I0826 15:36:38.616173 25446 solver.cpp:243] Iteration 2890, loss = 9.12997
I0826 15:36:38.616195 25446 solver.cpp:259]     Train net output #0: center_loss = 7.17539 (* 0.008 = 0.0574031 loss)
I0826 15:36:38.616201 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07257 (* 1 = 9.07257 loss)
I0826 15:36:38.616205 25446 sgd_solver.cpp:138] Iteration 2890, lr = 0.001
I0826 15:36:40.709564 25446 solver.cpp:243] Iteration 2900, loss = 9.06473
I0826 15:36:40.709589 25446 solver.cpp:259]     Train net output #0: center_loss = 7.10759 (* 0.008 = 0.0568607 loss)
I0826 15:36:40.709594 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00787 (* 1 = 9.00787 loss)
I0826 15:36:40.709597 25446 sgd_solver.cpp:138] Iteration 2900, lr = 0.001
I0826 15:36:42.786651 25446 solver.cpp:243] Iteration 2910, loss = 9.13175
I0826 15:36:42.786690 25446 solver.cpp:259]     Train net output #0: center_loss = 7.656 (* 0.008 = 0.061248 loss)
I0826 15:36:42.786696 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07051 (* 1 = 9.07051 loss)
I0826 15:36:42.786700 25446 sgd_solver.cpp:138] Iteration 2910, lr = 0.001
I0826 15:36:44.874603 25446 solver.cpp:243] Iteration 2920, loss = 9.16416
I0826 15:36:44.874625 25446 solver.cpp:259]     Train net output #0: center_loss = 7.70813 (* 0.008 = 0.0616651 loss)
I0826 15:36:44.874645 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10249 (* 1 = 9.10249 loss)
I0826 15:36:44.874650 25446 sgd_solver.cpp:138] Iteration 2920, lr = 0.001
I0826 15:36:46.977810 25446 solver.cpp:243] Iteration 2930, loss = 9.23295
I0826 15:36:46.977833 25446 solver.cpp:259]     Train net output #0: center_loss = 7.8061 (* 0.008 = 0.0624488 loss)
I0826 15:36:46.977839 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1705 (* 1 = 9.1705 loss)
I0826 15:36:46.977843 25446 sgd_solver.cpp:138] Iteration 2930, lr = 0.001
I0826 15:36:49.068219 25446 solver.cpp:243] Iteration 2940, loss = 9.09668
I0826 15:36:49.068256 25446 solver.cpp:259]     Train net output #0: center_loss = 7.18116 (* 0.008 = 0.0574493 loss)
I0826 15:36:49.068261 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.03923 (* 1 = 9.03923 loss)
I0826 15:36:49.068264 25446 sgd_solver.cpp:138] Iteration 2940, lr = 0.001
I0826 15:36:51.193379 25446 solver.cpp:243] Iteration 2950, loss = 9.19645
I0826 15:36:51.193405 25446 solver.cpp:259]     Train net output #0: center_loss = 6.87228 (* 0.008 = 0.0549782 loss)
I0826 15:36:51.193411 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14147 (* 1 = 9.14147 loss)
I0826 15:36:51.193415 25446 sgd_solver.cpp:138] Iteration 2950, lr = 0.001
I0826 15:36:53.357420 25446 solver.cpp:243] Iteration 2960, loss = 9.123
I0826 15:36:53.357458 25446 solver.cpp:259]     Train net output #0: center_loss = 8.33431 (* 0.008 = 0.0666745 loss)
I0826 15:36:53.357463 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05633 (* 1 = 9.05633 loss)
I0826 15:36:53.357467 25446 sgd_solver.cpp:138] Iteration 2960, lr = 0.001
I0826 15:36:55.531736 25446 solver.cpp:243] Iteration 2970, loss = 9.16061
I0826 15:36:55.531863 25446 solver.cpp:259]     Train net output #0: center_loss = 7.77864 (* 0.008 = 0.0622291 loss)
I0826 15:36:55.531870 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09838 (* 1 = 9.09838 loss)
I0826 15:36:55.531875 25446 sgd_solver.cpp:138] Iteration 2970, lr = 0.001
I0826 15:36:57.640362 25446 solver.cpp:243] Iteration 2980, loss = 9.12741
I0826 15:36:57.640385 25446 solver.cpp:259]     Train net output #0: center_loss = 9.52189 (* 0.008 = 0.0761751 loss)
I0826 15:36:57.640391 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05124 (* 1 = 9.05124 loss)
I0826 15:36:57.640395 25446 sgd_solver.cpp:138] Iteration 2980, lr = 0.001
I0826 15:36:59.721426 25446 solver.cpp:243] Iteration 2990, loss = 9.21692
I0826 15:36:59.721463 25446 solver.cpp:259]     Train net output #0: center_loss = 7.52896 (* 0.008 = 0.0602317 loss)
I0826 15:36:59.721468 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15668 (* 1 = 9.15668 loss)
I0826 15:36:59.721472 25446 sgd_solver.cpp:138] Iteration 2990, lr = 0.001
I0826 15:37:01.622448 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_3000.caffemodel
I0826 15:37:02.787883 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_3000.solverstate
I0826 15:37:03.122344 25446 solver.cpp:243] Iteration 3000, loss = 9.14145
I0826 15:37:03.122383 25446 solver.cpp:259]     Train net output #0: center_loss = 8.94662 (* 0.008 = 0.0715729 loss)
I0826 15:37:03.122390 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06988 (* 1 = 9.06988 loss)
I0826 15:37:03.122395 25446 sgd_solver.cpp:138] Iteration 3000, lr = 0.001
I0826 15:37:05.188167 25446 solver.cpp:243] Iteration 3010, loss = 9.152
I0826 15:37:05.188205 25446 solver.cpp:259]     Train net output #0: center_loss = 7.73175 (* 0.008 = 0.061854 loss)
I0826 15:37:05.188212 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09015 (* 1 = 9.09015 loss)
I0826 15:37:05.188215 25446 sgd_solver.cpp:138] Iteration 3010, lr = 0.001
I0826 15:37:07.335456 25446 solver.cpp:243] Iteration 3020, loss = 9.22429
I0826 15:37:07.335494 25446 solver.cpp:259]     Train net output #0: center_loss = 7.60581 (* 0.008 = 0.0608465 loss)
I0826 15:37:07.335500 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.16344 (* 1 = 9.16344 loss)
I0826 15:37:07.335503 25446 sgd_solver.cpp:138] Iteration 3020, lr = 0.001
I0826 15:37:09.422482 25446 solver.cpp:243] Iteration 3030, loss = 9.08455
I0826 15:37:09.422505 25446 solver.cpp:259]     Train net output #0: center_loss = 7.69447 (* 0.008 = 0.0615558 loss)
I0826 15:37:09.422526 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.023 (* 1 = 9.023 loss)
I0826 15:37:09.422530 25446 sgd_solver.cpp:138] Iteration 3030, lr = 0.001
I0826 15:37:11.488227 25446 solver.cpp:243] Iteration 3040, loss = 9.12441
I0826 15:37:11.488266 25446 solver.cpp:259]     Train net output #0: center_loss = 8.23113 (* 0.008 = 0.0658491 loss)
I0826 15:37:11.488287 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05856 (* 1 = 9.05856 loss)
I0826 15:37:11.488291 25446 sgd_solver.cpp:138] Iteration 3040, lr = 0.001
I0826 15:37:13.555614 25446 solver.cpp:243] Iteration 3050, loss = 9.17189
I0826 15:37:13.555652 25446 solver.cpp:259]     Train net output #0: center_loss = 7.56493 (* 0.008 = 0.0605194 loss)
I0826 15:37:13.555657 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11137 (* 1 = 9.11137 loss)
I0826 15:37:13.555660 25446 sgd_solver.cpp:138] Iteration 3050, lr = 0.001
I0826 15:37:15.621932 25446 solver.cpp:243] Iteration 3060, loss = 9.2038
I0826 15:37:15.621971 25446 solver.cpp:259]     Train net output #0: center_loss = 9.01999 (* 0.008 = 0.07216 loss)
I0826 15:37:15.621978 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13164 (* 1 = 9.13164 loss)
I0826 15:37:15.621984 25446 sgd_solver.cpp:138] Iteration 3060, lr = 0.001
I0826 15:37:17.684922 25446 solver.cpp:243] Iteration 3070, loss = 9.09674
I0826 15:37:17.684960 25446 solver.cpp:259]     Train net output #0: center_loss = 8.17575 (* 0.008 = 0.065406 loss)
I0826 15:37:17.685019 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.03133 (* 1 = 9.03133 loss)
I0826 15:37:17.685022 25446 sgd_solver.cpp:138] Iteration 3070, lr = 0.001
I0826 15:37:19.768816 25446 solver.cpp:243] Iteration 3080, loss = 9.12312
I0826 15:37:19.768838 25446 solver.cpp:259]     Train net output #0: center_loss = 8.82546 (* 0.008 = 0.0706037 loss)
I0826 15:37:19.768843 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05252 (* 1 = 9.05252 loss)
I0826 15:37:19.768847 25446 sgd_solver.cpp:138] Iteration 3080, lr = 0.001
I0826 15:37:21.906143 25446 solver.cpp:243] Iteration 3090, loss = 9.12627
I0826 15:37:21.906181 25446 solver.cpp:259]     Train net output #0: center_loss = 9.40811 (* 0.008 = 0.0752649 loss)
I0826 15:37:21.906186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.051 (* 1 = 9.051 loss)
I0826 15:37:21.906190 25446 sgd_solver.cpp:138] Iteration 3090, lr = 0.001
I0826 15:37:23.986605 25446 solver.cpp:243] Iteration 3100, loss = 9.05888
I0826 15:37:23.986627 25446 solver.cpp:259]     Train net output #0: center_loss = 9.4999 (* 0.008 = 0.0759992 loss)
I0826 15:37:23.986647 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98288 (* 1 = 8.98288 loss)
I0826 15:37:23.986650 25446 sgd_solver.cpp:138] Iteration 3100, lr = 0.001
I0826 15:37:26.100944 25446 solver.cpp:243] Iteration 3110, loss = 9.16607
I0826 15:37:26.101058 25446 solver.cpp:259]     Train net output #0: center_loss = 7.56162 (* 0.008 = 0.0604929 loss)
I0826 15:37:26.101065 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10558 (* 1 = 9.10558 loss)
I0826 15:37:26.101083 25446 sgd_solver.cpp:138] Iteration 3110, lr = 0.001
I0826 15:37:28.246289 25446 solver.cpp:243] Iteration 3120, loss = 9.14623
I0826 15:37:28.246315 25446 solver.cpp:259]     Train net output #0: center_loss = 7.24829 (* 0.008 = 0.0579864 loss)
I0826 15:37:28.246320 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.08824 (* 1 = 9.08824 loss)
I0826 15:37:28.246325 25446 sgd_solver.cpp:138] Iteration 3120, lr = 0.001
I0826 15:37:30.322579 25446 solver.cpp:243] Iteration 3130, loss = 9.18727
I0826 15:37:30.322618 25446 solver.cpp:259]     Train net output #0: center_loss = 6.76592 (* 0.008 = 0.0541274 loss)
I0826 15:37:30.322623 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13314 (* 1 = 9.13314 loss)
I0826 15:37:30.322626 25446 sgd_solver.cpp:138] Iteration 3130, lr = 0.001
I0826 15:37:32.475587 25446 solver.cpp:243] Iteration 3140, loss = 9.10745
I0826 15:37:32.475625 25446 solver.cpp:259]     Train net output #0: center_loss = 7.16271 (* 0.008 = 0.0573017 loss)
I0826 15:37:32.475630 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05015 (* 1 = 9.05015 loss)
I0826 15:37:32.475634 25446 sgd_solver.cpp:138] Iteration 3140, lr = 0.001
I0826 15:37:34.565757 25446 solver.cpp:243] Iteration 3150, loss = 9.04765
I0826 15:37:34.565779 25446 solver.cpp:259]     Train net output #0: center_loss = 8.27223 (* 0.008 = 0.0661779 loss)
I0826 15:37:34.565785 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98147 (* 1 = 8.98147 loss)
I0826 15:37:34.565789 25446 sgd_solver.cpp:138] Iteration 3150, lr = 0.001
I0826 15:37:36.630331 25446 solver.cpp:243] Iteration 3160, loss = 9.13723
I0826 15:37:36.630368 25446 solver.cpp:259]     Train net output #0: center_loss = 8.47112 (* 0.008 = 0.0677689 loss)
I0826 15:37:36.630374 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06946 (* 1 = 9.06946 loss)
I0826 15:37:36.630378 25446 sgd_solver.cpp:138] Iteration 3160, lr = 0.001
I0826 15:37:38.690697 25446 solver.cpp:243] Iteration 3170, loss = 9.1047
I0826 15:37:38.690735 25446 solver.cpp:259]     Train net output #0: center_loss = 9.58746 (* 0.008 = 0.0766997 loss)
I0826 15:37:38.690742 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.028 (* 1 = 9.028 loss)
I0826 15:37:38.690745 25446 sgd_solver.cpp:138] Iteration 3170, lr = 0.001
I0826 15:37:40.796110 25446 solver.cpp:243] Iteration 3180, loss = 9.08088
I0826 15:37:40.796136 25446 solver.cpp:259]     Train net output #0: center_loss = 10.4214 (* 0.008 = 0.083371 loss)
I0826 15:37:40.796142 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.99751 (* 1 = 8.99751 loss)
I0826 15:37:40.796147 25446 sgd_solver.cpp:138] Iteration 3180, lr = 0.001
I0826 15:37:42.960294 25446 solver.cpp:243] Iteration 3190, loss = 9.11748
I0826 15:37:42.960319 25446 solver.cpp:259]     Train net output #0: center_loss = 9.62996 (* 0.008 = 0.0770397 loss)
I0826 15:37:42.960325 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.04044 (* 1 = 9.04044 loss)
I0826 15:37:42.960330 25446 sgd_solver.cpp:138] Iteration 3190, lr = 0.001
I0826 15:37:45.039053 25446 solver.cpp:243] Iteration 3200, loss = 9.1039
I0826 15:37:45.039091 25446 solver.cpp:259]     Train net output #0: center_loss = 10.6516 (* 0.008 = 0.0852131 loss)
I0826 15:37:45.039098 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.01869 (* 1 = 9.01869 loss)
I0826 15:37:45.039100 25446 sgd_solver.cpp:138] Iteration 3200, lr = 0.001
I0826 15:37:47.139560 25446 solver.cpp:243] Iteration 3210, loss = 9.16986
I0826 15:37:47.139585 25446 solver.cpp:259]     Train net output #0: center_loss = 10.3845 (* 0.008 = 0.083076 loss)
I0826 15:37:47.139590 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.08678 (* 1 = 9.08678 loss)
I0826 15:37:47.139593 25446 sgd_solver.cpp:138] Iteration 3210, lr = 0.001
I0826 15:37:49.224184 25446 solver.cpp:243] Iteration 3220, loss = 9.20252
I0826 15:37:49.224221 25446 solver.cpp:259]     Train net output #0: center_loss = 9.21934 (* 0.008 = 0.0737547 loss)
I0826 15:37:49.224227 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.12877 (* 1 = 9.12877 loss)
I0826 15:37:49.224231 25446 sgd_solver.cpp:138] Iteration 3220, lr = 0.001
I0826 15:37:51.503283 25446 solver.cpp:243] Iteration 3230, loss = 9.1629
I0826 15:37:51.503309 25446 solver.cpp:259]     Train net output #0: center_loss = 7.58107 (* 0.008 = 0.0606486 loss)
I0826 15:37:51.503314 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10225 (* 1 = 9.10225 loss)
I0826 15:37:51.503319 25446 sgd_solver.cpp:138] Iteration 3230, lr = 0.001
I0826 15:37:53.773880 25446 solver.cpp:243] Iteration 3240, loss = 9.08533
I0826 15:37:53.773918 25446 solver.cpp:259]     Train net output #0: center_loss = 9.7929 (* 0.008 = 0.0783432 loss)
I0826 15:37:53.773924 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00699 (* 1 = 9.00699 loss)
I0826 15:37:53.773927 25446 sgd_solver.cpp:138] Iteration 3240, lr = 0.001
I0826 15:37:55.910300 25446 solver.cpp:243] Iteration 3250, loss = 9.18288
I0826 15:37:55.910323 25446 solver.cpp:259]     Train net output #0: center_loss = 9.56709 (* 0.008 = 0.0765367 loss)
I0826 15:37:55.910328 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10634 (* 1 = 9.10634 loss)
I0826 15:37:55.910333 25446 sgd_solver.cpp:138] Iteration 3250, lr = 0.001
I0826 15:37:58.015533 25446 solver.cpp:243] Iteration 3260, loss = 9.11952
I0826 15:37:58.015645 25446 solver.cpp:259]     Train net output #0: center_loss = 9.4785 (* 0.008 = 0.075828 loss)
I0826 15:37:58.015651 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.04369 (* 1 = 9.04369 loss)
I0826 15:37:58.015656 25446 sgd_solver.cpp:138] Iteration 3260, lr = 0.001
I0826 15:38:00.140424 25446 solver.cpp:243] Iteration 3270, loss = 9.18956
I0826 15:38:00.140446 25446 solver.cpp:259]     Train net output #0: center_loss = 10.9984 (* 0.008 = 0.0879872 loss)
I0826 15:38:00.140452 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.10157 (* 1 = 9.10157 loss)
I0826 15:38:00.140457 25446 sgd_solver.cpp:138] Iteration 3270, lr = 0.001
I0826 15:38:02.271407 25446 solver.cpp:243] Iteration 3280, loss = 9.14463
I0826 15:38:02.271430 25446 solver.cpp:259]     Train net output #0: center_loss = 11.468 (* 0.008 = 0.0917439 loss)
I0826 15:38:02.271451 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05288 (* 1 = 9.05288 loss)
I0826 15:38:02.271456 25446 sgd_solver.cpp:138] Iteration 3280, lr = 0.001
I0826 15:38:04.370523 25446 solver.cpp:243] Iteration 3290, loss = 9.19202
I0826 15:38:04.370561 25446 solver.cpp:259]     Train net output #0: center_loss = 9.2128 (* 0.008 = 0.0737024 loss)
I0826 15:38:04.370566 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.11832 (* 1 = 9.11832 loss)
I0826 15:38:04.370570 25446 sgd_solver.cpp:138] Iteration 3290, lr = 0.001
I0826 15:38:06.585772 25446 solver.cpp:243] Iteration 3300, loss = 9.16696
I0826 15:38:06.585798 25446 solver.cpp:259]     Train net output #0: center_loss = 9.49801 (* 0.008 = 0.0759841 loss)
I0826 15:38:06.585803 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09098 (* 1 = 9.09098 loss)
I0826 15:38:06.585808 25446 sgd_solver.cpp:138] Iteration 3300, lr = 0.001
I0826 15:38:08.717213 25446 solver.cpp:243] Iteration 3310, loss = 9.12404
I0826 15:38:08.717237 25446 solver.cpp:259]     Train net output #0: center_loss = 9.18992 (* 0.008 = 0.0735193 loss)
I0826 15:38:08.717242 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05052 (* 1 = 9.05052 loss)
I0826 15:38:08.717250 25446 sgd_solver.cpp:138] Iteration 3310, lr = 0.001
I0826 15:38:10.802706 25446 solver.cpp:243] Iteration 3320, loss = 9.09807
I0826 15:38:10.802742 25446 solver.cpp:259]     Train net output #0: center_loss = 11.8102 (* 0.008 = 0.0944813 loss)
I0826 15:38:10.802748 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00359 (* 1 = 9.00359 loss)
I0826 15:38:10.802752 25446 sgd_solver.cpp:138] Iteration 3320, lr = 0.001
I0826 15:38:12.866905 25446 solver.cpp:243] Iteration 3330, loss = 9.16633
I0826 15:38:12.866943 25446 solver.cpp:259]     Train net output #0: center_loss = 11.8795 (* 0.008 = 0.0950362 loss)
I0826 15:38:12.866948 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07129 (* 1 = 9.07129 loss)
I0826 15:38:12.866952 25446 sgd_solver.cpp:138] Iteration 3330, lr = 0.001
I0826 15:38:14.968618 25446 solver.cpp:243] Iteration 3340, loss = 9.17247
I0826 15:38:14.968657 25446 solver.cpp:259]     Train net output #0: center_loss = 13.1512 (* 0.008 = 0.10521 loss)
I0826 15:38:14.968662 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06726 (* 1 = 9.06726 loss)
I0826 15:38:14.968665 25446 sgd_solver.cpp:138] Iteration 3340, lr = 0.001
I0826 15:38:17.120218 25446 solver.cpp:243] Iteration 3350, loss = 9.08591
I0826 15:38:17.120246 25446 solver.cpp:259]     Train net output #0: center_loss = 12.011 (* 0.008 = 0.0960883 loss)
I0826 15:38:17.120252 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98982 (* 1 = 8.98982 loss)
I0826 15:38:17.120257 25446 sgd_solver.cpp:138] Iteration 3350, lr = 0.001
I0826 15:38:19.356864 25446 solver.cpp:243] Iteration 3360, loss = 9.22557
I0826 15:38:19.356889 25446 solver.cpp:259]     Train net output #0: center_loss = 8.45772 (* 0.008 = 0.0676618 loss)
I0826 15:38:19.356894 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15791 (* 1 = 9.15791 loss)
I0826 15:38:19.356899 25446 sgd_solver.cpp:138] Iteration 3360, lr = 0.001
I0826 15:38:21.485002 25446 solver.cpp:243] Iteration 3370, loss = 9.11364
I0826 15:38:21.485038 25446 solver.cpp:259]     Train net output #0: center_loss = 11.5115 (* 0.008 = 0.0920918 loss)
I0826 15:38:21.485044 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.02155 (* 1 = 9.02155 loss)
I0826 15:38:21.485049 25446 sgd_solver.cpp:138] Iteration 3370, lr = 0.001
I0826 15:38:23.549309 25446 solver.cpp:243] Iteration 3380, loss = 9.06901
I0826 15:38:23.549346 25446 solver.cpp:259]     Train net output #0: center_loss = 11.1508 (* 0.008 = 0.0892063 loss)
I0826 15:38:23.549352 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.9798 (* 1 = 8.9798 loss)
I0826 15:38:23.549356 25446 sgd_solver.cpp:138] Iteration 3380, lr = 0.001
I0826 15:38:25.687047 25446 solver.cpp:243] Iteration 3390, loss = 9.14695
I0826 15:38:25.687086 25446 solver.cpp:259]     Train net output #0: center_loss = 10.3983 (* 0.008 = 0.0831861 loss)
I0826 15:38:25.687093 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06376 (* 1 = 9.06376 loss)
I0826 15:38:25.687096 25446 sgd_solver.cpp:138] Iteration 3390, lr = 0.001
I0826 15:38:27.785085 25446 solver.cpp:243] Iteration 3400, loss = 9.01145
I0826 15:38:27.785109 25446 solver.cpp:259]     Train net output #0: center_loss = 11.3279 (* 0.008 = 0.090623 loss)
I0826 15:38:27.785115 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.92083 (* 1 = 8.92083 loss)
I0826 15:38:27.785120 25446 sgd_solver.cpp:138] Iteration 3400, lr = 0.001
I0826 15:38:29.904904 25446 solver.cpp:243] Iteration 3410, loss = 9.22171
I0826 15:38:29.905043 25446 solver.cpp:259]     Train net output #0: center_loss = 9.26196 (* 0.008 = 0.0740957 loss)
I0826 15:38:29.905062 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14761 (* 1 = 9.14761 loss)
I0826 15:38:29.905066 25446 sgd_solver.cpp:138] Iteration 3410, lr = 0.001
I0826 15:38:32.025635 25446 solver.cpp:243] Iteration 3420, loss = 9.29965
I0826 15:38:32.025671 25446 solver.cpp:259]     Train net output #0: center_loss = 9.96373 (* 0.008 = 0.0797099 loss)
I0826 15:38:32.025676 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.21994 (* 1 = 9.21994 loss)
I0826 15:38:32.025681 25446 sgd_solver.cpp:138] Iteration 3420, lr = 0.001
I0826 15:38:34.089185 25446 solver.cpp:243] Iteration 3430, loss = 9.13519
I0826 15:38:34.089222 25446 solver.cpp:259]     Train net output #0: center_loss = 9.81624 (* 0.008 = 0.0785299 loss)
I0826 15:38:34.089228 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05666 (* 1 = 9.05666 loss)
I0826 15:38:34.089231 25446 sgd_solver.cpp:138] Iteration 3430, lr = 0.001
I0826 15:38:36.150307 25446 solver.cpp:243] Iteration 3440, loss = 9.19725
I0826 15:38:36.150331 25446 solver.cpp:259]     Train net output #0: center_loss = 9.45586 (* 0.008 = 0.0756469 loss)
I0826 15:38:36.150336 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.1216 (* 1 = 9.1216 loss)
I0826 15:38:36.150339 25446 sgd_solver.cpp:138] Iteration 3440, lr = 0.001
I0826 15:38:38.214304 25446 solver.cpp:243] Iteration 3450, loss = 9.11563
I0826 15:38:38.214342 25446 solver.cpp:259]     Train net output #0: center_loss = 9.25909 (* 0.008 = 0.0740727 loss)
I0826 15:38:38.214349 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.04156 (* 1 = 9.04156 loss)
I0826 15:38:38.214351 25446 sgd_solver.cpp:138] Iteration 3450, lr = 0.001
I0826 15:38:40.324491 25446 solver.cpp:243] Iteration 3460, loss = 9.11147
I0826 15:38:40.324530 25446 solver.cpp:259]     Train net output #0: center_loss = 9.69129 (* 0.008 = 0.0775304 loss)
I0826 15:38:40.324535 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.03394 (* 1 = 9.03394 loss)
I0826 15:38:40.324540 25446 sgd_solver.cpp:138] Iteration 3460, lr = 0.001
I0826 15:38:42.410487 25446 solver.cpp:243] Iteration 3470, loss = 8.98535
I0826 15:38:42.410511 25446 solver.cpp:259]     Train net output #0: center_loss = 10.7692 (* 0.008 = 0.086154 loss)
I0826 15:38:42.410516 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.89919 (* 1 = 8.89919 loss)
I0826 15:38:42.410521 25446 sgd_solver.cpp:138] Iteration 3470, lr = 0.001
I0826 15:38:44.505193 25446 solver.cpp:243] Iteration 3480, loss = 9.08678
I0826 15:38:44.505230 25446 solver.cpp:259]     Train net output #0: center_loss = 9.28626 (* 0.008 = 0.0742901 loss)
I0826 15:38:44.505236 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.01249 (* 1 = 9.01249 loss)
I0826 15:38:44.505240 25446 sgd_solver.cpp:138] Iteration 3480, lr = 0.001
I0826 15:38:46.569387 25446 solver.cpp:243] Iteration 3490, loss = 9.24186
I0826 15:38:46.569425 25446 solver.cpp:259]     Train net output #0: center_loss = 10.8014 (* 0.008 = 0.0864116 loss)
I0826 15:38:46.569430 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.15545 (* 1 = 9.15545 loss)
I0826 15:38:46.569433 25446 sgd_solver.cpp:138] Iteration 3490, lr = 0.001
I0826 15:38:48.708072 25446 solver.cpp:243] Iteration 3500, loss = 9.23335
I0826 15:38:48.708096 25446 solver.cpp:259]     Train net output #0: center_loss = 13.2356 (* 0.008 = 0.105885 loss)
I0826 15:38:48.708102 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.12747 (* 1 = 9.12747 loss)
I0826 15:38:48.708106 25446 sgd_solver.cpp:138] Iteration 3500, lr = 0.001
I0826 15:38:50.775017 25446 solver.cpp:243] Iteration 3510, loss = 8.99099
I0826 15:38:50.775053 25446 solver.cpp:259]     Train net output #0: center_loss = 10.0814 (* 0.008 = 0.0806512 loss)
I0826 15:38:50.775059 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.91034 (* 1 = 8.91034 loss)
I0826 15:38:50.775063 25446 sgd_solver.cpp:138] Iteration 3510, lr = 0.001
I0826 15:38:52.842919 25446 solver.cpp:243] Iteration 3520, loss = 9.07226
I0826 15:38:52.842958 25446 solver.cpp:259]     Train net output #0: center_loss = 13.7782 (* 0.008 = 0.110225 loss)
I0826 15:38:52.842964 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96203 (* 1 = 8.96203 loss)
I0826 15:38:52.842969 25446 sgd_solver.cpp:138] Iteration 3520, lr = 0.001
I0826 15:38:54.909893 25446 solver.cpp:243] Iteration 3530, loss = 9.08421
I0826 15:38:54.909931 25446 solver.cpp:259]     Train net output #0: center_loss = 10.8798 (* 0.008 = 0.0870388 loss)
I0826 15:38:54.909936 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.99717 (* 1 = 8.99717 loss)
I0826 15:38:54.909940 25446 sgd_solver.cpp:138] Iteration 3530, lr = 0.001
I0826 15:38:56.989500 25446 solver.cpp:243] Iteration 3540, loss = 9.13902
I0826 15:38:56.989537 25446 solver.cpp:259]     Train net output #0: center_loss = 10.897 (* 0.008 = 0.0871763 loss)
I0826 15:38:56.989542 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05184 (* 1 = 9.05184 loss)
I0826 15:38:56.989547 25446 sgd_solver.cpp:138] Iteration 3540, lr = 0.001
I0826 15:38:59.074550 25446 solver.cpp:243] Iteration 3550, loss = 9.14556
I0826 15:38:59.074587 25446 solver.cpp:259]     Train net output #0: center_loss = 11.4814 (* 0.008 = 0.0918511 loss)
I0826 15:38:59.074594 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05371 (* 1 = 9.05371 loss)
I0826 15:38:59.074596 25446 sgd_solver.cpp:138] Iteration 3550, lr = 0.001
I0826 15:39:01.158792 25446 solver.cpp:243] Iteration 3560, loss = 9.16814
I0826 15:39:01.158905 25446 solver.cpp:259]     Train net output #0: center_loss = 11.0737 (* 0.008 = 0.0885892 loss)
I0826 15:39:01.158911 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07955 (* 1 = 9.07955 loss)
I0826 15:39:01.158916 25446 sgd_solver.cpp:138] Iteration 3560, lr = 0.001
I0826 15:39:03.226158 25446 solver.cpp:243] Iteration 3570, loss = 9.20616
I0826 15:39:03.226181 25446 solver.cpp:259]     Train net output #0: center_loss = 7.96222 (* 0.008 = 0.0636978 loss)
I0826 15:39:03.226186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14246 (* 1 = 9.14246 loss)
I0826 15:39:03.226191 25446 sgd_solver.cpp:138] Iteration 3570, lr = 0.001
I0826 15:39:05.295617 25446 solver.cpp:243] Iteration 3580, loss = 9.04035
I0826 15:39:05.295655 25446 solver.cpp:259]     Train net output #0: center_loss = 10.183 (* 0.008 = 0.0814641 loss)
I0826 15:39:05.295660 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.95889 (* 1 = 8.95889 loss)
I0826 15:39:05.295663 25446 sgd_solver.cpp:138] Iteration 3580, lr = 0.001
I0826 15:39:07.361845 25446 solver.cpp:243] Iteration 3590, loss = 8.97943
I0826 15:39:07.361868 25446 solver.cpp:259]     Train net output #0: center_loss = 12.7275 (* 0.008 = 0.10182 loss)
I0826 15:39:07.361873 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87761 (* 1 = 8.87761 loss)
I0826 15:39:07.361877 25446 sgd_solver.cpp:138] Iteration 3590, lr = 0.001
I0826 15:39:09.469735 25446 solver.cpp:243] Iteration 3600, loss = 9.09727
I0826 15:39:09.469761 25446 solver.cpp:259]     Train net output #0: center_loss = 12.0481 (* 0.008 = 0.0963845 loss)
I0826 15:39:09.469768 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00089 (* 1 = 9.00089 loss)
I0826 15:39:09.469772 25446 sgd_solver.cpp:138] Iteration 3600, lr = 0.001
I0826 15:39:11.571677 25446 solver.cpp:243] Iteration 3610, loss = 9.17738
I0826 15:39:11.571715 25446 solver.cpp:259]     Train net output #0: center_loss = 13.1297 (* 0.008 = 0.105038 loss)
I0826 15:39:11.571722 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07234 (* 1 = 9.07234 loss)
I0826 15:39:11.571725 25446 sgd_solver.cpp:138] Iteration 3610, lr = 0.001
I0826 15:39:13.711069 25446 solver.cpp:243] Iteration 3620, loss = 9.1027
I0826 15:39:13.711112 25446 solver.cpp:259]     Train net output #0: center_loss = 14.0694 (* 0.008 = 0.112556 loss)
I0826 15:39:13.711117 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.99014 (* 1 = 8.99014 loss)
I0826 15:39:13.711122 25446 sgd_solver.cpp:138] Iteration 3620, lr = 0.001
I0826 15:39:15.783566 25446 solver.cpp:243] Iteration 3630, loss = 9.11596
I0826 15:39:15.783588 25446 solver.cpp:259]     Train net output #0: center_loss = 10.6707 (* 0.008 = 0.0853657 loss)
I0826 15:39:15.783593 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.0306 (* 1 = 9.0306 loss)
I0826 15:39:15.783597 25446 sgd_solver.cpp:138] Iteration 3630, lr = 0.001
I0826 15:39:17.847147 25446 solver.cpp:243] Iteration 3640, loss = 9.12644
I0826 15:39:17.847184 25446 solver.cpp:259]     Train net output #0: center_loss = 9.01278 (* 0.008 = 0.0721023 loss)
I0826 15:39:17.847189 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05434 (* 1 = 9.05434 loss)
I0826 15:39:17.847193 25446 sgd_solver.cpp:138] Iteration 3640, lr = 0.001
I0826 15:39:19.916119 25446 solver.cpp:243] Iteration 3650, loss = 9.11211
I0826 15:39:19.916155 25446 solver.cpp:259]     Train net output #0: center_loss = 10.833 (* 0.008 = 0.0866639 loss)
I0826 15:39:19.916162 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.02544 (* 1 = 9.02544 loss)
I0826 15:39:19.916165 25446 sgd_solver.cpp:138] Iteration 3650, lr = 0.001
I0826 15:39:21.980057 25446 solver.cpp:243] Iteration 3660, loss = 9.17357
I0826 15:39:21.980094 25446 solver.cpp:259]     Train net output #0: center_loss = 10.8751 (* 0.008 = 0.0870005 loss)
I0826 15:39:21.980099 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.08657 (* 1 = 9.08657 loss)
I0826 15:39:21.980103 25446 sgd_solver.cpp:138] Iteration 3660, lr = 0.001
I0826 15:39:24.050156 25446 solver.cpp:243] Iteration 3670, loss = 9.17786
I0826 15:39:24.050194 25446 solver.cpp:259]     Train net output #0: center_loss = 10.6327 (* 0.008 = 0.0850615 loss)
I0826 15:39:24.050199 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.0928 (* 1 = 9.0928 loss)
I0826 15:39:24.050204 25446 sgd_solver.cpp:138] Iteration 3670, lr = 0.001
I0826 15:39:26.123471 25446 solver.cpp:243] Iteration 3680, loss = 9.22446
I0826 15:39:26.123507 25446 solver.cpp:259]     Train net output #0: center_loss = 11.4313 (* 0.008 = 0.0914504 loss)
I0826 15:39:26.123513 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13301 (* 1 = 9.13301 loss)
I0826 15:39:26.123517 25446 sgd_solver.cpp:138] Iteration 3680, lr = 0.001
I0826 15:39:28.221943 25446 solver.cpp:243] Iteration 3690, loss = 9.18227
I0826 15:39:28.221968 25446 solver.cpp:259]     Train net output #0: center_loss = 11.631 (* 0.008 = 0.0930481 loss)
I0826 15:39:28.221974 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.08922 (* 1 = 9.08922 loss)
I0826 15:39:28.221978 25446 sgd_solver.cpp:138] Iteration 3690, lr = 0.001
I0826 15:39:30.335521 25446 solver.cpp:243] Iteration 3700, loss = 9.06622
I0826 15:39:30.335546 25446 solver.cpp:259]     Train net output #0: center_loss = 12.3339 (* 0.008 = 0.0986716 loss)
I0826 15:39:30.335551 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96755 (* 1 = 8.96755 loss)
I0826 15:39:30.335556 25446 sgd_solver.cpp:138] Iteration 3700, lr = 0.001
I0826 15:39:32.408226 25446 solver.cpp:243] Iteration 3710, loss = 8.89374
I0826 15:39:32.408355 25446 solver.cpp:259]     Train net output #0: center_loss = 12.7047 (* 0.008 = 0.101638 loss)
I0826 15:39:32.408362 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.7921 (* 1 = 8.7921 loss)
I0826 15:39:32.408366 25446 sgd_solver.cpp:138] Iteration 3710, lr = 0.001
I0826 15:39:34.493436 25446 solver.cpp:243] Iteration 3720, loss = 9.04222
I0826 15:39:34.493460 25446 solver.cpp:259]     Train net output #0: center_loss = 11.5571 (* 0.008 = 0.0924564 loss)
I0826 15:39:34.493481 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.94976 (* 1 = 8.94976 loss)
I0826 15:39:34.493485 25446 sgd_solver.cpp:138] Iteration 3720, lr = 0.001
I0826 15:39:36.603144 25446 solver.cpp:243] Iteration 3730, loss = 9.07448
I0826 15:39:36.603181 25446 solver.cpp:259]     Train net output #0: center_loss = 11.3928 (* 0.008 = 0.0911423 loss)
I0826 15:39:36.603188 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98334 (* 1 = 8.98334 loss)
I0826 15:39:36.603191 25446 sgd_solver.cpp:138] Iteration 3730, lr = 0.001
I0826 15:39:38.728193 25446 solver.cpp:243] Iteration 3740, loss = 9.16481
I0826 15:39:38.728216 25446 solver.cpp:259]     Train net output #0: center_loss = 8.78264 (* 0.008 = 0.0702611 loss)
I0826 15:39:38.728222 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.09455 (* 1 = 9.09455 loss)
I0826 15:39:38.728226 25446 sgd_solver.cpp:138] Iteration 3740, lr = 0.001
I0826 15:39:40.830530 25446 solver.cpp:243] Iteration 3750, loss = 9.06385
I0826 15:39:40.830570 25446 solver.cpp:259]     Train net output #0: center_loss = 11.7851 (* 0.008 = 0.0942811 loss)
I0826 15:39:40.830577 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96957 (* 1 = 8.96957 loss)
I0826 15:39:40.830582 25446 sgd_solver.cpp:138] Iteration 3750, lr = 0.001
I0826 15:39:42.901410 25446 solver.cpp:243] Iteration 3760, loss = 9.08009
I0826 15:39:42.901448 25446 solver.cpp:259]     Train net output #0: center_loss = 13.0062 (* 0.008 = 0.10405 loss)
I0826 15:39:42.901455 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97604 (* 1 = 8.97604 loss)
I0826 15:39:42.901458 25446 sgd_solver.cpp:138] Iteration 3760, lr = 0.001
I0826 15:39:44.972636 25446 solver.cpp:243] Iteration 3770, loss = 9.23886
I0826 15:39:44.972674 25446 solver.cpp:259]     Train net output #0: center_loss = 12.6751 (* 0.008 = 0.1014 loss)
I0826 15:39:44.972681 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.13746 (* 1 = 9.13746 loss)
I0826 15:39:44.972683 25446 sgd_solver.cpp:138] Iteration 3770, lr = 0.001
I0826 15:39:47.057884 25446 solver.cpp:243] Iteration 3780, loss = 9.05439
I0826 15:39:47.057922 25446 solver.cpp:259]     Train net output #0: center_loss = 11.6691 (* 0.008 = 0.0933524 loss)
I0826 15:39:47.057929 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96103 (* 1 = 8.96103 loss)
I0826 15:39:47.057931 25446 sgd_solver.cpp:138] Iteration 3780, lr = 0.001
I0826 15:39:49.122632 25446 solver.cpp:243] Iteration 3790, loss = 9.03695
I0826 15:39:49.122654 25446 solver.cpp:259]     Train net output #0: center_loss = 13.8455 (* 0.008 = 0.110764 loss)
I0826 15:39:49.122675 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.92618 (* 1 = 8.92618 loss)
I0826 15:39:49.122679 25446 sgd_solver.cpp:138] Iteration 3790, lr = 0.001
I0826 15:39:51.186897 25446 solver.cpp:243] Iteration 3800, loss = 9.08999
I0826 15:39:51.186920 25446 solver.cpp:259]     Train net output #0: center_loss = 10.8103 (* 0.008 = 0.0864822 loss)
I0826 15:39:51.186926 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00351 (* 1 = 9.00351 loss)
I0826 15:39:51.186929 25446 sgd_solver.cpp:138] Iteration 3800, lr = 0.001
I0826 15:39:53.280635 25446 solver.cpp:243] Iteration 3810, loss = 9.06849
I0826 15:39:53.280683 25446 solver.cpp:259]     Train net output #0: center_loss = 11.6933 (* 0.008 = 0.0935466 loss)
I0826 15:39:53.280689 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97495 (* 1 = 8.97495 loss)
I0826 15:39:53.280694 25446 sgd_solver.cpp:138] Iteration 3810, lr = 0.001
I0826 15:39:55.383456 25446 solver.cpp:243] Iteration 3820, loss = 9.01438
I0826 15:39:55.383481 25446 solver.cpp:259]     Train net output #0: center_loss = 14.0765 (* 0.008 = 0.112612 loss)
I0826 15:39:55.383486 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.90177 (* 1 = 8.90177 loss)
I0826 15:39:55.383491 25446 sgd_solver.cpp:138] Iteration 3820, lr = 0.001
I0826 15:39:57.484071 25446 solver.cpp:243] Iteration 3830, loss = 9.17353
I0826 15:39:57.484108 25446 solver.cpp:259]     Train net output #0: center_loss = 11.0163 (* 0.008 = 0.0881301 loss)
I0826 15:39:57.484114 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.0854 (* 1 = 9.0854 loss)
I0826 15:39:57.484118 25446 sgd_solver.cpp:138] Iteration 3830, lr = 0.001
I0826 15:39:59.581111 25446 solver.cpp:243] Iteration 3840, loss = 9.03759
I0826 15:39:59.581135 25446 solver.cpp:259]     Train net output #0: center_loss = 11.9494 (* 0.008 = 0.0955952 loss)
I0826 15:39:59.581141 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.942 (* 1 = 8.942 loss)
I0826 15:39:59.581146 25446 sgd_solver.cpp:138] Iteration 3840, lr = 0.001
I0826 15:40:01.678344 25446 solver.cpp:243] Iteration 3850, loss = 9.08319
I0826 15:40:01.678366 25446 solver.cpp:259]     Train net output #0: center_loss = 12.4558 (* 0.008 = 0.0996461 loss)
I0826 15:40:01.678372 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98354 (* 1 = 8.98354 loss)
I0826 15:40:01.678376 25446 sgd_solver.cpp:138] Iteration 3850, lr = 0.001
I0826 15:40:03.800195 25446 solver.cpp:243] Iteration 3860, loss = 9.17824
I0826 15:40:03.800323 25446 solver.cpp:259]     Train net output #0: center_loss = 15.7721 (* 0.008 = 0.126176 loss)
I0826 15:40:03.800349 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.05206 (* 1 = 9.05206 loss)
I0826 15:40:03.800354 25446 sgd_solver.cpp:138] Iteration 3860, lr = 0.001
I0826 15:40:05.859921 25446 solver.cpp:243] Iteration 3870, loss = 8.98901
I0826 15:40:05.859958 25446 solver.cpp:259]     Train net output #0: center_loss = 14.2898 (* 0.008 = 0.114318 loss)
I0826 15:40:05.859964 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87469 (* 1 = 8.87469 loss)
I0826 15:40:05.859967 25446 sgd_solver.cpp:138] Iteration 3870, lr = 0.001
I0826 15:40:07.939462 25446 solver.cpp:243] Iteration 3880, loss = 9.21459
I0826 15:40:07.939499 25446 solver.cpp:259]     Train net output #0: center_loss = 9.00474 (* 0.008 = 0.072038 loss)
I0826 15:40:07.939504 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.14256 (* 1 = 9.14256 loss)
I0826 15:40:07.939508 25446 sgd_solver.cpp:138] Iteration 3880, lr = 0.001
I0826 15:40:10.050998 25446 solver.cpp:243] Iteration 3890, loss = 9.11797
I0826 15:40:10.051038 25446 solver.cpp:259]     Train net output #0: center_loss = 12.5172 (* 0.008 = 0.100137 loss)
I0826 15:40:10.051044 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.01783 (* 1 = 9.01783 loss)
I0826 15:40:10.051049 25446 sgd_solver.cpp:138] Iteration 3890, lr = 0.001
I0826 15:40:12.159768 25446 solver.cpp:243] Iteration 3900, loss = 9.07108
I0826 15:40:12.159792 25446 solver.cpp:259]     Train net output #0: center_loss = 14.1992 (* 0.008 = 0.113593 loss)
I0826 15:40:12.159798 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.95749 (* 1 = 8.95749 loss)
I0826 15:40:12.159803 25446 sgd_solver.cpp:138] Iteration 3900, lr = 0.001
I0826 15:40:14.257787 25446 solver.cpp:243] Iteration 3910, loss = 9.13756
I0826 15:40:14.257824 25446 solver.cpp:259]     Train net output #0: center_loss = 11.1802 (* 0.008 = 0.0894419 loss)
I0826 15:40:14.257830 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.04812 (* 1 = 9.04812 loss)
I0826 15:40:14.257834 25446 sgd_solver.cpp:138] Iteration 3910, lr = 0.001
I0826 15:40:16.332588 25446 solver.cpp:243] Iteration 3920, loss = 9.01756
I0826 15:40:16.332610 25446 solver.cpp:259]     Train net output #0: center_loss = 12.8402 (* 0.008 = 0.102722 loss)
I0826 15:40:16.332617 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.91484 (* 1 = 8.91484 loss)
I0826 15:40:16.332619 25446 sgd_solver.cpp:138] Iteration 3920, lr = 0.001
I0826 15:40:18.391122 25446 solver.cpp:243] Iteration 3930, loss = 9.09025
I0826 15:40:18.391160 25446 solver.cpp:259]     Train net output #0: center_loss = 12.3147 (* 0.008 = 0.0985176 loss)
I0826 15:40:18.391166 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.99174 (* 1 = 8.99174 loss)
I0826 15:40:18.391170 25446 sgd_solver.cpp:138] Iteration 3930, lr = 0.001
I0826 15:40:20.466295 25446 solver.cpp:243] Iteration 3940, loss = 9.15389
I0826 15:40:20.466333 25446 solver.cpp:259]     Train net output #0: center_loss = 13.5777 (* 0.008 = 0.108622 loss)
I0826 15:40:20.466339 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.04527 (* 1 = 9.04527 loss)
I0826 15:40:20.466342 25446 sgd_solver.cpp:138] Iteration 3940, lr = 0.001
I0826 15:40:22.543256 25446 solver.cpp:243] Iteration 3950, loss = 8.98203
I0826 15:40:22.543294 25446 solver.cpp:259]     Train net output #0: center_loss = 12.3316 (* 0.008 = 0.0986527 loss)
I0826 15:40:22.543301 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.88338 (* 1 = 8.88338 loss)
I0826 15:40:22.543304 25446 sgd_solver.cpp:138] Iteration 3950, lr = 0.001
I0826 15:40:24.601128 25446 solver.cpp:243] Iteration 3960, loss = 9.00647
I0826 15:40:24.601152 25446 solver.cpp:259]     Train net output #0: center_loss = 15.7246 (* 0.008 = 0.125796 loss)
I0826 15:40:24.601173 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.88067 (* 1 = 8.88067 loss)
I0826 15:40:24.601176 25446 sgd_solver.cpp:138] Iteration 3960, lr = 0.001
I0826 15:40:26.672559 25446 solver.cpp:243] Iteration 3970, loss = 8.88257
I0826 15:40:26.672598 25446 solver.cpp:259]     Train net output #0: center_loss = 16.9873 (* 0.008 = 0.135898 loss)
I0826 15:40:26.672605 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.74667 (* 1 = 8.74667 loss)
I0826 15:40:26.672608 25446 sgd_solver.cpp:138] Iteration 3970, lr = 0.001
I0826 15:40:28.758667 25446 solver.cpp:243] Iteration 3980, loss = 9.03338
I0826 15:40:28.758690 25446 solver.cpp:259]     Train net output #0: center_loss = 15.8354 (* 0.008 = 0.126683 loss)
I0826 15:40:28.758697 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.9067 (* 1 = 8.9067 loss)
I0826 15:40:28.758700 25446 sgd_solver.cpp:138] Iteration 3980, lr = 0.001
I0826 15:40:30.853785 25446 solver.cpp:243] Iteration 3990, loss = 9.07115
I0826 15:40:30.853807 25446 solver.cpp:259]     Train net output #0: center_loss = 12.5814 (* 0.008 = 0.100651 loss)
I0826 15:40:30.853814 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.9705 (* 1 = 8.9705 loss)
I0826 15:40:30.853818 25446 sgd_solver.cpp:138] Iteration 3990, lr = 0.001
I0826 15:40:32.736583 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_4000.caffemodel
I0826 15:40:33.854300 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_4000.solverstate
I0826 15:40:34.174749 25446 solver.cpp:243] Iteration 4000, loss = 9.00354
I0826 15:40:34.174789 25446 solver.cpp:259]     Train net output #0: center_loss = 16.19 (* 0.008 = 0.12952 loss)
I0826 15:40:34.174795 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87402 (* 1 = 8.87402 loss)
I0826 15:40:34.174799 25446 sgd_solver.cpp:138] Iteration 4000, lr = 0.001
I0826 15:40:36.235826 25446 solver.cpp:243] Iteration 4010, loss = 9.08464
I0826 15:40:36.235863 25446 solver.cpp:259]     Train net output #0: center_loss = 13.0317 (* 0.008 = 0.104254 loss)
I0826 15:40:36.235868 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98039 (* 1 = 8.98039 loss)
I0826 15:40:36.235873 25446 sgd_solver.cpp:138] Iteration 4010, lr = 0.001
I0826 15:40:38.322109 25446 solver.cpp:243] Iteration 4020, loss = 9.07642
I0826 15:40:38.322146 25446 solver.cpp:259]     Train net output #0: center_loss = 12.2768 (* 0.008 = 0.0982145 loss)
I0826 15:40:38.322152 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97821 (* 1 = 8.97821 loss)
I0826 15:40:38.322156 25446 sgd_solver.cpp:138] Iteration 4020, lr = 0.001
I0826 15:40:40.401123 25446 solver.cpp:243] Iteration 4030, loss = 9.04271
I0826 15:40:40.401146 25446 solver.cpp:259]     Train net output #0: center_loss = 13.7953 (* 0.008 = 0.110362 loss)
I0826 15:40:40.401152 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93235 (* 1 = 8.93235 loss)
I0826 15:40:40.401156 25446 sgd_solver.cpp:138] Iteration 4030, lr = 0.001
I0826 15:40:42.482008 25446 solver.cpp:243] Iteration 4040, loss = 9.05532
I0826 15:40:42.482046 25446 solver.cpp:259]     Train net output #0: center_loss = 10.3265 (* 0.008 = 0.0826117 loss)
I0826 15:40:42.482053 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97271 (* 1 = 8.97271 loss)
I0826 15:40:42.482056 25446 sgd_solver.cpp:138] Iteration 4040, lr = 0.001
I0826 15:40:44.590457 25446 solver.cpp:243] Iteration 4050, loss = 9.08218
I0826 15:40:44.590497 25446 solver.cpp:259]     Train net output #0: center_loss = 16.042 (* 0.008 = 0.128336 loss)
I0826 15:40:44.590503 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.95384 (* 1 = 8.95384 loss)
I0826 15:40:44.590507 25446 sgd_solver.cpp:138] Iteration 4050, lr = 0.001
I0826 15:40:46.688028 25446 solver.cpp:243] Iteration 4060, loss = 9.0919
I0826 15:40:46.688066 25446 solver.cpp:259]     Train net output #0: center_loss = 15.0265 (* 0.008 = 0.120212 loss)
I0826 15:40:46.688072 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97169 (* 1 = 8.97169 loss)
I0826 15:40:46.688077 25446 sgd_solver.cpp:138] Iteration 4060, lr = 0.001
I0826 15:40:48.789224 25446 solver.cpp:243] Iteration 4070, loss = 9.07235
I0826 15:40:48.789250 25446 solver.cpp:259]     Train net output #0: center_loss = 14.6115 (* 0.008 = 0.116892 loss)
I0826 15:40:48.789255 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.95546 (* 1 = 8.95546 loss)
I0826 15:40:48.789259 25446 sgd_solver.cpp:138] Iteration 4070, lr = 0.001
I0826 15:40:50.958375 25446 solver.cpp:243] Iteration 4080, loss = 9.08227
I0826 15:40:50.958400 25446 solver.cpp:259]     Train net output #0: center_loss = 14.0971 (* 0.008 = 0.112777 loss)
I0826 15:40:50.958406 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96949 (* 1 = 8.96949 loss)
I0826 15:40:50.958411 25446 sgd_solver.cpp:138] Iteration 4080, lr = 0.001
I0826 15:40:53.125731 25446 solver.cpp:243] Iteration 4090, loss = 8.96824
I0826 15:40:53.125769 25446 solver.cpp:259]     Train net output #0: center_loss = 15.1427 (* 0.008 = 0.121142 loss)
I0826 15:40:53.125774 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.8471 (* 1 = 8.8471 loss)
I0826 15:40:53.125779 25446 sgd_solver.cpp:138] Iteration 4090, lr = 0.001
I0826 15:40:55.196835 25446 solver.cpp:243] Iteration 4100, loss = 9.03982
I0826 15:40:55.196871 25446 solver.cpp:259]     Train net output #0: center_loss = 13.0641 (* 0.008 = 0.104513 loss)
I0826 15:40:55.196877 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93531 (* 1 = 8.93531 loss)
I0826 15:40:55.196933 25446 sgd_solver.cpp:138] Iteration 4100, lr = 0.001
I0826 15:40:57.287387 25446 solver.cpp:243] Iteration 4110, loss = 8.99225
I0826 15:40:57.287425 25446 solver.cpp:259]     Train net output #0: center_loss = 14.5826 (* 0.008 = 0.116661 loss)
I0826 15:40:57.287431 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87559 (* 1 = 8.87559 loss)
I0826 15:40:57.287434 25446 sgd_solver.cpp:138] Iteration 4110, lr = 0.001
I0826 15:40:59.374292 25446 solver.cpp:243] Iteration 4120, loss = 9.02943
I0826 15:40:59.374315 25446 solver.cpp:259]     Train net output #0: center_loss = 14.8364 (* 0.008 = 0.118691 loss)
I0826 15:40:59.374320 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.91074 (* 1 = 8.91074 loss)
I0826 15:40:59.374325 25446 sgd_solver.cpp:138] Iteration 4120, lr = 0.001
I0826 15:41:01.481058 25446 solver.cpp:243] Iteration 4130, loss = 9.00432
I0826 15:41:01.481098 25446 solver.cpp:259]     Train net output #0: center_loss = 14.7148 (* 0.008 = 0.117718 loss)
I0826 15:41:01.481104 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.88661 (* 1 = 8.88661 loss)
I0826 15:41:01.481109 25446 sgd_solver.cpp:138] Iteration 4130, lr = 0.001
I0826 15:41:03.575348 25446 solver.cpp:243] Iteration 4140, loss = 9.05363
I0826 15:41:03.575386 25446 solver.cpp:259]     Train net output #0: center_loss = 16.7514 (* 0.008 = 0.134012 loss)
I0826 15:41:03.575392 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.91961 (* 1 = 8.91961 loss)
I0826 15:41:03.575395 25446 sgd_solver.cpp:138] Iteration 4140, lr = 0.001
I0826 15:41:05.698344 25446 solver.cpp:243] Iteration 4150, loss = 9.105
I0826 15:41:05.698446 25446 solver.cpp:259]     Train net output #0: center_loss = 16.1359 (* 0.008 = 0.129088 loss)
I0826 15:41:05.698452 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97591 (* 1 = 8.97591 loss)
I0826 15:41:05.698457 25446 sgd_solver.cpp:138] Iteration 4150, lr = 0.001
I0826 15:41:07.791790 25446 solver.cpp:243] Iteration 4160, loss = 9.02275
I0826 15:41:07.791826 25446 solver.cpp:259]     Train net output #0: center_loss = 16.2893 (* 0.008 = 0.130315 loss)
I0826 15:41:07.791832 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.89243 (* 1 = 8.89243 loss)
I0826 15:41:07.791836 25446 sgd_solver.cpp:138] Iteration 4160, lr = 0.001
I0826 15:41:09.860910 25446 solver.cpp:243] Iteration 4170, loss = 9.11947
I0826 15:41:09.860949 25446 solver.cpp:259]     Train net output #0: center_loss = 17.6924 (* 0.008 = 0.141539 loss)
I0826 15:41:09.860954 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97793 (* 1 = 8.97793 loss)
I0826 15:41:09.860957 25446 sgd_solver.cpp:138] Iteration 4170, lr = 0.001
I0826 15:41:11.979336 25446 solver.cpp:243] Iteration 4180, loss = 9.13732
I0826 15:41:11.979358 25446 solver.cpp:259]     Train net output #0: center_loss = 16.895 (* 0.008 = 0.13516 loss)
I0826 15:41:11.979364 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00216 (* 1 = 9.00216 loss)
I0826 15:41:11.979369 25446 sgd_solver.cpp:138] Iteration 4180, lr = 0.001
I0826 15:41:14.043004 25446 solver.cpp:243] Iteration 4190, loss = 9.00804
I0826 15:41:14.043026 25446 solver.cpp:259]     Train net output #0: center_loss = 18.7872 (* 0.008 = 0.150298 loss)
I0826 15:41:14.043032 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85774 (* 1 = 8.85774 loss)
I0826 15:41:14.043035 25446 sgd_solver.cpp:138] Iteration 4190, lr = 0.001
I0826 15:41:16.112643 25446 solver.cpp:243] Iteration 4200, loss = 9.06704
I0826 15:41:16.112664 25446 solver.cpp:259]     Train net output #0: center_loss = 16.2714 (* 0.008 = 0.130171 loss)
I0826 15:41:16.112670 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93686 (* 1 = 8.93686 loss)
I0826 15:41:16.112674 25446 sgd_solver.cpp:138] Iteration 4200, lr = 0.001
I0826 15:41:18.180003 25446 solver.cpp:243] Iteration 4210, loss = 9.06005
I0826 15:41:18.180027 25446 solver.cpp:259]     Train net output #0: center_loss = 18.3608 (* 0.008 = 0.146886 loss)
I0826 15:41:18.180032 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.91316 (* 1 = 8.91316 loss)
I0826 15:41:18.180037 25446 sgd_solver.cpp:138] Iteration 4210, lr = 0.001
I0826 15:41:20.265328 25446 solver.cpp:243] Iteration 4220, loss = 9.09823
I0826 15:41:20.265365 25446 solver.cpp:259]     Train net output #0: center_loss = 17.7733 (* 0.008 = 0.142187 loss)
I0826 15:41:20.265372 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.95604 (* 1 = 8.95604 loss)
I0826 15:41:20.265375 25446 sgd_solver.cpp:138] Iteration 4220, lr = 0.001
I0826 15:41:22.327392 25446 solver.cpp:243] Iteration 4230, loss = 9.11436
I0826 15:41:22.327430 25446 solver.cpp:259]     Train net output #0: center_loss = 12.8972 (* 0.008 = 0.103177 loss)
I0826 15:41:22.327437 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.01119 (* 1 = 9.01119 loss)
I0826 15:41:22.327440 25446 sgd_solver.cpp:138] Iteration 4230, lr = 0.001
I0826 15:41:24.395640 25446 solver.cpp:243] Iteration 4240, loss = 9.01523
I0826 15:41:24.395678 25446 solver.cpp:259]     Train net output #0: center_loss = 15.1987 (* 0.008 = 0.121589 loss)
I0826 15:41:24.395684 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.89364 (* 1 = 8.89364 loss)
I0826 15:41:24.395689 25446 sgd_solver.cpp:138] Iteration 4240, lr = 0.001
I0826 15:41:26.471825 25446 solver.cpp:243] Iteration 4250, loss = 9.08278
I0826 15:41:26.471849 25446 solver.cpp:259]     Train net output #0: center_loss = 18.0107 (* 0.008 = 0.144086 loss)
I0826 15:41:26.471855 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.9387 (* 1 = 8.9387 loss)
I0826 15:41:26.471859 25446 sgd_solver.cpp:138] Iteration 4250, lr = 0.001
I0826 15:41:28.602586 25446 solver.cpp:243] Iteration 4260, loss = 8.99871
I0826 15:41:28.602609 25446 solver.cpp:259]     Train net output #0: center_loss = 18.1355 (* 0.008 = 0.145084 loss)
I0826 15:41:28.602615 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85362 (* 1 = 8.85362 loss)
I0826 15:41:28.602619 25446 sgd_solver.cpp:138] Iteration 4260, lr = 0.001
I0826 15:41:30.713949 25446 solver.cpp:243] Iteration 4270, loss = 9.1116
I0826 15:41:30.713989 25446 solver.cpp:259]     Train net output #0: center_loss = 16.564 (* 0.008 = 0.132512 loss)
I0826 15:41:30.713994 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97909 (* 1 = 8.97909 loss)
I0826 15:41:30.713999 25446 sgd_solver.cpp:138] Iteration 4270, lr = 0.001
I0826 15:41:32.788867 25446 solver.cpp:243] Iteration 4280, loss = 9.00093
I0826 15:41:32.788892 25446 solver.cpp:259]     Train net output #0: center_loss = 17.3065 (* 0.008 = 0.138452 loss)
I0826 15:41:32.788897 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.86247 (* 1 = 8.86247 loss)
I0826 15:41:32.788902 25446 sgd_solver.cpp:138] Iteration 4280, lr = 0.001
I0826 15:41:34.846310 25446 solver.cpp:243] Iteration 4290, loss = 9.07553
I0826 15:41:34.846349 25446 solver.cpp:259]     Train net output #0: center_loss = 16.6617 (* 0.008 = 0.133293 loss)
I0826 15:41:34.846354 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.94224 (* 1 = 8.94224 loss)
I0826 15:41:34.846357 25446 sgd_solver.cpp:138] Iteration 4290, lr = 0.001
I0826 15:41:36.908704 25446 solver.cpp:243] Iteration 4300, loss = 9.01416
I0826 15:41:36.908833 25446 solver.cpp:259]     Train net output #0: center_loss = 18.2814 (* 0.008 = 0.146251 loss)
I0826 15:41:36.908851 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.86791 (* 1 = 8.86791 loss)
I0826 15:41:36.908855 25446 sgd_solver.cpp:138] Iteration 4300, lr = 0.001
I0826 15:41:38.972110 25446 solver.cpp:243] Iteration 4310, loss = 9.08783
I0826 15:41:38.972148 25446 solver.cpp:259]     Train net output #0: center_loss = 19.2333 (* 0.008 = 0.153866 loss)
I0826 15:41:38.972154 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93397 (* 1 = 8.93397 loss)
I0826 15:41:38.972157 25446 sgd_solver.cpp:138] Iteration 4310, lr = 0.001
I0826 15:41:41.031971 25446 solver.cpp:243] Iteration 4320, loss = 9.10169
I0826 15:41:41.032008 25446 solver.cpp:259]     Train net output #0: center_loss = 18.7656 (* 0.008 = 0.150125 loss)
I0826 15:41:41.032014 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.95156 (* 1 = 8.95156 loss)
I0826 15:41:41.032017 25446 sgd_solver.cpp:138] Iteration 4320, lr = 0.001
I0826 15:41:43.093080 25446 solver.cpp:243] Iteration 4330, loss = 8.94625
I0826 15:41:43.093117 25446 solver.cpp:259]     Train net output #0: center_loss = 20.1229 (* 0.008 = 0.160984 loss)
I0826 15:41:43.093123 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.78526 (* 1 = 8.78526 loss)
I0826 15:41:43.093127 25446 sgd_solver.cpp:138] Iteration 4330, lr = 0.001
I0826 15:41:45.155339 25446 solver.cpp:243] Iteration 4340, loss = 9.12695
I0826 15:41:45.155376 25446 solver.cpp:259]     Train net output #0: center_loss = 15.8195 (* 0.008 = 0.126556 loss)
I0826 15:41:45.155382 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00039 (* 1 = 9.00039 loss)
I0826 15:41:45.155385 25446 sgd_solver.cpp:138] Iteration 4340, lr = 0.001
I0826 15:41:47.215174 25446 solver.cpp:243] Iteration 4350, loss = 8.89411
I0826 15:41:47.215211 25446 solver.cpp:259]     Train net output #0: center_loss = 18.0555 (* 0.008 = 0.144444 loss)
I0826 15:41:47.215217 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.74966 (* 1 = 8.74966 loss)
I0826 15:41:47.215221 25446 sgd_solver.cpp:138] Iteration 4350, lr = 0.001
I0826 15:41:49.272822 25446 solver.cpp:243] Iteration 4360, loss = 8.87315
I0826 15:41:49.272859 25446 solver.cpp:259]     Train net output #0: center_loss = 19.86 (* 0.008 = 0.15888 loss)
I0826 15:41:49.272866 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.71427 (* 1 = 8.71427 loss)
I0826 15:41:49.272868 25446 sgd_solver.cpp:138] Iteration 4360, lr = 0.001
I0826 15:41:51.333497 25446 solver.cpp:243] Iteration 4370, loss = 8.95188
I0826 15:41:51.333534 25446 solver.cpp:259]     Train net output #0: center_loss = 15.0692 (* 0.008 = 0.120554 loss)
I0826 15:41:51.333539 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.83132 (* 1 = 8.83132 loss)
I0826 15:41:51.333542 25446 sgd_solver.cpp:138] Iteration 4370, lr = 0.001
I0826 15:41:53.395084 25446 solver.cpp:243] Iteration 4380, loss = 8.80059
I0826 15:41:53.395121 25446 solver.cpp:259]     Train net output #0: center_loss = 20.7189 (* 0.008 = 0.165751 loss)
I0826 15:41:53.395128 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.63484 (* 1 = 8.63484 loss)
I0826 15:41:53.395130 25446 sgd_solver.cpp:138] Iteration 4380, lr = 0.001
I0826 15:41:55.451828 25446 solver.cpp:243] Iteration 4390, loss = 9.00922
I0826 15:41:55.451866 25446 solver.cpp:259]     Train net output #0: center_loss = 17.0585 (* 0.008 = 0.136468 loss)
I0826 15:41:55.451872 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87275 (* 1 = 8.87275 loss)
I0826 15:41:55.451875 25446 sgd_solver.cpp:138] Iteration 4390, lr = 0.001
I0826 15:41:57.511837 25446 solver.cpp:243] Iteration 4400, loss = 8.87729
I0826 15:41:57.511874 25446 solver.cpp:259]     Train net output #0: center_loss = 17.6723 (* 0.008 = 0.141378 loss)
I0826 15:41:57.511880 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.73591 (* 1 = 8.73591 loss)
I0826 15:41:57.511883 25446 sgd_solver.cpp:138] Iteration 4400, lr = 0.001
I0826 15:41:59.569304 25446 solver.cpp:243] Iteration 4410, loss = 8.96312
I0826 15:41:59.569344 25446 solver.cpp:259]     Train net output #0: center_loss = 15.927 (* 0.008 = 0.127416 loss)
I0826 15:41:59.569350 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.8357 (* 1 = 8.8357 loss)
I0826 15:41:59.569352 25446 sgd_solver.cpp:138] Iteration 4410, lr = 0.001
I0826 15:42:01.631047 25446 solver.cpp:243] Iteration 4420, loss = 9.00167
I0826 15:42:01.631084 25446 solver.cpp:259]     Train net output #0: center_loss = 19.2273 (* 0.008 = 0.153818 loss)
I0826 15:42:01.631089 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.84785 (* 1 = 8.84785 loss)
I0826 15:42:01.631093 25446 sgd_solver.cpp:138] Iteration 4420, lr = 0.001
I0826 15:42:03.696416 25446 solver.cpp:243] Iteration 4430, loss = 9.00496
I0826 15:42:03.696455 25446 solver.cpp:259]     Train net output #0: center_loss = 16.5148 (* 0.008 = 0.132118 loss)
I0826 15:42:03.696460 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87284 (* 1 = 8.87284 loss)
I0826 15:42:03.696462 25446 sgd_solver.cpp:138] Iteration 4430, lr = 0.001
I0826 15:42:05.765691 25446 solver.cpp:243] Iteration 4440, loss = 9.1862
I0826 15:42:05.765730 25446 solver.cpp:259]     Train net output #0: center_loss = 17.1213 (* 0.008 = 0.13697 loss)
I0826 15:42:05.765736 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.04923 (* 1 = 9.04923 loss)
I0826 15:42:05.765740 25446 sgd_solver.cpp:138] Iteration 4440, lr = 0.001
I0826 15:42:07.842583 25446 solver.cpp:243] Iteration 4450, loss = 9.09211
I0826 15:42:07.842723 25446 solver.cpp:259]     Train net output #0: center_loss = 20.2114 (* 0.008 = 0.161692 loss)
I0826 15:42:07.842743 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93042 (* 1 = 8.93042 loss)
I0826 15:42:07.842761 25446 sgd_solver.cpp:138] Iteration 4450, lr = 0.001
I0826 15:42:09.934621 25446 solver.cpp:243] Iteration 4460, loss = 9.13156
I0826 15:42:09.934660 25446 solver.cpp:259]     Train net output #0: center_loss = 14.246 (* 0.008 = 0.113968 loss)
I0826 15:42:09.934667 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.01759 (* 1 = 9.01759 loss)
I0826 15:42:09.934671 25446 sgd_solver.cpp:138] Iteration 4460, lr = 0.001
I0826 15:42:12.047926 25446 solver.cpp:243] Iteration 4470, loss = 9.09097
I0826 15:42:12.047955 25446 solver.cpp:259]     Train net output #0: center_loss = 15.9794 (* 0.008 = 0.127835 loss)
I0826 15:42:12.047961 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96313 (* 1 = 8.96313 loss)
I0826 15:42:12.047966 25446 sgd_solver.cpp:138] Iteration 4470, lr = 0.001
I0826 15:42:14.225304 25446 solver.cpp:243] Iteration 4480, loss = 9.13456
I0826 15:42:14.225330 25446 solver.cpp:259]     Train net output #0: center_loss = 12.9152 (* 0.008 = 0.103321 loss)
I0826 15:42:14.225337 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.03124 (* 1 = 9.03124 loss)
I0826 15:42:14.225342 25446 sgd_solver.cpp:138] Iteration 4480, lr = 0.001
I0826 15:42:16.370802 25446 solver.cpp:243] Iteration 4490, loss = 9.01308
I0826 15:42:16.370826 25446 solver.cpp:259]     Train net output #0: center_loss = 16.5519 (* 0.008 = 0.132415 loss)
I0826 15:42:16.370846 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.88066 (* 1 = 8.88066 loss)
I0826 15:42:16.370849 25446 sgd_solver.cpp:138] Iteration 4490, lr = 0.001
I0826 15:42:18.456115 25446 solver.cpp:243] Iteration 4500, loss = 9.12938
I0826 15:42:18.456151 25446 solver.cpp:259]     Train net output #0: center_loss = 18.0828 (* 0.008 = 0.144663 loss)
I0826 15:42:18.456157 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98472 (* 1 = 8.98472 loss)
I0826 15:42:18.456161 25446 sgd_solver.cpp:138] Iteration 4500, lr = 0.001
I0826 15:42:20.526455 25446 solver.cpp:243] Iteration 4510, loss = 9.10638
I0826 15:42:20.526494 25446 solver.cpp:259]     Train net output #0: center_loss = 15.6903 (* 0.008 = 0.125523 loss)
I0826 15:42:20.526499 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98085 (* 1 = 8.98085 loss)
I0826 15:42:20.526502 25446 sgd_solver.cpp:138] Iteration 4510, lr = 0.001
I0826 15:42:22.598366 25446 solver.cpp:243] Iteration 4520, loss = 9.16233
I0826 15:42:22.598404 25446 solver.cpp:259]     Train net output #0: center_loss = 17.1915 (* 0.008 = 0.137532 loss)
I0826 15:42:22.598410 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.02479 (* 1 = 9.02479 loss)
I0826 15:42:22.598414 25446 sgd_solver.cpp:138] Iteration 4520, lr = 0.001
I0826 15:42:24.664829 25446 solver.cpp:243] Iteration 4530, loss = 9.2091
I0826 15:42:24.664856 25446 solver.cpp:259]     Train net output #0: center_loss = 16.9358 (* 0.008 = 0.135487 loss)
I0826 15:42:24.664877 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.07361 (* 1 = 9.07361 loss)
I0826 15:42:24.664881 25446 sgd_solver.cpp:138] Iteration 4530, lr = 0.001
I0826 15:42:26.750797 25446 solver.cpp:243] Iteration 4540, loss = 9.0273
I0826 15:42:26.750819 25446 solver.cpp:259]     Train net output #0: center_loss = 18.2933 (* 0.008 = 0.146346 loss)
I0826 15:42:26.750825 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.88095 (* 1 = 8.88095 loss)
I0826 15:42:26.750829 25446 sgd_solver.cpp:138] Iteration 4540, lr = 0.001
I0826 15:42:28.832119 25446 solver.cpp:243] Iteration 4550, loss = 9.10176
I0826 15:42:28.832142 25446 solver.cpp:259]     Train net output #0: center_loss = 15.4101 (* 0.008 = 0.123281 loss)
I0826 15:42:28.832149 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.97848 (* 1 = 8.97848 loss)
I0826 15:42:28.832154 25446 sgd_solver.cpp:138] Iteration 4550, lr = 0.001
I0826 15:42:30.891136 25446 solver.cpp:243] Iteration 4560, loss = 9.16036
I0826 15:42:30.891173 25446 solver.cpp:259]     Train net output #0: center_loss = 18.5326 (* 0.008 = 0.148261 loss)
I0826 15:42:30.891180 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.01209 (* 1 = 9.01209 loss)
I0826 15:42:30.891182 25446 sgd_solver.cpp:138] Iteration 4560, lr = 0.001
I0826 15:42:32.953856 25446 solver.cpp:243] Iteration 4570, loss = 8.81856
I0826 15:42:32.953879 25446 solver.cpp:259]     Train net output #0: center_loss = 21.2356 (* 0.008 = 0.169884 loss)
I0826 15:42:32.953900 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.64868 (* 1 = 8.64868 loss)
I0826 15:42:32.953903 25446 sgd_solver.cpp:138] Iteration 4570, lr = 0.001
I0826 15:42:35.017396 25446 solver.cpp:243] Iteration 4580, loss = 9.03846
I0826 15:42:35.017433 25446 solver.cpp:259]     Train net output #0: center_loss = 17.247 (* 0.008 = 0.137976 loss)
I0826 15:42:35.017438 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.90049 (* 1 = 8.90049 loss)
I0826 15:42:35.017442 25446 sgd_solver.cpp:138] Iteration 4580, lr = 0.001
I0826 15:42:37.114848 25446 solver.cpp:243] Iteration 4590, loss = 9.10923
I0826 15:42:37.114874 25446 solver.cpp:259]     Train net output #0: center_loss = 17.8515 (* 0.008 = 0.142812 loss)
I0826 15:42:37.114879 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96642 (* 1 = 8.96642 loss)
I0826 15:42:37.114882 25446 sgd_solver.cpp:138] Iteration 4590, lr = 0.001
I0826 15:42:39.205943 25446 solver.cpp:243] Iteration 4600, loss = 8.97372
I0826 15:42:39.206091 25446 solver.cpp:259]     Train net output #0: center_loss = 15.3589 (* 0.008 = 0.122871 loss)
I0826 15:42:39.206099 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85085 (* 1 = 8.85085 loss)
I0826 15:42:39.206102 25446 sgd_solver.cpp:138] Iteration 4600, lr = 0.001
I0826 15:42:41.295120 25446 solver.cpp:243] Iteration 4610, loss = 9.04731
I0826 15:42:41.295158 25446 solver.cpp:259]     Train net output #0: center_loss = 18.791 (* 0.008 = 0.150328 loss)
I0826 15:42:41.295164 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.89698 (* 1 = 8.89698 loss)
I0826 15:42:41.295167 25446 sgd_solver.cpp:138] Iteration 4610, lr = 0.001
I0826 15:42:43.386883 25446 solver.cpp:243] Iteration 4620, loss = 9.08261
I0826 15:42:43.386920 25446 solver.cpp:259]     Train net output #0: center_loss = 14.595 (* 0.008 = 0.11676 loss)
I0826 15:42:43.386926 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96585 (* 1 = 8.96585 loss)
I0826 15:42:43.386929 25446 sgd_solver.cpp:138] Iteration 4620, lr = 0.001
I0826 15:42:45.456739 25446 solver.cpp:243] Iteration 4630, loss = 8.94432
I0826 15:42:45.456761 25446 solver.cpp:259]     Train net output #0: center_loss = 20.3257 (* 0.008 = 0.162606 loss)
I0826 15:42:45.456768 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.78172 (* 1 = 8.78172 loss)
I0826 15:42:45.456773 25446 sgd_solver.cpp:138] Iteration 4630, lr = 0.001
I0826 15:42:47.574431 25446 solver.cpp:243] Iteration 4640, loss = 8.82914
I0826 15:42:47.574470 25446 solver.cpp:259]     Train net output #0: center_loss = 22.7846 (* 0.008 = 0.182277 loss)
I0826 15:42:47.574476 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.64686 (* 1 = 8.64686 loss)
I0826 15:42:47.574479 25446 sgd_solver.cpp:138] Iteration 4640, lr = 0.001
I0826 15:42:49.692735 25446 solver.cpp:243] Iteration 4650, loss = 9.03661
I0826 15:42:49.692757 25446 solver.cpp:259]     Train net output #0: center_loss = 20.0744 (* 0.008 = 0.160595 loss)
I0826 15:42:49.692764 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87602 (* 1 = 8.87602 loss)
I0826 15:42:49.692767 25446 sgd_solver.cpp:138] Iteration 4650, lr = 0.001
I0826 15:42:51.759161 25446 solver.cpp:243] Iteration 4660, loss = 9.13031
I0826 15:42:51.759198 25446 solver.cpp:259]     Train net output #0: center_loss = 21.0702 (* 0.008 = 0.168562 loss)
I0826 15:42:51.759204 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.96175 (* 1 = 8.96175 loss)
I0826 15:42:51.759207 25446 sgd_solver.cpp:138] Iteration 4660, lr = 0.001
I0826 15:42:53.833511 25446 solver.cpp:243] Iteration 4670, loss = 8.96342
I0826 15:42:53.833549 25446 solver.cpp:259]     Train net output #0: center_loss = 17.1273 (* 0.008 = 0.137019 loss)
I0826 15:42:53.833555 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.8264 (* 1 = 8.8264 loss)
I0826 15:42:53.833559 25446 sgd_solver.cpp:138] Iteration 4670, lr = 0.001
I0826 15:42:55.954550 25446 solver.cpp:243] Iteration 4680, loss = 9.01784
I0826 15:42:55.954576 25446 solver.cpp:259]     Train net output #0: center_loss = 18.3202 (* 0.008 = 0.146561 loss)
I0826 15:42:55.954581 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.87128 (* 1 = 8.87128 loss)
I0826 15:42:55.954586 25446 sgd_solver.cpp:138] Iteration 4680, lr = 0.001
I0826 15:42:58.048074 25446 solver.cpp:243] Iteration 4690, loss = 9.1547
I0826 15:42:58.048110 25446 solver.cpp:259]     Train net output #0: center_loss = 18.1616 (* 0.008 = 0.145293 loss)
I0826 15:42:58.048116 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00941 (* 1 = 9.00941 loss)
I0826 15:42:58.048120 25446 sgd_solver.cpp:138] Iteration 4690, lr = 0.001
I0826 15:43:00.120752 25446 solver.cpp:243] Iteration 4700, loss = 9.08985
I0826 15:43:00.120790 25446 solver.cpp:259]     Train net output #0: center_loss = 23.8034 (* 0.008 = 0.190427 loss)
I0826 15:43:00.120796 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.89943 (* 1 = 8.89943 loss)
I0826 15:43:00.120800 25446 sgd_solver.cpp:138] Iteration 4700, lr = 0.001
I0826 15:43:02.182943 25446 solver.cpp:243] Iteration 4710, loss = 8.9854
I0826 15:43:02.182967 25446 solver.cpp:259]     Train net output #0: center_loss = 19.14 (* 0.008 = 0.15312 loss)
I0826 15:43:02.182973 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.83228 (* 1 = 8.83228 loss)
I0826 15:43:02.182976 25446 sgd_solver.cpp:138] Iteration 4710, lr = 0.001
I0826 15:43:04.306138 25446 solver.cpp:243] Iteration 4720, loss = 8.87719
I0826 15:43:04.306161 25446 solver.cpp:259]     Train net output #0: center_loss = 20.3571 (* 0.008 = 0.162857 loss)
I0826 15:43:04.306167 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.71433 (* 1 = 8.71433 loss)
I0826 15:43:04.306172 25446 sgd_solver.cpp:138] Iteration 4720, lr = 0.001
I0826 15:43:06.451550 25446 solver.cpp:243] Iteration 4730, loss = 9.07889
I0826 15:43:06.451575 25446 solver.cpp:259]     Train net output #0: center_loss = 19.2071 (* 0.008 = 0.153657 loss)
I0826 15:43:06.451581 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.92523 (* 1 = 8.92523 loss)
I0826 15:43:06.451584 25446 sgd_solver.cpp:138] Iteration 4730, lr = 0.001
I0826 15:43:08.519894 25446 solver.cpp:243] Iteration 4740, loss = 9.06179
I0826 15:43:08.519918 25446 solver.cpp:259]     Train net output #0: center_loss = 19.2769 (* 0.008 = 0.154215 loss)
I0826 15:43:08.519923 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.90757 (* 1 = 8.90757 loss)
I0826 15:43:08.519927 25446 sgd_solver.cpp:138] Iteration 4740, lr = 0.001
I0826 15:43:10.587880 25446 solver.cpp:243] Iteration 4750, loss = 9.07491
I0826 15:43:10.588001 25446 solver.cpp:259]     Train net output #0: center_loss = 16.8879 (* 0.008 = 0.135103 loss)
I0826 15:43:10.588008 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93981 (* 1 = 8.93981 loss)
I0826 15:43:10.588012 25446 sgd_solver.cpp:138] Iteration 4750, lr = 0.001
I0826 15:43:12.649217 25446 solver.cpp:243] Iteration 4760, loss = 9.08828
I0826 15:43:12.649260 25446 solver.cpp:259]     Train net output #0: center_loss = 17.4295 (* 0.008 = 0.139436 loss)
I0826 15:43:12.649284 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.94884 (* 1 = 8.94884 loss)
I0826 15:43:12.649287 25446 sgd_solver.cpp:138] Iteration 4760, lr = 0.001
I0826 15:43:14.712527 25446 solver.cpp:243] Iteration 4770, loss = 9.1303
I0826 15:43:14.712564 25446 solver.cpp:259]     Train net output #0: center_loss = 17.9761 (* 0.008 = 0.143809 loss)
I0826 15:43:14.712570 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98649 (* 1 = 8.98649 loss)
I0826 15:43:14.712574 25446 sgd_solver.cpp:138] Iteration 4770, lr = 0.001
I0826 15:43:16.848093 25446 solver.cpp:243] Iteration 4780, loss = 8.87543
I0826 15:43:16.848117 25446 solver.cpp:259]     Train net output #0: center_loss = 19.2285 (* 0.008 = 0.153828 loss)
I0826 15:43:16.848124 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.7216 (* 1 = 8.7216 loss)
I0826 15:43:16.848127 25446 sgd_solver.cpp:138] Iteration 4780, lr = 0.001
I0826 15:43:18.956578 25446 solver.cpp:243] Iteration 4790, loss = 9.03457
I0826 15:43:18.956601 25446 solver.cpp:259]     Train net output #0: center_loss = 21.4372 (* 0.008 = 0.171498 loss)
I0826 15:43:18.956609 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.86307 (* 1 = 8.86307 loss)
I0826 15:43:18.956612 25446 sgd_solver.cpp:138] Iteration 4790, lr = 0.001
I0826 15:43:21.040634 25446 solver.cpp:243] Iteration 4800, loss = 9.00902
I0826 15:43:21.040659 25446 solver.cpp:259]     Train net output #0: center_loss = 19.007 (* 0.008 = 0.152056 loss)
I0826 15:43:21.040665 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85696 (* 1 = 8.85696 loss)
I0826 15:43:21.040670 25446 sgd_solver.cpp:138] Iteration 4800, lr = 0.001
I0826 15:43:23.118635 25446 solver.cpp:243] Iteration 4810, loss = 8.98112
I0826 15:43:23.118661 25446 solver.cpp:259]     Train net output #0: center_loss = 25.7506 (* 0.008 = 0.206005 loss)
I0826 15:43:23.118667 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.77512 (* 1 = 8.77512 loss)
I0826 15:43:23.118672 25446 sgd_solver.cpp:138] Iteration 4810, lr = 0.001
I0826 15:43:25.244253 25446 solver.cpp:243] Iteration 4820, loss = 8.95358
I0826 15:43:25.244276 25446 solver.cpp:259]     Train net output #0: center_loss = 20.0057 (* 0.008 = 0.160045 loss)
I0826 15:43:25.244282 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.79353 (* 1 = 8.79353 loss)
I0826 15:43:25.244287 25446 sgd_solver.cpp:138] Iteration 4820, lr = 0.001
I0826 15:43:27.391553 25446 solver.cpp:243] Iteration 4830, loss = 9.1455
I0826 15:43:27.391579 25446 solver.cpp:259]     Train net output #0: center_loss = 18.3508 (* 0.008 = 0.146807 loss)
I0826 15:43:27.391587 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.99869 (* 1 = 8.99869 loss)
I0826 15:43:27.391592 25446 sgd_solver.cpp:138] Iteration 4830, lr = 0.001
I0826 15:43:29.551818 25446 solver.cpp:243] Iteration 4840, loss = 9.08332
I0826 15:43:29.551841 25446 solver.cpp:259]     Train net output #0: center_loss = 20.7691 (* 0.008 = 0.166153 loss)
I0826 15:43:29.551862 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.91717 (* 1 = 8.91717 loss)
I0826 15:43:29.551867 25446 sgd_solver.cpp:138] Iteration 4840, lr = 0.001
I0826 15:43:31.650686 25446 solver.cpp:243] Iteration 4850, loss = 9.09814
I0826 15:43:31.650709 25446 solver.cpp:259]     Train net output #0: center_loss = 20.8405 (* 0.008 = 0.166724 loss)
I0826 15:43:31.650715 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93142 (* 1 = 8.93142 loss)
I0826 15:43:31.650719 25446 sgd_solver.cpp:138] Iteration 4850, lr = 0.001
I0826 15:43:33.769212 25446 solver.cpp:243] Iteration 4860, loss = 9.06962
I0826 15:43:33.769234 25446 solver.cpp:259]     Train net output #0: center_loss = 19.4903 (* 0.008 = 0.155922 loss)
I0826 15:43:33.769240 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.9137 (* 1 = 8.9137 loss)
I0826 15:43:33.769244 25446 sgd_solver.cpp:138] Iteration 4860, lr = 0.001
I0826 15:43:35.988497 25446 solver.cpp:243] Iteration 4870, loss = 8.83581
I0826 15:43:35.988520 25446 solver.cpp:259]     Train net output #0: center_loss = 25.3676 (* 0.008 = 0.202941 loss)
I0826 15:43:35.988541 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.63287 (* 1 = 8.63287 loss)
I0826 15:43:35.988545 25446 sgd_solver.cpp:138] Iteration 4870, lr = 0.001
I0826 15:43:38.110661 25446 solver.cpp:243] Iteration 4880, loss = 9.17359
I0826 15:43:38.110698 25446 solver.cpp:259]     Train net output #0: center_loss = 23.5586 (* 0.008 = 0.188468 loss)
I0826 15:43:38.110704 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.98512 (* 1 = 8.98512 loss)
I0826 15:43:38.110707 25446 sgd_solver.cpp:138] Iteration 4880, lr = 0.001
I0826 15:43:40.203663 25446 solver.cpp:243] Iteration 4890, loss = 9.19631
I0826 15:43:40.203701 25446 solver.cpp:259]     Train net output #0: center_loss = 16.9217 (* 0.008 = 0.135373 loss)
I0826 15:43:40.203706 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06094 (* 1 = 9.06094 loss)
I0826 15:43:40.203709 25446 sgd_solver.cpp:138] Iteration 4890, lr = 0.001
I0826 15:43:42.303437 25446 solver.cpp:243] Iteration 4900, loss = 9.03347
I0826 15:43:42.303540 25446 solver.cpp:259]     Train net output #0: center_loss = 22.0944 (* 0.008 = 0.176755 loss)
I0826 15:43:42.303547 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85672 (* 1 = 8.85672 loss)
I0826 15:43:42.303565 25446 sgd_solver.cpp:138] Iteration 4900, lr = 0.001
I0826 15:43:44.379963 25446 solver.cpp:243] Iteration 4910, loss = 8.92749
I0826 15:43:44.379988 25446 solver.cpp:259]     Train net output #0: center_loss = 23.0418 (* 0.008 = 0.184335 loss)
I0826 15:43:44.379994 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.74316 (* 1 = 8.74316 loss)
I0826 15:43:44.379999 25446 sgd_solver.cpp:138] Iteration 4910, lr = 0.001
I0826 15:43:46.464578 25446 solver.cpp:243] Iteration 4920, loss = 9.05009
I0826 15:43:46.464615 25446 solver.cpp:259]     Train net output #0: center_loss = 24.943 (* 0.008 = 0.199544 loss)
I0826 15:43:46.464622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85055 (* 1 = 8.85055 loss)
I0826 15:43:46.464625 25446 sgd_solver.cpp:138] Iteration 4920, lr = 0.001
I0826 15:43:48.529927 25446 solver.cpp:243] Iteration 4930, loss = 9.08438
I0826 15:43:48.529948 25446 solver.cpp:259]     Train net output #0: center_loss = 16.1464 (* 0.008 = 0.129172 loss)
I0826 15:43:48.529954 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.95521 (* 1 = 8.95521 loss)
I0826 15:43:48.529958 25446 sgd_solver.cpp:138] Iteration 4930, lr = 0.001
I0826 15:43:50.595240 25446 solver.cpp:243] Iteration 4940, loss = 8.9516
I0826 15:43:50.595278 25446 solver.cpp:259]     Train net output #0: center_loss = 24.3845 (* 0.008 = 0.195076 loss)
I0826 15:43:50.595283 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.75653 (* 1 = 8.75653 loss)
I0826 15:43:50.595288 25446 sgd_solver.cpp:138] Iteration 4940, lr = 0.001
I0826 15:43:52.670848 25446 solver.cpp:243] Iteration 4950, loss = 8.9392
I0826 15:43:52.670874 25446 solver.cpp:259]     Train net output #0: center_loss = 24.6294 (* 0.008 = 0.197035 loss)
I0826 15:43:52.670881 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.74216 (* 1 = 8.74216 loss)
I0826 15:43:52.670886 25446 sgd_solver.cpp:138] Iteration 4950, lr = 0.001
I0826 15:43:54.806922 25446 solver.cpp:243] Iteration 4960, loss = 8.97863
I0826 15:43:54.806953 25446 solver.cpp:259]     Train net output #0: center_loss = 21.8431 (* 0.008 = 0.174745 loss)
I0826 15:43:54.806959 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.80388 (* 1 = 8.80388 loss)
I0826 15:43:54.806964 25446 sgd_solver.cpp:138] Iteration 4960, lr = 0.001
I0826 15:43:56.923637 25446 solver.cpp:243] Iteration 4970, loss = 8.91444
I0826 15:43:56.923676 25446 solver.cpp:259]     Train net output #0: center_loss = 26.2466 (* 0.008 = 0.209973 loss)
I0826 15:43:56.923681 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.70447 (* 1 = 8.70447 loss)
I0826 15:43:56.923684 25446 sgd_solver.cpp:138] Iteration 4970, lr = 0.001
I0826 15:43:58.986886 25446 solver.cpp:243] Iteration 4980, loss = 8.93194
I0826 15:43:58.986923 25446 solver.cpp:259]     Train net output #0: center_loss = 24.7905 (* 0.008 = 0.198324 loss)
I0826 15:43:58.986929 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.73362 (* 1 = 8.73362 loss)
I0826 15:43:58.986932 25446 sgd_solver.cpp:138] Iteration 4980, lr = 0.001
I0826 15:44:01.058292 25446 solver.cpp:243] Iteration 4990, loss = 9.02794
I0826 15:44:01.058316 25446 solver.cpp:259]     Train net output #0: center_loss = 21.8609 (* 0.008 = 0.174888 loss)
I0826 15:44:01.058322 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85305 (* 1 = 8.85305 loss)
I0826 15:44:01.058342 25446 sgd_solver.cpp:138] Iteration 4990, lr = 0.001
I0826 15:44:02.963066 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_5000.caffemodel
I0826 15:44:04.097290 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_5000.solverstate
I0826 15:44:04.445073 25446 solver.cpp:243] Iteration 5000, loss = 8.88815
I0826 15:44:04.445097 25446 solver.cpp:259]     Train net output #0: center_loss = 26.1867 (* 0.008 = 0.209493 loss)
I0826 15:44:04.445124 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.67866 (* 1 = 8.67866 loss)
I0826 15:44:04.445129 25446 sgd_solver.cpp:138] Iteration 5000, lr = 0.001
I0826 15:44:06.519040 25446 solver.cpp:243] Iteration 5010, loss = 8.87845
I0826 15:44:06.519063 25446 solver.cpp:259]     Train net output #0: center_loss = 21.4647 (* 0.008 = 0.171717 loss)
I0826 15:44:06.519069 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.70674 (* 1 = 8.70674 loss)
I0826 15:44:06.519073 25446 sgd_solver.cpp:138] Iteration 5010, lr = 0.001
I0826 15:44:08.598327 25446 solver.cpp:243] Iteration 5020, loss = 8.99745
I0826 15:44:08.598351 25446 solver.cpp:259]     Train net output #0: center_loss = 24.2949 (* 0.008 = 0.194359 loss)
I0826 15:44:08.598357 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.80309 (* 1 = 8.80309 loss)
I0826 15:44:08.598361 25446 sgd_solver.cpp:138] Iteration 5020, lr = 0.001
I0826 15:44:10.707516 25446 solver.cpp:243] Iteration 5030, loss = 8.87755
I0826 15:44:10.707538 25446 solver.cpp:259]     Train net output #0: center_loss = 27.8298 (* 0.008 = 0.222639 loss)
I0826 15:44:10.707545 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.65491 (* 1 = 8.65491 loss)
I0826 15:44:10.707547 25446 sgd_solver.cpp:138] Iteration 5030, lr = 0.001
I0826 15:44:12.802320 25446 solver.cpp:243] Iteration 5040, loss = 8.95486
I0826 15:44:12.802431 25446 solver.cpp:259]     Train net output #0: center_loss = 26.158 (* 0.008 = 0.209264 loss)
I0826 15:44:12.802453 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.7456 (* 1 = 8.7456 loss)
I0826 15:44:12.802456 25446 sgd_solver.cpp:138] Iteration 5040, lr = 0.001
I0826 15:44:14.888298 25446 solver.cpp:243] Iteration 5050, loss = 8.68865
I0826 15:44:14.888321 25446 solver.cpp:259]     Train net output #0: center_loss = 21.5294 (* 0.008 = 0.172235 loss)
I0826 15:44:14.888342 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.51641 (* 1 = 8.51641 loss)
I0826 15:44:14.888345 25446 sgd_solver.cpp:138] Iteration 5050, lr = 0.001
I0826 15:44:17.018520 25446 solver.cpp:243] Iteration 5060, loss = 9.25881
I0826 15:44:17.018543 25446 solver.cpp:259]     Train net output #0: center_loss = 24.5295 (* 0.008 = 0.196236 loss)
I0826 15:44:17.018549 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.06258 (* 1 = 9.06258 loss)
I0826 15:44:17.018553 25446 sgd_solver.cpp:138] Iteration 5060, lr = 0.001
I0826 15:44:19.077536 25446 solver.cpp:243] Iteration 5070, loss = 8.86731
I0826 15:44:19.077560 25446 solver.cpp:259]     Train net output #0: center_loss = 24.81 (* 0.008 = 0.19848 loss)
I0826 15:44:19.077566 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.66883 (* 1 = 8.66883 loss)
I0826 15:44:19.077571 25446 sgd_solver.cpp:138] Iteration 5070, lr = 0.001
I0826 15:44:21.251952 25446 solver.cpp:243] Iteration 5080, loss = 9.04268
I0826 15:44:21.251989 25446 solver.cpp:259]     Train net output #0: center_loss = 26.9615 (* 0.008 = 0.215692 loss)
I0826 15:44:21.251996 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.82699 (* 1 = 8.82699 loss)
I0826 15:44:21.251999 25446 sgd_solver.cpp:138] Iteration 5080, lr = 0.001
I0826 15:44:23.411799 25446 solver.cpp:243] Iteration 5090, loss = 8.85468
I0826 15:44:23.411824 25446 solver.cpp:259]     Train net output #0: center_loss = 29.4733 (* 0.008 = 0.235787 loss)
I0826 15:44:23.411830 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.61889 (* 1 = 8.61889 loss)
I0826 15:44:23.411834 25446 sgd_solver.cpp:138] Iteration 5090, lr = 0.001
I0826 15:44:25.497403 25446 solver.cpp:243] Iteration 5100, loss = 8.78101
I0826 15:44:25.497438 25446 solver.cpp:259]     Train net output #0: center_loss = 29.0267 (* 0.008 = 0.232213 loss)
I0826 15:44:25.497444 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.5488 (* 1 = 8.5488 loss)
I0826 15:44:25.497448 25446 sgd_solver.cpp:138] Iteration 5100, lr = 0.001
I0826 15:44:27.561115 25446 solver.cpp:243] Iteration 5110, loss = 9.00089
I0826 15:44:27.561151 25446 solver.cpp:259]     Train net output #0: center_loss = 24.129 (* 0.008 = 0.193032 loss)
I0826 15:44:27.561157 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.80785 (* 1 = 8.80785 loss)
I0826 15:44:27.561161 25446 sgd_solver.cpp:138] Iteration 5110, lr = 0.001
I0826 15:44:29.623293 25446 solver.cpp:243] Iteration 5120, loss = 8.88697
I0826 15:44:29.623332 25446 solver.cpp:259]     Train net output #0: center_loss = 24.3031 (* 0.008 = 0.194424 loss)
I0826 15:44:29.623337 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.69254 (* 1 = 8.69254 loss)
I0826 15:44:29.623340 25446 sgd_solver.cpp:138] Iteration 5120, lr = 0.001
I0826 15:44:31.720628 25446 solver.cpp:243] Iteration 5130, loss = 8.95588
I0826 15:44:31.720657 25446 solver.cpp:259]     Train net output #0: center_loss = 25.1247 (* 0.008 = 0.200997 loss)
I0826 15:44:31.720664 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.75489 (* 1 = 8.75489 loss)
I0826 15:44:31.720669 25446 sgd_solver.cpp:138] Iteration 5130, lr = 0.001
I0826 15:44:33.836316 25446 solver.cpp:243] Iteration 5140, loss = 9.00744
I0826 15:44:33.836354 25446 solver.cpp:259]     Train net output #0: center_loss = 21.0068 (* 0.008 = 0.168054 loss)
I0826 15:44:33.836361 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.83939 (* 1 = 8.83939 loss)
I0826 15:44:33.836365 25446 sgd_solver.cpp:138] Iteration 5140, lr = 0.001
I0826 15:44:36.024031 25446 solver.cpp:243] Iteration 5150, loss = 9.05899
I0826 15:44:36.024080 25446 solver.cpp:259]     Train net output #0: center_loss = 21.5533 (* 0.008 = 0.172427 loss)
I0826 15:44:36.024087 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.88656 (* 1 = 8.88656 loss)
I0826 15:44:36.024092 25446 sgd_solver.cpp:138] Iteration 5150, lr = 0.001
I0826 15:44:38.214913 25446 solver.cpp:243] Iteration 5160, loss = 9.0179
I0826 15:44:38.214938 25446 solver.cpp:259]     Train net output #0: center_loss = 21.8704 (* 0.008 = 0.174963 loss)
I0826 15:44:38.214946 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.84293 (* 1 = 8.84293 loss)
I0826 15:44:38.214949 25446 sgd_solver.cpp:138] Iteration 5160, lr = 0.001
I0826 15:44:40.369079 25446 solver.cpp:243] Iteration 5170, loss = 9.19056
I0826 15:44:40.369107 25446 solver.cpp:259]     Train net output #0: center_loss = 20.4668 (* 0.008 = 0.163734 loss)
I0826 15:44:40.369113 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.02682 (* 1 = 9.02682 loss)
I0826 15:44:40.369118 25446 sgd_solver.cpp:138] Iteration 5170, lr = 0.001
I0826 15:44:42.469941 25446 solver.cpp:243] Iteration 5180, loss = 8.88746
I0826 15:44:42.469980 25446 solver.cpp:259]     Train net output #0: center_loss = 22.3257 (* 0.008 = 0.178606 loss)
I0826 15:44:42.469986 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.70886 (* 1 = 8.70886 loss)
I0826 15:44:42.469991 25446 sgd_solver.cpp:138] Iteration 5180, lr = 0.001
I0826 15:44:44.529901 25446 solver.cpp:243] Iteration 5190, loss = 8.90489
I0826 15:44:44.530019 25446 solver.cpp:259]     Train net output #0: center_loss = 23.3893 (* 0.008 = 0.187114 loss)
I0826 15:44:44.530025 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.71778 (* 1 = 8.71778 loss)
I0826 15:44:44.530030 25446 sgd_solver.cpp:138] Iteration 5190, lr = 0.001
I0826 15:44:46.587316 25446 solver.cpp:243] Iteration 5200, loss = 9.07456
I0826 15:44:46.587353 25446 solver.cpp:259]     Train net output #0: center_loss = 33.72 (* 0.008 = 0.26976 loss)
I0826 15:44:46.587359 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.8048 (* 1 = 8.8048 loss)
I0826 15:44:46.587363 25446 sgd_solver.cpp:138] Iteration 5200, lr = 0.001
I0826 15:44:48.645280 25446 solver.cpp:243] Iteration 5210, loss = 9.11572
I0826 15:44:48.645318 25446 solver.cpp:259]     Train net output #0: center_loss = 25.5312 (* 0.008 = 0.204249 loss)
I0826 15:44:48.645323 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.91147 (* 1 = 8.91147 loss)
I0826 15:44:48.645326 25446 sgd_solver.cpp:138] Iteration 5210, lr = 0.001
I0826 15:44:50.701967 25446 solver.cpp:243] Iteration 5220, loss = 8.73273
I0826 15:44:50.702005 25446 solver.cpp:259]     Train net output #0: center_loss = 27.0274 (* 0.008 = 0.216219 loss)
I0826 15:44:50.702011 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.51651 (* 1 = 8.51651 loss)
I0826 15:44:50.702014 25446 sgd_solver.cpp:138] Iteration 5220, lr = 0.001
I0826 15:44:52.758440 25446 solver.cpp:243] Iteration 5230, loss = 8.94251
I0826 15:44:52.758477 25446 solver.cpp:259]     Train net output #0: center_loss = 29.8542 (* 0.008 = 0.238834 loss)
I0826 15:44:52.758483 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.70367 (* 1 = 8.70367 loss)
I0826 15:44:52.758486 25446 sgd_solver.cpp:138] Iteration 5230, lr = 0.001
I0826 15:44:54.837190 25446 solver.cpp:243] Iteration 5240, loss = 8.99614
I0826 15:44:54.837229 25446 solver.cpp:259]     Train net output #0: center_loss = 22.7439 (* 0.008 = 0.181951 loss)
I0826 15:44:54.837234 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.81419 (* 1 = 8.81419 loss)
I0826 15:44:54.837239 25446 sgd_solver.cpp:138] Iteration 5240, lr = 0.001
I0826 15:44:56.900871 25446 solver.cpp:243] Iteration 5250, loss = 9.15137
I0826 15:44:56.900909 25446 solver.cpp:259]     Train net output #0: center_loss = 27.0178 (* 0.008 = 0.216143 loss)
I0826 15:44:56.900914 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.93523 (* 1 = 8.93523 loss)
I0826 15:44:56.900918 25446 sgd_solver.cpp:138] Iteration 5250, lr = 0.001
I0826 15:44:59.032263 25446 solver.cpp:243] Iteration 5260, loss = 8.8458
I0826 15:44:59.032300 25446 solver.cpp:259]     Train net output #0: center_loss = 29.582 (* 0.008 = 0.236656 loss)
I0826 15:44:59.032305 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.60915 (* 1 = 8.60915 loss)
I0826 15:44:59.032310 25446 sgd_solver.cpp:138] Iteration 5260, lr = 0.001
I0826 15:45:01.203393 25446 solver.cpp:243] Iteration 5270, loss = 8.86841
I0826 15:45:01.203431 25446 solver.cpp:259]     Train net output #0: center_loss = 23.5054 (* 0.008 = 0.188043 loss)
I0826 15:45:01.203438 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.68036 (* 1 = 8.68036 loss)
I0826 15:45:01.203442 25446 sgd_solver.cpp:138] Iteration 5270, lr = 0.001
I0826 15:45:03.305187 25446 solver.cpp:243] Iteration 5280, loss = 8.85105
I0826 15:45:03.305225 25446 solver.cpp:259]     Train net output #0: center_loss = 23.6085 (* 0.008 = 0.188868 loss)
I0826 15:45:03.305232 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.66218 (* 1 = 8.66218 loss)
I0826 15:45:03.305234 25446 sgd_solver.cpp:138] Iteration 5280, lr = 0.001
I0826 15:45:05.382165 25446 solver.cpp:243] Iteration 5290, loss = 8.79917
I0826 15:45:05.382205 25446 solver.cpp:259]     Train net output #0: center_loss = 25.8884 (* 0.008 = 0.207107 loss)
I0826 15:45:05.382211 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.59206 (* 1 = 8.59206 loss)
I0826 15:45:05.382215 25446 sgd_solver.cpp:138] Iteration 5290, lr = 0.001
I0826 15:45:07.438956 25446 solver.cpp:243] Iteration 5300, loss = 9.06173
I0826 15:45:07.438993 25446 solver.cpp:259]     Train net output #0: center_loss = 24.6621 (* 0.008 = 0.197297 loss)
I0826 15:45:07.438999 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.86444 (* 1 = 8.86444 loss)
I0826 15:45:07.439002 25446 sgd_solver.cpp:138] Iteration 5300, lr = 0.001
I0826 15:45:09.499593 25446 solver.cpp:243] Iteration 5310, loss = 9.04129
I0826 15:45:09.499615 25446 solver.cpp:259]     Train net output #0: center_loss = 28.3904 (* 0.008 = 0.227124 loss)
I0826 15:45:09.499636 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.81416 (* 1 = 8.81416 loss)
I0826 15:45:09.499639 25446 sgd_solver.cpp:138] Iteration 5310, lr = 0.001
I0826 15:45:11.560950 25446 solver.cpp:243] Iteration 5320, loss = 8.96927
I0826 15:45:11.560986 25446 solver.cpp:259]     Train net output #0: center_loss = 29.6569 (* 0.008 = 0.237255 loss)
I0826 15:45:11.560992 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.73201 (* 1 = 8.73201 loss)
I0826 15:45:11.560995 25446 sgd_solver.cpp:138] Iteration 5320, lr = 0.001
I0826 15:45:13.620302 25446 solver.cpp:243] Iteration 5330, loss = 8.96187
I0826 15:45:13.620339 25446 solver.cpp:259]     Train net output #0: center_loss = 31.1084 (* 0.008 = 0.248867 loss)
I0826 15:45:13.620345 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.713 (* 1 = 8.713 loss)
I0826 15:45:13.620348 25446 sgd_solver.cpp:138] Iteration 5330, lr = 0.001
I0826 15:45:15.677945 25446 solver.cpp:243] Iteration 5340, loss = 9.09962
I0826 15:45:15.678119 25446 solver.cpp:259]     Train net output #0: center_loss = 25.0088 (* 0.008 = 0.20007 loss)
I0826 15:45:15.678139 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.89955 (* 1 = 8.89955 loss)
I0826 15:45:15.678143 25446 sgd_solver.cpp:138] Iteration 5340, lr = 0.001
I0826 15:45:17.764802 25446 solver.cpp:243] Iteration 5350, loss = 8.64382
I0826 15:45:17.764825 25446 solver.cpp:259]     Train net output #0: center_loss = 24.3803 (* 0.008 = 0.195043 loss)
I0826 15:45:17.764832 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.44878 (* 1 = 8.44878 loss)
I0826 15:45:17.764834 25446 sgd_solver.cpp:138] Iteration 5350, lr = 0.001
I0826 15:45:19.825670 25446 solver.cpp:243] Iteration 5360, loss = 9.14627
I0826 15:45:19.825707 25446 solver.cpp:259]     Train net output #0: center_loss = 24.689 (* 0.008 = 0.197512 loss)
I0826 15:45:19.825713 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.94876 (* 1 = 8.94876 loss)
I0826 15:45:19.825716 25446 sgd_solver.cpp:138] Iteration 5360, lr = 0.001
I0826 15:45:21.888659 25446 solver.cpp:243] Iteration 5370, loss = 8.93518
I0826 15:45:21.888695 25446 solver.cpp:259]     Train net output #0: center_loss = 26.8881 (* 0.008 = 0.215105 loss)
I0826 15:45:21.888702 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.72008 (* 1 = 8.72008 loss)
I0826 15:45:21.888705 25446 sgd_solver.cpp:138] Iteration 5370, lr = 0.001
I0826 15:45:23.952666 25446 solver.cpp:243] Iteration 5380, loss = 8.86213
I0826 15:45:23.952689 25446 solver.cpp:259]     Train net output #0: center_loss = 21.2089 (* 0.008 = 0.169671 loss)
I0826 15:45:23.952695 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.69246 (* 1 = 8.69246 loss)
I0826 15:45:23.952699 25446 sgd_solver.cpp:138] Iteration 5380, lr = 0.001
I0826 15:45:26.040288 25446 solver.cpp:243] Iteration 5390, loss = 8.961
I0826 15:45:26.040313 25446 solver.cpp:259]     Train net output #0: center_loss = 27.379 (* 0.008 = 0.219032 loss)
I0826 15:45:26.040318 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.74197 (* 1 = 8.74197 loss)
I0826 15:45:26.040323 25446 sgd_solver.cpp:138] Iteration 5390, lr = 0.001
I0826 15:45:28.107867 25446 solver.cpp:243] Iteration 5400, loss = 8.79657
I0826 15:45:28.107904 25446 solver.cpp:259]     Train net output #0: center_loss = 26.4328 (* 0.008 = 0.211462 loss)
I0826 15:45:28.107909 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.58511 (* 1 = 8.58511 loss)
I0826 15:45:28.107913 25446 sgd_solver.cpp:138] Iteration 5400, lr = 0.001
I0826 15:45:30.202994 25446 solver.cpp:243] Iteration 5410, loss = 8.95862
I0826 15:45:30.203022 25446 solver.cpp:259]     Train net output #0: center_loss = 31.963 (* 0.008 = 0.255704 loss)
I0826 15:45:30.203028 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.70291 (* 1 = 8.70291 loss)
I0826 15:45:30.203033 25446 sgd_solver.cpp:138] Iteration 5410, lr = 0.001
I0826 15:45:32.355901 25446 solver.cpp:243] Iteration 5420, loss = 9.12124
I0826 15:45:32.355931 25446 solver.cpp:259]     Train net output #0: center_loss = 29.072 (* 0.008 = 0.232576 loss)
I0826 15:45:32.355937 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.88867 (* 1 = 8.88867 loss)
I0826 15:45:32.355942 25446 sgd_solver.cpp:138] Iteration 5420, lr = 0.001
I0826 15:45:34.589716 25446 solver.cpp:243] Iteration 5430, loss = 9.16174
I0826 15:45:34.589740 25446 solver.cpp:259]     Train net output #0: center_loss = 23.5541 (* 0.008 = 0.188433 loss)
I0826 15:45:34.589745 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.9733 (* 1 = 8.9733 loss)
I0826 15:45:34.589749 25446 sgd_solver.cpp:138] Iteration 5430, lr = 0.001
I0826 15:45:36.697796 25446 solver.cpp:243] Iteration 5440, loss = 9.06474
I0826 15:45:36.697834 25446 solver.cpp:259]     Train net output #0: center_loss = 26.8916 (* 0.008 = 0.215133 loss)
I0826 15:45:36.697839 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.84961 (* 1 = 8.84961 loss)
I0826 15:45:36.697844 25446 sgd_solver.cpp:138] Iteration 5440, lr = 0.001
I0826 15:45:38.832996 25446 solver.cpp:243] Iteration 5450, loss = 8.66898
I0826 15:45:38.833041 25446 solver.cpp:259]     Train net output #0: center_loss = 33.8353 (* 0.008 = 0.270683 loss)
I0826 15:45:38.833047 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.3983 (* 1 = 8.3983 loss)
I0826 15:45:38.833051 25446 sgd_solver.cpp:138] Iteration 5450, lr = 0.001
I0826 15:45:40.948537 25446 solver.cpp:243] Iteration 5460, loss = 8.81749
I0826 15:45:40.948563 25446 solver.cpp:259]     Train net output #0: center_loss = 27.3136 (* 0.008 = 0.218509 loss)
I0826 15:45:40.948570 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.59899 (* 1 = 8.59899 loss)
I0826 15:45:40.948575 25446 sgd_solver.cpp:138] Iteration 5460, lr = 0.001
I0826 15:45:43.180055 25446 solver.cpp:243] Iteration 5470, loss = 8.90406
I0826 15:45:43.180080 25446 solver.cpp:259]     Train net output #0: center_loss = 34.4213 (* 0.008 = 0.27537 loss)
I0826 15:45:43.180086 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.62869 (* 1 = 8.62869 loss)
I0826 15:45:43.180091 25446 sgd_solver.cpp:138] Iteration 5470, lr = 0.001
I0826 15:45:45.324793 25446 solver.cpp:243] Iteration 5480, loss = 8.96565
I0826 15:45:45.324831 25446 solver.cpp:259]     Train net output #0: center_loss = 26.4191 (* 0.008 = 0.211353 loss)
I0826 15:45:45.324836 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.75429 (* 1 = 8.75429 loss)
I0826 15:45:45.324841 25446 sgd_solver.cpp:138] Iteration 5480, lr = 0.001
I0826 15:45:47.483119 25446 solver.cpp:243] Iteration 5490, loss = 8.90793
I0826 15:45:47.483237 25446 solver.cpp:259]     Train net output #0: center_loss = 32.0173 (* 0.008 = 0.256139 loss)
I0826 15:45:47.483263 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.65179 (* 1 = 8.65179 loss)
I0826 15:45:47.483268 25446 sgd_solver.cpp:138] Iteration 5490, lr = 0.001
I0826 15:45:49.574479 25446 solver.cpp:243] Iteration 5500, loss = 8.91746
I0826 15:45:49.574506 25446 solver.cpp:259]     Train net output #0: center_loss = 29.2421 (* 0.008 = 0.233937 loss)
I0826 15:45:49.574527 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.68352 (* 1 = 8.68352 loss)
I0826 15:45:49.574530 25446 sgd_solver.cpp:138] Iteration 5500, lr = 0.001
I0826 15:45:51.643213 25446 solver.cpp:243] Iteration 5510, loss = 9.01408
I0826 15:45:51.643249 25446 solver.cpp:259]     Train net output #0: center_loss = 26.2823 (* 0.008 = 0.210258 loss)
I0826 15:45:51.643255 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.80382 (* 1 = 8.80382 loss)
I0826 15:45:51.643260 25446 sgd_solver.cpp:138] Iteration 5510, lr = 0.001
I0826 15:45:53.704749 25446 solver.cpp:243] Iteration 5520, loss = 8.67078
I0826 15:45:53.704787 25446 solver.cpp:259]     Train net output #0: center_loss = 31.0285 (* 0.008 = 0.248228 loss)
I0826 15:45:53.704793 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.42255 (* 1 = 8.42255 loss)
I0826 15:45:53.704797 25446 sgd_solver.cpp:138] Iteration 5520, lr = 0.001
I0826 15:45:55.770503 25446 solver.cpp:243] Iteration 5530, loss = 8.64913
I0826 15:45:55.770540 25446 solver.cpp:259]     Train net output #0: center_loss = 31.8077 (* 0.008 = 0.254462 loss)
I0826 15:45:55.770546 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.39467 (* 1 = 8.39467 loss)
I0826 15:45:55.770550 25446 sgd_solver.cpp:138] Iteration 5530, lr = 0.001
I0826 15:45:57.835306 25446 solver.cpp:243] Iteration 5540, loss = 8.94199
I0826 15:45:57.835342 25446 solver.cpp:259]     Train net output #0: center_loss = 28.7371 (* 0.008 = 0.229897 loss)
I0826 15:45:57.835348 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.7121 (* 1 = 8.7121 loss)
I0826 15:45:57.835352 25446 sgd_solver.cpp:138] Iteration 5540, lr = 0.001
I0826 15:45:59.923099 25446 solver.cpp:243] Iteration 5550, loss = 8.75201
I0826 15:45:59.923135 25446 solver.cpp:259]     Train net output #0: center_loss = 29.6469 (* 0.008 = 0.237176 loss)
I0826 15:45:59.923141 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.51484 (* 1 = 8.51484 loss)
I0826 15:45:59.923144 25446 sgd_solver.cpp:138] Iteration 5550, lr = 0.001
I0826 15:46:01.986189 25446 solver.cpp:243] Iteration 5560, loss = 8.75638
I0826 15:46:01.986225 25446 solver.cpp:259]     Train net output #0: center_loss = 26.1457 (* 0.008 = 0.209165 loss)
I0826 15:46:01.986232 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.54721 (* 1 = 8.54721 loss)
I0826 15:46:01.986234 25446 sgd_solver.cpp:138] Iteration 5560, lr = 0.001
I0826 15:46:04.069016 25446 solver.cpp:243] Iteration 5570, loss = 8.99831
I0826 15:46:04.069041 25446 solver.cpp:259]     Train net output #0: center_loss = 34.4903 (* 0.008 = 0.275923 loss)
I0826 15:46:04.069046 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.72239 (* 1 = 8.72239 loss)
I0826 15:46:04.069051 25446 sgd_solver.cpp:138] Iteration 5570, lr = 0.001
I0826 15:46:06.133791 25446 solver.cpp:243] Iteration 5580, loss = 9.00172
I0826 15:46:06.133829 25446 solver.cpp:259]     Train net output #0: center_loss = 31.0335 (* 0.008 = 0.248268 loss)
I0826 15:46:06.133834 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.75346 (* 1 = 8.75346 loss)
I0826 15:46:06.133853 25446 sgd_solver.cpp:138] Iteration 5580, lr = 0.001
I0826 15:46:08.196923 25446 solver.cpp:243] Iteration 5590, loss = 9.21301
I0826 15:46:08.196944 25446 solver.cpp:259]     Train net output #0: center_loss = 26.4602 (* 0.008 = 0.211682 loss)
I0826 15:46:08.196950 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.00133 (* 1 = 9.00133 loss)
I0826 15:46:08.196954 25446 sgd_solver.cpp:138] Iteration 5590, lr = 0.001
I0826 15:46:10.295377 25446 solver.cpp:243] Iteration 5600, loss = 8.75224
I0826 15:46:10.295416 25446 solver.cpp:259]     Train net output #0: center_loss = 29.2266 (* 0.008 = 0.233813 loss)
I0826 15:46:10.295421 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.51843 (* 1 = 8.51843 loss)
I0826 15:46:10.295425 25446 sgd_solver.cpp:138] Iteration 5600, lr = 0.001
I0826 15:46:12.357235 25446 solver.cpp:243] Iteration 5610, loss = 8.6057
I0826 15:46:12.357275 25446 solver.cpp:259]     Train net output #0: center_loss = 30.0572 (* 0.008 = 0.240458 loss)
I0826 15:46:12.357281 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36524 (* 1 = 8.36524 loss)
I0826 15:46:12.357285 25446 sgd_solver.cpp:138] Iteration 5610, lr = 0.001
I0826 15:46:14.428855 25446 solver.cpp:243] Iteration 5620, loss = 8.81594
I0826 15:46:14.428894 25446 solver.cpp:259]     Train net output #0: center_loss = 30.0269 (* 0.008 = 0.240215 loss)
I0826 15:46:14.428900 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.57572 (* 1 = 8.57572 loss)
I0826 15:46:14.428903 25446 sgd_solver.cpp:138] Iteration 5620, lr = 0.001
I0826 15:46:16.507730 25446 solver.cpp:243] Iteration 5630, loss = 8.90982
I0826 15:46:16.507753 25446 solver.cpp:259]     Train net output #0: center_loss = 31.8226 (* 0.008 = 0.254581 loss)
I0826 15:46:16.507773 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.65524 (* 1 = 8.65524 loss)
I0826 15:46:16.507777 25446 sgd_solver.cpp:138] Iteration 5630, lr = 0.001
I0826 15:46:18.565766 25446 solver.cpp:243] Iteration 5640, loss = 9.05631
I0826 15:46:18.565886 25446 solver.cpp:259]     Train net output #0: center_loss = 31.0358 (* 0.008 = 0.248287 loss)
I0826 15:46:18.565892 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.80803 (* 1 = 8.80803 loss)
I0826 15:46:18.565896 25446 sgd_solver.cpp:138] Iteration 5640, lr = 0.001
I0826 15:46:20.624491 25446 solver.cpp:243] Iteration 5650, loss = 8.8986
I0826 15:46:20.624528 25446 solver.cpp:259]     Train net output #0: center_loss = 25.3548 (* 0.008 = 0.202838 loss)
I0826 15:46:20.624533 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.69576 (* 1 = 8.69576 loss)
I0826 15:46:20.624537 25446 sgd_solver.cpp:138] Iteration 5650, lr = 0.001
I0826 15:46:22.680871 25446 solver.cpp:243] Iteration 5660, loss = 8.95432
I0826 15:46:22.680907 25446 solver.cpp:259]     Train net output #0: center_loss = 27.6329 (* 0.008 = 0.221063 loss)
I0826 15:46:22.680913 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.73326 (* 1 = 8.73326 loss)
I0826 15:46:22.680917 25446 sgd_solver.cpp:138] Iteration 5660, lr = 0.001
I0826 15:46:24.745453 25446 solver.cpp:243] Iteration 5670, loss = 8.93094
I0826 15:46:24.745491 25446 solver.cpp:259]     Train net output #0: center_loss = 31.4552 (* 0.008 = 0.251641 loss)
I0826 15:46:24.745496 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.6793 (* 1 = 8.6793 loss)
I0826 15:46:24.745499 25446 sgd_solver.cpp:138] Iteration 5670, lr = 0.001
I0826 15:46:26.802402 25446 solver.cpp:243] Iteration 5680, loss = 8.6624
I0826 15:46:26.802439 25446 solver.cpp:259]     Train net output #0: center_loss = 35.3016 (* 0.008 = 0.282413 loss)
I0826 15:46:26.802445 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.37999 (* 1 = 8.37999 loss)
I0826 15:46:26.802449 25446 sgd_solver.cpp:138] Iteration 5680, lr = 0.001
I0826 15:46:28.867471 25446 solver.cpp:243] Iteration 5690, loss = 8.84199
I0826 15:46:28.867494 25446 solver.cpp:259]     Train net output #0: center_loss = 22.8273 (* 0.008 = 0.182619 loss)
I0826 15:46:28.867501 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.65937 (* 1 = 8.65937 loss)
I0826 15:46:28.867504 25446 sgd_solver.cpp:138] Iteration 5690, lr = 0.001
I0826 15:46:31.022511 25446 solver.cpp:243] Iteration 5700, loss = 8.68694
I0826 15:46:31.022534 25446 solver.cpp:259]     Train net output #0: center_loss = 30.7349 (* 0.008 = 0.245879 loss)
I0826 15:46:31.022541 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.44106 (* 1 = 8.44106 loss)
I0826 15:46:31.022544 25446 sgd_solver.cpp:138] Iteration 5700, lr = 0.001
I0826 15:46:33.110707 25446 solver.cpp:243] Iteration 5710, loss = 8.99637
I0826 15:46:33.110729 25446 solver.cpp:259]     Train net output #0: center_loss = 27.0208 (* 0.008 = 0.216167 loss)
I0826 15:46:33.110736 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.78021 (* 1 = 8.78021 loss)
I0826 15:46:33.110740 25446 sgd_solver.cpp:138] Iteration 5710, lr = 0.001
I0826 15:46:35.203233 25446 solver.cpp:243] Iteration 5720, loss = 8.85702
I0826 15:46:35.203260 25446 solver.cpp:259]     Train net output #0: center_loss = 29.2297 (* 0.008 = 0.233838 loss)
I0826 15:46:35.203266 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.62318 (* 1 = 8.62318 loss)
I0826 15:46:35.203271 25446 sgd_solver.cpp:138] Iteration 5720, lr = 0.001
I0826 15:46:37.357832 25446 solver.cpp:243] Iteration 5730, loss = 8.88475
I0826 15:46:37.357861 25446 solver.cpp:259]     Train net output #0: center_loss = 32.3514 (* 0.008 = 0.258811 loss)
I0826 15:46:37.357867 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.62593 (* 1 = 8.62593 loss)
I0826 15:46:37.357872 25446 sgd_solver.cpp:138] Iteration 5730, lr = 0.001
I0826 15:46:39.500582 25446 solver.cpp:243] Iteration 5740, loss = 8.92773
I0826 15:46:39.500610 25446 solver.cpp:259]     Train net output #0: center_loss = 34.1327 (* 0.008 = 0.273061 loss)
I0826 15:46:39.500617 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.65467 (* 1 = 8.65467 loss)
I0826 15:46:39.500622 25446 sgd_solver.cpp:138] Iteration 5740, lr = 0.001
I0826 15:46:41.608893 25446 solver.cpp:243] Iteration 5750, loss = 8.95295
I0826 15:46:41.608961 25446 solver.cpp:259]     Train net output #0: center_loss = 34.2787 (* 0.008 = 0.27423 loss)
I0826 15:46:41.608968 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.67872 (* 1 = 8.67872 loss)
I0826 15:46:41.608988 25446 sgd_solver.cpp:138] Iteration 5750, lr = 0.001
I0826 15:46:43.757819 25446 solver.cpp:243] Iteration 5760, loss = 9.06855
I0826 15:46:43.757858 25446 solver.cpp:259]     Train net output #0: center_loss = 35.387 (* 0.008 = 0.283096 loss)
I0826 15:46:43.757863 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.78546 (* 1 = 8.78546 loss)
I0826 15:46:43.757865 25446 sgd_solver.cpp:138] Iteration 5760, lr = 0.001
I0826 15:46:45.915416 25446 solver.cpp:243] Iteration 5770, loss = 9.05735
I0826 15:46:45.915452 25446 solver.cpp:259]     Train net output #0: center_loss = 35.6287 (* 0.008 = 0.28503 loss)
I0826 15:46:45.915462 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.77232 (* 1 = 8.77232 loss)
I0826 15:46:45.915468 25446 sgd_solver.cpp:138] Iteration 5770, lr = 0.001
I0826 15:46:48.027633 25446 solver.cpp:243] Iteration 5780, loss = 9.21401
I0826 15:46:48.027662 25446 solver.cpp:259]     Train net output #0: center_loss = 23.6087 (* 0.008 = 0.18887 loss)
I0826 15:46:48.027669 25446 solver.cpp:259]     Train net output #1: softmax_loss = 9.02514 (* 1 = 9.02514 loss)
I0826 15:46:48.027674 25446 sgd_solver.cpp:138] Iteration 5780, lr = 0.001
I0826 15:46:50.121861 25446 solver.cpp:243] Iteration 5790, loss = 8.78017
I0826 15:46:50.121976 25446 solver.cpp:259]     Train net output #0: center_loss = 29.7654 (* 0.008 = 0.238123 loss)
I0826 15:46:50.121984 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.54205 (* 1 = 8.54205 loss)
I0826 15:46:50.121989 25446 sgd_solver.cpp:138] Iteration 5790, lr = 0.001
I0826 15:46:52.211118 25446 solver.cpp:243] Iteration 5800, loss = 8.84876
I0826 15:46:52.211143 25446 solver.cpp:259]     Train net output #0: center_loss = 26.3834 (* 0.008 = 0.211067 loss)
I0826 15:46:52.211148 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.63769 (* 1 = 8.63769 loss)
I0826 15:46:52.211153 25446 sgd_solver.cpp:138] Iteration 5800, lr = 0.001
I0826 15:46:54.339308 25446 solver.cpp:243] Iteration 5810, loss = 8.82115
I0826 15:46:54.339336 25446 solver.cpp:259]     Train net output #0: center_loss = 32.9511 (* 0.008 = 0.263609 loss)
I0826 15:46:54.339342 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.55754 (* 1 = 8.55754 loss)
I0826 15:46:54.339347 25446 sgd_solver.cpp:138] Iteration 5810, lr = 0.001
I0826 15:46:56.496304 25446 solver.cpp:243] Iteration 5820, loss = 8.93278
I0826 15:46:56.496331 25446 solver.cpp:259]     Train net output #0: center_loss = 30.5811 (* 0.008 = 0.244649 loss)
I0826 15:46:56.496337 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.68813 (* 1 = 8.68813 loss)
I0826 15:46:56.496343 25446 sgd_solver.cpp:138] Iteration 5820, lr = 0.001
I0826 15:46:58.613106 25446 solver.cpp:243] Iteration 5830, loss = 8.81275
I0826 15:46:58.613133 25446 solver.cpp:259]     Train net output #0: center_loss = 33.9807 (* 0.008 = 0.271845 loss)
I0826 15:46:58.613140 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.5409 (* 1 = 8.5409 loss)
I0826 15:46:58.613145 25446 sgd_solver.cpp:138] Iteration 5830, lr = 0.001
I0826 15:47:00.755991 25446 solver.cpp:243] Iteration 5840, loss = 8.8932
I0826 15:47:00.756016 25446 solver.cpp:259]     Train net output #0: center_loss = 31.9371 (* 0.008 = 0.255497 loss)
I0826 15:47:00.756022 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.6377 (* 1 = 8.6377 loss)
I0826 15:47:00.756028 25446 sgd_solver.cpp:138] Iteration 5840, lr = 0.001
I0826 15:47:02.859149 25446 solver.cpp:243] Iteration 5850, loss = 8.64247
I0826 15:47:02.859175 25446 solver.cpp:259]     Train net output #0: center_loss = 28.1574 (* 0.008 = 0.225259 loss)
I0826 15:47:02.859181 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.41721 (* 1 = 8.41721 loss)
I0826 15:47:02.859186 25446 sgd_solver.cpp:138] Iteration 5850, lr = 0.001
I0826 15:47:04.982998 25446 solver.cpp:243] Iteration 5860, loss = 8.67553
I0826 15:47:04.983023 25446 solver.cpp:259]     Train net output #0: center_loss = 30.3018 (* 0.008 = 0.242414 loss)
I0826 15:47:04.983028 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.43311 (* 1 = 8.43311 loss)
I0826 15:47:04.983033 25446 sgd_solver.cpp:138] Iteration 5860, lr = 0.001
I0826 15:47:07.092856 25446 solver.cpp:243] Iteration 5870, loss = 8.95541
I0826 15:47:07.092886 25446 solver.cpp:259]     Train net output #0: center_loss = 31.9784 (* 0.008 = 0.255827 loss)
I0826 15:47:07.092893 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.69959 (* 1 = 8.69959 loss)
I0826 15:47:07.092900 25446 sgd_solver.cpp:138] Iteration 5870, lr = 0.001
I0826 15:47:09.188300 25446 solver.cpp:243] Iteration 5880, loss = 8.79171
I0826 15:47:09.188324 25446 solver.cpp:259]     Train net output #0: center_loss = 28.2983 (* 0.008 = 0.226387 loss)
I0826 15:47:09.188329 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.56532 (* 1 = 8.56532 loss)
I0826 15:47:09.188334 25446 sgd_solver.cpp:138] Iteration 5880, lr = 0.001
I0826 15:47:11.269490 25446 solver.cpp:243] Iteration 5890, loss = 8.91497
I0826 15:47:11.269515 25446 solver.cpp:259]     Train net output #0: center_loss = 35.8127 (* 0.008 = 0.286502 loss)
I0826 15:47:11.269520 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.62847 (* 1 = 8.62847 loss)
I0826 15:47:11.269526 25446 sgd_solver.cpp:138] Iteration 5890, lr = 0.001
I0826 15:47:13.354845 25446 solver.cpp:243] Iteration 5900, loss = 9.11341
I0826 15:47:13.354868 25446 solver.cpp:259]     Train net output #0: center_loss = 33.1172 (* 0.008 = 0.264938 loss)
I0826 15:47:13.354874 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.84847 (* 1 = 8.84847 loss)
I0826 15:47:13.354879 25446 sgd_solver.cpp:138] Iteration 5900, lr = 0.001
I0826 15:47:15.429231 25446 solver.cpp:243] Iteration 5910, loss = 8.65944
I0826 15:47:15.429260 25446 solver.cpp:259]     Train net output #0: center_loss = 39.4873 (* 0.008 = 0.315898 loss)
I0826 15:47:15.429265 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.34354 (* 1 = 8.34354 loss)
I0826 15:47:15.429270 25446 sgd_solver.cpp:138] Iteration 5910, lr = 0.001
I0826 15:47:17.531778 25446 solver.cpp:243] Iteration 5920, loss = 9.05482
I0826 15:47:17.531800 25446 solver.cpp:259]     Train net output #0: center_loss = 30.2522 (* 0.008 = 0.242018 loss)
I0826 15:47:17.531807 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.8128 (* 1 = 8.8128 loss)
I0826 15:47:17.531811 25446 sgd_solver.cpp:138] Iteration 5920, lr = 0.001
I0826 15:47:19.651144 25446 solver.cpp:243] Iteration 5930, loss = 8.82259
I0826 15:47:19.651170 25446 solver.cpp:259]     Train net output #0: center_loss = 27.5194 (* 0.008 = 0.220155 loss)
I0826 15:47:19.651175 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.60244 (* 1 = 8.60244 loss)
I0826 15:47:19.651180 25446 sgd_solver.cpp:138] Iteration 5930, lr = 0.001
I0826 15:47:21.773497 25446 solver.cpp:243] Iteration 5940, loss = 8.60745
I0826 15:47:21.773654 25446 solver.cpp:259]     Train net output #0: center_loss = 40.8564 (* 0.008 = 0.326851 loss)
I0826 15:47:21.773661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.2806 (* 1 = 8.2806 loss)
I0826 15:47:21.773677 25446 sgd_solver.cpp:138] Iteration 5940, lr = 0.001
I0826 15:47:23.856300 25446 solver.cpp:243] Iteration 5950, loss = 8.65049
I0826 15:47:23.856324 25446 solver.cpp:259]     Train net output #0: center_loss = 36.787 (* 0.008 = 0.294296 loss)
I0826 15:47:23.856330 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.3562 (* 1 = 8.3562 loss)
I0826 15:47:23.856334 25446 sgd_solver.cpp:138] Iteration 5950, lr = 0.001
I0826 15:47:25.915062 25446 solver.cpp:243] Iteration 5960, loss = 8.83775
I0826 15:47:25.915099 25446 solver.cpp:259]     Train net output #0: center_loss = 29.8078 (* 0.008 = 0.238462 loss)
I0826 15:47:25.915105 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.59929 (* 1 = 8.59929 loss)
I0826 15:47:25.915108 25446 sgd_solver.cpp:138] Iteration 5960, lr = 0.001
I0826 15:47:27.978194 25446 solver.cpp:243] Iteration 5970, loss = 8.57452
I0826 15:47:27.978232 25446 solver.cpp:259]     Train net output #0: center_loss = 37.4438 (* 0.008 = 0.29955 loss)
I0826 15:47:27.978238 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.27497 (* 1 = 8.27497 loss)
I0826 15:47:27.978242 25446 sgd_solver.cpp:138] Iteration 5970, lr = 0.001
I0826 15:47:30.040205 25446 solver.cpp:243] Iteration 5980, loss = 9.0198
I0826 15:47:30.040227 25446 solver.cpp:259]     Train net output #0: center_loss = 30.4353 (* 0.008 = 0.243482 loss)
I0826 15:47:30.040233 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.77632 (* 1 = 8.77632 loss)
I0826 15:47:30.040237 25446 sgd_solver.cpp:138] Iteration 5980, lr = 0.001
I0826 15:47:32.119755 25446 solver.cpp:243] Iteration 5990, loss = 8.69781
I0826 15:47:32.119792 25446 solver.cpp:259]     Train net output #0: center_loss = 35.342 (* 0.008 = 0.282736 loss)
I0826 15:47:32.119798 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.41507 (* 1 = 8.41507 loss)
I0826 15:47:32.119802 25446 sgd_solver.cpp:138] Iteration 5990, lr = 0.001
I0826 15:47:33.979298 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_6000.caffemodel
I0826 15:47:35.111228 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_6000.solverstate
I0826 15:47:35.439216 25446 solver.cpp:243] Iteration 6000, loss = 9.14403
I0826 15:47:35.439240 25446 solver.cpp:259]     Train net output #0: center_loss = 35.7793 (* 0.008 = 0.286235 loss)
I0826 15:47:35.439246 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.8578 (* 1 = 8.8578 loss)
I0826 15:47:35.439251 25446 sgd_solver.cpp:138] Iteration 6000, lr = 0.001
I0826 15:47:37.497711 25446 solver.cpp:243] Iteration 6010, loss = 8.8804
I0826 15:47:37.497750 25446 solver.cpp:259]     Train net output #0: center_loss = 30.241 (* 0.008 = 0.241928 loss)
I0826 15:47:37.497756 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.63848 (* 1 = 8.63848 loss)
I0826 15:47:37.497759 25446 sgd_solver.cpp:138] Iteration 6010, lr = 0.001
I0826 15:47:39.561662 25446 solver.cpp:243] Iteration 6020, loss = 9.11825
I0826 15:47:39.561699 25446 solver.cpp:259]     Train net output #0: center_loss = 31.4647 (* 0.008 = 0.251717 loss)
I0826 15:47:39.561705 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.86653 (* 1 = 8.86653 loss)
I0826 15:47:39.561708 25446 sgd_solver.cpp:138] Iteration 6020, lr = 0.001
I0826 15:47:41.627214 25446 solver.cpp:243] Iteration 6030, loss = 8.95432
I0826 15:47:41.627250 25446 solver.cpp:259]     Train net output #0: center_loss = 31.5917 (* 0.008 = 0.252734 loss)
I0826 15:47:41.627256 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.70159 (* 1 = 8.70159 loss)
I0826 15:47:41.627259 25446 sgd_solver.cpp:138] Iteration 6030, lr = 0.001
I0826 15:47:43.690333 25446 solver.cpp:243] Iteration 6040, loss = 9.06655
I0826 15:47:43.690357 25446 solver.cpp:259]     Train net output #0: center_loss = 26.8653 (* 0.008 = 0.214922 loss)
I0826 15:47:43.690387 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.85163 (* 1 = 8.85163 loss)
I0826 15:47:43.690390 25446 sgd_solver.cpp:138] Iteration 6040, lr = 0.001
I0826 15:47:45.750725 25446 solver.cpp:243] Iteration 6050, loss = 8.90471
I0826 15:47:45.750762 25446 solver.cpp:259]     Train net output #0: center_loss = 39.1513 (* 0.008 = 0.313211 loss)
I0826 15:47:45.750768 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.5915 (* 1 = 8.5915 loss)
I0826 15:47:45.750772 25446 sgd_solver.cpp:138] Iteration 6050, lr = 0.001
I0826 15:47:47.811214 25446 solver.cpp:243] Iteration 6060, loss = 8.83505
I0826 15:47:47.811254 25446 solver.cpp:259]     Train net output #0: center_loss = 33.5501 (* 0.008 = 0.268401 loss)
I0826 15:47:47.811259 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.56665 (* 1 = 8.56665 loss)
I0826 15:47:47.811262 25446 sgd_solver.cpp:138] Iteration 6060, lr = 0.001
I0826 15:47:49.869165 25446 solver.cpp:243] Iteration 6070, loss = 8.82497
I0826 15:47:49.869202 25446 solver.cpp:259]     Train net output #0: center_loss = 29.3323 (* 0.008 = 0.234658 loss)
I0826 15:47:49.869207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.59031 (* 1 = 8.59031 loss)
I0826 15:47:49.869211 25446 sgd_solver.cpp:138] Iteration 6070, lr = 0.001
I0826 15:47:51.983021 25446 solver.cpp:243] Iteration 6080, loss = 8.68152
I0826 15:47:51.983134 25446 solver.cpp:259]     Train net output #0: center_loss = 36.1173 (* 0.008 = 0.288938 loss)
I0826 15:47:51.983160 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.39259 (* 1 = 8.39259 loss)
I0826 15:47:51.983165 25446 sgd_solver.cpp:138] Iteration 6080, lr = 0.001
I0826 15:47:54.144475 25446 solver.cpp:243] Iteration 6090, loss = 8.69417
I0826 15:47:54.144513 25446 solver.cpp:259]     Train net output #0: center_loss = 40.3289 (* 0.008 = 0.322631 loss)
I0826 15:47:54.144520 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.37154 (* 1 = 8.37154 loss)
I0826 15:47:54.144523 25446 sgd_solver.cpp:138] Iteration 6090, lr = 0.001
I0826 15:47:56.205854 25446 solver.cpp:243] Iteration 6100, loss = 8.75889
I0826 15:47:56.205891 25446 solver.cpp:259]     Train net output #0: center_loss = 31.4103 (* 0.008 = 0.251282 loss)
I0826 15:47:56.205898 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.50761 (* 1 = 8.50761 loss)
I0826 15:47:56.205900 25446 sgd_solver.cpp:138] Iteration 6100, lr = 0.001
I0826 15:47:58.267297 25446 solver.cpp:243] Iteration 6110, loss = 8.81891
I0826 15:47:58.267335 25446 solver.cpp:259]     Train net output #0: center_loss = 27.3274 (* 0.008 = 0.218619 loss)
I0826 15:47:58.267341 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.60029 (* 1 = 8.60029 loss)
I0826 15:47:58.267344 25446 sgd_solver.cpp:138] Iteration 6110, lr = 0.001
I0826 15:48:00.330307 25446 solver.cpp:243] Iteration 6120, loss = 8.77387
I0826 15:48:00.330344 25446 solver.cpp:259]     Train net output #0: center_loss = 33.6131 (* 0.008 = 0.268905 loss)
I0826 15:48:00.330349 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.50497 (* 1 = 8.50497 loss)
I0826 15:48:00.330353 25446 sgd_solver.cpp:138] Iteration 6120, lr = 0.001
I0826 15:48:02.401558 25446 solver.cpp:243] Iteration 6130, loss = 8.85938
I0826 15:48:02.401595 25446 solver.cpp:259]     Train net output #0: center_loss = 34.0774 (* 0.008 = 0.272619 loss)
I0826 15:48:02.401602 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.58676 (* 1 = 8.58676 loss)
I0826 15:48:02.401604 25446 sgd_solver.cpp:138] Iteration 6130, lr = 0.001
I0826 15:48:04.483217 25446 solver.cpp:243] Iteration 6140, loss = 8.90951
I0826 15:48:04.483239 25446 solver.cpp:259]     Train net output #0: center_loss = 26.7671 (* 0.008 = 0.214137 loss)
I0826 15:48:04.483244 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.69537 (* 1 = 8.69537 loss)
I0826 15:48:04.483248 25446 sgd_solver.cpp:138] Iteration 6140, lr = 0.001
I0826 15:48:06.544632 25446 solver.cpp:243] Iteration 6150, loss = 8.91924
I0826 15:48:06.544656 25446 solver.cpp:259]     Train net output #0: center_loss = 29.1254 (* 0.008 = 0.233004 loss)
I0826 15:48:06.544662 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.68624 (* 1 = 8.68624 loss)
I0826 15:48:06.544667 25446 sgd_solver.cpp:138] Iteration 6150, lr = 0.001
I0826 15:48:08.610399 25446 solver.cpp:243] Iteration 6160, loss = 8.95369
I0826 15:48:08.610436 25446 solver.cpp:259]     Train net output #0: center_loss = 30.5308 (* 0.008 = 0.244246 loss)
I0826 15:48:08.610441 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.70944 (* 1 = 8.70944 loss)
I0826 15:48:08.610445 25446 sgd_solver.cpp:138] Iteration 6160, lr = 0.001
I0826 15:48:10.694443 25446 solver.cpp:243] Iteration 6170, loss = 8.891
I0826 15:48:10.694466 25446 solver.cpp:259]     Train net output #0: center_loss = 34.8524 (* 0.008 = 0.278819 loss)
I0826 15:48:10.694473 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.61218 (* 1 = 8.61218 loss)
I0826 15:48:10.694475 25446 sgd_solver.cpp:138] Iteration 6170, lr = 0.001
I0826 15:48:12.760140 25446 solver.cpp:243] Iteration 6180, loss = 8.87278
I0826 15:48:12.760179 25446 solver.cpp:259]     Train net output #0: center_loss = 36.5608 (* 0.008 = 0.292487 loss)
I0826 15:48:12.760185 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.5803 (* 1 = 8.5803 loss)
I0826 15:48:12.760190 25446 sgd_solver.cpp:138] Iteration 6180, lr = 0.001
I0826 15:48:14.854429 25446 solver.cpp:243] Iteration 6190, loss = 8.36609
I0826 15:48:14.854452 25446 solver.cpp:259]     Train net output #0: center_loss = 44.6944 (* 0.008 = 0.357555 loss)
I0826 15:48:14.854459 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.00853 (* 1 = 8.00853 loss)
I0826 15:48:14.854462 25446 sgd_solver.cpp:138] Iteration 6190, lr = 0.001
I0826 15:48:16.926213 25446 solver.cpp:243] Iteration 6200, loss = 8.82849
I0826 15:48:16.926254 25446 solver.cpp:259]     Train net output #0: center_loss = 37.5009 (* 0.008 = 0.300007 loss)
I0826 15:48:16.926261 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.52849 (* 1 = 8.52849 loss)
I0826 15:48:16.926265 25446 sgd_solver.cpp:138] Iteration 6200, lr = 0.001
I0826 15:48:19.016122 25446 solver.cpp:243] Iteration 6210, loss = 8.81322
I0826 15:48:19.016146 25446 solver.cpp:259]     Train net output #0: center_loss = 31.5795 (* 0.008 = 0.252636 loss)
I0826 15:48:19.016152 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.56058 (* 1 = 8.56058 loss)
I0826 15:48:19.016157 25446 sgd_solver.cpp:138] Iteration 6210, lr = 0.001
I0826 15:48:21.090003 25446 solver.cpp:243] Iteration 6220, loss = 9.09811
I0826 15:48:21.090029 25446 solver.cpp:259]     Train net output #0: center_loss = 38.6895 (* 0.008 = 0.309516 loss)
I0826 15:48:21.090037 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.7886 (* 1 = 8.7886 loss)
I0826 15:48:21.090044 25446 sgd_solver.cpp:138] Iteration 6220, lr = 0.001
I0826 15:48:23.212414 25446 solver.cpp:243] Iteration 6230, loss = 8.8939
I0826 15:48:23.212555 25446 solver.cpp:259]     Train net output #0: center_loss = 38.5036 (* 0.008 = 0.308029 loss)
I0826 15:48:23.212563 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.58587 (* 1 = 8.58587 loss)
I0826 15:48:23.212579 25446 sgd_solver.cpp:138] Iteration 6230, lr = 0.001
I0826 15:48:25.274869 25446 solver.cpp:243] Iteration 6240, loss = 8.68184
I0826 15:48:25.274906 25446 solver.cpp:259]     Train net output #0: center_loss = 35.1058 (* 0.008 = 0.280846 loss)
I0826 15:48:25.274912 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.401 (* 1 = 8.401 loss)
I0826 15:48:25.274916 25446 sgd_solver.cpp:138] Iteration 6240, lr = 0.001
I0826 15:48:27.392207 25446 solver.cpp:243] Iteration 6250, loss = 8.70912
I0826 15:48:27.392242 25446 solver.cpp:259]     Train net output #0: center_loss = 30.4435 (* 0.008 = 0.243548 loss)
I0826 15:48:27.392249 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.46557 (* 1 = 8.46557 loss)
I0826 15:48:27.392256 25446 sgd_solver.cpp:138] Iteration 6250, lr = 0.001
I0826 15:48:29.474567 25446 solver.cpp:243] Iteration 6260, loss = 8.87827
I0826 15:48:29.474604 25446 solver.cpp:259]     Train net output #0: center_loss = 43.6889 (* 0.008 = 0.349511 loss)
I0826 15:48:29.474611 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.52876 (* 1 = 8.52876 loss)
I0826 15:48:29.474614 25446 sgd_solver.cpp:138] Iteration 6260, lr = 0.001
I0826 15:48:31.536048 25446 solver.cpp:243] Iteration 6270, loss = 8.61887
I0826 15:48:31.536085 25446 solver.cpp:259]     Train net output #0: center_loss = 42.0944 (* 0.008 = 0.336755 loss)
I0826 15:48:31.536092 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.28212 (* 1 = 8.28212 loss)
I0826 15:48:31.536095 25446 sgd_solver.cpp:138] Iteration 6270, lr = 0.001
I0826 15:48:33.599195 25446 solver.cpp:243] Iteration 6280, loss = 8.43747
I0826 15:48:33.599231 25446 solver.cpp:259]     Train net output #0: center_loss = 50.3117 (* 0.008 = 0.402494 loss)
I0826 15:48:33.599236 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.03498 (* 1 = 8.03498 loss)
I0826 15:48:33.599241 25446 sgd_solver.cpp:138] Iteration 6280, lr = 0.001
I0826 15:48:35.662022 25446 solver.cpp:243] Iteration 6290, loss = 8.7092
I0826 15:48:35.662060 25446 solver.cpp:259]     Train net output #0: center_loss = 42.8918 (* 0.008 = 0.343135 loss)
I0826 15:48:35.662065 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36607 (* 1 = 8.36607 loss)
I0826 15:48:35.662068 25446 sgd_solver.cpp:138] Iteration 6290, lr = 0.001
I0826 15:48:37.724222 25446 solver.cpp:243] Iteration 6300, loss = 8.67478
I0826 15:48:37.724259 25446 solver.cpp:259]     Train net output #0: center_loss = 40.2535 (* 0.008 = 0.322028 loss)
I0826 15:48:37.724265 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.35276 (* 1 = 8.35276 loss)
I0826 15:48:37.724269 25446 sgd_solver.cpp:138] Iteration 6300, lr = 0.001
I0826 15:48:39.837630 25446 solver.cpp:243] Iteration 6310, loss = 8.87354
I0826 15:48:39.837654 25446 solver.cpp:259]     Train net output #0: center_loss = 36.7022 (* 0.008 = 0.293618 loss)
I0826 15:48:39.837661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.57992 (* 1 = 8.57992 loss)
I0826 15:48:39.837664 25446 sgd_solver.cpp:138] Iteration 6310, lr = 0.001
I0826 15:48:41.934412 25446 solver.cpp:243] Iteration 6320, loss = 9.01907
I0826 15:48:41.934434 25446 solver.cpp:259]     Train net output #0: center_loss = 29.7084 (* 0.008 = 0.237668 loss)
I0826 15:48:41.934440 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.7814 (* 1 = 8.7814 loss)
I0826 15:48:41.934444 25446 sgd_solver.cpp:138] Iteration 6320, lr = 0.001
I0826 15:48:44.083943 25446 solver.cpp:243] Iteration 6330, loss = 8.84882
I0826 15:48:44.083966 25446 solver.cpp:259]     Train net output #0: center_loss = 36.7323 (* 0.008 = 0.293858 loss)
I0826 15:48:44.083971 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.55496 (* 1 = 8.55496 loss)
I0826 15:48:44.083976 25446 sgd_solver.cpp:138] Iteration 6330, lr = 0.001
I0826 15:48:46.177471 25446 solver.cpp:243] Iteration 6340, loss = 8.94765
I0826 15:48:46.177495 25446 solver.cpp:259]     Train net output #0: center_loss = 50.0618 (* 0.008 = 0.400494 loss)
I0826 15:48:46.177500 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.54715 (* 1 = 8.54715 loss)
I0826 15:48:46.177505 25446 sgd_solver.cpp:138] Iteration 6340, lr = 0.001
I0826 15:48:48.263622 25446 solver.cpp:243] Iteration 6350, loss = 8.79247
I0826 15:48:48.263660 25446 solver.cpp:259]     Train net output #0: center_loss = 44.568 (* 0.008 = 0.356544 loss)
I0826 15:48:48.263665 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.43592 (* 1 = 8.43592 loss)
I0826 15:48:48.263669 25446 sgd_solver.cpp:138] Iteration 6350, lr = 0.001
I0826 15:48:50.369624 25446 solver.cpp:243] Iteration 6360, loss = 8.79806
I0826 15:48:50.369662 25446 solver.cpp:259]     Train net output #0: center_loss = 37.2209 (* 0.008 = 0.297768 loss)
I0826 15:48:50.369668 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.50029 (* 1 = 8.50029 loss)
I0826 15:48:50.369670 25446 sgd_solver.cpp:138] Iteration 6360, lr = 0.001
I0826 15:48:52.459506 25446 solver.cpp:243] Iteration 6370, loss = 8.77042
I0826 15:48:52.459544 25446 solver.cpp:259]     Train net output #0: center_loss = 42.2522 (* 0.008 = 0.338017 loss)
I0826 15:48:52.459551 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.4324 (* 1 = 8.4324 loss)
I0826 15:48:52.459554 25446 sgd_solver.cpp:138] Iteration 6370, lr = 0.001
I0826 15:48:54.557010 25446 solver.cpp:243] Iteration 6380, loss = 9.01361
I0826 15:48:54.557137 25446 solver.cpp:259]     Train net output #0: center_loss = 33.9713 (* 0.008 = 0.27177 loss)
I0826 15:48:54.557145 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.74184 (* 1 = 8.74184 loss)
I0826 15:48:54.557149 25446 sgd_solver.cpp:138] Iteration 6380, lr = 0.001
I0826 15:48:56.737182 25446 solver.cpp:243] Iteration 6390, loss = 8.46911
I0826 15:48:56.737221 25446 solver.cpp:259]     Train net output #0: center_loss = 33.5819 (* 0.008 = 0.268655 loss)
I0826 15:48:56.737228 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.20045 (* 1 = 8.20045 loss)
I0826 15:48:56.737233 25446 sgd_solver.cpp:138] Iteration 6390, lr = 0.001
I0826 15:48:58.828889 25446 solver.cpp:243] Iteration 6400, loss = 8.74259
I0826 15:48:58.828927 25446 solver.cpp:259]     Train net output #0: center_loss = 45.0859 (* 0.008 = 0.360687 loss)
I0826 15:48:58.828933 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.3819 (* 1 = 8.3819 loss)
I0826 15:48:58.828936 25446 sgd_solver.cpp:138] Iteration 6400, lr = 0.001
I0826 15:49:00.911458 25446 solver.cpp:243] Iteration 6410, loss = 8.57853
I0826 15:49:00.911480 25446 solver.cpp:259]     Train net output #0: center_loss = 41.8995 (* 0.008 = 0.335196 loss)
I0826 15:49:00.911485 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.24333 (* 1 = 8.24333 loss)
I0826 15:49:00.911490 25446 sgd_solver.cpp:138] Iteration 6410, lr = 0.001
I0826 15:49:02.989431 25446 solver.cpp:243] Iteration 6420, loss = 8.67087
I0826 15:49:02.989454 25446 solver.cpp:259]     Train net output #0: center_loss = 45.382 (* 0.008 = 0.363056 loss)
I0826 15:49:02.989475 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.30781 (* 1 = 8.30781 loss)
I0826 15:49:02.989480 25446 sgd_solver.cpp:138] Iteration 6420, lr = 0.001
I0826 15:49:05.073945 25446 solver.cpp:243] Iteration 6430, loss = 8.86553
I0826 15:49:05.073968 25446 solver.cpp:259]     Train net output #0: center_loss = 41.2608 (* 0.008 = 0.330086 loss)
I0826 15:49:05.073973 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.53544 (* 1 = 8.53544 loss)
I0826 15:49:05.073978 25446 sgd_solver.cpp:138] Iteration 6430, lr = 0.001
I0826 15:49:07.192677 25446 solver.cpp:243] Iteration 6440, loss = 8.89953
I0826 15:49:07.192716 25446 solver.cpp:259]     Train net output #0: center_loss = 37.0056 (* 0.008 = 0.296045 loss)
I0826 15:49:07.192723 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.60349 (* 1 = 8.60349 loss)
I0826 15:49:07.192728 25446 sgd_solver.cpp:138] Iteration 6440, lr = 0.001
I0826 15:49:09.297964 25446 solver.cpp:243] Iteration 6450, loss = 8.77513
I0826 15:49:09.298002 25446 solver.cpp:259]     Train net output #0: center_loss = 35.7773 (* 0.008 = 0.286218 loss)
I0826 15:49:09.298008 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.48891 (* 1 = 8.48891 loss)
I0826 15:49:09.298013 25446 sgd_solver.cpp:138] Iteration 6450, lr = 0.001
I0826 15:49:11.376260 25446 solver.cpp:243] Iteration 6460, loss = 9.0638
I0826 15:49:11.376283 25446 solver.cpp:259]     Train net output #0: center_loss = 25.7991 (* 0.008 = 0.206392 loss)
I0826 15:49:11.376289 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.8574 (* 1 = 8.8574 loss)
I0826 15:49:11.376294 25446 sgd_solver.cpp:138] Iteration 6460, lr = 0.001
I0826 15:49:13.449647 25446 solver.cpp:243] Iteration 6470, loss = 8.8808
I0826 15:49:13.449685 25446 solver.cpp:259]     Train net output #0: center_loss = 34.8335 (* 0.008 = 0.278668 loss)
I0826 15:49:13.449692 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.60213 (* 1 = 8.60213 loss)
I0826 15:49:13.449697 25446 sgd_solver.cpp:138] Iteration 6470, lr = 0.001
I0826 15:49:15.524474 25446 solver.cpp:243] Iteration 6480, loss = 8.83774
I0826 15:49:15.524497 25446 solver.cpp:259]     Train net output #0: center_loss = 39.4567 (* 0.008 = 0.315654 loss)
I0826 15:49:15.524502 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.52209 (* 1 = 8.52209 loss)
I0826 15:49:15.524507 25446 sgd_solver.cpp:138] Iteration 6480, lr = 0.001
I0826 15:49:17.597525 25446 solver.cpp:243] Iteration 6490, loss = 8.91129
I0826 15:49:17.597563 25446 solver.cpp:259]     Train net output #0: center_loss = 40.2513 (* 0.008 = 0.32201 loss)
I0826 15:49:17.597568 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.58928 (* 1 = 8.58928 loss)
I0826 15:49:17.597573 25446 sgd_solver.cpp:138] Iteration 6490, lr = 0.001
I0826 15:49:19.668335 25446 solver.cpp:243] Iteration 6500, loss = 8.81182
I0826 15:49:19.668375 25446 solver.cpp:259]     Train net output #0: center_loss = 36.4979 (* 0.008 = 0.291984 loss)
I0826 15:49:19.668380 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.51983 (* 1 = 8.51983 loss)
I0826 15:49:19.668385 25446 sgd_solver.cpp:138] Iteration 6500, lr = 0.001
I0826 15:49:21.744724 25446 solver.cpp:243] Iteration 6510, loss = 8.50034
I0826 15:49:21.744761 25446 solver.cpp:259]     Train net output #0: center_loss = 50.293 (* 0.008 = 0.402344 loss)
I0826 15:49:21.744767 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.098 (* 1 = 8.098 loss)
I0826 15:49:21.744771 25446 sgd_solver.cpp:138] Iteration 6510, lr = 0.001
I0826 15:49:23.817662 25446 solver.cpp:243] Iteration 6520, loss = 9.0682
I0826 15:49:23.817718 25446 solver.cpp:259]     Train net output #0: center_loss = 44.2556 (* 0.008 = 0.354045 loss)
I0826 15:49:23.817724 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.71416 (* 1 = 8.71416 loss)
I0826 15:49:23.817728 25446 sgd_solver.cpp:138] Iteration 6520, lr = 0.001
I0826 15:49:25.894443 25446 solver.cpp:243] Iteration 6530, loss = 8.7891
I0826 15:49:25.894567 25446 solver.cpp:259]     Train net output #0: center_loss = 40.7641 (* 0.008 = 0.326113 loss)
I0826 15:49:25.894587 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.46299 (* 1 = 8.46299 loss)
I0826 15:49:25.894592 25446 sgd_solver.cpp:138] Iteration 6530, lr = 0.001
I0826 15:49:27.973646 25446 solver.cpp:243] Iteration 6540, loss = 8.7697
I0826 15:49:27.973685 25446 solver.cpp:259]     Train net output #0: center_loss = 36.6629 (* 0.008 = 0.293304 loss)
I0826 15:49:27.973690 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.47639 (* 1 = 8.47639 loss)
I0826 15:49:27.973695 25446 sgd_solver.cpp:138] Iteration 6540, lr = 0.001
I0826 15:49:30.049523 25446 solver.cpp:243] Iteration 6550, loss = 8.65117
I0826 15:49:30.049561 25446 solver.cpp:259]     Train net output #0: center_loss = 34.2196 (* 0.008 = 0.273757 loss)
I0826 15:49:30.049567 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.37741 (* 1 = 8.37741 loss)
I0826 15:49:30.049572 25446 sgd_solver.cpp:138] Iteration 6550, lr = 0.001
I0826 15:49:32.124243 25446 solver.cpp:243] Iteration 6560, loss = 8.4505
I0826 15:49:32.124280 25446 solver.cpp:259]     Train net output #0: center_loss = 51.0662 (* 0.008 = 0.40853 loss)
I0826 15:49:32.124285 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.04197 (* 1 = 8.04197 loss)
I0826 15:49:32.124289 25446 sgd_solver.cpp:138] Iteration 6560, lr = 0.001
I0826 15:49:34.197051 25446 solver.cpp:243] Iteration 6570, loss = 8.7927
I0826 15:49:34.197073 25446 solver.cpp:259]     Train net output #0: center_loss = 48.2149 (* 0.008 = 0.385719 loss)
I0826 15:49:34.197079 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.40698 (* 1 = 8.40698 loss)
I0826 15:49:34.197083 25446 sgd_solver.cpp:138] Iteration 6570, lr = 0.001
I0826 15:49:36.269712 25446 solver.cpp:243] Iteration 6580, loss = 8.84498
I0826 15:49:36.269750 25446 solver.cpp:259]     Train net output #0: center_loss = 41.6154 (* 0.008 = 0.332923 loss)
I0826 15:49:36.269757 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.51206 (* 1 = 8.51206 loss)
I0826 15:49:36.269760 25446 sgd_solver.cpp:138] Iteration 6580, lr = 0.001
I0826 15:49:38.347987 25446 solver.cpp:243] Iteration 6590, loss = 8.90924
I0826 15:49:38.348024 25446 solver.cpp:259]     Train net output #0: center_loss = 47.9648 (* 0.008 = 0.383718 loss)
I0826 15:49:38.348031 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.52552 (* 1 = 8.52552 loss)
I0826 15:49:38.348035 25446 sgd_solver.cpp:138] Iteration 6590, lr = 0.001
I0826 15:49:40.424521 25446 solver.cpp:243] Iteration 6600, loss = 8.32983
I0826 15:49:40.424561 25446 solver.cpp:259]     Train net output #0: center_loss = 37.8505 (* 0.008 = 0.302804 loss)
I0826 15:49:40.424566 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.02703 (* 1 = 8.02703 loss)
I0826 15:49:40.424571 25446 sgd_solver.cpp:138] Iteration 6600, lr = 0.001
I0826 15:49:42.496136 25446 solver.cpp:243] Iteration 6610, loss = 8.68439
I0826 15:49:42.496160 25446 solver.cpp:259]     Train net output #0: center_loss = 39.5352 (* 0.008 = 0.316281 loss)
I0826 15:49:42.496181 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36811 (* 1 = 8.36811 loss)
I0826 15:49:42.496186 25446 sgd_solver.cpp:138] Iteration 6610, lr = 0.001
I0826 15:49:44.573460 25446 solver.cpp:243] Iteration 6620, loss = 8.68348
I0826 15:49:44.573498 25446 solver.cpp:259]     Train net output #0: center_loss = 34.8108 (* 0.008 = 0.278486 loss)
I0826 15:49:44.573504 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.405 (* 1 = 8.405 loss)
I0826 15:49:44.573509 25446 sgd_solver.cpp:138] Iteration 6620, lr = 0.001
I0826 15:49:46.649736 25446 solver.cpp:243] Iteration 6630, loss = 8.802
I0826 15:49:46.649757 25446 solver.cpp:259]     Train net output #0: center_loss = 48.9544 (* 0.008 = 0.391635 loss)
I0826 15:49:46.649763 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.41036 (* 1 = 8.41036 loss)
I0826 15:49:46.649767 25446 sgd_solver.cpp:138] Iteration 6630, lr = 0.001
I0826 15:49:48.727775 25446 solver.cpp:243] Iteration 6640, loss = 8.82715
I0826 15:49:48.727843 25446 solver.cpp:259]     Train net output #0: center_loss = 35.6991 (* 0.008 = 0.285592 loss)
I0826 15:49:48.727864 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.54156 (* 1 = 8.54156 loss)
I0826 15:49:48.727870 25446 sgd_solver.cpp:138] Iteration 6640, lr = 0.001
I0826 15:49:50.788437 25446 solver.cpp:243] Iteration 6650, loss = 8.84404
I0826 15:49:50.788476 25446 solver.cpp:259]     Train net output #0: center_loss = 39.3305 (* 0.008 = 0.314644 loss)
I0826 15:49:50.788481 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.52939 (* 1 = 8.52939 loss)
I0826 15:49:50.788486 25446 sgd_solver.cpp:138] Iteration 6650, lr = 0.001
I0826 15:49:52.848997 25446 solver.cpp:243] Iteration 6660, loss = 8.70274
I0826 15:49:52.849035 25446 solver.cpp:259]     Train net output #0: center_loss = 38.3356 (* 0.008 = 0.306685 loss)
I0826 15:49:52.849041 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.39605 (* 1 = 8.39605 loss)
I0826 15:49:52.849045 25446 sgd_solver.cpp:138] Iteration 6660, lr = 0.001
I0826 15:49:54.908571 25446 solver.cpp:243] Iteration 6670, loss = 8.42769
I0826 15:49:54.908607 25446 solver.cpp:259]     Train net output #0: center_loss = 48.9689 (* 0.008 = 0.391751 loss)
I0826 15:49:54.908613 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.03594 (* 1 = 8.03594 loss)
I0826 15:49:54.908617 25446 sgd_solver.cpp:138] Iteration 6670, lr = 0.001
I0826 15:49:56.969324 25446 solver.cpp:243] Iteration 6680, loss = 8.78335
I0826 15:49:56.969486 25446 solver.cpp:259]     Train net output #0: center_loss = 47.1034 (* 0.008 = 0.376827 loss)
I0826 15:49:56.969508 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.40652 (* 1 = 8.40652 loss)
I0826 15:49:56.969511 25446 sgd_solver.cpp:138] Iteration 6680, lr = 0.001
I0826 15:49:59.024205 25446 solver.cpp:243] Iteration 6690, loss = 8.87022
I0826 15:49:59.024242 25446 solver.cpp:259]     Train net output #0: center_loss = 38.8332 (* 0.008 = 0.310666 loss)
I0826 15:49:59.024248 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.55956 (* 1 = 8.55956 loss)
I0826 15:49:59.024251 25446 sgd_solver.cpp:138] Iteration 6690, lr = 0.001
I0826 15:50:01.083720 25446 solver.cpp:243] Iteration 6700, loss = 9.01239
I0826 15:50:01.083742 25446 solver.cpp:259]     Train net output #0: center_loss = 33.964 (* 0.008 = 0.271712 loss)
I0826 15:50:01.083763 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.74068 (* 1 = 8.74068 loss)
I0826 15:50:01.083766 25446 sgd_solver.cpp:138] Iteration 6700, lr = 0.001
I0826 15:50:03.143846 25446 solver.cpp:243] Iteration 6710, loss = 8.95436
I0826 15:50:03.143884 25446 solver.cpp:259]     Train net output #0: center_loss = 38.2233 (* 0.008 = 0.305786 loss)
I0826 15:50:03.143889 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.64857 (* 1 = 8.64857 loss)
I0826 15:50:03.143893 25446 sgd_solver.cpp:138] Iteration 6710, lr = 0.001
I0826 15:50:05.198873 25446 solver.cpp:243] Iteration 6720, loss = 8.82173
I0826 15:50:05.198909 25446 solver.cpp:259]     Train net output #0: center_loss = 36.531 (* 0.008 = 0.292248 loss)
I0826 15:50:05.198915 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.52948 (* 1 = 8.52948 loss)
I0826 15:50:05.198918 25446 sgd_solver.cpp:138] Iteration 6720, lr = 0.001
I0826 15:50:07.255975 25446 solver.cpp:243] Iteration 6730, loss = 8.93828
I0826 15:50:07.256013 25446 solver.cpp:259]     Train net output #0: center_loss = 29.9658 (* 0.008 = 0.239727 loss)
I0826 15:50:07.256018 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.69855 (* 1 = 8.69855 loss)
I0826 15:50:07.256021 25446 sgd_solver.cpp:138] Iteration 6730, lr = 0.001
I0826 15:50:09.349167 25446 solver.cpp:243] Iteration 6740, loss = 8.37182
I0826 15:50:09.349191 25446 solver.cpp:259]     Train net output #0: center_loss = 43.9593 (* 0.008 = 0.351674 loss)
I0826 15:50:09.349197 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.02015 (* 1 = 8.02015 loss)
I0826 15:50:09.349201 25446 sgd_solver.cpp:138] Iteration 6740, lr = 0.001
I0826 15:50:11.500711 25446 solver.cpp:243] Iteration 6750, loss = 9.01595
I0826 15:50:11.500736 25446 solver.cpp:259]     Train net output #0: center_loss = 48.1455 (* 0.008 = 0.385164 loss)
I0826 15:50:11.500742 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.63079 (* 1 = 8.63079 loss)
I0826 15:50:11.500748 25446 sgd_solver.cpp:138] Iteration 6750, lr = 0.001
I0826 15:50:13.575793 25446 solver.cpp:243] Iteration 6760, loss = 8.706
I0826 15:50:13.575831 25446 solver.cpp:259]     Train net output #0: center_loss = 36.5891 (* 0.008 = 0.292712 loss)
I0826 15:50:13.575837 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.41328 (* 1 = 8.41328 loss)
I0826 15:50:13.575841 25446 sgd_solver.cpp:138] Iteration 6760, lr = 0.001
I0826 15:50:15.633345 25446 solver.cpp:243] Iteration 6770, loss = 8.71164
I0826 15:50:15.633384 25446 solver.cpp:259]     Train net output #0: center_loss = 38.6509 (* 0.008 = 0.309207 loss)
I0826 15:50:15.633390 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.40243 (* 1 = 8.40243 loss)
I0826 15:50:15.633394 25446 sgd_solver.cpp:138] Iteration 6770, lr = 0.001
I0826 15:50:17.689874 25446 solver.cpp:243] Iteration 6780, loss = 8.95912
I0826 15:50:17.689913 25446 solver.cpp:259]     Train net output #0: center_loss = 46.0489 (* 0.008 = 0.368391 loss)
I0826 15:50:17.689918 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.59073 (* 1 = 8.59073 loss)
I0826 15:50:17.689921 25446 sgd_solver.cpp:138] Iteration 6780, lr = 0.001
I0826 15:50:19.746978 25446 solver.cpp:243] Iteration 6790, loss = 9.1
I0826 15:50:19.747016 25446 solver.cpp:259]     Train net output #0: center_loss = 29.6066 (* 0.008 = 0.236853 loss)
I0826 15:50:19.747022 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.86314 (* 1 = 8.86314 loss)
I0826 15:50:19.747025 25446 sgd_solver.cpp:138] Iteration 6790, lr = 0.001
I0826 15:50:21.820479 25446 solver.cpp:243] Iteration 6800, loss = 8.94073
I0826 15:50:21.820518 25446 solver.cpp:259]     Train net output #0: center_loss = 34.5641 (* 0.008 = 0.276513 loss)
I0826 15:50:21.820523 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.66422 (* 1 = 8.66422 loss)
I0826 15:50:21.820526 25446 sgd_solver.cpp:138] Iteration 6800, lr = 0.001
I0826 15:50:23.954479 25446 solver.cpp:243] Iteration 6810, loss = 8.60299
I0826 15:50:23.954509 25446 solver.cpp:259]     Train net output #0: center_loss = 49.0714 (* 0.008 = 0.392571 loss)
I0826 15:50:23.954514 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.21042 (* 1 = 8.21042 loss)
I0826 15:50:23.954519 25446 sgd_solver.cpp:138] Iteration 6810, lr = 0.001
I0826 15:50:26.173661 25446 solver.cpp:243] Iteration 6820, loss = 9.11692
I0826 15:50:26.173691 25446 solver.cpp:259]     Train net output #0: center_loss = 33.4462 (* 0.008 = 0.26757 loss)
I0826 15:50:26.173696 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.84935 (* 1 = 8.84935 loss)
I0826 15:50:26.173702 25446 sgd_solver.cpp:138] Iteration 6820, lr = 0.001
I0826 15:50:28.288833 25446 solver.cpp:243] Iteration 6830, loss = 8.71912
I0826 15:50:28.288938 25446 solver.cpp:259]     Train net output #0: center_loss = 34.989 (* 0.008 = 0.279912 loss)
I0826 15:50:28.288959 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.43921 (* 1 = 8.43921 loss)
I0826 15:50:28.288964 25446 sgd_solver.cpp:138] Iteration 6830, lr = 0.001
I0826 15:50:30.419992 25446 solver.cpp:243] Iteration 6840, loss = 8.72387
I0826 15:50:30.420047 25446 solver.cpp:259]     Train net output #0: center_loss = 40.8797 (* 0.008 = 0.327037 loss)
I0826 15:50:30.420053 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.39683 (* 1 = 8.39683 loss)
I0826 15:50:30.420058 25446 sgd_solver.cpp:138] Iteration 6840, lr = 0.001
I0826 15:50:32.521559 25446 solver.cpp:243] Iteration 6850, loss = 8.66588
I0826 15:50:32.521597 25446 solver.cpp:259]     Train net output #0: center_loss = 43.3767 (* 0.008 = 0.347014 loss)
I0826 15:50:32.521603 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.31887 (* 1 = 8.31887 loss)
I0826 15:50:32.521607 25446 sgd_solver.cpp:138] Iteration 6850, lr = 0.001
I0826 15:50:34.595293 25446 solver.cpp:243] Iteration 6860, loss = 8.62226
I0826 15:50:34.595329 25446 solver.cpp:259]     Train net output #0: center_loss = 43.6076 (* 0.008 = 0.348861 loss)
I0826 15:50:34.595335 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.2734 (* 1 = 8.2734 loss)
I0826 15:50:34.595337 25446 sgd_solver.cpp:138] Iteration 6860, lr = 0.001
I0826 15:50:36.656298 25446 solver.cpp:243] Iteration 6870, loss = 8.6796
I0826 15:50:36.656337 25446 solver.cpp:259]     Train net output #0: center_loss = 40.566 (* 0.008 = 0.324528 loss)
I0826 15:50:36.656342 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.35507 (* 1 = 8.35507 loss)
I0826 15:50:36.656345 25446 sgd_solver.cpp:138] Iteration 6870, lr = 0.001
I0826 15:50:38.713421 25446 solver.cpp:243] Iteration 6880, loss = 8.57629
I0826 15:50:38.713460 25446 solver.cpp:259]     Train net output #0: center_loss = 49.7553 (* 0.008 = 0.398042 loss)
I0826 15:50:38.713465 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.17825 (* 1 = 8.17825 loss)
I0826 15:50:38.713469 25446 sgd_solver.cpp:138] Iteration 6880, lr = 0.001
I0826 15:50:40.771188 25446 solver.cpp:243] Iteration 6890, loss = 8.73098
I0826 15:50:40.771225 25446 solver.cpp:259]     Train net output #0: center_loss = 48.4952 (* 0.008 = 0.387962 loss)
I0826 15:50:40.771230 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.34302 (* 1 = 8.34302 loss)
I0826 15:50:40.771234 25446 sgd_solver.cpp:138] Iteration 6890, lr = 0.001
I0826 15:50:42.826833 25446 solver.cpp:243] Iteration 6900, loss = 9.04832
I0826 15:50:42.826870 25446 solver.cpp:259]     Train net output #0: center_loss = 35.2389 (* 0.008 = 0.281911 loss)
I0826 15:50:42.826876 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.76641 (* 1 = 8.76641 loss)
I0826 15:50:42.826879 25446 sgd_solver.cpp:138] Iteration 6900, lr = 0.001
I0826 15:50:44.886498 25446 solver.cpp:243] Iteration 6910, loss = 8.6024
I0826 15:50:44.886536 25446 solver.cpp:259]     Train net output #0: center_loss = 42.2796 (* 0.008 = 0.338236 loss)
I0826 15:50:44.886541 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.26417 (* 1 = 8.26417 loss)
I0826 15:50:44.886544 25446 sgd_solver.cpp:138] Iteration 6910, lr = 0.001
I0826 15:50:46.940186 25446 solver.cpp:243] Iteration 6920, loss = 8.72613
I0826 15:50:46.940223 25446 solver.cpp:259]     Train net output #0: center_loss = 60.0055 (* 0.008 = 0.480044 loss)
I0826 15:50:46.940228 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.24608 (* 1 = 8.24608 loss)
I0826 15:50:46.940232 25446 sgd_solver.cpp:138] Iteration 6920, lr = 0.001
I0826 15:50:48.996845 25446 solver.cpp:243] Iteration 6930, loss = 8.75373
I0826 15:50:48.996883 25446 solver.cpp:259]     Train net output #0: center_loss = 50.3924 (* 0.008 = 0.403139 loss)
I0826 15:50:48.996889 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.35059 (* 1 = 8.35059 loss)
I0826 15:50:48.996892 25446 sgd_solver.cpp:138] Iteration 6930, lr = 0.001
I0826 15:50:51.057039 25446 solver.cpp:243] Iteration 6940, loss = 8.79394
I0826 15:50:51.057077 25446 solver.cpp:259]     Train net output #0: center_loss = 53.1244 (* 0.008 = 0.424995 loss)
I0826 15:50:51.057082 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36894 (* 1 = 8.36894 loss)
I0826 15:50:51.057086 25446 sgd_solver.cpp:138] Iteration 6940, lr = 0.001
I0826 15:50:53.119273 25446 solver.cpp:243] Iteration 6950, loss = 8.76527
I0826 15:50:53.119310 25446 solver.cpp:259]     Train net output #0: center_loss = 46.9274 (* 0.008 = 0.375419 loss)
I0826 15:50:53.119316 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.38985 (* 1 = 8.38985 loss)
I0826 15:50:53.119319 25446 sgd_solver.cpp:138] Iteration 6950, lr = 0.001
I0826 15:50:55.173264 25446 solver.cpp:243] Iteration 6960, loss = 8.67617
I0826 15:50:55.173300 25446 solver.cpp:259]     Train net output #0: center_loss = 48.5899 (* 0.008 = 0.388719 loss)
I0826 15:50:55.173305 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.28745 (* 1 = 8.28745 loss)
I0826 15:50:55.173310 25446 sgd_solver.cpp:138] Iteration 6960, lr = 0.001
I0826 15:50:57.234436 25446 solver.cpp:243] Iteration 6970, loss = 8.49568
I0826 15:50:57.234474 25446 solver.cpp:259]     Train net output #0: center_loss = 56.4705 (* 0.008 = 0.451764 loss)
I0826 15:50:57.234479 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.04391 (* 1 = 8.04391 loss)
I0826 15:50:57.234483 25446 sgd_solver.cpp:138] Iteration 6970, lr = 0.001
I0826 15:50:59.290195 25446 solver.cpp:243] Iteration 6980, loss = 8.43945
I0826 15:50:59.290333 25446 solver.cpp:259]     Train net output #0: center_loss = 52.8804 (* 0.008 = 0.423043 loss)
I0826 15:50:59.290339 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.01641 (* 1 = 8.01641 loss)
I0826 15:50:59.290343 25446 sgd_solver.cpp:138] Iteration 6980, lr = 0.001
I0826 15:51:01.350348 25446 solver.cpp:243] Iteration 6990, loss = 8.44658
I0826 15:51:01.350386 25446 solver.cpp:259]     Train net output #0: center_loss = 49.5275 (* 0.008 = 0.39622 loss)
I0826 15:51:01.350392 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.05036 (* 1 = 8.05036 loss)
I0826 15:51:01.350395 25446 sgd_solver.cpp:138] Iteration 6990, lr = 0.001
I0826 15:51:03.199659 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_7000.caffemodel
I0826 15:51:04.316069 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_7000.solverstate
I0826 15:51:04.636723 25446 solver.cpp:243] Iteration 7000, loss = 8.67618
I0826 15:51:04.636763 25446 solver.cpp:259]     Train net output #0: center_loss = 43.4153 (* 0.008 = 0.347322 loss)
I0826 15:51:04.636768 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.32886 (* 1 = 8.32886 loss)
I0826 15:51:04.636773 25446 sgd_solver.cpp:138] Iteration 7000, lr = 0.001
I0826 15:51:06.690086 25446 solver.cpp:243] Iteration 7010, loss = 8.80414
I0826 15:51:06.690124 25446 solver.cpp:259]     Train net output #0: center_loss = 44.1755 (* 0.008 = 0.353404 loss)
I0826 15:51:06.690130 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.45074 (* 1 = 8.45074 loss)
I0826 15:51:06.690133 25446 sgd_solver.cpp:138] Iteration 7010, lr = 0.001
I0826 15:51:08.745470 25446 solver.cpp:243] Iteration 7020, loss = 8.69392
I0826 15:51:08.745507 25446 solver.cpp:259]     Train net output #0: center_loss = 36.6134 (* 0.008 = 0.292907 loss)
I0826 15:51:08.745512 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.40101 (* 1 = 8.40101 loss)
I0826 15:51:08.745517 25446 sgd_solver.cpp:138] Iteration 7020, lr = 0.001
I0826 15:51:10.802423 25446 solver.cpp:243] Iteration 7030, loss = 8.96991
I0826 15:51:10.802461 25446 solver.cpp:259]     Train net output #0: center_loss = 53.6743 (* 0.008 = 0.429394 loss)
I0826 15:51:10.802467 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.54052 (* 1 = 8.54052 loss)
I0826 15:51:10.802470 25446 sgd_solver.cpp:138] Iteration 7030, lr = 0.001
I0826 15:51:12.862679 25446 solver.cpp:243] Iteration 7040, loss = 8.84095
I0826 15:51:12.862716 25446 solver.cpp:259]     Train net output #0: center_loss = 59.1794 (* 0.008 = 0.473435 loss)
I0826 15:51:12.862722 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36752 (* 1 = 8.36752 loss)
I0826 15:51:12.862725 25446 sgd_solver.cpp:138] Iteration 7040, lr = 0.001
I0826 15:51:14.917037 25446 solver.cpp:243] Iteration 7050, loss = 8.73079
I0826 15:51:14.917074 25446 solver.cpp:259]     Train net output #0: center_loss = 44.7554 (* 0.008 = 0.358044 loss)
I0826 15:51:14.917081 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.37275 (* 1 = 8.37275 loss)
I0826 15:51:14.917084 25446 sgd_solver.cpp:138] Iteration 7050, lr = 0.001
I0826 15:51:16.976847 25446 solver.cpp:243] Iteration 7060, loss = 8.69829
I0826 15:51:16.976886 25446 solver.cpp:259]     Train net output #0: center_loss = 46.6711 (* 0.008 = 0.373369 loss)
I0826 15:51:16.976891 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.32492 (* 1 = 8.32492 loss)
I0826 15:51:16.976894 25446 sgd_solver.cpp:138] Iteration 7060, lr = 0.001
I0826 15:51:19.035058 25446 solver.cpp:243] Iteration 7070, loss = 9.1398
I0826 15:51:19.035094 25446 solver.cpp:259]     Train net output #0: center_loss = 47.6673 (* 0.008 = 0.381338 loss)
I0826 15:51:19.035100 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.75846 (* 1 = 8.75846 loss)
I0826 15:51:19.035104 25446 sgd_solver.cpp:138] Iteration 7070, lr = 0.001
I0826 15:51:21.094743 25446 solver.cpp:243] Iteration 7080, loss = 8.80877
I0826 15:51:21.094781 25446 solver.cpp:259]     Train net output #0: center_loss = 38.7487 (* 0.008 = 0.30999 loss)
I0826 15:51:21.094841 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.49878 (* 1 = 8.49878 loss)
I0826 15:51:21.094844 25446 sgd_solver.cpp:138] Iteration 7080, lr = 0.001
I0826 15:51:23.153617 25446 solver.cpp:243] Iteration 7090, loss = 8.65385
I0826 15:51:23.153656 25446 solver.cpp:259]     Train net output #0: center_loss = 36.1569 (* 0.008 = 0.289255 loss)
I0826 15:51:23.153661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.3646 (* 1 = 8.3646 loss)
I0826 15:51:23.153664 25446 sgd_solver.cpp:138] Iteration 7090, lr = 0.001
I0826 15:51:25.216104 25446 solver.cpp:243] Iteration 7100, loss = 8.662
I0826 15:51:25.216140 25446 solver.cpp:259]     Train net output #0: center_loss = 47.772 (* 0.008 = 0.382176 loss)
I0826 15:51:25.216146 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.27983 (* 1 = 8.27983 loss)
I0826 15:51:25.216150 25446 sgd_solver.cpp:138] Iteration 7100, lr = 0.001
I0826 15:51:27.276932 25446 solver.cpp:243] Iteration 7110, loss = 8.87326
I0826 15:51:27.276968 25446 solver.cpp:259]     Train net output #0: center_loss = 42.6105 (* 0.008 = 0.340884 loss)
I0826 15:51:27.276974 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.53237 (* 1 = 8.53237 loss)
I0826 15:51:27.276978 25446 sgd_solver.cpp:138] Iteration 7110, lr = 0.001
I0826 15:51:29.337255 25446 solver.cpp:243] Iteration 7120, loss = 8.71997
I0826 15:51:29.337378 25446 solver.cpp:259]     Train net output #0: center_loss = 39.0716 (* 0.008 = 0.312573 loss)
I0826 15:51:29.337399 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.40739 (* 1 = 8.40739 loss)
I0826 15:51:29.337402 25446 sgd_solver.cpp:138] Iteration 7120, lr = 0.001
I0826 15:51:31.396453 25446 solver.cpp:243] Iteration 7130, loss = 8.79875
I0826 15:51:31.396492 25446 solver.cpp:259]     Train net output #0: center_loss = 40.3595 (* 0.008 = 0.322876 loss)
I0826 15:51:31.396497 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.47588 (* 1 = 8.47588 loss)
I0826 15:51:31.396502 25446 sgd_solver.cpp:138] Iteration 7130, lr = 0.001
I0826 15:51:33.455456 25446 solver.cpp:243] Iteration 7140, loss = 8.59501
I0826 15:51:33.455493 25446 solver.cpp:259]     Train net output #0: center_loss = 50.1277 (* 0.008 = 0.401022 loss)
I0826 15:51:33.455498 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.19398 (* 1 = 8.19398 loss)
I0826 15:51:33.455502 25446 sgd_solver.cpp:138] Iteration 7140, lr = 0.001
I0826 15:51:35.564272 25446 solver.cpp:243] Iteration 7150, loss = 8.7322
I0826 15:51:35.564303 25446 solver.cpp:259]     Train net output #0: center_loss = 46.1722 (* 0.008 = 0.369378 loss)
I0826 15:51:35.564311 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36282 (* 1 = 8.36282 loss)
I0826 15:51:35.564316 25446 sgd_solver.cpp:138] Iteration 7150, lr = 0.001
I0826 15:51:37.706531 25446 solver.cpp:243] Iteration 7160, loss = 8.65375
I0826 15:51:37.706557 25446 solver.cpp:259]     Train net output #0: center_loss = 50.2512 (* 0.008 = 0.40201 loss)
I0826 15:51:37.706563 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.25174 (* 1 = 8.25174 loss)
I0826 15:51:37.706568 25446 sgd_solver.cpp:138] Iteration 7160, lr = 0.001
I0826 15:51:39.807307 25446 solver.cpp:243] Iteration 7170, loss = 8.82617
I0826 15:51:39.807345 25446 solver.cpp:259]     Train net output #0: center_loss = 46.0406 (* 0.008 = 0.368325 loss)
I0826 15:51:39.807351 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.45784 (* 1 = 8.45784 loss)
I0826 15:51:39.807354 25446 sgd_solver.cpp:138] Iteration 7170, lr = 0.001
I0826 15:51:41.861040 25446 solver.cpp:243] Iteration 7180, loss = 8.67715
I0826 15:51:41.861078 25446 solver.cpp:259]     Train net output #0: center_loss = 53.5529 (* 0.008 = 0.428423 loss)
I0826 15:51:41.861084 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.24873 (* 1 = 8.24873 loss)
I0826 15:51:41.861088 25446 sgd_solver.cpp:138] Iteration 7180, lr = 0.001
I0826 15:51:43.921758 25446 solver.cpp:243] Iteration 7190, loss = 8.2475
I0826 15:51:43.921797 25446 solver.cpp:259]     Train net output #0: center_loss = 54.0389 (* 0.008 = 0.432311 loss)
I0826 15:51:43.921803 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.81519 (* 1 = 7.81519 loss)
I0826 15:51:43.921806 25446 sgd_solver.cpp:138] Iteration 7190, lr = 0.001
I0826 15:51:45.978875 25446 solver.cpp:243] Iteration 7200, loss = 8.83002
I0826 15:51:45.978914 25446 solver.cpp:259]     Train net output #0: center_loss = 44.2893 (* 0.008 = 0.354314 loss)
I0826 15:51:45.978919 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.4757 (* 1 = 8.4757 loss)
I0826 15:51:45.978924 25446 sgd_solver.cpp:138] Iteration 7200, lr = 0.001
I0826 15:51:48.037910 25446 solver.cpp:243] Iteration 7210, loss = 8.69518
I0826 15:51:48.037950 25446 solver.cpp:259]     Train net output #0: center_loss = 39.845 (* 0.008 = 0.31876 loss)
I0826 15:51:48.037955 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.37642 (* 1 = 8.37642 loss)
I0826 15:51:48.037959 25446 sgd_solver.cpp:138] Iteration 7210, lr = 0.001
I0826 15:51:50.129403 25446 solver.cpp:243] Iteration 7220, loss = 8.47072
I0826 15:51:50.129429 25446 solver.cpp:259]     Train net output #0: center_loss = 56.0421 (* 0.008 = 0.448337 loss)
I0826 15:51:50.129436 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.02239 (* 1 = 8.02239 loss)
I0826 15:51:50.129441 25446 sgd_solver.cpp:138] Iteration 7220, lr = 0.001
I0826 15:51:52.345181 25446 solver.cpp:243] Iteration 7230, loss = 9.01983
I0826 15:51:52.345208 25446 solver.cpp:259]     Train net output #0: center_loss = 43.5316 (* 0.008 = 0.348253 loss)
I0826 15:51:52.345214 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.67158 (* 1 = 8.67158 loss)
I0826 15:51:52.345219 25446 sgd_solver.cpp:138] Iteration 7230, lr = 0.001
I0826 15:51:54.485414 25446 solver.cpp:243] Iteration 7240, loss = 9.05837
I0826 15:51:54.485436 25446 solver.cpp:259]     Train net output #0: center_loss = 35.7574 (* 0.008 = 0.286059 loss)
I0826 15:51:54.485457 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.77231 (* 1 = 8.77231 loss)
I0826 15:51:54.485460 25446 sgd_solver.cpp:138] Iteration 7240, lr = 0.001
I0826 15:51:56.573467 25446 solver.cpp:243] Iteration 7250, loss = 8.75655
I0826 15:51:56.573490 25446 solver.cpp:259]     Train net output #0: center_loss = 57.0079 (* 0.008 = 0.456063 loss)
I0826 15:51:56.573511 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.30049 (* 1 = 8.30049 loss)
I0826 15:51:56.573516 25446 sgd_solver.cpp:138] Iteration 7250, lr = 0.001
I0826 15:51:58.632455 25446 solver.cpp:243] Iteration 7260, loss = 8.52229
I0826 15:51:58.632494 25446 solver.cpp:259]     Train net output #0: center_loss = 48.7276 (* 0.008 = 0.38982 loss)
I0826 15:51:58.632500 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.13247 (* 1 = 8.13247 loss)
I0826 15:51:58.632504 25446 sgd_solver.cpp:138] Iteration 7260, lr = 0.001
I0826 15:52:00.691579 25446 solver.cpp:243] Iteration 7270, loss = 8.66665
I0826 15:52:00.691752 25446 solver.cpp:259]     Train net output #0: center_loss = 46.7211 (* 0.008 = 0.373769 loss)
I0826 15:52:00.691761 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.29288 (* 1 = 8.29288 loss)
I0826 15:52:00.691778 25446 sgd_solver.cpp:138] Iteration 7270, lr = 0.001
I0826 15:52:02.744118 25446 solver.cpp:243] Iteration 7280, loss = 8.56275
I0826 15:52:02.744158 25446 solver.cpp:259]     Train net output #0: center_loss = 47.4406 (* 0.008 = 0.379525 loss)
I0826 15:52:02.744163 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.18323 (* 1 = 8.18323 loss)
I0826 15:52:02.744166 25446 sgd_solver.cpp:138] Iteration 7280, lr = 0.001
I0826 15:52:04.808981 25446 solver.cpp:243] Iteration 7290, loss = 8.43627
I0826 15:52:04.809020 25446 solver.cpp:259]     Train net output #0: center_loss = 51.3516 (* 0.008 = 0.410813 loss)
I0826 15:52:04.809026 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.02546 (* 1 = 8.02546 loss)
I0826 15:52:04.809029 25446 sgd_solver.cpp:138] Iteration 7290, lr = 0.001
I0826 15:52:06.869315 25446 solver.cpp:243] Iteration 7300, loss = 8.47618
I0826 15:52:06.869354 25446 solver.cpp:259]     Train net output #0: center_loss = 46.0129 (* 0.008 = 0.368103 loss)
I0826 15:52:06.869359 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.10807 (* 1 = 8.10807 loss)
I0826 15:52:06.869362 25446 sgd_solver.cpp:138] Iteration 7300, lr = 0.001
I0826 15:52:08.926182 25446 solver.cpp:243] Iteration 7310, loss = 8.18051
I0826 15:52:08.926220 25446 solver.cpp:259]     Train net output #0: center_loss = 66.9807 (* 0.008 = 0.535845 loss)
I0826 15:52:08.926226 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.64467 (* 1 = 7.64467 loss)
I0826 15:52:08.926230 25446 sgd_solver.cpp:138] Iteration 7310, lr = 0.001
I0826 15:52:10.983405 25446 solver.cpp:243] Iteration 7320, loss = 8.90112
I0826 15:52:10.983444 25446 solver.cpp:259]     Train net output #0: center_loss = 38.361 (* 0.008 = 0.306888 loss)
I0826 15:52:10.983449 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.59423 (* 1 = 8.59423 loss)
I0826 15:52:10.983453 25446 sgd_solver.cpp:138] Iteration 7320, lr = 0.001
I0826 15:52:13.043537 25446 solver.cpp:243] Iteration 7330, loss = 9.11754
I0826 15:52:13.043561 25446 solver.cpp:259]     Train net output #0: center_loss = 28.2612 (* 0.008 = 0.226089 loss)
I0826 15:52:13.043582 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.89145 (* 1 = 8.89145 loss)
I0826 15:52:13.043586 25446 sgd_solver.cpp:138] Iteration 7330, lr = 0.001
I0826 15:52:15.100188 25446 solver.cpp:243] Iteration 7340, loss = 8.69835
I0826 15:52:15.100224 25446 solver.cpp:259]     Train net output #0: center_loss = 41.7241 (* 0.008 = 0.333793 loss)
I0826 15:52:15.100230 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36456 (* 1 = 8.36456 loss)
I0826 15:52:15.100234 25446 sgd_solver.cpp:138] Iteration 7340, lr = 0.001
I0826 15:52:17.160323 25446 solver.cpp:243] Iteration 7350, loss = 8.42503
I0826 15:52:17.160362 25446 solver.cpp:259]     Train net output #0: center_loss = 46.1678 (* 0.008 = 0.369342 loss)
I0826 15:52:17.160367 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.05569 (* 1 = 8.05569 loss)
I0826 15:52:17.160370 25446 sgd_solver.cpp:138] Iteration 7350, lr = 0.001
I0826 15:52:19.220157 25446 solver.cpp:243] Iteration 7360, loss = 8.85501
I0826 15:52:19.220196 25446 solver.cpp:259]     Train net output #0: center_loss = 43.3806 (* 0.008 = 0.347045 loss)
I0826 15:52:19.220201 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.50796 (* 1 = 8.50796 loss)
I0826 15:52:19.220204 25446 sgd_solver.cpp:138] Iteration 7360, lr = 0.001
I0826 15:52:21.277293 25446 solver.cpp:243] Iteration 7370, loss = 8.54663
I0826 15:52:21.277331 25446 solver.cpp:259]     Train net output #0: center_loss = 56.1103 (* 0.008 = 0.448882 loss)
I0826 15:52:21.277338 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.09775 (* 1 = 8.09775 loss)
I0826 15:52:21.277340 25446 sgd_solver.cpp:138] Iteration 7370, lr = 0.001
I0826 15:52:23.335443 25446 solver.cpp:243] Iteration 7380, loss = 8.96039
I0826 15:52:23.335482 25446 solver.cpp:259]     Train net output #0: center_loss = 38.089 (* 0.008 = 0.304712 loss)
I0826 15:52:23.335489 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.65568 (* 1 = 8.65568 loss)
I0826 15:52:23.335491 25446 sgd_solver.cpp:138] Iteration 7380, lr = 0.001
I0826 15:52:25.398201 25446 solver.cpp:243] Iteration 7390, loss = 8.48885
I0826 15:52:25.398238 25446 solver.cpp:259]     Train net output #0: center_loss = 51.0714 (* 0.008 = 0.408571 loss)
I0826 15:52:25.398244 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08028 (* 1 = 8.08028 loss)
I0826 15:52:25.398247 25446 sgd_solver.cpp:138] Iteration 7390, lr = 0.001
I0826 15:52:27.453693 25446 solver.cpp:243] Iteration 7400, loss = 8.79365
I0826 15:52:27.453732 25446 solver.cpp:259]     Train net output #0: center_loss = 45.6847 (* 0.008 = 0.365478 loss)
I0826 15:52:27.453737 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.42817 (* 1 = 8.42817 loss)
I0826 15:52:27.453740 25446 sgd_solver.cpp:138] Iteration 7400, lr = 0.001
I0826 15:52:29.512029 25446 solver.cpp:243] Iteration 7410, loss = 8.561
I0826 15:52:29.512068 25446 solver.cpp:259]     Train net output #0: center_loss = 43.9127 (* 0.008 = 0.351301 loss)
I0826 15:52:29.512073 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.2097 (* 1 = 8.2097 loss)
I0826 15:52:29.512076 25446 sgd_solver.cpp:138] Iteration 7410, lr = 0.001
I0826 15:52:31.565955 25446 solver.cpp:243] Iteration 7420, loss = 8.44428
I0826 15:52:31.566079 25446 solver.cpp:259]     Train net output #0: center_loss = 69.3969 (* 0.008 = 0.555175 loss)
I0826 15:52:31.566085 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.8891 (* 1 = 7.8891 loss)
I0826 15:52:31.566102 25446 sgd_solver.cpp:138] Iteration 7420, lr = 0.001
I0826 15:52:33.619014 25446 solver.cpp:243] Iteration 7430, loss = 8.63893
I0826 15:52:33.619051 25446 solver.cpp:259]     Train net output #0: center_loss = 55.278 (* 0.008 = 0.442224 loss)
I0826 15:52:33.619057 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.19671 (* 1 = 8.19671 loss)
I0826 15:52:33.619060 25446 sgd_solver.cpp:138] Iteration 7430, lr = 0.001
I0826 15:52:35.680006 25446 solver.cpp:243] Iteration 7440, loss = 8.83225
I0826 15:52:35.680044 25446 solver.cpp:259]     Train net output #0: center_loss = 41.9933 (* 0.008 = 0.335946 loss)
I0826 15:52:35.680050 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.49631 (* 1 = 8.49631 loss)
I0826 15:52:35.680053 25446 sgd_solver.cpp:138] Iteration 7440, lr = 0.001
I0826 15:52:37.738759 25446 solver.cpp:243] Iteration 7450, loss = 8.523
I0826 15:52:37.738797 25446 solver.cpp:259]     Train net output #0: center_loss = 51.6529 (* 0.008 = 0.413224 loss)
I0826 15:52:37.738802 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.10978 (* 1 = 8.10978 loss)
I0826 15:52:37.738806 25446 sgd_solver.cpp:138] Iteration 7450, lr = 0.001
I0826 15:52:39.794288 25446 solver.cpp:243] Iteration 7460, loss = 8.91592
I0826 15:52:39.794327 25446 solver.cpp:259]     Train net output #0: center_loss = 46.3238 (* 0.008 = 0.370591 loss)
I0826 15:52:39.794332 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.54533 (* 1 = 8.54533 loss)
I0826 15:52:39.794335 25446 sgd_solver.cpp:138] Iteration 7460, lr = 0.001
I0826 15:52:41.848560 25446 solver.cpp:243] Iteration 7470, loss = 8.58842
I0826 15:52:41.848599 25446 solver.cpp:259]     Train net output #0: center_loss = 46.1113 (* 0.008 = 0.368891 loss)
I0826 15:52:41.848605 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.21953 (* 1 = 8.21953 loss)
I0826 15:52:41.848608 25446 sgd_solver.cpp:138] Iteration 7470, lr = 0.001
I0826 15:52:43.902758 25446 solver.cpp:243] Iteration 7480, loss = 8.56609
I0826 15:52:43.902796 25446 solver.cpp:259]     Train net output #0: center_loss = 48.5585 (* 0.008 = 0.388468 loss)
I0826 15:52:43.902801 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.17762 (* 1 = 8.17762 loss)
I0826 15:52:43.902806 25446 sgd_solver.cpp:138] Iteration 7480, lr = 0.001
I0826 15:52:45.962918 25446 solver.cpp:243] Iteration 7490, loss = 8.73158
I0826 15:52:45.962956 25446 solver.cpp:259]     Train net output #0: center_loss = 53.4023 (* 0.008 = 0.427218 loss)
I0826 15:52:45.962962 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.30436 (* 1 = 8.30436 loss)
I0826 15:52:45.962965 25446 sgd_solver.cpp:138] Iteration 7490, lr = 0.001
I0826 15:52:48.023097 25446 solver.cpp:243] Iteration 7500, loss = 8.87255
I0826 15:52:48.023133 25446 solver.cpp:259]     Train net output #0: center_loss = 51.0513 (* 0.008 = 0.40841 loss)
I0826 15:52:48.023139 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.46414 (* 1 = 8.46414 loss)
I0826 15:52:48.023142 25446 sgd_solver.cpp:138] Iteration 7500, lr = 0.001
I0826 15:52:50.082706 25446 solver.cpp:243] Iteration 7510, loss = 8.78596
I0826 15:52:50.082743 25446 solver.cpp:259]     Train net output #0: center_loss = 47.8805 (* 0.008 = 0.383044 loss)
I0826 15:52:50.082749 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.40292 (* 1 = 8.40292 loss)
I0826 15:52:50.082752 25446 sgd_solver.cpp:138] Iteration 7510, lr = 0.001
I0826 15:52:52.141971 25446 solver.cpp:243] Iteration 7520, loss = 8.67551
I0826 15:52:52.141995 25446 solver.cpp:259]     Train net output #0: center_loss = 46.8192 (* 0.008 = 0.374554 loss)
I0826 15:52:52.142016 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.30096 (* 1 = 8.30096 loss)
I0826 15:52:52.142019 25446 sgd_solver.cpp:138] Iteration 7520, lr = 0.001
I0826 15:52:54.198141 25446 solver.cpp:243] Iteration 7530, loss = 8.645
I0826 15:52:54.198179 25446 solver.cpp:259]     Train net output #0: center_loss = 46.0585 (* 0.008 = 0.368468 loss)
I0826 15:52:54.198185 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.27654 (* 1 = 8.27654 loss)
I0826 15:52:54.198189 25446 sgd_solver.cpp:138] Iteration 7530, lr = 0.001
I0826 15:52:56.256415 25446 solver.cpp:243] Iteration 7540, loss = 8.71285
I0826 15:52:56.256453 25446 solver.cpp:259]     Train net output #0: center_loss = 47.0992 (* 0.008 = 0.376794 loss)
I0826 15:52:56.256459 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.33605 (* 1 = 8.33605 loss)
I0826 15:52:56.256462 25446 sgd_solver.cpp:138] Iteration 7540, lr = 0.001
I0826 15:52:58.315992 25446 solver.cpp:243] Iteration 7550, loss = 8.27243
I0826 15:52:58.316031 25446 solver.cpp:259]     Train net output #0: center_loss = 62.2467 (* 0.008 = 0.497974 loss)
I0826 15:52:58.316036 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.77445 (* 1 = 7.77445 loss)
I0826 15:52:58.316040 25446 sgd_solver.cpp:138] Iteration 7550, lr = 0.001
I0826 15:53:00.371410 25446 solver.cpp:243] Iteration 7560, loss = 8.77339
I0826 15:53:00.371448 25446 solver.cpp:259]     Train net output #0: center_loss = 54.4442 (* 0.008 = 0.435553 loss)
I0826 15:53:00.371454 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.33784 (* 1 = 8.33784 loss)
I0826 15:53:00.371457 25446 sgd_solver.cpp:138] Iteration 7560, lr = 0.001
I0826 15:53:02.425284 25446 solver.cpp:243] Iteration 7570, loss = 8.61446
I0826 15:53:02.425415 25446 solver.cpp:259]     Train net output #0: center_loss = 48.1613 (* 0.008 = 0.385291 loss)
I0826 15:53:02.425421 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.22917 (* 1 = 8.22917 loss)
I0826 15:53:02.425424 25446 sgd_solver.cpp:138] Iteration 7570, lr = 0.001
I0826 15:53:04.485734 25446 solver.cpp:243] Iteration 7580, loss = 8.96913
I0826 15:53:04.485771 25446 solver.cpp:259]     Train net output #0: center_loss = 40.7449 (* 0.008 = 0.325959 loss)
I0826 15:53:04.485776 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.64317 (* 1 = 8.64317 loss)
I0826 15:53:04.485780 25446 sgd_solver.cpp:138] Iteration 7580, lr = 0.001
I0826 15:53:06.539299 25446 solver.cpp:243] Iteration 7590, loss = 8.92826
I0826 15:53:06.539336 25446 solver.cpp:259]     Train net output #0: center_loss = 38.1074 (* 0.008 = 0.304859 loss)
I0826 15:53:06.539342 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.6234 (* 1 = 8.6234 loss)
I0826 15:53:06.539345 25446 sgd_solver.cpp:138] Iteration 7590, lr = 0.001
I0826 15:53:08.595701 25446 solver.cpp:243] Iteration 7600, loss = 8.55403
I0826 15:53:08.595738 25446 solver.cpp:259]     Train net output #0: center_loss = 55.1583 (* 0.008 = 0.441266 loss)
I0826 15:53:08.595744 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.11277 (* 1 = 8.11277 loss)
I0826 15:53:08.595747 25446 sgd_solver.cpp:138] Iteration 7600, lr = 0.001
I0826 15:53:10.653393 25446 solver.cpp:243] Iteration 7610, loss = 8.98567
I0826 15:53:10.653445 25446 solver.cpp:259]     Train net output #0: center_loss = 51.5281 (* 0.008 = 0.412225 loss)
I0826 15:53:10.653451 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.57345 (* 1 = 8.57345 loss)
I0826 15:53:10.653455 25446 sgd_solver.cpp:138] Iteration 7610, lr = 0.001
I0826 15:53:12.714330 25446 solver.cpp:243] Iteration 7620, loss = 8.46671
I0826 15:53:12.714368 25446 solver.cpp:259]     Train net output #0: center_loss = 49.5881 (* 0.008 = 0.396705 loss)
I0826 15:53:12.714375 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.07001 (* 1 = 8.07001 loss)
I0826 15:53:12.714377 25446 sgd_solver.cpp:138] Iteration 7620, lr = 0.001
I0826 15:53:14.768164 25446 solver.cpp:243] Iteration 7630, loss = 8.66256
I0826 15:53:14.768203 25446 solver.cpp:259]     Train net output #0: center_loss = 44.7048 (* 0.008 = 0.357638 loss)
I0826 15:53:14.768208 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.30493 (* 1 = 8.30493 loss)
I0826 15:53:14.768211 25446 sgd_solver.cpp:138] Iteration 7630, lr = 0.001
I0826 15:53:16.829144 25446 solver.cpp:243] Iteration 7640, loss = 7.9869
I0826 15:53:16.829181 25446 solver.cpp:259]     Train net output #0: center_loss = 61.1674 (* 0.008 = 0.489339 loss)
I0826 15:53:16.829186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.49756 (* 1 = 7.49756 loss)
I0826 15:53:16.829190 25446 sgd_solver.cpp:138] Iteration 7640, lr = 0.001
I0826 15:53:18.889297 25446 solver.cpp:243] Iteration 7650, loss = 8.6318
I0826 15:53:18.889335 25446 solver.cpp:259]     Train net output #0: center_loss = 72.1423 (* 0.008 = 0.577139 loss)
I0826 15:53:18.889340 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.05466 (* 1 = 8.05466 loss)
I0826 15:53:18.889344 25446 sgd_solver.cpp:138] Iteration 7650, lr = 0.001
I0826 15:53:20.943799 25446 solver.cpp:243] Iteration 7660, loss = 8.44189
I0826 15:53:20.943833 25446 solver.cpp:259]     Train net output #0: center_loss = 57.1873 (* 0.008 = 0.457498 loss)
I0826 15:53:20.943855 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.98439 (* 1 = 7.98439 loss)
I0826 15:53:20.943857 25446 sgd_solver.cpp:138] Iteration 7660, lr = 0.001
I0826 15:53:23.002928 25446 solver.cpp:243] Iteration 7670, loss = 8.77188
I0826 15:53:23.002966 25446 solver.cpp:259]     Train net output #0: center_loss = 46.6256 (* 0.008 = 0.373004 loss)
I0826 15:53:23.002971 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.39888 (* 1 = 8.39888 loss)
I0826 15:53:23.002975 25446 sgd_solver.cpp:138] Iteration 7670, lr = 0.001
I0826 15:53:25.056113 25446 solver.cpp:243] Iteration 7680, loss = 8.38587
I0826 15:53:25.056149 25446 solver.cpp:259]     Train net output #0: center_loss = 56.0105 (* 0.008 = 0.448084 loss)
I0826 15:53:25.056154 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.93778 (* 1 = 7.93778 loss)
I0826 15:53:25.056157 25446 sgd_solver.cpp:138] Iteration 7680, lr = 0.001
I0826 15:53:27.114385 25446 solver.cpp:243] Iteration 7690, loss = 8.39466
I0826 15:53:27.114423 25446 solver.cpp:259]     Train net output #0: center_loss = 54.4402 (* 0.008 = 0.435521 loss)
I0826 15:53:27.114428 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.95914 (* 1 = 7.95914 loss)
I0826 15:53:27.114432 25446 sgd_solver.cpp:138] Iteration 7690, lr = 0.001
I0826 15:53:29.170521 25446 solver.cpp:243] Iteration 7700, loss = 9.12955
I0826 15:53:29.170559 25446 solver.cpp:259]     Train net output #0: center_loss = 49.6363 (* 0.008 = 0.397091 loss)
I0826 15:53:29.170564 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.73246 (* 1 = 8.73246 loss)
I0826 15:53:29.170568 25446 sgd_solver.cpp:138] Iteration 7700, lr = 0.001
I0826 15:53:31.228920 25446 solver.cpp:243] Iteration 7710, loss = 8.74384
I0826 15:53:31.228957 25446 solver.cpp:259]     Train net output #0: center_loss = 49.5343 (* 0.008 = 0.396274 loss)
I0826 15:53:31.228963 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.34757 (* 1 = 8.34757 loss)
I0826 15:53:31.228966 25446 sgd_solver.cpp:138] Iteration 7710, lr = 0.001
I0826 15:53:33.285596 25446 solver.cpp:243] Iteration 7720, loss = 8.63943
I0826 15:53:33.285753 25446 solver.cpp:259]     Train net output #0: center_loss = 55.7875 (* 0.008 = 0.4463 loss)
I0826 15:53:33.285760 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.19313 (* 1 = 8.19313 loss)
I0826 15:53:33.285776 25446 sgd_solver.cpp:138] Iteration 7720, lr = 0.001
I0826 15:53:35.342654 25446 solver.cpp:243] Iteration 7730, loss = 8.86685
I0826 15:53:35.342692 25446 solver.cpp:259]     Train net output #0: center_loss = 55.8074 (* 0.008 = 0.446459 loss)
I0826 15:53:35.342698 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.42039 (* 1 = 8.42039 loss)
I0826 15:53:35.342701 25446 sgd_solver.cpp:138] Iteration 7730, lr = 0.001
I0826 15:53:37.395916 25446 solver.cpp:243] Iteration 7740, loss = 9.15598
I0826 15:53:37.395938 25446 solver.cpp:259]     Train net output #0: center_loss = 49.7922 (* 0.008 = 0.398337 loss)
I0826 15:53:37.395959 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.75764 (* 1 = 8.75764 loss)
I0826 15:53:37.395962 25446 sgd_solver.cpp:138] Iteration 7740, lr = 0.001
I0826 15:53:39.454143 25446 solver.cpp:243] Iteration 7750, loss = 8.97847
I0826 15:53:39.454180 25446 solver.cpp:259]     Train net output #0: center_loss = 48.8055 (* 0.008 = 0.390444 loss)
I0826 15:53:39.454185 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.58803 (* 1 = 8.58803 loss)
I0826 15:53:39.454188 25446 sgd_solver.cpp:138] Iteration 7750, lr = 0.001
I0826 15:53:41.509167 25446 solver.cpp:243] Iteration 7760, loss = 9.03384
I0826 15:53:41.509191 25446 solver.cpp:259]     Train net output #0: center_loss = 64.6728 (* 0.008 = 0.517383 loss)
I0826 15:53:41.509212 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.51646 (* 1 = 8.51646 loss)
I0826 15:53:41.509214 25446 sgd_solver.cpp:138] Iteration 7760, lr = 0.001
I0826 15:53:43.568625 25446 solver.cpp:243] Iteration 7770, loss = 8.56259
I0826 15:53:43.568665 25446 solver.cpp:259]     Train net output #0: center_loss = 53.2412 (* 0.008 = 0.425929 loss)
I0826 15:53:43.568671 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.13666 (* 1 = 8.13666 loss)
I0826 15:53:43.568675 25446 sgd_solver.cpp:138] Iteration 7770, lr = 0.001
I0826 15:53:45.626672 25446 solver.cpp:243] Iteration 7780, loss = 8.69274
I0826 15:53:45.626710 25446 solver.cpp:259]     Train net output #0: center_loss = 49.794 (* 0.008 = 0.398352 loss)
I0826 15:53:45.626716 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.29438 (* 1 = 8.29438 loss)
I0826 15:53:45.626719 25446 sgd_solver.cpp:138] Iteration 7780, lr = 0.001
I0826 15:53:47.685310 25446 solver.cpp:243] Iteration 7790, loss = 8.90437
I0826 15:53:47.685333 25446 solver.cpp:259]     Train net output #0: center_loss = 44.625 (* 0.008 = 0.357 loss)
I0826 15:53:47.685355 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.54737 (* 1 = 8.54737 loss)
I0826 15:53:47.685359 25446 sgd_solver.cpp:138] Iteration 7790, lr = 0.001
I0826 15:53:49.745414 25446 solver.cpp:243] Iteration 7800, loss = 8.34069
I0826 15:53:49.745453 25446 solver.cpp:259]     Train net output #0: center_loss = 64.9799 (* 0.008 = 0.519839 loss)
I0826 15:53:49.745460 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.82086 (* 1 = 7.82086 loss)
I0826 15:53:49.745462 25446 sgd_solver.cpp:138] Iteration 7800, lr = 0.001
I0826 15:53:51.803316 25446 solver.cpp:243] Iteration 7810, loss = 8.88171
I0826 15:53:51.803355 25446 solver.cpp:259]     Train net output #0: center_loss = 60.8823 (* 0.008 = 0.487059 loss)
I0826 15:53:51.803361 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.39465 (* 1 = 8.39465 loss)
I0826 15:53:51.803380 25446 sgd_solver.cpp:138] Iteration 7810, lr = 0.001
I0826 15:53:53.860960 25446 solver.cpp:243] Iteration 7820, loss = 8.53338
I0826 15:53:53.860998 25446 solver.cpp:259]     Train net output #0: center_loss = 50.8906 (* 0.008 = 0.407125 loss)
I0826 15:53:53.861004 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.12625 (* 1 = 8.12625 loss)
I0826 15:53:53.861007 25446 sgd_solver.cpp:138] Iteration 7820, lr = 0.001
I0826 15:53:55.915406 25446 solver.cpp:243] Iteration 7830, loss = 8.72566
I0826 15:53:55.915442 25446 solver.cpp:259]     Train net output #0: center_loss = 70.6368 (* 0.008 = 0.565094 loss)
I0826 15:53:55.915448 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.16057 (* 1 = 8.16057 loss)
I0826 15:53:55.915452 25446 sgd_solver.cpp:138] Iteration 7830, lr = 0.001
I0826 15:53:57.993383 25446 solver.cpp:243] Iteration 7840, loss = 8.85348
I0826 15:53:57.993420 25446 solver.cpp:259]     Train net output #0: center_loss = 49.5638 (* 0.008 = 0.39651 loss)
I0826 15:53:57.993427 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.45697 (* 1 = 8.45697 loss)
I0826 15:53:57.993430 25446 sgd_solver.cpp:138] Iteration 7840, lr = 0.001
I0826 15:54:00.087884 25446 solver.cpp:243] Iteration 7850, loss = 8.7721
I0826 15:54:00.087922 25446 solver.cpp:259]     Train net output #0: center_loss = 43.1132 (* 0.008 = 0.344905 loss)
I0826 15:54:00.087929 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.42719 (* 1 = 8.42719 loss)
I0826 15:54:00.087932 25446 sgd_solver.cpp:138] Iteration 7850, lr = 0.001
I0826 15:54:02.180771 25446 solver.cpp:243] Iteration 7860, loss = 8.84087
I0826 15:54:02.180795 25446 solver.cpp:259]     Train net output #0: center_loss = 46.7861 (* 0.008 = 0.374289 loss)
I0826 15:54:02.180801 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.46658 (* 1 = 8.46658 loss)
I0826 15:54:02.180805 25446 sgd_solver.cpp:138] Iteration 7860, lr = 0.001
I0826 15:54:04.367084 25446 solver.cpp:243] Iteration 7870, loss = 8.69396
I0826 15:54:04.367215 25446 solver.cpp:259]     Train net output #0: center_loss = 57.2656 (* 0.008 = 0.458125 loss)
I0826 15:54:04.367236 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.23584 (* 1 = 8.23584 loss)
I0826 15:54:04.367239 25446 sgd_solver.cpp:138] Iteration 7870, lr = 0.001
I0826 15:54:06.426640 25446 solver.cpp:243] Iteration 7880, loss = 8.41621
I0826 15:54:06.426677 25446 solver.cpp:259]     Train net output #0: center_loss = 53.3291 (* 0.008 = 0.426633 loss)
I0826 15:54:06.426683 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.98957 (* 1 = 7.98957 loss)
I0826 15:54:06.426687 25446 sgd_solver.cpp:138] Iteration 7880, lr = 0.001
I0826 15:54:08.489773 25446 solver.cpp:243] Iteration 7890, loss = 8.47143
I0826 15:54:08.489810 25446 solver.cpp:259]     Train net output #0: center_loss = 59.8478 (* 0.008 = 0.478783 loss)
I0826 15:54:08.489815 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.99265 (* 1 = 7.99265 loss)
I0826 15:54:08.489820 25446 sgd_solver.cpp:138] Iteration 7890, lr = 0.001
I0826 15:54:10.550946 25446 solver.cpp:243] Iteration 7900, loss = 8.66017
I0826 15:54:10.550985 25446 solver.cpp:259]     Train net output #0: center_loss = 44.4205 (* 0.008 = 0.355364 loss)
I0826 15:54:10.550990 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.3048 (* 1 = 8.3048 loss)
I0826 15:54:10.550994 25446 sgd_solver.cpp:138] Iteration 7900, lr = 0.001
I0826 15:54:12.614269 25446 solver.cpp:243] Iteration 7910, loss = 8.88983
I0826 15:54:12.614306 25446 solver.cpp:259]     Train net output #0: center_loss = 56.4489 (* 0.008 = 0.451591 loss)
I0826 15:54:12.614311 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.43824 (* 1 = 8.43824 loss)
I0826 15:54:12.614315 25446 sgd_solver.cpp:138] Iteration 7910, lr = 0.001
I0826 15:54:14.676098 25446 solver.cpp:243] Iteration 7920, loss = 8.57999
I0826 15:54:14.676136 25446 solver.cpp:259]     Train net output #0: center_loss = 53.0306 (* 0.008 = 0.424245 loss)
I0826 15:54:14.676141 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.15575 (* 1 = 8.15575 loss)
I0826 15:54:14.676144 25446 sgd_solver.cpp:138] Iteration 7920, lr = 0.001
I0826 15:54:16.734997 25446 solver.cpp:243] Iteration 7930, loss = 8.56496
I0826 15:54:16.735033 25446 solver.cpp:259]     Train net output #0: center_loss = 54.545 (* 0.008 = 0.43636 loss)
I0826 15:54:16.735038 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.1286 (* 1 = 8.1286 loss)
I0826 15:54:16.735042 25446 sgd_solver.cpp:138] Iteration 7930, lr = 0.001
I0826 15:54:18.789835 25446 solver.cpp:243] Iteration 7940, loss = 8.22066
I0826 15:54:18.789873 25446 solver.cpp:259]     Train net output #0: center_loss = 64.148 (* 0.008 = 0.513184 loss)
I0826 15:54:18.789878 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.70748 (* 1 = 7.70748 loss)
I0826 15:54:18.789881 25446 sgd_solver.cpp:138] Iteration 7940, lr = 0.001
I0826 15:54:20.847223 25446 solver.cpp:243] Iteration 7950, loss = 8.7984
I0826 15:54:20.847260 25446 solver.cpp:259]     Train net output #0: center_loss = 48.5087 (* 0.008 = 0.388069 loss)
I0826 15:54:20.847266 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.41033 (* 1 = 8.41033 loss)
I0826 15:54:20.847270 25446 sgd_solver.cpp:138] Iteration 7950, lr = 0.001
I0826 15:54:22.903107 25446 solver.cpp:243] Iteration 7960, loss = 8.77651
I0826 15:54:22.903146 25446 solver.cpp:259]     Train net output #0: center_loss = 48.2901 (* 0.008 = 0.386321 loss)
I0826 15:54:22.903151 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.39019 (* 1 = 8.39019 loss)
I0826 15:54:22.903154 25446 sgd_solver.cpp:138] Iteration 7960, lr = 0.001
I0826 15:54:24.960464 25446 solver.cpp:243] Iteration 7970, loss = 8.75313
I0826 15:54:24.960500 25446 solver.cpp:259]     Train net output #0: center_loss = 51.5926 (* 0.008 = 0.412741 loss)
I0826 15:54:24.960506 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.34039 (* 1 = 8.34039 loss)
I0826 15:54:24.960510 25446 sgd_solver.cpp:138] Iteration 7970, lr = 0.001
I0826 15:54:27.020777 25446 solver.cpp:243] Iteration 7980, loss = 8.219
I0826 15:54:27.020815 25446 solver.cpp:259]     Train net output #0: center_loss = 62.417 (* 0.008 = 0.499336 loss)
I0826 15:54:27.020822 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.71966 (* 1 = 7.71966 loss)
I0826 15:54:27.020824 25446 sgd_solver.cpp:138] Iteration 7980, lr = 0.001
I0826 15:54:29.080148 25446 solver.cpp:243] Iteration 7990, loss = 8.74881
I0826 15:54:29.080185 25446 solver.cpp:259]     Train net output #0: center_loss = 57.7027 (* 0.008 = 0.461621 loss)
I0826 15:54:29.080191 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.28718 (* 1 = 8.28718 loss)
I0826 15:54:29.080194 25446 sgd_solver.cpp:138] Iteration 7990, lr = 0.001
I0826 15:54:30.935446 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_8000.caffemodel
I0826 15:54:32.042440 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_8000.solverstate
I0826 15:54:32.364814 25446 solver.cpp:243] Iteration 8000, loss = 8.30241
I0826 15:54:32.364856 25446 solver.cpp:259]     Train net output #0: center_loss = 57.5254 (* 0.008 = 0.460203 loss)
I0826 15:54:32.364861 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.84221 (* 1 = 7.84221 loss)
I0826 15:54:32.364866 25446 sgd_solver.cpp:138] Iteration 8000, lr = 0.001
I0826 15:54:34.423286 25446 solver.cpp:243] Iteration 8010, loss = 8.53627
I0826 15:54:34.423425 25446 solver.cpp:259]     Train net output #0: center_loss = 60.9238 (* 0.008 = 0.487391 loss)
I0826 15:54:34.423445 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.04888 (* 1 = 8.04888 loss)
I0826 15:54:34.423449 25446 sgd_solver.cpp:138] Iteration 8010, lr = 0.001
I0826 15:54:36.482514 25446 solver.cpp:243] Iteration 8020, loss = 8.87106
I0826 15:54:36.482553 25446 solver.cpp:259]     Train net output #0: center_loss = 51.3628 (* 0.008 = 0.410902 loss)
I0826 15:54:36.482558 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.46016 (* 1 = 8.46016 loss)
I0826 15:54:36.482561 25446 sgd_solver.cpp:138] Iteration 8020, lr = 0.001
I0826 15:54:38.537473 25446 solver.cpp:243] Iteration 8030, loss = 8.66972
I0826 15:54:38.537511 25446 solver.cpp:259]     Train net output #0: center_loss = 70.1024 (* 0.008 = 0.560819 loss)
I0826 15:54:38.537516 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.1089 (* 1 = 8.1089 loss)
I0826 15:54:38.537520 25446 sgd_solver.cpp:138] Iteration 8030, lr = 0.001
I0826 15:54:40.595261 25446 solver.cpp:243] Iteration 8040, loss = 8.31007
I0826 15:54:40.595299 25446 solver.cpp:259]     Train net output #0: center_loss = 58.9738 (* 0.008 = 0.471791 loss)
I0826 15:54:40.595304 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.83828 (* 1 = 7.83828 loss)
I0826 15:54:40.595307 25446 sgd_solver.cpp:138] Iteration 8040, lr = 0.001
I0826 15:54:42.650137 25446 solver.cpp:243] Iteration 8050, loss = 8.64499
I0826 15:54:42.650177 25446 solver.cpp:259]     Train net output #0: center_loss = 49.173 (* 0.008 = 0.393384 loss)
I0826 15:54:42.650182 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.2516 (* 1 = 8.2516 loss)
I0826 15:54:42.650185 25446 sgd_solver.cpp:138] Iteration 8050, lr = 0.001
I0826 15:54:44.710440 25446 solver.cpp:243] Iteration 8060, loss = 8.69465
I0826 15:54:44.710477 25446 solver.cpp:259]     Train net output #0: center_loss = 53.801 (* 0.008 = 0.430408 loss)
I0826 15:54:44.710484 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.26424 (* 1 = 8.26424 loss)
I0826 15:54:44.710486 25446 sgd_solver.cpp:138] Iteration 8060, lr = 0.001
I0826 15:54:46.767288 25446 solver.cpp:243] Iteration 8070, loss = 8.68736
I0826 15:54:46.767311 25446 solver.cpp:259]     Train net output #0: center_loss = 61.757 (* 0.008 = 0.494056 loss)
I0826 15:54:46.767333 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.19331 (* 1 = 8.19331 loss)
I0826 15:54:46.767335 25446 sgd_solver.cpp:138] Iteration 8070, lr = 0.001
I0826 15:54:48.826727 25446 solver.cpp:243] Iteration 8080, loss = 8.71171
I0826 15:54:48.826764 25446 solver.cpp:259]     Train net output #0: center_loss = 51.8746 (* 0.008 = 0.414997 loss)
I0826 15:54:48.826771 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.29672 (* 1 = 8.29672 loss)
I0826 15:54:48.826773 25446 sgd_solver.cpp:138] Iteration 8080, lr = 0.001
I0826 15:54:50.885236 25446 solver.cpp:243] Iteration 8090, loss = 8.84626
I0826 15:54:50.885277 25446 solver.cpp:259]     Train net output #0: center_loss = 43.8004 (* 0.008 = 0.350403 loss)
I0826 15:54:50.885283 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.49586 (* 1 = 8.49586 loss)
I0826 15:54:50.885287 25446 sgd_solver.cpp:138] Iteration 8090, lr = 0.001
I0826 15:54:52.946372 25446 solver.cpp:243] Iteration 8100, loss = 8.56266
I0826 15:54:52.946410 25446 solver.cpp:259]     Train net output #0: center_loss = 46.7134 (* 0.008 = 0.373707 loss)
I0826 15:54:52.946416 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.18895 (* 1 = 8.18895 loss)
I0826 15:54:52.946419 25446 sgd_solver.cpp:138] Iteration 8100, lr = 0.001
I0826 15:54:55.003594 25446 solver.cpp:243] Iteration 8110, loss = 8.6725
I0826 15:54:55.003633 25446 solver.cpp:259]     Train net output #0: center_loss = 51.0499 (* 0.008 = 0.408399 loss)
I0826 15:54:55.003638 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.2641 (* 1 = 8.2641 loss)
I0826 15:54:55.003641 25446 sgd_solver.cpp:138] Iteration 8110, lr = 0.001
I0826 15:54:57.065814 25446 solver.cpp:243] Iteration 8120, loss = 8.3859
I0826 15:54:57.065871 25446 solver.cpp:259]     Train net output #0: center_loss = 47.7904 (* 0.008 = 0.382323 loss)
I0826 15:54:57.065876 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.00358 (* 1 = 8.00358 loss)
I0826 15:54:57.065881 25446 sgd_solver.cpp:138] Iteration 8120, lr = 0.001
I0826 15:54:59.125437 25446 solver.cpp:243] Iteration 8130, loss = 8.09016
I0826 15:54:59.125474 25446 solver.cpp:259]     Train net output #0: center_loss = 50.8413 (* 0.008 = 0.406731 loss)
I0826 15:54:59.125480 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.68343 (* 1 = 7.68343 loss)
I0826 15:54:59.125483 25446 sgd_solver.cpp:138] Iteration 8130, lr = 0.001
I0826 15:55:01.182121 25446 solver.cpp:243] Iteration 8140, loss = 9.09492
I0826 15:55:01.182142 25446 solver.cpp:259]     Train net output #0: center_loss = 47.377 (* 0.008 = 0.379016 loss)
I0826 15:55:01.182163 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.7159 (* 1 = 8.7159 loss)
I0826 15:55:01.182168 25446 sgd_solver.cpp:138] Iteration 8140, lr = 0.001
I0826 15:55:03.240839 25446 solver.cpp:243] Iteration 8150, loss = 8.68703
I0826 15:55:03.240880 25446 solver.cpp:259]     Train net output #0: center_loss = 75.7309 (* 0.008 = 0.605847 loss)
I0826 15:55:03.240886 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08118 (* 1 = 8.08118 loss)
I0826 15:55:03.240891 25446 sgd_solver.cpp:138] Iteration 8150, lr = 0.001
I0826 15:55:05.298806 25446 solver.cpp:243] Iteration 8160, loss = 8.63592
I0826 15:55:05.298938 25446 solver.cpp:259]     Train net output #0: center_loss = 50.4541 (* 0.008 = 0.403633 loss)
I0826 15:55:05.298944 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.23229 (* 1 = 8.23229 loss)
I0826 15:55:05.298961 25446 sgd_solver.cpp:138] Iteration 8160, lr = 0.001
I0826 15:55:07.360543 25446 solver.cpp:243] Iteration 8170, loss = 8.46941
I0826 15:55:07.360581 25446 solver.cpp:259]     Train net output #0: center_loss = 51.2026 (* 0.008 = 0.409621 loss)
I0826 15:55:07.360587 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.05979 (* 1 = 8.05979 loss)
I0826 15:55:07.360591 25446 sgd_solver.cpp:138] Iteration 8170, lr = 0.001
I0826 15:55:09.420891 25446 solver.cpp:243] Iteration 8180, loss = 8.54889
I0826 15:55:09.420929 25446 solver.cpp:259]     Train net output #0: center_loss = 72.6552 (* 0.008 = 0.581241 loss)
I0826 15:55:09.420935 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.96765 (* 1 = 7.96765 loss)
I0826 15:55:09.420938 25446 sgd_solver.cpp:138] Iteration 8180, lr = 0.001
I0826 15:55:11.479912 25446 solver.cpp:243] Iteration 8190, loss = 8.81738
I0826 15:55:11.479951 25446 solver.cpp:259]     Train net output #0: center_loss = 62.1524 (* 0.008 = 0.497219 loss)
I0826 15:55:11.479956 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.32016 (* 1 = 8.32016 loss)
I0826 15:55:11.479960 25446 sgd_solver.cpp:138] Iteration 8190, lr = 0.001
I0826 15:55:13.534345 25446 solver.cpp:243] Iteration 8200, loss = 8.86523
I0826 15:55:13.534384 25446 solver.cpp:259]     Train net output #0: center_loss = 55.0795 (* 0.008 = 0.440636 loss)
I0826 15:55:13.534389 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.4246 (* 1 = 8.4246 loss)
I0826 15:55:13.534392 25446 sgd_solver.cpp:138] Iteration 8200, lr = 0.001
I0826 15:55:15.592643 25446 solver.cpp:243] Iteration 8210, loss = 8.66664
I0826 15:55:15.592681 25446 solver.cpp:259]     Train net output #0: center_loss = 74.035 (* 0.008 = 0.59228 loss)
I0826 15:55:15.592687 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.07436 (* 1 = 8.07436 loss)
I0826 15:55:15.592690 25446 sgd_solver.cpp:138] Iteration 8210, lr = 0.001
I0826 15:55:17.649003 25446 solver.cpp:243] Iteration 8220, loss = 8.41824
I0826 15:55:17.649041 25446 solver.cpp:259]     Train net output #0: center_loss = 63.4452 (* 0.008 = 0.507562 loss)
I0826 15:55:17.649046 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91068 (* 1 = 7.91068 loss)
I0826 15:55:17.649049 25446 sgd_solver.cpp:138] Iteration 8220, lr = 0.001
I0826 15:55:19.706642 25446 solver.cpp:243] Iteration 8230, loss = 8.81889
I0826 15:55:19.706681 25446 solver.cpp:259]     Train net output #0: center_loss = 54.4551 (* 0.008 = 0.435641 loss)
I0826 15:55:19.706686 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.38325 (* 1 = 8.38325 loss)
I0826 15:55:19.706689 25446 sgd_solver.cpp:138] Iteration 8230, lr = 0.001
I0826 15:55:21.767374 25446 solver.cpp:243] Iteration 8240, loss = 8.69459
I0826 15:55:21.767412 25446 solver.cpp:259]     Train net output #0: center_loss = 76.9592 (* 0.008 = 0.615674 loss)
I0826 15:55:21.767418 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.07891 (* 1 = 8.07891 loss)
I0826 15:55:21.767421 25446 sgd_solver.cpp:138] Iteration 8240, lr = 0.001
I0826 15:55:23.831393 25446 solver.cpp:243] Iteration 8250, loss = 8.51475
I0826 15:55:23.831429 25446 solver.cpp:259]     Train net output #0: center_loss = 59.0579 (* 0.008 = 0.472463 loss)
I0826 15:55:23.831435 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.04228 (* 1 = 8.04228 loss)
I0826 15:55:23.831439 25446 sgd_solver.cpp:138] Iteration 8250, lr = 0.001
I0826 15:55:25.890823 25446 solver.cpp:243] Iteration 8260, loss = 8.74104
I0826 15:55:25.890861 25446 solver.cpp:259]     Train net output #0: center_loss = 67.575 (* 0.008 = 0.5406 loss)
I0826 15:55:25.890867 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.20044 (* 1 = 8.20044 loss)
I0826 15:55:25.890871 25446 sgd_solver.cpp:138] Iteration 8260, lr = 0.001
I0826 15:55:27.948786 25446 solver.cpp:243] Iteration 8270, loss = 8.44465
I0826 15:55:27.948823 25446 solver.cpp:259]     Train net output #0: center_loss = 66.8093 (* 0.008 = 0.534475 loss)
I0826 15:55:27.948829 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91018 (* 1 = 7.91018 loss)
I0826 15:55:27.948832 25446 sgd_solver.cpp:138] Iteration 8270, lr = 0.001
I0826 15:55:30.006412 25446 solver.cpp:243] Iteration 8280, loss = 7.88987
I0826 15:55:30.006449 25446 solver.cpp:259]     Train net output #0: center_loss = 77.5515 (* 0.008 = 0.620412 loss)
I0826 15:55:30.006455 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.26945 (* 1 = 7.26945 loss)
I0826 15:55:30.006458 25446 sgd_solver.cpp:138] Iteration 8280, lr = 0.001
I0826 15:55:32.065428 25446 solver.cpp:243] Iteration 8290, loss = 8.26762
I0826 15:55:32.065465 25446 solver.cpp:259]     Train net output #0: center_loss = 65.0108 (* 0.008 = 0.520086 loss)
I0826 15:55:32.065470 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.74753 (* 1 = 7.74753 loss)
I0826 15:55:32.065474 25446 sgd_solver.cpp:138] Iteration 8290, lr = 0.001
I0826 15:55:34.122078 25446 solver.cpp:243] Iteration 8300, loss = 8.55696
I0826 15:55:34.122130 25446 solver.cpp:259]     Train net output #0: center_loss = 54.4843 (* 0.008 = 0.435874 loss)
I0826 15:55:34.122136 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.12109 (* 1 = 8.12109 loss)
I0826 15:55:34.122140 25446 sgd_solver.cpp:138] Iteration 8300, lr = 0.001
I0826 15:55:36.181892 25446 solver.cpp:243] Iteration 8310, loss = 8.12439
I0826 15:55:36.182024 25446 solver.cpp:259]     Train net output #0: center_loss = 56.0486 (* 0.008 = 0.448389 loss)
I0826 15:55:36.182030 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.676 (* 1 = 7.676 loss)
I0826 15:55:36.182046 25446 sgd_solver.cpp:138] Iteration 8310, lr = 0.001
I0826 15:55:38.239413 25446 solver.cpp:243] Iteration 8320, loss = 8.22363
I0826 15:55:38.239450 25446 solver.cpp:259]     Train net output #0: center_loss = 74.4561 (* 0.008 = 0.595648 loss)
I0826 15:55:38.239456 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.62799 (* 1 = 7.62799 loss)
I0826 15:55:38.239459 25446 sgd_solver.cpp:138] Iteration 8320, lr = 0.001
I0826 15:55:40.296655 25446 solver.cpp:243] Iteration 8330, loss = 8.81521
I0826 15:55:40.296692 25446 solver.cpp:259]     Train net output #0: center_loss = 55.304 (* 0.008 = 0.442432 loss)
I0826 15:55:40.296699 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.37278 (* 1 = 8.37278 loss)
I0826 15:55:40.296701 25446 sgd_solver.cpp:138] Iteration 8330, lr = 0.001
I0826 15:55:42.355610 25446 solver.cpp:243] Iteration 8340, loss = 8.75688
I0826 15:55:42.355648 25446 solver.cpp:259]     Train net output #0: center_loss = 37.1245 (* 0.008 = 0.296996 loss)
I0826 15:55:42.355654 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.45988 (* 1 = 8.45988 loss)
I0826 15:55:42.355657 25446 sgd_solver.cpp:138] Iteration 8340, lr = 0.001
I0826 15:55:44.412668 25446 solver.cpp:243] Iteration 8350, loss = 8.88035
I0826 15:55:44.412705 25446 solver.cpp:259]     Train net output #0: center_loss = 67.991 (* 0.008 = 0.543928 loss)
I0826 15:55:44.412711 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.33642 (* 1 = 8.33642 loss)
I0826 15:55:44.412715 25446 sgd_solver.cpp:138] Iteration 8350, lr = 0.001
I0826 15:55:46.471881 25446 solver.cpp:243] Iteration 8360, loss = 8.59206
I0826 15:55:46.471918 25446 solver.cpp:259]     Train net output #0: center_loss = 57.757 (* 0.008 = 0.462056 loss)
I0826 15:55:46.471925 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.13 (* 1 = 8.13 loss)
I0826 15:55:46.471927 25446 sgd_solver.cpp:138] Iteration 8360, lr = 0.001
I0826 15:55:48.528869 25446 solver.cpp:243] Iteration 8370, loss = 8.96598
I0826 15:55:48.528908 25446 solver.cpp:259]     Train net output #0: center_loss = 46.8428 (* 0.008 = 0.374743 loss)
I0826 15:55:48.528913 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.59124 (* 1 = 8.59124 loss)
I0826 15:55:48.528916 25446 sgd_solver.cpp:138] Iteration 8370, lr = 0.001
I0826 15:55:50.585870 25446 solver.cpp:243] Iteration 8380, loss = 8.73348
I0826 15:55:50.585907 25446 solver.cpp:259]     Train net output #0: center_loss = 55.9999 (* 0.008 = 0.447999 loss)
I0826 15:55:50.585912 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.28548 (* 1 = 8.28548 loss)
I0826 15:55:50.585916 25446 sgd_solver.cpp:138] Iteration 8380, lr = 0.001
I0826 15:55:52.644049 25446 solver.cpp:243] Iteration 8390, loss = 8.47218
I0826 15:55:52.644088 25446 solver.cpp:259]     Train net output #0: center_loss = 48.005 (* 0.008 = 0.38404 loss)
I0826 15:55:52.644094 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08814 (* 1 = 8.08814 loss)
I0826 15:55:52.644098 25446 sgd_solver.cpp:138] Iteration 8390, lr = 0.001
I0826 15:55:54.698066 25446 solver.cpp:243] Iteration 8400, loss = 8.29579
I0826 15:55:54.698105 25446 solver.cpp:259]     Train net output #0: center_loss = 64.3809 (* 0.008 = 0.515047 loss)
I0826 15:55:54.698112 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.78075 (* 1 = 7.78075 loss)
I0826 15:55:54.698115 25446 sgd_solver.cpp:138] Iteration 8400, lr = 0.001
I0826 15:55:56.756070 25446 solver.cpp:243] Iteration 8410, loss = 9.00009
I0826 15:55:56.756108 25446 solver.cpp:259]     Train net output #0: center_loss = 52.0116 (* 0.008 = 0.416093 loss)
I0826 15:55:56.756114 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.58399 (* 1 = 8.58399 loss)
I0826 15:55:56.756117 25446 sgd_solver.cpp:138] Iteration 8410, lr = 0.001
I0826 15:55:58.813644 25446 solver.cpp:243] Iteration 8420, loss = 8.37357
I0826 15:55:58.813704 25446 solver.cpp:259]     Train net output #0: center_loss = 55.9551 (* 0.008 = 0.447641 loss)
I0826 15:55:58.813710 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.92593 (* 1 = 7.92593 loss)
I0826 15:55:58.813714 25446 sgd_solver.cpp:138] Iteration 8420, lr = 0.001
I0826 15:56:00.873073 25446 solver.cpp:243] Iteration 8430, loss = 8.43613
I0826 15:56:00.873111 25446 solver.cpp:259]     Train net output #0: center_loss = 46.4039 (* 0.008 = 0.371231 loss)
I0826 15:56:00.873116 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.0649 (* 1 = 8.0649 loss)
I0826 15:56:00.873119 25446 sgd_solver.cpp:138] Iteration 8430, lr = 0.001
I0826 15:56:02.931890 25446 solver.cpp:243] Iteration 8440, loss = 8.37562
I0826 15:56:02.931929 25446 solver.cpp:259]     Train net output #0: center_loss = 73.4944 (* 0.008 = 0.587955 loss)
I0826 15:56:02.931936 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.78767 (* 1 = 7.78767 loss)
I0826 15:56:02.931938 25446 sgd_solver.cpp:138] Iteration 8440, lr = 0.001
I0826 15:56:04.986889 25446 solver.cpp:243] Iteration 8450, loss = 9.05301
I0826 15:56:04.986925 25446 solver.cpp:259]     Train net output #0: center_loss = 52.2303 (* 0.008 = 0.417842 loss)
I0826 15:56:04.986932 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.63517 (* 1 = 8.63517 loss)
I0826 15:56:04.986934 25446 sgd_solver.cpp:138] Iteration 8450, lr = 0.001
I0826 15:56:07.045857 25446 solver.cpp:243] Iteration 8460, loss = 8.69468
I0826 15:56:07.045981 25446 solver.cpp:259]     Train net output #0: center_loss = 61.3868 (* 0.008 = 0.491094 loss)
I0826 15:56:07.045989 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.20359 (* 1 = 8.20359 loss)
I0826 15:56:07.046007 25446 sgd_solver.cpp:138] Iteration 8460, lr = 0.001
I0826 15:56:09.107616 25446 solver.cpp:243] Iteration 8470, loss = 8.8067
I0826 15:56:09.107653 25446 solver.cpp:259]     Train net output #0: center_loss = 75.251 (* 0.008 = 0.602008 loss)
I0826 15:56:09.107661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.20469 (* 1 = 8.20469 loss)
I0826 15:56:09.107663 25446 sgd_solver.cpp:138] Iteration 8470, lr = 0.001
I0826 15:56:11.162194 25446 solver.cpp:243] Iteration 8480, loss = 8.53179
I0826 15:56:11.162231 25446 solver.cpp:259]     Train net output #0: center_loss = 63.2948 (* 0.008 = 0.506358 loss)
I0826 15:56:11.162237 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.02543 (* 1 = 8.02543 loss)
I0826 15:56:11.162240 25446 sgd_solver.cpp:138] Iteration 8480, lr = 0.001
I0826 15:56:13.220084 25446 solver.cpp:243] Iteration 8490, loss = 8.78018
I0826 15:56:13.220121 25446 solver.cpp:259]     Train net output #0: center_loss = 61.472 (* 0.008 = 0.491776 loss)
I0826 15:56:13.220127 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.2884 (* 1 = 8.2884 loss)
I0826 15:56:13.220130 25446 sgd_solver.cpp:138] Iteration 8490, lr = 0.001
I0826 15:56:15.277714 25446 solver.cpp:243] Iteration 8500, loss = 8.56696
I0826 15:56:15.277750 25446 solver.cpp:259]     Train net output #0: center_loss = 49.0504 (* 0.008 = 0.392404 loss)
I0826 15:56:15.277756 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.17455 (* 1 = 8.17455 loss)
I0826 15:56:15.277760 25446 sgd_solver.cpp:138] Iteration 8500, lr = 0.001
I0826 15:56:17.335513 25446 solver.cpp:243] Iteration 8510, loss = 8.47618
I0826 15:56:17.335551 25446 solver.cpp:259]     Train net output #0: center_loss = 72.3796 (* 0.008 = 0.579037 loss)
I0826 15:56:17.335557 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.89714 (* 1 = 7.89714 loss)
I0826 15:56:17.335561 25446 sgd_solver.cpp:138] Iteration 8510, lr = 0.001
I0826 15:56:19.395128 25446 solver.cpp:243] Iteration 8520, loss = 8.88333
I0826 15:56:19.395165 25446 solver.cpp:259]     Train net output #0: center_loss = 53.7748 (* 0.008 = 0.430199 loss)
I0826 15:56:19.395171 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.45313 (* 1 = 8.45313 loss)
I0826 15:56:19.395175 25446 sgd_solver.cpp:138] Iteration 8520, lr = 0.001
I0826 15:56:21.450887 25446 solver.cpp:243] Iteration 8530, loss = 8.49415
I0826 15:56:21.450927 25446 solver.cpp:259]     Train net output #0: center_loss = 62.9874 (* 0.008 = 0.503899 loss)
I0826 15:56:21.450932 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.99025 (* 1 = 7.99025 loss)
I0826 15:56:21.450935 25446 sgd_solver.cpp:138] Iteration 8530, lr = 0.001
I0826 15:56:23.510936 25446 solver.cpp:243] Iteration 8540, loss = 8.40833
I0826 15:56:23.510973 25446 solver.cpp:259]     Train net output #0: center_loss = 46.5349 (* 0.008 = 0.372279 loss)
I0826 15:56:23.510980 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.03605 (* 1 = 8.03605 loss)
I0826 15:56:23.510983 25446 sgd_solver.cpp:138] Iteration 8540, lr = 0.001
I0826 15:56:25.570158 25446 solver.cpp:243] Iteration 8550, loss = 8.70795
I0826 15:56:25.570196 25446 solver.cpp:259]     Train net output #0: center_loss = 59.4093 (* 0.008 = 0.475275 loss)
I0826 15:56:25.570204 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.23267 (* 1 = 8.23267 loss)
I0826 15:56:25.570206 25446 sgd_solver.cpp:138] Iteration 8550, lr = 0.001
I0826 15:56:27.626369 25446 solver.cpp:243] Iteration 8560, loss = 8.44583
I0826 15:56:27.626407 25446 solver.cpp:259]     Train net output #0: center_loss = 74.3399 (* 0.008 = 0.594719 loss)
I0826 15:56:27.626413 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.85111 (* 1 = 7.85111 loss)
I0826 15:56:27.626417 25446 sgd_solver.cpp:138] Iteration 8560, lr = 0.001
I0826 15:56:29.679729 25446 solver.cpp:243] Iteration 8570, loss = 8.80696
I0826 15:56:29.679767 25446 solver.cpp:259]     Train net output #0: center_loss = 71.3283 (* 0.008 = 0.570626 loss)
I0826 15:56:29.679774 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.23634 (* 1 = 8.23634 loss)
I0826 15:56:29.679777 25446 sgd_solver.cpp:138] Iteration 8570, lr = 0.001
I0826 15:56:31.738306 25446 solver.cpp:243] Iteration 8580, loss = 8.55239
I0826 15:56:31.738344 25446 solver.cpp:259]     Train net output #0: center_loss = 61.2889 (* 0.008 = 0.490311 loss)
I0826 15:56:31.738349 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.06207 (* 1 = 8.06207 loss)
I0826 15:56:31.738353 25446 sgd_solver.cpp:138] Iteration 8580, lr = 0.001
I0826 15:56:33.796180 25446 solver.cpp:243] Iteration 8590, loss = 8.47447
I0826 15:56:33.796217 25446 solver.cpp:259]     Train net output #0: center_loss = 75.4301 (* 0.008 = 0.603441 loss)
I0826 15:56:33.796223 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.87103 (* 1 = 7.87103 loss)
I0826 15:56:33.796226 25446 sgd_solver.cpp:138] Iteration 8590, lr = 0.001
I0826 15:56:35.853327 25446 solver.cpp:243] Iteration 8600, loss = 8.28027
I0826 15:56:35.853364 25446 solver.cpp:259]     Train net output #0: center_loss = 53.8283 (* 0.008 = 0.430627 loss)
I0826 15:56:35.853370 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.84965 (* 1 = 7.84965 loss)
I0826 15:56:35.853374 25446 sgd_solver.cpp:138] Iteration 8600, lr = 0.001
I0826 15:56:37.912845 25446 solver.cpp:243] Iteration 8610, loss = 8.61844
I0826 15:56:37.912968 25446 solver.cpp:259]     Train net output #0: center_loss = 87.3519 (* 0.008 = 0.698816 loss)
I0826 15:56:37.912976 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91963 (* 1 = 7.91963 loss)
I0826 15:56:37.912979 25446 sgd_solver.cpp:138] Iteration 8610, lr = 0.001
I0826 15:56:39.972785 25446 solver.cpp:243] Iteration 8620, loss = 8.87194
I0826 15:56:39.972823 25446 solver.cpp:259]     Train net output #0: center_loss = 83.1507 (* 0.008 = 0.665205 loss)
I0826 15:56:39.972829 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.20674 (* 1 = 8.20674 loss)
I0826 15:56:39.972832 25446 sgd_solver.cpp:138] Iteration 8620, lr = 0.001
I0826 15:56:42.035276 25446 solver.cpp:243] Iteration 8630, loss = 8.75988
I0826 15:56:42.035315 25446 solver.cpp:259]     Train net output #0: center_loss = 53.0928 (* 0.008 = 0.424743 loss)
I0826 15:56:42.035320 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.33513 (* 1 = 8.33513 loss)
I0826 15:56:42.035323 25446 sgd_solver.cpp:138] Iteration 8630, lr = 0.001
I0826 15:56:44.091631 25446 solver.cpp:243] Iteration 8640, loss = 8.55726
I0826 15:56:44.091670 25446 solver.cpp:259]     Train net output #0: center_loss = 50.8455 (* 0.008 = 0.406764 loss)
I0826 15:56:44.091675 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.15049 (* 1 = 8.15049 loss)
I0826 15:56:44.091678 25446 sgd_solver.cpp:138] Iteration 8640, lr = 0.001
I0826 15:56:46.150046 25446 solver.cpp:243] Iteration 8650, loss = 8.56626
I0826 15:56:46.150084 25446 solver.cpp:259]     Train net output #0: center_loss = 58.6169 (* 0.008 = 0.468935 loss)
I0826 15:56:46.150089 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.09732 (* 1 = 8.09732 loss)
I0826 15:56:46.150094 25446 sgd_solver.cpp:138] Iteration 8650, lr = 0.001
I0826 15:56:48.211043 25446 solver.cpp:243] Iteration 8660, loss = 8.79515
I0826 15:56:48.211079 25446 solver.cpp:259]     Train net output #0: center_loss = 60.8189 (* 0.008 = 0.486552 loss)
I0826 15:56:48.211086 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.3086 (* 1 = 8.3086 loss)
I0826 15:56:48.211088 25446 sgd_solver.cpp:138] Iteration 8660, lr = 0.001
I0826 15:56:50.260759 25446 solver.cpp:243] Iteration 8670, loss = 8.45572
I0826 15:56:50.260797 25446 solver.cpp:259]     Train net output #0: center_loss = 60.2941 (* 0.008 = 0.482353 loss)
I0826 15:56:50.260802 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.97337 (* 1 = 7.97337 loss)
I0826 15:56:50.260807 25446 sgd_solver.cpp:138] Iteration 8670, lr = 0.001
I0826 15:56:52.316311 25446 solver.cpp:243] Iteration 8680, loss = 8.4907
I0826 15:56:52.316349 25446 solver.cpp:259]     Train net output #0: center_loss = 61.5767 (* 0.008 = 0.492613 loss)
I0826 15:56:52.316354 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.99809 (* 1 = 7.99809 loss)
I0826 15:56:52.316359 25446 sgd_solver.cpp:138] Iteration 8680, lr = 0.001
I0826 15:56:54.375697 25446 solver.cpp:243] Iteration 8690, loss = 8.60091
I0826 15:56:54.375736 25446 solver.cpp:259]     Train net output #0: center_loss = 63.9337 (* 0.008 = 0.51147 loss)
I0826 15:56:54.375743 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08944 (* 1 = 8.08944 loss)
I0826 15:56:54.375746 25446 sgd_solver.cpp:138] Iteration 8690, lr = 0.001
I0826 15:56:56.435178 25446 solver.cpp:243] Iteration 8700, loss = 8.9022
I0826 15:56:56.435215 25446 solver.cpp:259]     Train net output #0: center_loss = 53.3237 (* 0.008 = 0.42659 loss)
I0826 15:56:56.435221 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.47561 (* 1 = 8.47561 loss)
I0826 15:56:56.435225 25446 sgd_solver.cpp:138] Iteration 8700, lr = 0.001
I0826 15:56:58.491698 25446 solver.cpp:243] Iteration 8710, loss = 8.40186
I0826 15:56:58.491721 25446 solver.cpp:259]     Train net output #0: center_loss = 77.0765 (* 0.008 = 0.616612 loss)
I0826 15:56:58.491742 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.78525 (* 1 = 7.78525 loss)
I0826 15:56:58.491746 25446 sgd_solver.cpp:138] Iteration 8710, lr = 0.001
I0826 15:57:00.553812 25446 solver.cpp:243] Iteration 8720, loss = 8.59126
I0826 15:57:00.553851 25446 solver.cpp:259]     Train net output #0: center_loss = 64.3077 (* 0.008 = 0.514461 loss)
I0826 15:57:00.553856 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.0768 (* 1 = 8.0768 loss)
I0826 15:57:00.553860 25446 sgd_solver.cpp:138] Iteration 8720, lr = 0.001
I0826 15:57:02.609918 25446 solver.cpp:243] Iteration 8730, loss = 8.09177
I0826 15:57:02.609956 25446 solver.cpp:259]     Train net output #0: center_loss = 87.1163 (* 0.008 = 0.696931 loss)
I0826 15:57:02.609962 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.39483 (* 1 = 7.39483 loss)
I0826 15:57:02.609966 25446 sgd_solver.cpp:138] Iteration 8730, lr = 0.001
I0826 15:57:04.671123 25446 solver.cpp:243] Iteration 8740, loss = 8.53785
I0826 15:57:04.671160 25446 solver.cpp:259]     Train net output #0: center_loss = 56.5104 (* 0.008 = 0.452083 loss)
I0826 15:57:04.671166 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08577 (* 1 = 8.08577 loss)
I0826 15:57:04.671169 25446 sgd_solver.cpp:138] Iteration 8740, lr = 0.001
I0826 15:57:06.729497 25446 solver.cpp:243] Iteration 8750, loss = 8.19049
I0826 15:57:06.729535 25446 solver.cpp:259]     Train net output #0: center_loss = 80.4011 (* 0.008 = 0.643209 loss)
I0826 15:57:06.729542 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.54728 (* 1 = 7.54728 loss)
I0826 15:57:06.729544 25446 sgd_solver.cpp:138] Iteration 8750, lr = 0.001
I0826 15:57:08.783752 25446 solver.cpp:243] Iteration 8760, loss = 8.56404
I0826 15:57:08.783883 25446 solver.cpp:259]     Train net output #0: center_loss = 57.5299 (* 0.008 = 0.460239 loss)
I0826 15:57:08.783902 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.1038 (* 1 = 8.1038 loss)
I0826 15:57:08.783906 25446 sgd_solver.cpp:138] Iteration 8760, lr = 0.001
I0826 15:57:10.845579 25446 solver.cpp:243] Iteration 8770, loss = 8.39036
I0826 15:57:10.845618 25446 solver.cpp:259]     Train net output #0: center_loss = 66.8053 (* 0.008 = 0.534443 loss)
I0826 15:57:10.845623 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.85592 (* 1 = 7.85592 loss)
I0826 15:57:10.845626 25446 sgd_solver.cpp:138] Iteration 8770, lr = 0.001
I0826 15:57:12.905453 25446 solver.cpp:243] Iteration 8780, loss = 8.77801
I0826 15:57:12.905490 25446 solver.cpp:259]     Train net output #0: center_loss = 49.2946 (* 0.008 = 0.394357 loss)
I0826 15:57:12.905496 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.38366 (* 1 = 8.38366 loss)
I0826 15:57:12.905499 25446 sgd_solver.cpp:138] Iteration 8780, lr = 0.001
I0826 15:57:14.963565 25446 solver.cpp:243] Iteration 8790, loss = 8.4549
I0826 15:57:14.963603 25446 solver.cpp:259]     Train net output #0: center_loss = 58.5252 (* 0.008 = 0.468202 loss)
I0826 15:57:14.963609 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.98669 (* 1 = 7.98669 loss)
I0826 15:57:14.963613 25446 sgd_solver.cpp:138] Iteration 8790, lr = 0.001
I0826 15:57:17.022204 25446 solver.cpp:243] Iteration 8800, loss = 8.55793
I0826 15:57:17.022241 25446 solver.cpp:259]     Train net output #0: center_loss = 86.4808 (* 0.008 = 0.691846 loss)
I0826 15:57:17.022246 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.86608 (* 1 = 7.86608 loss)
I0826 15:57:17.022250 25446 sgd_solver.cpp:138] Iteration 8800, lr = 0.001
I0826 15:57:19.080449 25446 solver.cpp:243] Iteration 8810, loss = 8.54497
I0826 15:57:19.080487 25446 solver.cpp:259]     Train net output #0: center_loss = 48.4282 (* 0.008 = 0.387426 loss)
I0826 15:57:19.080492 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.15755 (* 1 = 8.15755 loss)
I0826 15:57:19.080497 25446 sgd_solver.cpp:138] Iteration 8810, lr = 0.001
I0826 15:57:21.141389 25446 solver.cpp:243] Iteration 8820, loss = 8.17079
I0826 15:57:21.141425 25446 solver.cpp:259]     Train net output #0: center_loss = 81.5605 (* 0.008 = 0.652484 loss)
I0826 15:57:21.141432 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.51831 (* 1 = 7.51831 loss)
I0826 15:57:21.141434 25446 sgd_solver.cpp:138] Iteration 8820, lr = 0.001
I0826 15:57:23.198987 25446 solver.cpp:243] Iteration 8830, loss = 8.70941
I0826 15:57:23.199025 25446 solver.cpp:259]     Train net output #0: center_loss = 62.1494 (* 0.008 = 0.497196 loss)
I0826 15:57:23.199031 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.21221 (* 1 = 8.21221 loss)
I0826 15:57:23.199035 25446 sgd_solver.cpp:138] Iteration 8830, lr = 0.001
I0826 15:57:25.256736 25446 solver.cpp:243] Iteration 8840, loss = 8.86532
I0826 15:57:25.256773 25446 solver.cpp:259]     Train net output #0: center_loss = 65.9449 (* 0.008 = 0.527559 loss)
I0826 15:57:25.256779 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.33776 (* 1 = 8.33776 loss)
I0826 15:57:25.256783 25446 sgd_solver.cpp:138] Iteration 8840, lr = 0.001
I0826 15:57:27.315975 25446 solver.cpp:243] Iteration 8850, loss = 8.89253
I0826 15:57:27.316013 25446 solver.cpp:259]     Train net output #0: center_loss = 81.7809 (* 0.008 = 0.654247 loss)
I0826 15:57:27.316020 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.23828 (* 1 = 8.23828 loss)
I0826 15:57:27.316022 25446 sgd_solver.cpp:138] Iteration 8850, lr = 0.001
I0826 15:57:29.378511 25446 solver.cpp:243] Iteration 8860, loss = 8.39113
I0826 15:57:29.378548 25446 solver.cpp:259]     Train net output #0: center_loss = 67.3999 (* 0.008 = 0.539199 loss)
I0826 15:57:29.378554 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.85193 (* 1 = 7.85193 loss)
I0826 15:57:29.378557 25446 sgd_solver.cpp:138] Iteration 8860, lr = 0.001
I0826 15:57:31.437001 25446 solver.cpp:243] Iteration 8870, loss = 8.95582
I0826 15:57:31.437039 25446 solver.cpp:259]     Train net output #0: center_loss = 49.0016 (* 0.008 = 0.392013 loss)
I0826 15:57:31.437045 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.56381 (* 1 = 8.56381 loss)
I0826 15:57:31.437048 25446 sgd_solver.cpp:138] Iteration 8870, lr = 0.001
I0826 15:57:33.492995 25446 solver.cpp:243] Iteration 8880, loss = 8.51515
I0826 15:57:33.493033 25446 solver.cpp:259]     Train net output #0: center_loss = 66.4531 (* 0.008 = 0.531624 loss)
I0826 15:57:33.493039 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.98353 (* 1 = 7.98353 loss)
I0826 15:57:33.493042 25446 sgd_solver.cpp:138] Iteration 8880, lr = 0.001
I0826 15:57:35.551415 25446 solver.cpp:243] Iteration 8890, loss = 8.27724
I0826 15:57:35.551455 25446 solver.cpp:259]     Train net output #0: center_loss = 80.254 (* 0.008 = 0.642032 loss)
I0826 15:57:35.551460 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.63521 (* 1 = 7.63521 loss)
I0826 15:57:35.551462 25446 sgd_solver.cpp:138] Iteration 8890, lr = 0.001
I0826 15:57:37.608258 25446 solver.cpp:243] Iteration 8900, loss = 8.19667
I0826 15:57:37.608299 25446 solver.cpp:259]     Train net output #0: center_loss = 72.6291 (* 0.008 = 0.581033 loss)
I0826 15:57:37.608304 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.61563 (* 1 = 7.61563 loss)
I0826 15:57:37.608309 25446 sgd_solver.cpp:138] Iteration 8900, lr = 0.001
I0826 15:57:39.665830 25446 solver.cpp:243] Iteration 8910, loss = 9.06037
I0826 15:57:39.665969 25446 solver.cpp:259]     Train net output #0: center_loss = 62.2821 (* 0.008 = 0.498257 loss)
I0826 15:57:39.665990 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.56212 (* 1 = 8.56212 loss)
I0826 15:57:39.665993 25446 sgd_solver.cpp:138] Iteration 8910, lr = 0.001
I0826 15:57:41.724438 25446 solver.cpp:243] Iteration 8920, loss = 8.37531
I0826 15:57:41.724478 25446 solver.cpp:259]     Train net output #0: center_loss = 62.2347 (* 0.008 = 0.497878 loss)
I0826 15:57:41.724483 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.87743 (* 1 = 7.87743 loss)
I0826 15:57:41.724485 25446 sgd_solver.cpp:138] Iteration 8920, lr = 0.001
I0826 15:57:43.787825 25446 solver.cpp:243] Iteration 8930, loss = 8.54578
I0826 15:57:43.787863 25446 solver.cpp:259]     Train net output #0: center_loss = 70.9431 (* 0.008 = 0.567545 loss)
I0826 15:57:43.787868 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.97824 (* 1 = 7.97824 loss)
I0826 15:57:43.787873 25446 sgd_solver.cpp:138] Iteration 8930, lr = 0.001
I0826 15:57:45.838275 25446 solver.cpp:243] Iteration 8940, loss = 8.56961
I0826 15:57:45.838313 25446 solver.cpp:259]     Train net output #0: center_loss = 83.4836 (* 0.008 = 0.667869 loss)
I0826 15:57:45.838320 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.90174 (* 1 = 7.90174 loss)
I0826 15:57:45.838323 25446 sgd_solver.cpp:138] Iteration 8940, lr = 0.001
I0826 15:57:47.895934 25446 solver.cpp:243] Iteration 8950, loss = 8.62757
I0826 15:57:47.895972 25446 solver.cpp:259]     Train net output #0: center_loss = 70.1645 (* 0.008 = 0.561316 loss)
I0826 15:57:47.895978 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.06625 (* 1 = 8.06625 loss)
I0826 15:57:47.895982 25446 sgd_solver.cpp:138] Iteration 8950, lr = 0.001
I0826 15:57:49.955394 25446 solver.cpp:243] Iteration 8960, loss = 8.33728
I0826 15:57:49.955436 25446 solver.cpp:259]     Train net output #0: center_loss = 59.5682 (* 0.008 = 0.476546 loss)
I0826 15:57:49.955441 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.86074 (* 1 = 7.86074 loss)
I0826 15:57:49.955446 25446 sgd_solver.cpp:138] Iteration 8960, lr = 0.001
I0826 15:57:52.013698 25446 solver.cpp:243] Iteration 8970, loss = 8.45042
I0826 15:57:52.013736 25446 solver.cpp:259]     Train net output #0: center_loss = 65.3559 (* 0.008 = 0.522847 loss)
I0826 15:57:52.013742 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.92757 (* 1 = 7.92757 loss)
I0826 15:57:52.013746 25446 sgd_solver.cpp:138] Iteration 8970, lr = 0.001
I0826 15:57:54.069416 25446 solver.cpp:243] Iteration 8980, loss = 8.40977
I0826 15:57:54.069453 25446 solver.cpp:259]     Train net output #0: center_loss = 74.4602 (* 0.008 = 0.595682 loss)
I0826 15:57:54.069459 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.81409 (* 1 = 7.81409 loss)
I0826 15:57:54.069463 25446 sgd_solver.cpp:138] Iteration 8980, lr = 0.001
I0826 15:57:56.131214 25446 solver.cpp:243] Iteration 8990, loss = 8.78386
I0826 15:57:56.131251 25446 solver.cpp:259]     Train net output #0: center_loss = 62.9828 (* 0.008 = 0.503863 loss)
I0826 15:57:56.131258 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.28 (* 1 = 8.28 loss)
I0826 15:57:56.131260 25446 sgd_solver.cpp:138] Iteration 8990, lr = 0.001
I0826 15:57:57.987246 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_9000.caffemodel
I0826 15:57:59.086000 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_9000.solverstate
I0826 15:57:59.411183 25446 solver.cpp:243] Iteration 9000, loss = 8.34902
I0826 15:57:59.411224 25446 solver.cpp:259]     Train net output #0: center_loss = 68.5128 (* 0.008 = 0.548102 loss)
I0826 15:57:59.411231 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.80092 (* 1 = 7.80092 loss)
I0826 15:57:59.411236 25446 sgd_solver.cpp:138] Iteration 9000, lr = 0.001
I0826 15:58:01.470171 25446 solver.cpp:243] Iteration 9010, loss = 8.20097
I0826 15:58:01.470211 25446 solver.cpp:259]     Train net output #0: center_loss = 71.5473 (* 0.008 = 0.572378 loss)
I0826 15:58:01.470255 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.62859 (* 1 = 7.62859 loss)
I0826 15:58:01.470265 25446 sgd_solver.cpp:138] Iteration 9010, lr = 0.001
I0826 15:58:03.524991 25446 solver.cpp:243] Iteration 9020, loss = 8.63965
I0826 15:58:03.525028 25446 solver.cpp:259]     Train net output #0: center_loss = 59.4717 (* 0.008 = 0.475774 loss)
I0826 15:58:03.525033 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.16388 (* 1 = 8.16388 loss)
I0826 15:58:03.525038 25446 sgd_solver.cpp:138] Iteration 9020, lr = 0.001
I0826 15:58:05.584408 25446 solver.cpp:243] Iteration 9030, loss = 8.40145
I0826 15:58:05.584446 25446 solver.cpp:259]     Train net output #0: center_loss = 72.9639 (* 0.008 = 0.583711 loss)
I0826 15:58:05.584452 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.81774 (* 1 = 7.81774 loss)
I0826 15:58:05.584455 25446 sgd_solver.cpp:138] Iteration 9030, lr = 0.001
I0826 15:58:07.643321 25446 solver.cpp:243] Iteration 9040, loss = 8.71038
I0826 15:58:07.643342 25446 solver.cpp:259]     Train net output #0: center_loss = 77.5951 (* 0.008 = 0.620761 loss)
I0826 15:58:07.643363 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08962 (* 1 = 8.08962 loss)
I0826 15:58:07.643366 25446 sgd_solver.cpp:138] Iteration 9040, lr = 0.001
I0826 15:58:09.697314 25446 solver.cpp:243] Iteration 9050, loss = 8.53736
I0826 15:58:09.697427 25446 solver.cpp:259]     Train net output #0: center_loss = 72.4007 (* 0.008 = 0.579206 loss)
I0826 15:58:09.697433 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.95815 (* 1 = 7.95815 loss)
I0826 15:58:09.697438 25446 sgd_solver.cpp:138] Iteration 9050, lr = 0.001
I0826 15:58:11.757932 25446 solver.cpp:243] Iteration 9060, loss = 8.51646
I0826 15:58:11.757968 25446 solver.cpp:259]     Train net output #0: center_loss = 86.8185 (* 0.008 = 0.694548 loss)
I0826 15:58:11.757974 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.82191 (* 1 = 7.82191 loss)
I0826 15:58:11.757977 25446 sgd_solver.cpp:138] Iteration 9060, lr = 0.001
I0826 15:58:13.815949 25446 solver.cpp:243] Iteration 9070, loss = 8.33834
I0826 15:58:13.815986 25446 solver.cpp:259]     Train net output #0: center_loss = 86.4162 (* 0.008 = 0.691329 loss)
I0826 15:58:13.815992 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.64701 (* 1 = 7.64701 loss)
I0826 15:58:13.815996 25446 sgd_solver.cpp:138] Iteration 9070, lr = 0.001
I0826 15:58:15.876067 25446 solver.cpp:243] Iteration 9080, loss = 8.2892
I0826 15:58:15.876103 25446 solver.cpp:259]     Train net output #0: center_loss = 61.9259 (* 0.008 = 0.495407 loss)
I0826 15:58:15.876109 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.79379 (* 1 = 7.79379 loss)
I0826 15:58:15.876113 25446 sgd_solver.cpp:138] Iteration 9080, lr = 0.001
I0826 15:58:17.935247 25446 solver.cpp:243] Iteration 9090, loss = 8.49474
I0826 15:58:17.935283 25446 solver.cpp:259]     Train net output #0: center_loss = 55.8195 (* 0.008 = 0.446556 loss)
I0826 15:58:17.935289 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.04818 (* 1 = 8.04818 loss)
I0826 15:58:17.935292 25446 sgd_solver.cpp:138] Iteration 9090, lr = 0.001
I0826 15:58:19.995376 25446 solver.cpp:243] Iteration 9100, loss = 8.28505
I0826 15:58:19.995414 25446 solver.cpp:259]     Train net output #0: center_loss = 90.7247 (* 0.008 = 0.725797 loss)
I0826 15:58:19.995419 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.55925 (* 1 = 7.55925 loss)
I0826 15:58:19.995422 25446 sgd_solver.cpp:138] Iteration 9100, lr = 0.001
I0826 15:58:22.054356 25446 solver.cpp:243] Iteration 9110, loss = 8.61049
I0826 15:58:22.054394 25446 solver.cpp:259]     Train net output #0: center_loss = 55.7748 (* 0.008 = 0.446198 loss)
I0826 15:58:22.054400 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.16429 (* 1 = 8.16429 loss)
I0826 15:58:22.054404 25446 sgd_solver.cpp:138] Iteration 9110, lr = 0.001
I0826 15:58:24.112905 25446 solver.cpp:243] Iteration 9120, loss = 9.12949
I0826 15:58:24.112941 25446 solver.cpp:259]     Train net output #0: center_loss = 86.2405 (* 0.008 = 0.689924 loss)
I0826 15:58:24.112947 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.43957 (* 1 = 8.43957 loss)
I0826 15:58:24.112951 25446 sgd_solver.cpp:138] Iteration 9120, lr = 0.001
I0826 15:58:26.167958 25446 solver.cpp:243] Iteration 9130, loss = 8.68722
I0826 15:58:26.167979 25446 solver.cpp:259]     Train net output #0: center_loss = 63.7997 (* 0.008 = 0.510398 loss)
I0826 15:58:26.168000 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.17682 (* 1 = 8.17682 loss)
I0826 15:58:26.168004 25446 sgd_solver.cpp:138] Iteration 9130, lr = 0.001
I0826 15:58:28.225731 25446 solver.cpp:243] Iteration 9140, loss = 7.90745
I0826 15:58:28.225769 25446 solver.cpp:259]     Train net output #0: center_loss = 77.1132 (* 0.008 = 0.616905 loss)
I0826 15:58:28.225775 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.29054 (* 1 = 7.29054 loss)
I0826 15:58:28.225778 25446 sgd_solver.cpp:138] Iteration 9140, lr = 0.001
I0826 15:58:30.288139 25446 solver.cpp:243] Iteration 9150, loss = 8.14527
I0826 15:58:30.288179 25446 solver.cpp:259]     Train net output #0: center_loss = 91.2517 (* 0.008 = 0.730014 loss)
I0826 15:58:30.288185 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.41525 (* 1 = 7.41525 loss)
I0826 15:58:30.288189 25446 sgd_solver.cpp:138] Iteration 9150, lr = 0.001
I0826 15:58:32.348253 25446 solver.cpp:243] Iteration 9160, loss = 7.94864
I0826 15:58:32.348291 25446 solver.cpp:259]     Train net output #0: center_loss = 73.2029 (* 0.008 = 0.585624 loss)
I0826 15:58:32.348297 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.36302 (* 1 = 7.36302 loss)
I0826 15:58:32.348300 25446 sgd_solver.cpp:138] Iteration 9160, lr = 0.001
I0826 15:58:34.409435 25446 solver.cpp:243] Iteration 9170, loss = 8.92167
I0826 15:58:34.409473 25446 solver.cpp:259]     Train net output #0: center_loss = 52.9418 (* 0.008 = 0.423535 loss)
I0826 15:58:34.409479 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.49813 (* 1 = 8.49813 loss)
I0826 15:58:34.409482 25446 sgd_solver.cpp:138] Iteration 9170, lr = 0.001
I0826 15:58:36.470204 25446 solver.cpp:243] Iteration 9180, loss = 8.42471
I0826 15:58:36.470242 25446 solver.cpp:259]     Train net output #0: center_loss = 94.0785 (* 0.008 = 0.752628 loss)
I0826 15:58:36.470247 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.67208 (* 1 = 7.67208 loss)
I0826 15:58:36.470250 25446 sgd_solver.cpp:138] Iteration 9180, lr = 0.001
I0826 15:58:38.528184 25446 solver.cpp:243] Iteration 9190, loss = 8.67655
I0826 15:58:38.528221 25446 solver.cpp:259]     Train net output #0: center_loss = 61.5691 (* 0.008 = 0.492553 loss)
I0826 15:58:38.528228 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.184 (* 1 = 8.184 loss)
I0826 15:58:38.528230 25446 sgd_solver.cpp:138] Iteration 9190, lr = 0.001
I0826 15:58:40.585930 25446 solver.cpp:243] Iteration 9200, loss = 7.98793
I0826 15:58:40.586062 25446 solver.cpp:259]     Train net output #0: center_loss = 93.8859 (* 0.008 = 0.751087 loss)
I0826 15:58:40.586071 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.23684 (* 1 = 7.23684 loss)
I0826 15:58:40.586073 25446 sgd_solver.cpp:138] Iteration 9200, lr = 0.001
I0826 15:58:42.642773 25446 solver.cpp:243] Iteration 9210, loss = 8.65507
I0826 15:58:42.642812 25446 solver.cpp:259]     Train net output #0: center_loss = 62.3036 (* 0.008 = 0.498429 loss)
I0826 15:58:42.642817 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.15664 (* 1 = 8.15664 loss)
I0826 15:58:42.642820 25446 sgd_solver.cpp:138] Iteration 9210, lr = 0.001
I0826 15:58:44.701225 25446 solver.cpp:243] Iteration 9220, loss = 8.83404
I0826 15:58:44.701267 25446 solver.cpp:259]     Train net output #0: center_loss = 91.2483 (* 0.008 = 0.729986 loss)
I0826 15:58:44.701272 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.10406 (* 1 = 8.10406 loss)
I0826 15:58:44.701275 25446 sgd_solver.cpp:138] Iteration 9220, lr = 0.001
I0826 15:58:46.754838 25446 solver.cpp:243] Iteration 9230, loss = 8.46332
I0826 15:58:46.754878 25446 solver.cpp:259]     Train net output #0: center_loss = 117.529 (* 0.008 = 0.940232 loss)
I0826 15:58:46.754882 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.52309 (* 1 = 7.52309 loss)
I0826 15:58:46.754886 25446 sgd_solver.cpp:138] Iteration 9230, lr = 0.001
I0826 15:58:48.813480 25446 solver.cpp:243] Iteration 9240, loss = 8.27699
I0826 15:58:48.813518 25446 solver.cpp:259]     Train net output #0: center_loss = 54.7119 (* 0.008 = 0.437695 loss)
I0826 15:58:48.813522 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.83929 (* 1 = 7.83929 loss)
I0826 15:58:48.813525 25446 sgd_solver.cpp:138] Iteration 9240, lr = 0.001
I0826 15:58:50.872166 25446 solver.cpp:243] Iteration 9250, loss = 8.40298
I0826 15:58:50.872203 25446 solver.cpp:259]     Train net output #0: center_loss = 84.7295 (* 0.008 = 0.677836 loss)
I0826 15:58:50.872210 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.72514 (* 1 = 7.72514 loss)
I0826 15:58:50.872212 25446 sgd_solver.cpp:138] Iteration 9250, lr = 0.001
I0826 15:58:52.931092 25446 solver.cpp:243] Iteration 9260, loss = 8.55867
I0826 15:58:52.931128 25446 solver.cpp:259]     Train net output #0: center_loss = 88.0317 (* 0.008 = 0.704254 loss)
I0826 15:58:52.931134 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.85442 (* 1 = 7.85442 loss)
I0826 15:58:52.931138 25446 sgd_solver.cpp:138] Iteration 9260, lr = 0.001
I0826 15:58:54.987735 25446 solver.cpp:243] Iteration 9270, loss = 8.58023
I0826 15:58:54.987771 25446 solver.cpp:259]     Train net output #0: center_loss = 83.2451 (* 0.008 = 0.665961 loss)
I0826 15:58:54.987777 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91427 (* 1 = 7.91427 loss)
I0826 15:58:54.987782 25446 sgd_solver.cpp:138] Iteration 9270, lr = 0.001
I0826 15:58:57.046408 25446 solver.cpp:243] Iteration 9280, loss = 8.20062
I0826 15:58:57.046444 25446 solver.cpp:259]     Train net output #0: center_loss = 81.1927 (* 0.008 = 0.649542 loss)
I0826 15:58:57.046452 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.55108 (* 1 = 7.55108 loss)
I0826 15:58:57.046454 25446 sgd_solver.cpp:138] Iteration 9280, lr = 0.001
I0826 15:58:59.105497 25446 solver.cpp:243] Iteration 9290, loss = 8.76121
I0826 15:58:59.105535 25446 solver.cpp:259]     Train net output #0: center_loss = 73.9492 (* 0.008 = 0.591593 loss)
I0826 15:58:59.105540 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.16961 (* 1 = 8.16961 loss)
I0826 15:58:59.105543 25446 sgd_solver.cpp:138] Iteration 9290, lr = 0.001
I0826 15:59:01.164966 25446 solver.cpp:243] Iteration 9300, loss = 8.71799
I0826 15:59:01.165004 25446 solver.cpp:259]     Train net output #0: center_loss = 81.7257 (* 0.008 = 0.653805 loss)
I0826 15:59:01.165009 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.06418 (* 1 = 8.06418 loss)
I0826 15:59:01.165012 25446 sgd_solver.cpp:138] Iteration 9300, lr = 0.001
I0826 15:59:03.219503 25446 solver.cpp:243] Iteration 9310, loss = 8.20469
I0826 15:59:03.219539 25446 solver.cpp:259]     Train net output #0: center_loss = 63.282 (* 0.008 = 0.506256 loss)
I0826 15:59:03.219547 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.69844 (* 1 = 7.69844 loss)
I0826 15:59:03.219549 25446 sgd_solver.cpp:138] Iteration 9310, lr = 0.001
I0826 15:59:05.278122 25446 solver.cpp:243] Iteration 9320, loss = 8.60877
I0826 15:59:05.278158 25446 solver.cpp:259]     Train net output #0: center_loss = 63.7429 (* 0.008 = 0.509943 loss)
I0826 15:59:05.278164 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.09882 (* 1 = 8.09882 loss)
I0826 15:59:05.278167 25446 sgd_solver.cpp:138] Iteration 9320, lr = 0.001
I0826 15:59:07.335435 25446 solver.cpp:243] Iteration 9330, loss = 8.69959
I0826 15:59:07.335475 25446 solver.cpp:259]     Train net output #0: center_loss = 78.2282 (* 0.008 = 0.625826 loss)
I0826 15:59:07.335481 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.07376 (* 1 = 8.07376 loss)
I0826 15:59:07.335485 25446 sgd_solver.cpp:138] Iteration 9330, lr = 0.001
I0826 15:59:09.393764 25446 solver.cpp:243] Iteration 9340, loss = 8.85666
I0826 15:59:09.393801 25446 solver.cpp:259]     Train net output #0: center_loss = 72.2779 (* 0.008 = 0.578223 loss)
I0826 15:59:09.393807 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.27844 (* 1 = 8.27844 loss)
I0826 15:59:09.393810 25446 sgd_solver.cpp:138] Iteration 9340, lr = 0.001
I0826 15:59:11.447657 25446 solver.cpp:243] Iteration 9350, loss = 8.67135
I0826 15:59:11.447798 25446 solver.cpp:259]     Train net output #0: center_loss = 60.2934 (* 0.008 = 0.482347 loss)
I0826 15:59:11.447818 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.189 (* 1 = 8.189 loss)
I0826 15:59:11.447836 25446 sgd_solver.cpp:138] Iteration 9350, lr = 0.001
I0826 15:59:13.508415 25446 solver.cpp:243] Iteration 9360, loss = 8.2347
I0826 15:59:13.508453 25446 solver.cpp:259]     Train net output #0: center_loss = 82.1845 (* 0.008 = 0.657476 loss)
I0826 15:59:13.508458 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.57723 (* 1 = 7.57723 loss)
I0826 15:59:13.508461 25446 sgd_solver.cpp:138] Iteration 9360, lr = 0.001
I0826 15:59:15.564904 25446 solver.cpp:243] Iteration 9370, loss = 8.81452
I0826 15:59:15.564926 25446 solver.cpp:259]     Train net output #0: center_loss = 66.9639 (* 0.008 = 0.535711 loss)
I0826 15:59:15.564947 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.27881 (* 1 = 8.27881 loss)
I0826 15:59:15.564951 25446 sgd_solver.cpp:138] Iteration 9370, lr = 0.001
I0826 15:59:17.625000 25446 solver.cpp:243] Iteration 9380, loss = 8.43063
I0826 15:59:17.625039 25446 solver.cpp:259]     Train net output #0: center_loss = 83.6651 (* 0.008 = 0.66932 loss)
I0826 15:59:17.625047 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.76131 (* 1 = 7.76131 loss)
I0826 15:59:17.625052 25446 sgd_solver.cpp:138] Iteration 9380, lr = 0.001
I0826 15:59:19.678431 25446 solver.cpp:243] Iteration 9390, loss = 8.54746
I0826 15:59:19.678468 25446 solver.cpp:259]     Train net output #0: center_loss = 93.0193 (* 0.008 = 0.744154 loss)
I0826 15:59:19.678474 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.8033 (* 1 = 7.8033 loss)
I0826 15:59:19.678478 25446 sgd_solver.cpp:138] Iteration 9390, lr = 0.001
I0826 15:59:21.737843 25446 solver.cpp:243] Iteration 9400, loss = 7.66672
I0826 15:59:21.737864 25446 solver.cpp:259]     Train net output #0: center_loss = 86.0057 (* 0.008 = 0.688045 loss)
I0826 15:59:21.737884 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.97867 (* 1 = 6.97867 loss)
I0826 15:59:21.737888 25446 sgd_solver.cpp:138] Iteration 9400, lr = 0.001
I0826 15:59:23.798571 25446 solver.cpp:243] Iteration 9410, loss = 8.51412
I0826 15:59:23.798595 25446 solver.cpp:259]     Train net output #0: center_loss = 88.7532 (* 0.008 = 0.710026 loss)
I0826 15:59:23.798601 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.8041 (* 1 = 7.8041 loss)
I0826 15:59:23.798605 25446 sgd_solver.cpp:138] Iteration 9410, lr = 0.001
I0826 15:59:25.855993 25446 solver.cpp:243] Iteration 9420, loss = 8.83727
I0826 15:59:25.856029 25446 solver.cpp:259]     Train net output #0: center_loss = 62.1649 (* 0.008 = 0.497319 loss)
I0826 15:59:25.856035 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.33995 (* 1 = 8.33995 loss)
I0826 15:59:25.856039 25446 sgd_solver.cpp:138] Iteration 9420, lr = 0.001
I0826 15:59:27.911212 25446 solver.cpp:243] Iteration 9430, loss = 8.58863
I0826 15:59:27.911247 25446 solver.cpp:259]     Train net output #0: center_loss = 63.1764 (* 0.008 = 0.505411 loss)
I0826 15:59:27.911252 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08322 (* 1 = 8.08322 loss)
I0826 15:59:27.911255 25446 sgd_solver.cpp:138] Iteration 9430, lr = 0.001
I0826 15:59:29.971129 25446 solver.cpp:243] Iteration 9440, loss = 8.55263
I0826 15:59:29.971166 25446 solver.cpp:259]     Train net output #0: center_loss = 58.6108 (* 0.008 = 0.468886 loss)
I0826 15:59:29.971171 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08375 (* 1 = 8.08375 loss)
I0826 15:59:29.971175 25446 sgd_solver.cpp:138] Iteration 9440, lr = 0.001
I0826 15:59:32.024754 25446 solver.cpp:243] Iteration 9450, loss = 8.60451
I0826 15:59:32.024791 25446 solver.cpp:259]     Train net output #0: center_loss = 62.7688 (* 0.008 = 0.502151 loss)
I0826 15:59:32.024796 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.10236 (* 1 = 8.10236 loss)
I0826 15:59:32.024799 25446 sgd_solver.cpp:138] Iteration 9450, lr = 0.001
I0826 15:59:34.085058 25446 solver.cpp:243] Iteration 9460, loss = 8.6476
I0826 15:59:34.085112 25446 solver.cpp:259]     Train net output #0: center_loss = 52.0687 (* 0.008 = 0.41655 loss)
I0826 15:59:34.085134 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.23105 (* 1 = 8.23105 loss)
I0826 15:59:34.085137 25446 sgd_solver.cpp:138] Iteration 9460, lr = 0.001
I0826 15:59:36.141933 25446 solver.cpp:243] Iteration 9470, loss = 8.27258
I0826 15:59:36.141970 25446 solver.cpp:259]     Train net output #0: center_loss = 78.8997 (* 0.008 = 0.631197 loss)
I0826 15:59:36.141976 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.64138 (* 1 = 7.64138 loss)
I0826 15:59:36.141979 25446 sgd_solver.cpp:138] Iteration 9470, lr = 0.001
I0826 15:59:38.203217 25446 solver.cpp:243] Iteration 9480, loss = 8.39651
I0826 15:59:38.203253 25446 solver.cpp:259]     Train net output #0: center_loss = 76.3281 (* 0.008 = 0.610625 loss)
I0826 15:59:38.203258 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.78588 (* 1 = 7.78588 loss)
I0826 15:59:38.203261 25446 sgd_solver.cpp:138] Iteration 9480, lr = 0.001
I0826 15:59:40.256507 25446 solver.cpp:243] Iteration 9490, loss = 8.16323
I0826 15:59:40.256546 25446 solver.cpp:259]     Train net output #0: center_loss = 71.3952 (* 0.008 = 0.571162 loss)
I0826 15:59:40.256551 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.59206 (* 1 = 7.59206 loss)
I0826 15:59:40.256554 25446 sgd_solver.cpp:138] Iteration 9490, lr = 0.001
I0826 15:59:42.316534 25446 solver.cpp:243] Iteration 9500, loss = 8.60794
I0826 15:59:42.316659 25446 solver.cpp:259]     Train net output #0: center_loss = 66.5788 (* 0.008 = 0.53263 loss)
I0826 15:59:42.316666 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.07531 (* 1 = 8.07531 loss)
I0826 15:59:42.316684 25446 sgd_solver.cpp:138] Iteration 9500, lr = 0.001
I0826 15:59:44.376541 25446 solver.cpp:243] Iteration 9510, loss = 8.51579
I0826 15:59:44.376577 25446 solver.cpp:259]     Train net output #0: center_loss = 69.0831 (* 0.008 = 0.552665 loss)
I0826 15:59:44.376583 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.96312 (* 1 = 7.96312 loss)
I0826 15:59:44.376586 25446 sgd_solver.cpp:138] Iteration 9510, lr = 0.001
I0826 15:59:46.436303 25446 solver.cpp:243] Iteration 9520, loss = 7.69685
I0826 15:59:46.436341 25446 solver.cpp:259]     Train net output #0: center_loss = 95.1414 (* 0.008 = 0.761131 loss)
I0826 15:59:46.436347 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93572 (* 1 = 6.93572 loss)
I0826 15:59:46.436349 25446 sgd_solver.cpp:138] Iteration 9520, lr = 0.001
I0826 15:59:48.492935 25446 solver.cpp:243] Iteration 9530, loss = 8.25384
I0826 15:59:48.492974 25446 solver.cpp:259]     Train net output #0: center_loss = 99.4868 (* 0.008 = 0.795895 loss)
I0826 15:59:48.492980 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.45795 (* 1 = 7.45795 loss)
I0826 15:59:48.492982 25446 sgd_solver.cpp:138] Iteration 9530, lr = 0.001
I0826 15:59:50.550511 25446 solver.cpp:243] Iteration 9540, loss = 8.42443
I0826 15:59:50.550549 25446 solver.cpp:259]     Train net output #0: center_loss = 54.3482 (* 0.008 = 0.434785 loss)
I0826 15:59:50.550554 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.98964 (* 1 = 7.98964 loss)
I0826 15:59:50.550557 25446 sgd_solver.cpp:138] Iteration 9540, lr = 0.001
I0826 15:59:52.607420 25446 solver.cpp:243] Iteration 9550, loss = 8.16668
I0826 15:59:52.607444 25446 solver.cpp:259]     Train net output #0: center_loss = 99.7395 (* 0.008 = 0.797916 loss)
I0826 15:59:52.607463 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.36877 (* 1 = 7.36877 loss)
I0826 15:59:52.607466 25446 sgd_solver.cpp:138] Iteration 9550, lr = 0.001
I0826 15:59:54.662596 25446 solver.cpp:243] Iteration 9560, loss = 7.75431
I0826 15:59:54.662633 25446 solver.cpp:259]     Train net output #0: center_loss = 90.5847 (* 0.008 = 0.724678 loss)
I0826 15:59:54.662639 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.02963 (* 1 = 7.02963 loss)
I0826 15:59:54.662642 25446 sgd_solver.cpp:138] Iteration 9560, lr = 0.001
I0826 15:59:56.719599 25446 solver.cpp:243] Iteration 9570, loss = 8.06862
I0826 15:59:56.719636 25446 solver.cpp:259]     Train net output #0: center_loss = 58.4184 (* 0.008 = 0.467347 loss)
I0826 15:59:56.719642 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.60127 (* 1 = 7.60127 loss)
I0826 15:59:56.719645 25446 sgd_solver.cpp:138] Iteration 9570, lr = 0.001
I0826 15:59:58.775339 25446 solver.cpp:243] Iteration 9580, loss = 8.16453
I0826 15:59:58.775377 25446 solver.cpp:259]     Train net output #0: center_loss = 79.2892 (* 0.008 = 0.634314 loss)
I0826 15:59:58.775382 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.53022 (* 1 = 7.53022 loss)
I0826 15:59:58.775385 25446 sgd_solver.cpp:138] Iteration 9580, lr = 0.001
I0826 16:00:00.837674 25446 solver.cpp:243] Iteration 9590, loss = 8.9557
I0826 16:00:00.837710 25446 solver.cpp:259]     Train net output #0: center_loss = 61.8942 (* 0.008 = 0.495154 loss)
I0826 16:00:00.837716 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.46055 (* 1 = 8.46055 loss)
I0826 16:00:00.837719 25446 sgd_solver.cpp:138] Iteration 9590, lr = 0.001
I0826 16:00:02.892524 25446 solver.cpp:243] Iteration 9600, loss = 8.44403
I0826 16:00:02.892563 25446 solver.cpp:259]     Train net output #0: center_loss = 77.741 (* 0.008 = 0.621928 loss)
I0826 16:00:02.892568 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.8221 (* 1 = 7.8221 loss)
I0826 16:00:02.892572 25446 sgd_solver.cpp:138] Iteration 9600, lr = 0.001
I0826 16:00:04.951690 25446 solver.cpp:243] Iteration 9610, loss = 8.77446
I0826 16:00:04.951727 25446 solver.cpp:259]     Train net output #0: center_loss = 73.8835 (* 0.008 = 0.591068 loss)
I0826 16:00:04.951732 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.18339 (* 1 = 8.18339 loss)
I0826 16:00:04.951735 25446 sgd_solver.cpp:138] Iteration 9610, lr = 0.001
I0826 16:00:07.007856 25446 solver.cpp:243] Iteration 9620, loss = 8.37667
I0826 16:00:07.007894 25446 solver.cpp:259]     Train net output #0: center_loss = 77.3406 (* 0.008 = 0.618725 loss)
I0826 16:00:07.007899 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.75795 (* 1 = 7.75795 loss)
I0826 16:00:07.007902 25446 sgd_solver.cpp:138] Iteration 9620, lr = 0.001
I0826 16:00:09.064447 25446 solver.cpp:243] Iteration 9630, loss = 8.49849
I0826 16:00:09.064484 25446 solver.cpp:259]     Train net output #0: center_loss = 72.6251 (* 0.008 = 0.581001 loss)
I0826 16:00:09.064489 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91749 (* 1 = 7.91749 loss)
I0826 16:00:09.064492 25446 sgd_solver.cpp:138] Iteration 9630, lr = 0.001
I0826 16:00:11.122712 25446 solver.cpp:243] Iteration 9640, loss = 8.1232
I0826 16:00:11.122750 25446 solver.cpp:259]     Train net output #0: center_loss = 95.6885 (* 0.008 = 0.765508 loss)
I0826 16:00:11.122754 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.35769 (* 1 = 7.35769 loss)
I0826 16:00:11.122758 25446 sgd_solver.cpp:138] Iteration 9640, lr = 0.001
I0826 16:00:13.176673 25446 solver.cpp:243] Iteration 9650, loss = 8.46138
I0826 16:00:13.176832 25446 solver.cpp:259]     Train net output #0: center_loss = 88.6808 (* 0.008 = 0.709446 loss)
I0826 16:00:13.176852 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.75193 (* 1 = 7.75193 loss)
I0826 16:00:13.176856 25446 sgd_solver.cpp:138] Iteration 9650, lr = 0.001
I0826 16:00:15.234333 25446 solver.cpp:243] Iteration 9660, loss = 8.00865
I0826 16:00:15.234370 25446 solver.cpp:259]     Train net output #0: center_loss = 72.8949 (* 0.008 = 0.583159 loss)
I0826 16:00:15.234376 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.42549 (* 1 = 7.42549 loss)
I0826 16:00:15.234380 25446 sgd_solver.cpp:138] Iteration 9660, lr = 0.001
I0826 16:00:17.290560 25446 solver.cpp:243] Iteration 9670, loss = 8.84924
I0826 16:00:17.290580 25446 solver.cpp:259]     Train net output #0: center_loss = 90.8861 (* 0.008 = 0.727089 loss)
I0826 16:00:17.290601 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.12215 (* 1 = 8.12215 loss)
I0826 16:00:17.290606 25446 sgd_solver.cpp:138] Iteration 9670, lr = 0.001
I0826 16:00:19.350857 25446 solver.cpp:243] Iteration 9680, loss = 7.82962
I0826 16:00:19.350894 25446 solver.cpp:259]     Train net output #0: center_loss = 82.0199 (* 0.008 = 0.656159 loss)
I0826 16:00:19.350900 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.17346 (* 1 = 7.17346 loss)
I0826 16:00:19.350903 25446 sgd_solver.cpp:138] Iteration 9680, lr = 0.001
I0826 16:00:21.402340 25446 solver.cpp:243] Iteration 9690, loss = 8.11901
I0826 16:00:21.402377 25446 solver.cpp:259]     Train net output #0: center_loss = 99.3381 (* 0.008 = 0.794705 loss)
I0826 16:00:21.402382 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.3243 (* 1 = 7.3243 loss)
I0826 16:00:21.402385 25446 sgd_solver.cpp:138] Iteration 9690, lr = 0.001
I0826 16:00:23.462097 25446 solver.cpp:243] Iteration 9700, loss = 7.72934
I0826 16:00:23.462134 25446 solver.cpp:259]     Train net output #0: center_loss = 97.8643 (* 0.008 = 0.782915 loss)
I0826 16:00:23.462139 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.94643 (* 1 = 6.94643 loss)
I0826 16:00:23.462143 25446 sgd_solver.cpp:138] Iteration 9700, lr = 0.001
I0826 16:00:25.522444 25446 solver.cpp:243] Iteration 9710, loss = 8.2318
I0826 16:00:25.522480 25446 solver.cpp:259]     Train net output #0: center_loss = 88.7546 (* 0.008 = 0.710037 loss)
I0826 16:00:25.522485 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.52176 (* 1 = 7.52176 loss)
I0826 16:00:25.522490 25446 sgd_solver.cpp:138] Iteration 9710, lr = 0.001
I0826 16:00:27.582710 25446 solver.cpp:243] Iteration 9720, loss = 8.19928
I0826 16:00:27.582746 25446 solver.cpp:259]     Train net output #0: center_loss = 83.4958 (* 0.008 = 0.667966 loss)
I0826 16:00:27.582752 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.53131 (* 1 = 7.53131 loss)
I0826 16:00:27.582756 25446 sgd_solver.cpp:138] Iteration 9720, lr = 0.001
I0826 16:00:29.640264 25446 solver.cpp:243] Iteration 9730, loss = 8.7676
I0826 16:00:29.640302 25446 solver.cpp:259]     Train net output #0: center_loss = 63.3854 (* 0.008 = 0.507083 loss)
I0826 16:00:29.640308 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.26052 (* 1 = 8.26052 loss)
I0826 16:00:29.640311 25446 sgd_solver.cpp:138] Iteration 9730, lr = 0.001
I0826 16:00:31.697496 25446 solver.cpp:243] Iteration 9740, loss = 8.56324
I0826 16:00:31.697532 25446 solver.cpp:259]     Train net output #0: center_loss = 74.1482 (* 0.008 = 0.593186 loss)
I0826 16:00:31.697538 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.97006 (* 1 = 7.97006 loss)
I0826 16:00:31.697541 25446 sgd_solver.cpp:138] Iteration 9740, lr = 0.001
I0826 16:00:33.756726 25446 solver.cpp:243] Iteration 9750, loss = 8.25075
I0826 16:00:33.756763 25446 solver.cpp:259]     Train net output #0: center_loss = 96.8262 (* 0.008 = 0.774609 loss)
I0826 16:00:33.756769 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.47614 (* 1 = 7.47614 loss)
I0826 16:00:33.756772 25446 sgd_solver.cpp:138] Iteration 9750, lr = 0.001
I0826 16:00:35.812099 25446 solver.cpp:243] Iteration 9760, loss = 8.0097
I0826 16:00:35.812136 25446 solver.cpp:259]     Train net output #0: center_loss = 76.1816 (* 0.008 = 0.609453 loss)
I0826 16:00:35.812142 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.40025 (* 1 = 7.40025 loss)
I0826 16:00:35.812145 25446 sgd_solver.cpp:138] Iteration 9760, lr = 0.001
I0826 16:00:37.867714 25446 solver.cpp:243] Iteration 9770, loss = 8.13061
I0826 16:00:37.867750 25446 solver.cpp:259]     Train net output #0: center_loss = 111.024 (* 0.008 = 0.888191 loss)
I0826 16:00:37.867758 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.24242 (* 1 = 7.24242 loss)
I0826 16:00:37.867760 25446 sgd_solver.cpp:138] Iteration 9770, lr = 0.001
I0826 16:00:39.920972 25446 solver.cpp:243] Iteration 9780, loss = 8.32321
I0826 16:00:39.921008 25446 solver.cpp:259]     Train net output #0: center_loss = 83.8908 (* 0.008 = 0.671127 loss)
I0826 16:00:39.921015 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.65208 (* 1 = 7.65208 loss)
I0826 16:00:39.921018 25446 sgd_solver.cpp:138] Iteration 9780, lr = 0.001
I0826 16:00:41.979940 25446 solver.cpp:243] Iteration 9790, loss = 8.42037
I0826 16:00:41.979976 25446 solver.cpp:259]     Train net output #0: center_loss = 73.6699 (* 0.008 = 0.589359 loss)
I0826 16:00:41.979982 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.83101 (* 1 = 7.83101 loss)
I0826 16:00:41.979985 25446 sgd_solver.cpp:138] Iteration 9790, lr = 0.001
I0826 16:00:44.040969 25446 solver.cpp:243] Iteration 9800, loss = 8.29463
I0826 16:00:44.041110 25446 solver.cpp:259]     Train net output #0: center_loss = 117.568 (* 0.008 = 0.940544 loss)
I0826 16:00:44.041116 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.35409 (* 1 = 7.35409 loss)
I0826 16:00:44.041132 25446 sgd_solver.cpp:138] Iteration 9800, lr = 0.001
I0826 16:00:46.097338 25446 solver.cpp:243] Iteration 9810, loss = 8.31251
I0826 16:00:46.097375 25446 solver.cpp:259]     Train net output #0: center_loss = 73.0548 (* 0.008 = 0.584438 loss)
I0826 16:00:46.097381 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.72808 (* 1 = 7.72808 loss)
I0826 16:00:46.097384 25446 sgd_solver.cpp:138] Iteration 9810, lr = 0.001
I0826 16:00:48.157563 25446 solver.cpp:243] Iteration 9820, loss = 8.1384
I0826 16:00:48.157600 25446 solver.cpp:259]     Train net output #0: center_loss = 108.169 (* 0.008 = 0.865349 loss)
I0826 16:00:48.157606 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.27306 (* 1 = 7.27306 loss)
I0826 16:00:48.157609 25446 sgd_solver.cpp:138] Iteration 9820, lr = 0.001
I0826 16:00:50.216399 25446 solver.cpp:243] Iteration 9830, loss = 8.34471
I0826 16:00:50.216436 25446 solver.cpp:259]     Train net output #0: center_loss = 69.2733 (* 0.008 = 0.554186 loss)
I0826 16:00:50.216442 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.79053 (* 1 = 7.79053 loss)
I0826 16:00:50.216445 25446 sgd_solver.cpp:138] Iteration 9830, lr = 0.001
I0826 16:00:52.272282 25446 solver.cpp:243] Iteration 9840, loss = 8.16568
I0826 16:00:52.272320 25446 solver.cpp:259]     Train net output #0: center_loss = 90.5632 (* 0.008 = 0.724506 loss)
I0826 16:00:52.272325 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.44117 (* 1 = 7.44117 loss)
I0826 16:00:52.272328 25446 sgd_solver.cpp:138] Iteration 9840, lr = 0.001
I0826 16:00:54.329880 25446 solver.cpp:243] Iteration 9850, loss = 7.62128
I0826 16:00:54.329903 25446 solver.cpp:259]     Train net output #0: center_loss = 99.9013 (* 0.008 = 0.79921 loss)
I0826 16:00:54.329924 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.82207 (* 1 = 6.82207 loss)
I0826 16:00:54.329927 25446 sgd_solver.cpp:138] Iteration 9850, lr = 0.001
I0826 16:00:56.388890 25446 solver.cpp:243] Iteration 9860, loss = 8.04478
I0826 16:00:56.388927 25446 solver.cpp:259]     Train net output #0: center_loss = 90.9627 (* 0.008 = 0.727701 loss)
I0826 16:00:56.388933 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.31708 (* 1 = 7.31708 loss)
I0826 16:00:56.388936 25446 sgd_solver.cpp:138] Iteration 9860, lr = 0.001
I0826 16:00:58.445219 25446 solver.cpp:243] Iteration 9870, loss = 8.63425
I0826 16:00:58.445258 25446 solver.cpp:259]     Train net output #0: center_loss = 79.1293 (* 0.008 = 0.633035 loss)
I0826 16:00:58.445266 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.00121 (* 1 = 8.00121 loss)
I0826 16:00:58.445268 25446 sgd_solver.cpp:138] Iteration 9870, lr = 0.001
I0826 16:01:00.504376 25446 solver.cpp:243] Iteration 9880, loss = 8.29687
I0826 16:01:00.504413 25446 solver.cpp:259]     Train net output #0: center_loss = 66.1466 (* 0.008 = 0.529173 loss)
I0826 16:01:00.504420 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.7677 (* 1 = 7.7677 loss)
I0826 16:01:00.504422 25446 sgd_solver.cpp:138] Iteration 9880, lr = 0.001
I0826 16:01:02.562481 25446 solver.cpp:243] Iteration 9890, loss = 7.59767
I0826 16:01:02.562517 25446 solver.cpp:259]     Train net output #0: center_loss = 96.5775 (* 0.008 = 0.77262 loss)
I0826 16:01:02.562523 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.82505 (* 1 = 6.82505 loss)
I0826 16:01:02.562526 25446 sgd_solver.cpp:138] Iteration 9890, lr = 0.001
I0826 16:01:04.619062 25446 solver.cpp:243] Iteration 9900, loss = 7.84299
I0826 16:01:04.619097 25446 solver.cpp:259]     Train net output #0: center_loss = 82.1159 (* 0.008 = 0.656928 loss)
I0826 16:01:04.619103 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.18606 (* 1 = 7.18606 loss)
I0826 16:01:04.619107 25446 sgd_solver.cpp:138] Iteration 9900, lr = 0.001
I0826 16:01:06.680042 25446 solver.cpp:243] Iteration 9910, loss = 8.28338
I0826 16:01:06.680080 25446 solver.cpp:259]     Train net output #0: center_loss = 61.5948 (* 0.008 = 0.492759 loss)
I0826 16:01:06.680086 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.79062 (* 1 = 7.79062 loss)
I0826 16:01:06.680089 25446 sgd_solver.cpp:138] Iteration 9910, lr = 0.001
I0826 16:01:08.740527 25446 solver.cpp:243] Iteration 9920, loss = 7.92106
I0826 16:01:08.740563 25446 solver.cpp:259]     Train net output #0: center_loss = 90.5913 (* 0.008 = 0.72473 loss)
I0826 16:01:08.740569 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.19633 (* 1 = 7.19633 loss)
I0826 16:01:08.740573 25446 sgd_solver.cpp:138] Iteration 9920, lr = 0.001
I0826 16:01:10.799787 25446 solver.cpp:243] Iteration 9930, loss = 8.18764
I0826 16:01:10.799824 25446 solver.cpp:259]     Train net output #0: center_loss = 77.4611 (* 0.008 = 0.619689 loss)
I0826 16:01:10.799830 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.56795 (* 1 = 7.56795 loss)
I0826 16:01:10.799834 25446 sgd_solver.cpp:138] Iteration 9930, lr = 0.001
I0826 16:01:12.852797 25446 solver.cpp:243] Iteration 9940, loss = 7.34401
I0826 16:01:12.852833 25446 solver.cpp:259]     Train net output #0: center_loss = 107.914 (* 0.008 = 0.863315 loss)
I0826 16:01:12.852839 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.4807 (* 1 = 6.4807 loss)
I0826 16:01:12.852843 25446 sgd_solver.cpp:138] Iteration 9940, lr = 0.001
I0826 16:01:14.914887 25446 solver.cpp:243] Iteration 9950, loss = 8.31834
I0826 16:01:14.915052 25446 solver.cpp:259]     Train net output #0: center_loss = 122.026 (* 0.008 = 0.97621 loss)
I0826 16:01:14.915072 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.34213 (* 1 = 7.34213 loss)
I0826 16:01:14.915076 25446 sgd_solver.cpp:138] Iteration 9950, lr = 0.001
I0826 16:01:16.973228 25446 solver.cpp:243] Iteration 9960, loss = 8.35757
I0826 16:01:16.973266 25446 solver.cpp:259]     Train net output #0: center_loss = 80.8472 (* 0.008 = 0.646777 loss)
I0826 16:01:16.973271 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.71079 (* 1 = 7.71079 loss)
I0826 16:01:16.973275 25446 sgd_solver.cpp:138] Iteration 9960, lr = 0.001
I0826 16:01:19.028512 25446 solver.cpp:243] Iteration 9970, loss = 8.57443
I0826 16:01:19.028533 25446 solver.cpp:259]     Train net output #0: center_loss = 75.1336 (* 0.008 = 0.601069 loss)
I0826 16:01:19.028554 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.97336 (* 1 = 7.97336 loss)
I0826 16:01:19.028558 25446 sgd_solver.cpp:138] Iteration 9970, lr = 0.001
I0826 16:01:21.088052 25446 solver.cpp:243] Iteration 9980, loss = 8.28046
I0826 16:01:21.088089 25446 solver.cpp:259]     Train net output #0: center_loss = 75.7958 (* 0.008 = 0.606367 loss)
I0826 16:01:21.088095 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.6741 (* 1 = 7.6741 loss)
I0826 16:01:21.088099 25446 sgd_solver.cpp:138] Iteration 9980, lr = 0.001
I0826 16:01:23.141513 25446 solver.cpp:243] Iteration 9990, loss = 7.82666
I0826 16:01:23.141551 25446 solver.cpp:259]     Train net output #0: center_loss = 84.1561 (* 0.008 = 0.673249 loss)
I0826 16:01:23.141556 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.15341 (* 1 = 7.15341 loss)
I0826 16:01:23.141561 25446 sgd_solver.cpp:138] Iteration 9990, lr = 0.001
I0826 16:01:24.997385 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_10000.caffemodel
I0826 16:01:26.095477 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_10000.solverstate
I0826 16:01:26.414960 25446 solver.cpp:243] Iteration 10000, loss = 8.07474
I0826 16:01:26.414999 25446 solver.cpp:259]     Train net output #0: center_loss = 87.2646 (* 0.008 = 0.698116 loss)
I0826 16:01:26.415005 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.37662 (* 1 = 7.37662 loss)
I0826 16:01:26.415010 25446 sgd_solver.cpp:138] Iteration 10000, lr = 0.001
I0826 16:01:28.466166 25446 solver.cpp:243] Iteration 10010, loss = 8.75518
I0826 16:01:28.466203 25446 solver.cpp:259]     Train net output #0: center_loss = 68.8835 (* 0.008 = 0.551068 loss)
I0826 16:01:28.466209 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.20411 (* 1 = 8.20411 loss)
I0826 16:01:28.466213 25446 sgd_solver.cpp:138] Iteration 10010, lr = 0.001
I0826 16:01:30.524330 25446 solver.cpp:243] Iteration 10020, loss = 8.99434
I0826 16:01:30.524368 25446 solver.cpp:259]     Train net output #0: center_loss = 78.1442 (* 0.008 = 0.625154 loss)
I0826 16:01:30.524372 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.36918 (* 1 = 8.36918 loss)
I0826 16:01:30.524376 25446 sgd_solver.cpp:138] Iteration 10020, lr = 0.001
I0826 16:01:32.583678 25446 solver.cpp:243] Iteration 10030, loss = 8.30393
I0826 16:01:32.583715 25446 solver.cpp:259]     Train net output #0: center_loss = 75.1141 (* 0.008 = 0.600913 loss)
I0826 16:01:32.583721 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.70302 (* 1 = 7.70302 loss)
I0826 16:01:32.583724 25446 sgd_solver.cpp:138] Iteration 10030, lr = 0.001
I0826 16:01:34.636505 25446 solver.cpp:243] Iteration 10040, loss = 8.48191
I0826 16:01:34.636543 25446 solver.cpp:259]     Train net output #0: center_loss = 86.4918 (* 0.008 = 0.691934 loss)
I0826 16:01:34.636548 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.78998 (* 1 = 7.78998 loss)
I0826 16:01:34.636551 25446 sgd_solver.cpp:138] Iteration 10040, lr = 0.001
I0826 16:01:36.693702 25446 solver.cpp:243] Iteration 10050, loss = 8.76069
I0826 16:01:36.693739 25446 solver.cpp:259]     Train net output #0: center_loss = 62.291 (* 0.008 = 0.498328 loss)
I0826 16:01:36.693795 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.26236 (* 1 = 8.26236 loss)
I0826 16:01:36.693800 25446 sgd_solver.cpp:138] Iteration 10050, lr = 0.001
I0826 16:01:38.746881 25446 solver.cpp:243] Iteration 10060, loss = 8.58025
I0826 16:01:38.746918 25446 solver.cpp:259]     Train net output #0: center_loss = 63.3721 (* 0.008 = 0.506977 loss)
I0826 16:01:38.746924 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.07327 (* 1 = 8.07327 loss)
I0826 16:01:38.746927 25446 sgd_solver.cpp:138] Iteration 10060, lr = 0.001
I0826 16:01:40.804056 25446 solver.cpp:243] Iteration 10070, loss = 8.09912
I0826 16:01:40.804093 25446 solver.cpp:259]     Train net output #0: center_loss = 93.9079 (* 0.008 = 0.751263 loss)
I0826 16:01:40.804100 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.34786 (* 1 = 7.34786 loss)
I0826 16:01:40.804103 25446 sgd_solver.cpp:138] Iteration 10070, lr = 0.001
I0826 16:01:42.858018 25446 solver.cpp:243] Iteration 10080, loss = 8.44514
I0826 16:01:42.858054 25446 solver.cpp:259]     Train net output #0: center_loss = 78.1394 (* 0.008 = 0.625115 loss)
I0826 16:01:42.858060 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.82002 (* 1 = 7.82002 loss)
I0826 16:01:42.858063 25446 sgd_solver.cpp:138] Iteration 10080, lr = 0.001
I0826 16:01:44.916319 25446 solver.cpp:243] Iteration 10090, loss = 8.25967
I0826 16:01:44.916446 25446 solver.cpp:259]     Train net output #0: center_loss = 73.6059 (* 0.008 = 0.588848 loss)
I0826 16:01:44.916465 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.67083 (* 1 = 7.67083 loss)
I0826 16:01:44.916469 25446 sgd_solver.cpp:138] Iteration 10090, lr = 0.001
I0826 16:01:46.972503 25446 solver.cpp:243] Iteration 10100, loss = 8.52828
I0826 16:01:46.972527 25446 solver.cpp:259]     Train net output #0: center_loss = 79.8325 (* 0.008 = 0.63866 loss)
I0826 16:01:46.972546 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.88962 (* 1 = 7.88962 loss)
I0826 16:01:46.972549 25446 sgd_solver.cpp:138] Iteration 10100, lr = 0.001
I0826 16:01:49.029292 25446 solver.cpp:243] Iteration 10110, loss = 8.66759
I0826 16:01:49.029328 25446 solver.cpp:259]     Train net output #0: center_loss = 55.4635 (* 0.008 = 0.443708 loss)
I0826 16:01:49.029335 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.22388 (* 1 = 8.22388 loss)
I0826 16:01:49.029338 25446 sgd_solver.cpp:138] Iteration 10110, lr = 0.001
I0826 16:01:51.089198 25446 solver.cpp:243] Iteration 10120, loss = 8.84508
I0826 16:01:51.089236 25446 solver.cpp:259]     Train net output #0: center_loss = 83.6957 (* 0.008 = 0.669566 loss)
I0826 16:01:51.089241 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.17551 (* 1 = 8.17551 loss)
I0826 16:01:51.089244 25446 sgd_solver.cpp:138] Iteration 10120, lr = 0.001
I0826 16:01:53.144771 25446 solver.cpp:243] Iteration 10130, loss = 7.90055
I0826 16:01:53.144807 25446 solver.cpp:259]     Train net output #0: center_loss = 104.026 (* 0.008 = 0.832207 loss)
I0826 16:01:53.144814 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.06834 (* 1 = 7.06834 loss)
I0826 16:01:53.144816 25446 sgd_solver.cpp:138] Iteration 10130, lr = 0.001
I0826 16:01:55.200037 25446 solver.cpp:243] Iteration 10140, loss = 8.40926
I0826 16:01:55.200073 25446 solver.cpp:259]     Train net output #0: center_loss = 70.4489 (* 0.008 = 0.563591 loss)
I0826 16:01:55.200078 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.84567 (* 1 = 7.84567 loss)
I0826 16:01:55.200081 25446 sgd_solver.cpp:138] Iteration 10140, lr = 0.001
I0826 16:01:57.259757 25446 solver.cpp:243] Iteration 10150, loss = 7.93957
I0826 16:01:57.259794 25446 solver.cpp:259]     Train net output #0: center_loss = 98.3802 (* 0.008 = 0.787042 loss)
I0826 16:01:57.259800 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.15253 (* 1 = 7.15253 loss)
I0826 16:01:57.259804 25446 sgd_solver.cpp:138] Iteration 10150, lr = 0.001
I0826 16:01:59.316776 25446 solver.cpp:243] Iteration 10160, loss = 7.8756
I0826 16:01:59.316812 25446 solver.cpp:259]     Train net output #0: center_loss = 98.0349 (* 0.008 = 0.78428 loss)
I0826 16:01:59.316818 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.09132 (* 1 = 7.09132 loss)
I0826 16:01:59.316823 25446 sgd_solver.cpp:138] Iteration 10160, lr = 0.001
I0826 16:02:01.377079 25446 solver.cpp:243] Iteration 10170, loss = 8.53052
I0826 16:02:01.377104 25446 solver.cpp:259]     Train net output #0: center_loss = 98.6054 (* 0.008 = 0.788843 loss)
I0826 16:02:01.377110 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.74168 (* 1 = 7.74168 loss)
I0826 16:02:01.377115 25446 sgd_solver.cpp:138] Iteration 10170, lr = 0.001
I0826 16:02:03.430830 25446 solver.cpp:243] Iteration 10180, loss = 8.432
I0826 16:02:03.430866 25446 solver.cpp:259]     Train net output #0: center_loss = 118.886 (* 0.008 = 0.951091 loss)
I0826 16:02:03.430872 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.4809 (* 1 = 7.4809 loss)
I0826 16:02:03.430876 25446 sgd_solver.cpp:138] Iteration 10180, lr = 0.001
I0826 16:02:05.485009 25446 solver.cpp:243] Iteration 10190, loss = 8.51737
I0826 16:02:05.485046 25446 solver.cpp:259]     Train net output #0: center_loss = 75.6914 (* 0.008 = 0.605531 loss)
I0826 16:02:05.485051 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91184 (* 1 = 7.91184 loss)
I0826 16:02:05.485055 25446 sgd_solver.cpp:138] Iteration 10190, lr = 0.001
I0826 16:02:07.539858 25446 solver.cpp:243] Iteration 10200, loss = 7.99307
I0826 16:02:07.539896 25446 solver.cpp:259]     Train net output #0: center_loss = 102.869 (* 0.008 = 0.822954 loss)
I0826 16:02:07.539902 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.17011 (* 1 = 7.17011 loss)
I0826 16:02:07.539906 25446 sgd_solver.cpp:138] Iteration 10200, lr = 0.001
I0826 16:02:09.600193 25446 solver.cpp:243] Iteration 10210, loss = 7.89798
I0826 16:02:09.600229 25446 solver.cpp:259]     Train net output #0: center_loss = 92.1689 (* 0.008 = 0.737351 loss)
I0826 16:02:09.600235 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.16062 (* 1 = 7.16062 loss)
I0826 16:02:09.600239 25446 sgd_solver.cpp:138] Iteration 10210, lr = 0.001
I0826 16:02:11.652804 25446 solver.cpp:243] Iteration 10220, loss = 8.72075
I0826 16:02:11.652842 25446 solver.cpp:259]     Train net output #0: center_loss = 69.736 (* 0.008 = 0.557888 loss)
I0826 16:02:11.652848 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.16286 (* 1 = 8.16286 loss)
I0826 16:02:11.652851 25446 sgd_solver.cpp:138] Iteration 10220, lr = 0.001
I0826 16:02:13.711688 25446 solver.cpp:243] Iteration 10230, loss = 7.37193
I0826 16:02:13.711724 25446 solver.cpp:259]     Train net output #0: center_loss = 88.0551 (* 0.008 = 0.704441 loss)
I0826 16:02:13.711730 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.66749 (* 1 = 6.66749 loss)
I0826 16:02:13.711733 25446 sgd_solver.cpp:138] Iteration 10230, lr = 0.001
I0826 16:02:15.768515 25446 solver.cpp:243] Iteration 10240, loss = 8.36768
I0826 16:02:15.768638 25446 solver.cpp:259]     Train net output #0: center_loss = 94.5132 (* 0.008 = 0.756106 loss)
I0826 16:02:15.768661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.61157 (* 1 = 7.61157 loss)
I0826 16:02:15.768663 25446 sgd_solver.cpp:138] Iteration 10240, lr = 0.001
I0826 16:02:17.826005 25446 solver.cpp:243] Iteration 10250, loss = 8.20777
I0826 16:02:17.826043 25446 solver.cpp:259]     Train net output #0: center_loss = 100.039 (* 0.008 = 0.800313 loss)
I0826 16:02:17.826048 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.40745 (* 1 = 7.40745 loss)
I0826 16:02:17.826052 25446 sgd_solver.cpp:138] Iteration 10250, lr = 0.001
I0826 16:02:19.875859 25446 solver.cpp:243] Iteration 10260, loss = 8.36837
I0826 16:02:19.875896 25446 solver.cpp:259]     Train net output #0: center_loss = 67.5464 (* 0.008 = 0.540372 loss)
I0826 16:02:19.875902 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.828 (* 1 = 7.828 loss)
I0826 16:02:19.875906 25446 sgd_solver.cpp:138] Iteration 10260, lr = 0.001
I0826 16:02:21.930980 25446 solver.cpp:243] Iteration 10270, loss = 8.22985
I0826 16:02:21.931016 25446 solver.cpp:259]     Train net output #0: center_loss = 89.8426 (* 0.008 = 0.718741 loss)
I0826 16:02:21.931022 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.5111 (* 1 = 7.5111 loss)
I0826 16:02:21.931026 25446 sgd_solver.cpp:138] Iteration 10270, lr = 0.001
I0826 16:02:23.994256 25446 solver.cpp:243] Iteration 10280, loss = 8.54921
I0826 16:02:23.994292 25446 solver.cpp:259]     Train net output #0: center_loss = 83.1671 (* 0.008 = 0.665337 loss)
I0826 16:02:23.994298 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.88387 (* 1 = 7.88387 loss)
I0826 16:02:23.994302 25446 sgd_solver.cpp:138] Iteration 10280, lr = 0.001
I0826 16:02:26.047274 25446 solver.cpp:243] Iteration 10290, loss = 7.86409
I0826 16:02:26.047310 25446 solver.cpp:259]     Train net output #0: center_loss = 88.3569 (* 0.008 = 0.706855 loss)
I0826 16:02:26.047317 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.15723 (* 1 = 7.15723 loss)
I0826 16:02:26.047320 25446 sgd_solver.cpp:138] Iteration 10290, lr = 0.001
I0826 16:02:28.107244 25446 solver.cpp:243] Iteration 10300, loss = 8.38973
I0826 16:02:28.107280 25446 solver.cpp:259]     Train net output #0: center_loss = 100.465 (* 0.008 = 0.803718 loss)
I0826 16:02:28.107287 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.58602 (* 1 = 7.58602 loss)
I0826 16:02:28.107290 25446 sgd_solver.cpp:138] Iteration 10300, lr = 0.001
I0826 16:02:30.166986 25446 solver.cpp:243] Iteration 10310, loss = 8.1582
I0826 16:02:30.167024 25446 solver.cpp:259]     Train net output #0: center_loss = 81.6771 (* 0.008 = 0.653417 loss)
I0826 16:02:30.167029 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.50478 (* 1 = 7.50478 loss)
I0826 16:02:30.167032 25446 sgd_solver.cpp:138] Iteration 10310, lr = 0.001
I0826 16:02:32.221957 25446 solver.cpp:243] Iteration 10320, loss = 7.45323
I0826 16:02:32.221994 25446 solver.cpp:259]     Train net output #0: center_loss = 101.416 (* 0.008 = 0.811327 loss)
I0826 16:02:32.222002 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.6419 (* 1 = 6.6419 loss)
I0826 16:02:32.222004 25446 sgd_solver.cpp:138] Iteration 10320, lr = 0.001
I0826 16:02:34.281190 25446 solver.cpp:243] Iteration 10330, loss = 7.75718
I0826 16:02:34.281226 25446 solver.cpp:259]     Train net output #0: center_loss = 102.649 (* 0.008 = 0.821195 loss)
I0826 16:02:34.281234 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93599 (* 1 = 6.93599 loss)
I0826 16:02:34.281236 25446 sgd_solver.cpp:138] Iteration 10330, lr = 0.001
I0826 16:02:36.336669 25446 solver.cpp:243] Iteration 10340, loss = 8.56173
I0826 16:02:36.336706 25446 solver.cpp:259]     Train net output #0: center_loss = 84.1259 (* 0.008 = 0.673007 loss)
I0826 16:02:36.336714 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.88872 (* 1 = 7.88872 loss)
I0826 16:02:36.336716 25446 sgd_solver.cpp:138] Iteration 10340, lr = 0.001
I0826 16:02:38.395344 25446 solver.cpp:243] Iteration 10350, loss = 8.52595
I0826 16:02:38.395382 25446 solver.cpp:259]     Train net output #0: center_loss = 80.5044 (* 0.008 = 0.644035 loss)
I0826 16:02:38.395388 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.88191 (* 1 = 7.88191 loss)
I0826 16:02:38.395391 25446 sgd_solver.cpp:138] Iteration 10350, lr = 0.001
I0826 16:02:40.451788 25446 solver.cpp:243] Iteration 10360, loss = 8.50001
I0826 16:02:40.451824 25446 solver.cpp:259]     Train net output #0: center_loss = 112.631 (* 0.008 = 0.901048 loss)
I0826 16:02:40.451830 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.59896 (* 1 = 7.59896 loss)
I0826 16:02:40.451833 25446 sgd_solver.cpp:138] Iteration 10360, lr = 0.001
I0826 16:02:42.508482 25446 solver.cpp:243] Iteration 10370, loss = 8.22214
I0826 16:02:42.508520 25446 solver.cpp:259]     Train net output #0: center_loss = 96.6569 (* 0.008 = 0.773255 loss)
I0826 16:02:42.508527 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.44889 (* 1 = 7.44889 loss)
I0826 16:02:42.508529 25446 sgd_solver.cpp:138] Iteration 10370, lr = 0.001
I0826 16:02:44.569304 25446 solver.cpp:243] Iteration 10380, loss = 7.71955
I0826 16:02:44.569341 25446 solver.cpp:259]     Train net output #0: center_loss = 82.9936 (* 0.008 = 0.663948 loss)
I0826 16:02:44.569347 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.0556 (* 1 = 7.0556 loss)
I0826 16:02:44.569351 25446 sgd_solver.cpp:138] Iteration 10380, lr = 0.001
I0826 16:02:46.628068 25446 solver.cpp:243] Iteration 10390, loss = 8.36248
I0826 16:02:46.628233 25446 solver.cpp:259]     Train net output #0: center_loss = 88.0997 (* 0.008 = 0.704798 loss)
I0826 16:02:46.628252 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.65769 (* 1 = 7.65769 loss)
I0826 16:02:46.628257 25446 sgd_solver.cpp:138] Iteration 10390, lr = 0.001
I0826 16:02:48.683281 25446 solver.cpp:243] Iteration 10400, loss = 8.76342
I0826 16:02:48.683320 25446 solver.cpp:259]     Train net output #0: center_loss = 80.5848 (* 0.008 = 0.644678 loss)
I0826 16:02:48.683326 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.11874 (* 1 = 8.11874 loss)
I0826 16:02:48.683328 25446 sgd_solver.cpp:138] Iteration 10400, lr = 0.001
I0826 16:02:50.742616 25446 solver.cpp:243] Iteration 10410, loss = 8.6053
I0826 16:02:50.742653 25446 solver.cpp:259]     Train net output #0: center_loss = 101.042 (* 0.008 = 0.808337 loss)
I0826 16:02:50.742660 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.79696 (* 1 = 7.79696 loss)
I0826 16:02:50.742662 25446 sgd_solver.cpp:138] Iteration 10410, lr = 0.001
I0826 16:02:52.800699 25446 solver.cpp:243] Iteration 10420, loss = 8.44337
I0826 16:02:52.800737 25446 solver.cpp:259]     Train net output #0: center_loss = 80.5888 (* 0.008 = 0.644711 loss)
I0826 16:02:52.800742 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.79866 (* 1 = 7.79866 loss)
I0826 16:02:52.800746 25446 sgd_solver.cpp:138] Iteration 10420, lr = 0.001
I0826 16:02:54.855618 25446 solver.cpp:243] Iteration 10430, loss = 8.50603
I0826 16:02:54.855654 25446 solver.cpp:259]     Train net output #0: center_loss = 70.3699 (* 0.008 = 0.562959 loss)
I0826 16:02:54.855660 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.94307 (* 1 = 7.94307 loss)
I0826 16:02:54.855664 25446 sgd_solver.cpp:138] Iteration 10430, lr = 0.001
I0826 16:02:56.908277 25446 solver.cpp:243] Iteration 10440, loss = 8.41712
I0826 16:02:56.908313 25446 solver.cpp:259]     Train net output #0: center_loss = 77.7998 (* 0.008 = 0.622398 loss)
I0826 16:02:56.908318 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.79472 (* 1 = 7.79472 loss)
I0826 16:02:56.908322 25446 sgd_solver.cpp:138] Iteration 10440, lr = 0.001
I0826 16:02:58.966425 25446 solver.cpp:243] Iteration 10450, loss = 7.96992
I0826 16:02:58.966462 25446 solver.cpp:259]     Train net output #0: center_loss = 106.666 (* 0.008 = 0.853324 loss)
I0826 16:02:58.966470 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.1166 (* 1 = 7.1166 loss)
I0826 16:02:58.966472 25446 sgd_solver.cpp:138] Iteration 10450, lr = 0.001
I0826 16:03:01.022107 25446 solver.cpp:243] Iteration 10460, loss = 7.40051
I0826 16:03:01.022127 25446 solver.cpp:259]     Train net output #0: center_loss = 114.626 (* 0.008 = 0.91701 loss)
I0826 16:03:01.022148 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.4835 (* 1 = 6.4835 loss)
I0826 16:03:01.022152 25446 sgd_solver.cpp:138] Iteration 10460, lr = 0.001
I0826 16:03:03.080232 25446 solver.cpp:243] Iteration 10470, loss = 7.89957
I0826 16:03:03.080269 25446 solver.cpp:259]     Train net output #0: center_loss = 95.2506 (* 0.008 = 0.762004 loss)
I0826 16:03:03.080276 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.13756 (* 1 = 7.13756 loss)
I0826 16:03:03.080278 25446 sgd_solver.cpp:138] Iteration 10470, lr = 0.001
I0826 16:03:05.136271 25446 solver.cpp:243] Iteration 10480, loss = 7.94088
I0826 16:03:05.136292 25446 solver.cpp:259]     Train net output #0: center_loss = 87.6789 (* 0.008 = 0.701431 loss)
I0826 16:03:05.136313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.23945 (* 1 = 7.23945 loss)
I0826 16:03:05.136317 25446 sgd_solver.cpp:138] Iteration 10480, lr = 0.001
I0826 16:03:07.192481 25446 solver.cpp:243] Iteration 10490, loss = 8.45286
I0826 16:03:07.192517 25446 solver.cpp:259]     Train net output #0: center_loss = 92.3237 (* 0.008 = 0.738589 loss)
I0826 16:03:07.192523 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.71427 (* 1 = 7.71427 loss)
I0826 16:03:07.192526 25446 sgd_solver.cpp:138] Iteration 10490, lr = 0.001
I0826 16:03:09.251070 25446 solver.cpp:243] Iteration 10500, loss = 8.22713
I0826 16:03:09.251104 25446 solver.cpp:259]     Train net output #0: center_loss = 79.819 (* 0.008 = 0.638552 loss)
I0826 16:03:09.251111 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.58858 (* 1 = 7.58858 loss)
I0826 16:03:09.251113 25446 sgd_solver.cpp:138] Iteration 10500, lr = 0.001
I0826 16:03:11.306717 25446 solver.cpp:243] Iteration 10510, loss = 8.57301
I0826 16:03:11.306756 25446 solver.cpp:259]     Train net output #0: center_loss = 80.0271 (* 0.008 = 0.640217 loss)
I0826 16:03:11.306761 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.9328 (* 1 = 7.9328 loss)
I0826 16:03:11.306766 25446 sgd_solver.cpp:138] Iteration 10510, lr = 0.001
I0826 16:03:13.364594 25446 solver.cpp:243] Iteration 10520, loss = 8.13187
I0826 16:03:13.364631 25446 solver.cpp:259]     Train net output #0: center_loss = 73.3306 (* 0.008 = 0.586645 loss)
I0826 16:03:13.364637 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.54523 (* 1 = 7.54523 loss)
I0826 16:03:13.364640 25446 sgd_solver.cpp:138] Iteration 10520, lr = 0.001
I0826 16:03:15.419862 25446 solver.cpp:243] Iteration 10530, loss = 8.19843
I0826 16:03:15.419899 25446 solver.cpp:259]     Train net output #0: center_loss = 111.545 (* 0.008 = 0.892357 loss)
I0826 16:03:15.419905 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.30607 (* 1 = 7.30607 loss)
I0826 16:03:15.419909 25446 sgd_solver.cpp:138] Iteration 10530, lr = 0.001
I0826 16:03:17.475529 25446 solver.cpp:243] Iteration 10540, loss = 8.03979
I0826 16:03:17.475649 25446 solver.cpp:259]     Train net output #0: center_loss = 88.4373 (* 0.008 = 0.707498 loss)
I0826 16:03:17.475656 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.33229 (* 1 = 7.33229 loss)
I0826 16:03:17.475673 25446 sgd_solver.cpp:138] Iteration 10540, lr = 0.001
I0826 16:03:19.535617 25446 solver.cpp:243] Iteration 10550, loss = 7.54255
I0826 16:03:19.535655 25446 solver.cpp:259]     Train net output #0: center_loss = 105.144 (* 0.008 = 0.841149 loss)
I0826 16:03:19.535661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.7014 (* 1 = 6.7014 loss)
I0826 16:03:19.535665 25446 sgd_solver.cpp:138] Iteration 10550, lr = 0.001
I0826 16:03:21.590158 25446 solver.cpp:243] Iteration 10560, loss = 8.50503
I0826 16:03:21.590195 25446 solver.cpp:259]     Train net output #0: center_loss = 81.237 (* 0.008 = 0.649896 loss)
I0826 16:03:21.590201 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.85513 (* 1 = 7.85513 loss)
I0826 16:03:21.590204 25446 sgd_solver.cpp:138] Iteration 10560, lr = 0.001
I0826 16:03:23.645712 25446 solver.cpp:243] Iteration 10570, loss = 8.08228
I0826 16:03:23.645750 25446 solver.cpp:259]     Train net output #0: center_loss = 104.677 (* 0.008 = 0.837415 loss)
I0826 16:03:23.645756 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.24486 (* 1 = 7.24486 loss)
I0826 16:03:23.645759 25446 sgd_solver.cpp:138] Iteration 10570, lr = 0.001
I0826 16:03:25.705420 25446 solver.cpp:243] Iteration 10580, loss = 8.60622
I0826 16:03:25.705441 25446 solver.cpp:259]     Train net output #0: center_loss = 88.4708 (* 0.008 = 0.707767 loss)
I0826 16:03:25.705461 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.89845 (* 1 = 7.89845 loss)
I0826 16:03:25.705464 25446 sgd_solver.cpp:138] Iteration 10580, lr = 0.001
I0826 16:03:27.759999 25446 solver.cpp:243] Iteration 10590, loss = 7.93795
I0826 16:03:27.760036 25446 solver.cpp:259]     Train net output #0: center_loss = 111.615 (* 0.008 = 0.892923 loss)
I0826 16:03:27.760043 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.04503 (* 1 = 7.04503 loss)
I0826 16:03:27.760046 25446 sgd_solver.cpp:138] Iteration 10590, lr = 0.001
I0826 16:03:29.814492 25446 solver.cpp:243] Iteration 10600, loss = 8.4062
I0826 16:03:29.814527 25446 solver.cpp:259]     Train net output #0: center_loss = 75.4977 (* 0.008 = 0.603982 loss)
I0826 16:03:29.814533 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.80222 (* 1 = 7.80222 loss)
I0826 16:03:29.814536 25446 sgd_solver.cpp:138] Iteration 10600, lr = 0.001
I0826 16:03:31.870061 25446 solver.cpp:243] Iteration 10610, loss = 9.27222
I0826 16:03:31.870098 25446 solver.cpp:259]     Train net output #0: center_loss = 60.8365 (* 0.008 = 0.486692 loss)
I0826 16:03:31.870105 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.78553 (* 1 = 8.78553 loss)
I0826 16:03:31.870108 25446 sgd_solver.cpp:138] Iteration 10610, lr = 0.001
I0826 16:03:33.923791 25446 solver.cpp:243] Iteration 10620, loss = 8.01384
I0826 16:03:33.923827 25446 solver.cpp:259]     Train net output #0: center_loss = 98.97 (* 0.008 = 0.79176 loss)
I0826 16:03:33.923835 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.22208 (* 1 = 7.22208 loss)
I0826 16:03:33.923837 25446 sgd_solver.cpp:138] Iteration 10620, lr = 0.001
I0826 16:03:35.980556 25446 solver.cpp:243] Iteration 10630, loss = 8.63353
I0826 16:03:35.980593 25446 solver.cpp:259]     Train net output #0: center_loss = 68.1322 (* 0.008 = 0.545058 loss)
I0826 16:03:35.980599 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.08848 (* 1 = 8.08848 loss)
I0826 16:03:35.980602 25446 sgd_solver.cpp:138] Iteration 10630, lr = 0.001
I0826 16:03:38.036703 25446 solver.cpp:243] Iteration 10640, loss = 7.73343
I0826 16:03:38.036741 25446 solver.cpp:259]     Train net output #0: center_loss = 102.589 (* 0.008 = 0.820715 loss)
I0826 16:03:38.036746 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.91271 (* 1 = 6.91271 loss)
I0826 16:03:38.036751 25446 sgd_solver.cpp:138] Iteration 10640, lr = 0.001
I0826 16:03:40.091233 25446 solver.cpp:243] Iteration 10650, loss = 7.30067
I0826 16:03:40.091269 25446 solver.cpp:259]     Train net output #0: center_loss = 114.316 (* 0.008 = 0.914527 loss)
I0826 16:03:40.091275 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.38614 (* 1 = 6.38614 loss)
I0826 16:03:40.091279 25446 sgd_solver.cpp:138] Iteration 10650, lr = 0.001
I0826 16:03:42.148030 25446 solver.cpp:243] Iteration 10660, loss = 8.45365
I0826 16:03:42.148066 25446 solver.cpp:259]     Train net output #0: center_loss = 80.9971 (* 0.008 = 0.647977 loss)
I0826 16:03:42.148072 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.80568 (* 1 = 7.80568 loss)
I0826 16:03:42.148074 25446 sgd_solver.cpp:138] Iteration 10660, lr = 0.001
I0826 16:03:44.208122 25446 solver.cpp:243] Iteration 10670, loss = 8.42951
I0826 16:03:44.208158 25446 solver.cpp:259]     Train net output #0: center_loss = 82.0157 (* 0.008 = 0.656126 loss)
I0826 16:03:44.208164 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.77338 (* 1 = 7.77338 loss)
I0826 16:03:44.208168 25446 sgd_solver.cpp:138] Iteration 10670, lr = 0.001
I0826 16:03:46.263079 25446 solver.cpp:243] Iteration 10680, loss = 8.2126
I0826 16:03:46.263116 25446 solver.cpp:259]     Train net output #0: center_loss = 96.8651 (* 0.008 = 0.774921 loss)
I0826 16:03:46.263121 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.43768 (* 1 = 7.43768 loss)
I0826 16:03:46.263124 25446 sgd_solver.cpp:138] Iteration 10680, lr = 0.001
I0826 16:03:48.322971 25446 solver.cpp:243] Iteration 10690, loss = 7.77287
I0826 16:03:48.323132 25446 solver.cpp:259]     Train net output #0: center_loss = 95.1976 (* 0.008 = 0.761581 loss)
I0826 16:03:48.323153 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.01129 (* 1 = 7.01129 loss)
I0826 16:03:48.323155 25446 sgd_solver.cpp:138] Iteration 10690, lr = 0.001
I0826 16:03:50.377714 25446 solver.cpp:243] Iteration 10700, loss = 7.73857
I0826 16:03:50.377753 25446 solver.cpp:259]     Train net output #0: center_loss = 121.863 (* 0.008 = 0.974907 loss)
I0826 16:03:50.377758 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.76367 (* 1 = 6.76367 loss)
I0826 16:03:50.377761 25446 sgd_solver.cpp:138] Iteration 10700, lr = 0.001
I0826 16:03:52.433362 25446 solver.cpp:243] Iteration 10710, loss = 8.24249
I0826 16:03:52.433400 25446 solver.cpp:259]     Train net output #0: center_loss = 112.676 (* 0.008 = 0.90141 loss)
I0826 16:03:52.433406 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.34108 (* 1 = 7.34108 loss)
I0826 16:03:52.433410 25446 sgd_solver.cpp:138] Iteration 10710, lr = 0.001
I0826 16:03:54.490022 25446 solver.cpp:243] Iteration 10720, loss = 7.85339
I0826 16:03:54.490059 25446 solver.cpp:259]     Train net output #0: center_loss = 80.5385 (* 0.008 = 0.644308 loss)
I0826 16:03:54.490065 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.20909 (* 1 = 7.20909 loss)
I0826 16:03:54.490069 25446 sgd_solver.cpp:138] Iteration 10720, lr = 0.001
I0826 16:03:56.549814 25446 solver.cpp:243] Iteration 10730, loss = 7.86607
I0826 16:03:56.549851 25446 solver.cpp:259]     Train net output #0: center_loss = 122.44 (* 0.008 = 0.979517 loss)
I0826 16:03:56.549857 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.88655 (* 1 = 6.88655 loss)
I0826 16:03:56.549860 25446 sgd_solver.cpp:138] Iteration 10730, lr = 0.001
I0826 16:03:58.607100 25446 solver.cpp:243] Iteration 10740, loss = 7.70483
I0826 16:03:58.607122 25446 solver.cpp:259]     Train net output #0: center_loss = 94.4868 (* 0.008 = 0.755894 loss)
I0826 16:03:58.607142 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.94894 (* 1 = 6.94894 loss)
I0826 16:03:58.607146 25446 sgd_solver.cpp:138] Iteration 10740, lr = 0.001
I0826 16:04:00.664649 25446 solver.cpp:243] Iteration 10750, loss = 7.85239
I0826 16:04:00.664685 25446 solver.cpp:259]     Train net output #0: center_loss = 121.398 (* 0.008 = 0.971188 loss)
I0826 16:04:00.664691 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.8812 (* 1 = 6.8812 loss)
I0826 16:04:00.664695 25446 sgd_solver.cpp:138] Iteration 10750, lr = 0.001
I0826 16:04:02.720970 25446 solver.cpp:243] Iteration 10760, loss = 7.94974
I0826 16:04:02.720993 25446 solver.cpp:259]     Train net output #0: center_loss = 106.565 (* 0.008 = 0.852521 loss)
I0826 16:04:02.721014 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.09722 (* 1 = 7.09722 loss)
I0826 16:04:02.721017 25446 sgd_solver.cpp:138] Iteration 10760, lr = 0.001
I0826 16:04:04.779397 25446 solver.cpp:243] Iteration 10770, loss = 8.30153
I0826 16:04:04.779434 25446 solver.cpp:259]     Train net output #0: center_loss = 75.8996 (* 0.008 = 0.607197 loss)
I0826 16:04:04.779455 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.69433 (* 1 = 7.69433 loss)
I0826 16:04:04.779458 25446 sgd_solver.cpp:138] Iteration 10770, lr = 0.001
I0826 16:04:06.836803 25446 solver.cpp:243] Iteration 10780, loss = 8.25966
I0826 16:04:06.836840 25446 solver.cpp:259]     Train net output #0: center_loss = 100.279 (* 0.008 = 0.802229 loss)
I0826 16:04:06.836846 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.45743 (* 1 = 7.45743 loss)
I0826 16:04:06.836849 25446 sgd_solver.cpp:138] Iteration 10780, lr = 0.001
I0826 16:04:08.895323 25446 solver.cpp:243] Iteration 10790, loss = 8.5221
I0826 16:04:08.895359 25446 solver.cpp:259]     Train net output #0: center_loss = 93.542 (* 0.008 = 0.748336 loss)
I0826 16:04:08.895365 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.77377 (* 1 = 7.77377 loss)
I0826 16:04:08.895368 25446 sgd_solver.cpp:138] Iteration 10790, lr = 0.001
I0826 16:04:10.951956 25446 solver.cpp:243] Iteration 10800, loss = 8.09867
I0826 16:04:10.951994 25446 solver.cpp:259]     Train net output #0: center_loss = 68.7351 (* 0.008 = 0.549881 loss)
I0826 16:04:10.952000 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.54879 (* 1 = 7.54879 loss)
I0826 16:04:10.952003 25446 sgd_solver.cpp:138] Iteration 10800, lr = 0.001
I0826 16:04:13.013768 25446 solver.cpp:243] Iteration 10810, loss = 8.50011
I0826 16:04:13.013805 25446 solver.cpp:259]     Train net output #0: center_loss = 113.458 (* 0.008 = 0.907662 loss)
I0826 16:04:13.013811 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.59244 (* 1 = 7.59244 loss)
I0826 16:04:13.013814 25446 sgd_solver.cpp:138] Iteration 10810, lr = 0.001
I0826 16:04:15.071816 25446 solver.cpp:243] Iteration 10820, loss = 8.69802
I0826 16:04:15.071853 25446 solver.cpp:259]     Train net output #0: center_loss = 69.3461 (* 0.008 = 0.554769 loss)
I0826 16:04:15.071859 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.14325 (* 1 = 8.14325 loss)
I0826 16:04:15.071862 25446 sgd_solver.cpp:138] Iteration 10820, lr = 0.001
I0826 16:04:17.129213 25446 solver.cpp:243] Iteration 10830, loss = 8.16903
I0826 16:04:17.129252 25446 solver.cpp:259]     Train net output #0: center_loss = 100.672 (* 0.008 = 0.805376 loss)
I0826 16:04:17.129258 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.36366 (* 1 = 7.36366 loss)
I0826 16:04:17.129262 25446 sgd_solver.cpp:138] Iteration 10830, lr = 0.001
I0826 16:04:19.189363 25446 solver.cpp:243] Iteration 10840, loss = 7.50508
I0826 16:04:19.189491 25446 solver.cpp:259]     Train net output #0: center_loss = 113.803 (* 0.008 = 0.910421 loss)
I0826 16:04:19.189498 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.59466 (* 1 = 6.59466 loss)
I0826 16:04:19.189502 25446 sgd_solver.cpp:138] Iteration 10840, lr = 0.001
I0826 16:04:21.244433 25446 solver.cpp:243] Iteration 10850, loss = 7.95094
I0826 16:04:21.244469 25446 solver.cpp:259]     Train net output #0: center_loss = 89.7175 (* 0.008 = 0.71774 loss)
I0826 16:04:21.244475 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.2332 (* 1 = 7.2332 loss)
I0826 16:04:21.244479 25446 sgd_solver.cpp:138] Iteration 10850, lr = 0.001
I0826 16:04:23.302961 25446 solver.cpp:243] Iteration 10860, loss = 8.23503
I0826 16:04:23.302999 25446 solver.cpp:259]     Train net output #0: center_loss = 88.9705 (* 0.008 = 0.711764 loss)
I0826 16:04:23.303004 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.52326 (* 1 = 7.52326 loss)
I0826 16:04:23.303007 25446 sgd_solver.cpp:138] Iteration 10860, lr = 0.001
I0826 16:04:25.366420 25446 solver.cpp:243] Iteration 10870, loss = 7.99477
I0826 16:04:25.366444 25446 solver.cpp:259]     Train net output #0: center_loss = 76.443 (* 0.008 = 0.611544 loss)
I0826 16:04:25.366451 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.38322 (* 1 = 7.38322 loss)
I0826 16:04:25.366454 25446 sgd_solver.cpp:138] Iteration 10870, lr = 0.001
I0826 16:04:27.423683 25446 solver.cpp:243] Iteration 10880, loss = 8.34633
I0826 16:04:27.423720 25446 solver.cpp:259]     Train net output #0: center_loss = 120.928 (* 0.008 = 0.96742 loss)
I0826 16:04:27.423727 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.37891 (* 1 = 7.37891 loss)
I0826 16:04:27.423730 25446 sgd_solver.cpp:138] Iteration 10880, lr = 0.001
I0826 16:04:29.482565 25446 solver.cpp:243] Iteration 10890, loss = 8.38393
I0826 16:04:29.482602 25446 solver.cpp:259]     Train net output #0: center_loss = 94.7291 (* 0.008 = 0.757833 loss)
I0826 16:04:29.482607 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.6261 (* 1 = 7.6261 loss)
I0826 16:04:29.482610 25446 sgd_solver.cpp:138] Iteration 10890, lr = 0.001
I0826 16:04:31.544162 25446 solver.cpp:243] Iteration 10900, loss = 8.2712
I0826 16:04:31.544199 25446 solver.cpp:259]     Train net output #0: center_loss = 83.2038 (* 0.008 = 0.665631 loss)
I0826 16:04:31.544205 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.60557 (* 1 = 7.60557 loss)
I0826 16:04:31.544209 25446 sgd_solver.cpp:138] Iteration 10900, lr = 0.001
I0826 16:04:33.597971 25446 solver.cpp:243] Iteration 10910, loss = 8.95024
I0826 16:04:33.598018 25446 solver.cpp:259]     Train net output #0: center_loss = 91.4171 (* 0.008 = 0.731336 loss)
I0826 16:04:33.598024 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.2189 (* 1 = 8.2189 loss)
I0826 16:04:33.598027 25446 sgd_solver.cpp:138] Iteration 10910, lr = 0.001
I0826 16:04:35.660449 25446 solver.cpp:243] Iteration 10920, loss = 7.74797
I0826 16:04:35.660487 25446 solver.cpp:259]     Train net output #0: center_loss = 94.4253 (* 0.008 = 0.755402 loss)
I0826 16:04:35.660492 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.99257 (* 1 = 6.99257 loss)
I0826 16:04:35.660496 25446 sgd_solver.cpp:138] Iteration 10920, lr = 0.001
I0826 16:04:37.713536 25446 solver.cpp:243] Iteration 10930, loss = 8.43754
I0826 16:04:37.713572 25446 solver.cpp:259]     Train net output #0: center_loss = 87.9198 (* 0.008 = 0.703359 loss)
I0826 16:04:37.713577 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.73418 (* 1 = 7.73418 loss)
I0826 16:04:37.713580 25446 sgd_solver.cpp:138] Iteration 10930, lr = 0.001
I0826 16:04:39.770326 25446 solver.cpp:243] Iteration 10940, loss = 8.28008
I0826 16:04:39.770364 25446 solver.cpp:259]     Train net output #0: center_loss = 73.8815 (* 0.008 = 0.591052 loss)
I0826 16:04:39.770370 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.68902 (* 1 = 7.68902 loss)
I0826 16:04:39.770372 25446 sgd_solver.cpp:138] Iteration 10940, lr = 0.001
I0826 16:04:41.823815 25446 solver.cpp:243] Iteration 10950, loss = 8.45498
I0826 16:04:41.823851 25446 solver.cpp:259]     Train net output #0: center_loss = 87.8641 (* 0.008 = 0.702913 loss)
I0826 16:04:41.823858 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.75207 (* 1 = 7.75207 loss)
I0826 16:04:41.823860 25446 sgd_solver.cpp:138] Iteration 10950, lr = 0.001
I0826 16:04:43.880925 25446 solver.cpp:243] Iteration 10960, loss = 7.76618
I0826 16:04:43.880962 25446 solver.cpp:259]     Train net output #0: center_loss = 104.393 (* 0.008 = 0.835147 loss)
I0826 16:04:43.880969 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93103 (* 1 = 6.93103 loss)
I0826 16:04:43.880971 25446 sgd_solver.cpp:138] Iteration 10960, lr = 0.001
I0826 16:04:45.937265 25446 solver.cpp:243] Iteration 10970, loss = 8.1572
I0826 16:04:45.937301 25446 solver.cpp:259]     Train net output #0: center_loss = 94.6346 (* 0.008 = 0.757077 loss)
I0826 16:04:45.937306 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.40012 (* 1 = 7.40012 loss)
I0826 16:04:45.937310 25446 sgd_solver.cpp:138] Iteration 10970, lr = 0.001
I0826 16:04:47.995347 25446 solver.cpp:243] Iteration 10980, loss = 8.72116
I0826 16:04:47.995383 25446 solver.cpp:259]     Train net output #0: center_loss = 85.5839 (* 0.008 = 0.684672 loss)
I0826 16:04:47.995389 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.03649 (* 1 = 8.03649 loss)
I0826 16:04:47.995393 25446 sgd_solver.cpp:138] Iteration 10980, lr = 0.001
I0826 16:04:50.055868 25446 solver.cpp:243] Iteration 10990, loss = 8.1692
I0826 16:04:50.055997 25446 solver.cpp:259]     Train net output #0: center_loss = 75.851 (* 0.008 = 0.606808 loss)
I0826 16:04:50.056016 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.56239 (* 1 = 7.56239 loss)
I0826 16:04:50.056020 25446 sgd_solver.cpp:138] Iteration 10990, lr = 0.001
I0826 16:04:51.907714 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_11000.caffemodel
I0826 16:04:53.008882 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_11000.solverstate
I0826 16:04:53.329140 25446 solver.cpp:243] Iteration 11000, loss = 8.05638
I0826 16:04:53.329178 25446 solver.cpp:259]     Train net output #0: center_loss = 114.272 (* 0.008 = 0.914173 loss)
I0826 16:04:53.329185 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.14221 (* 1 = 7.14221 loss)
I0826 16:04:53.329190 25446 sgd_solver.cpp:138] Iteration 11000, lr = 0.001
I0826 16:04:55.383002 25446 solver.cpp:243] Iteration 11010, loss = 7.85029
I0826 16:04:55.383039 25446 solver.cpp:259]     Train net output #0: center_loss = 92.68 (* 0.008 = 0.74144 loss)
I0826 16:04:55.383044 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.10885 (* 1 = 7.10885 loss)
I0826 16:04:55.383049 25446 sgd_solver.cpp:138] Iteration 11010, lr = 0.001
I0826 16:04:57.441732 25446 solver.cpp:243] Iteration 11020, loss = 8.32209
I0826 16:04:57.441769 25446 solver.cpp:259]     Train net output #0: center_loss = 95.0159 (* 0.008 = 0.760127 loss)
I0826 16:04:57.441776 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.56196 (* 1 = 7.56196 loss)
I0826 16:04:57.441778 25446 sgd_solver.cpp:138] Iteration 11020, lr = 0.001
I0826 16:04:59.498538 25446 solver.cpp:243] Iteration 11030, loss = 7.43517
I0826 16:04:59.498574 25446 solver.cpp:259]     Train net output #0: center_loss = 113.592 (* 0.008 = 0.908739 loss)
I0826 16:04:59.498580 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.52643 (* 1 = 6.52643 loss)
I0826 16:04:59.498584 25446 sgd_solver.cpp:138] Iteration 11030, lr = 0.001
I0826 16:05:01.558423 25446 solver.cpp:243] Iteration 11040, loss = 8.23354
I0826 16:05:01.558459 25446 solver.cpp:259]     Train net output #0: center_loss = 79.8088 (* 0.008 = 0.63847 loss)
I0826 16:05:01.558465 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.59507 (* 1 = 7.59507 loss)
I0826 16:05:01.558467 25446 sgd_solver.cpp:138] Iteration 11040, lr = 0.001
I0826 16:05:03.617552 25446 solver.cpp:243] Iteration 11050, loss = 8.27709
I0826 16:05:03.617590 25446 solver.cpp:259]     Train net output #0: center_loss = 102.503 (* 0.008 = 0.820026 loss)
I0826 16:05:03.617596 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.45706 (* 1 = 7.45706 loss)
I0826 16:05:03.617614 25446 sgd_solver.cpp:138] Iteration 11050, lr = 0.001
I0826 16:05:05.676020 25446 solver.cpp:243] Iteration 11060, loss = 7.39971
I0826 16:05:05.676056 25446 solver.cpp:259]     Train net output #0: center_loss = 113.866 (* 0.008 = 0.910928 loss)
I0826 16:05:05.676062 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.48878 (* 1 = 6.48878 loss)
I0826 16:05:05.676065 25446 sgd_solver.cpp:138] Iteration 11060, lr = 0.001
I0826 16:05:07.791265 25446 solver.cpp:243] Iteration 11070, loss = 8.06192
I0826 16:05:07.791292 25446 solver.cpp:259]     Train net output #0: center_loss = 113.095 (* 0.008 = 0.904764 loss)
I0826 16:05:07.791298 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.15716 (* 1 = 7.15716 loss)
I0826 16:05:07.791303 25446 sgd_solver.cpp:138] Iteration 11070, lr = 0.001
I0826 16:05:09.934919 25446 solver.cpp:243] Iteration 11080, loss = 7.66926
I0826 16:05:09.934947 25446 solver.cpp:259]     Train net output #0: center_loss = 95.3344 (* 0.008 = 0.762675 loss)
I0826 16:05:09.934952 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.90659 (* 1 = 6.90659 loss)
I0826 16:05:09.934957 25446 sgd_solver.cpp:138] Iteration 11080, lr = 0.001
I0826 16:05:12.144095 25446 solver.cpp:243] Iteration 11090, loss = 8.02357
I0826 16:05:12.144119 25446 solver.cpp:259]     Train net output #0: center_loss = 121.531 (* 0.008 = 0.97225 loss)
I0826 16:05:12.144148 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.05132 (* 1 = 7.05132 loss)
I0826 16:05:12.144153 25446 sgd_solver.cpp:138] Iteration 11090, lr = 0.001
I0826 16:05:14.272296 25446 solver.cpp:243] Iteration 11100, loss = 8.18253
I0826 16:05:14.272320 25446 solver.cpp:259]     Train net output #0: center_loss = 102.457 (* 0.008 = 0.819659 loss)
I0826 16:05:14.272327 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.36287 (* 1 = 7.36287 loss)
I0826 16:05:14.272331 25446 sgd_solver.cpp:138] Iteration 11100, lr = 0.001
I0826 16:05:16.367349 25446 solver.cpp:243] Iteration 11110, loss = 8.26503
I0826 16:05:16.367375 25446 solver.cpp:259]     Train net output #0: center_loss = 78.8087 (* 0.008 = 0.63047 loss)
I0826 16:05:16.367383 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.63456 (* 1 = 7.63456 loss)
I0826 16:05:16.367386 25446 sgd_solver.cpp:138] Iteration 11110, lr = 0.001
I0826 16:05:18.428110 25446 solver.cpp:243] Iteration 11120, loss = 7.54228
I0826 16:05:18.428136 25446 solver.cpp:259]     Train net output #0: center_loss = 91.3883 (* 0.008 = 0.731106 loss)
I0826 16:05:18.428143 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.81117 (* 1 = 6.81117 loss)
I0826 16:05:18.428148 25446 sgd_solver.cpp:138] Iteration 11120, lr = 0.001
I0826 16:05:20.489126 25446 solver.cpp:243] Iteration 11130, loss = 8.3215
I0826 16:05:20.489264 25446 solver.cpp:259]     Train net output #0: center_loss = 100.586 (* 0.008 = 0.804687 loss)
I0826 16:05:20.489272 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.51681 (* 1 = 7.51681 loss)
I0826 16:05:20.489276 25446 sgd_solver.cpp:138] Iteration 11130, lr = 0.001
I0826 16:05:22.548172 25446 solver.cpp:243] Iteration 11140, loss = 8.29181
I0826 16:05:22.548197 25446 solver.cpp:259]     Train net output #0: center_loss = 113.638 (* 0.008 = 0.9091 loss)
I0826 16:05:22.548202 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.38271 (* 1 = 7.38271 loss)
I0826 16:05:22.548207 25446 sgd_solver.cpp:138] Iteration 11140, lr = 0.001
I0826 16:05:24.611744 25446 solver.cpp:243] Iteration 11150, loss = 8.52492
I0826 16:05:24.611769 25446 solver.cpp:259]     Train net output #0: center_loss = 62.6023 (* 0.008 = 0.500818 loss)
I0826 16:05:24.611775 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.0241 (* 1 = 8.0241 loss)
I0826 16:05:24.611779 25446 sgd_solver.cpp:138] Iteration 11150, lr = 0.001
I0826 16:05:26.671995 25446 solver.cpp:243] Iteration 11160, loss = 6.77587
I0826 16:05:26.672022 25446 solver.cpp:259]     Train net output #0: center_loss = 154.354 (* 0.008 = 1.23483 loss)
I0826 16:05:26.672029 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.54104 (* 1 = 5.54104 loss)
I0826 16:05:26.672034 25446 sgd_solver.cpp:138] Iteration 11160, lr = 0.001
I0826 16:05:28.736434 25446 solver.cpp:243] Iteration 11170, loss = 8.11638
I0826 16:05:28.736459 25446 solver.cpp:259]     Train net output #0: center_loss = 83.2358 (* 0.008 = 0.665886 loss)
I0826 16:05:28.736465 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.45049 (* 1 = 7.45049 loss)
I0826 16:05:28.736469 25446 sgd_solver.cpp:138] Iteration 11170, lr = 0.001
I0826 16:05:30.795822 25446 solver.cpp:243] Iteration 11180, loss = 8.38809
I0826 16:05:30.795848 25446 solver.cpp:259]     Train net output #0: center_loss = 66.5887 (* 0.008 = 0.53271 loss)
I0826 16:05:30.795855 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.85538 (* 1 = 7.85538 loss)
I0826 16:05:30.795858 25446 sgd_solver.cpp:138] Iteration 11180, lr = 0.001
I0826 16:05:32.858891 25446 solver.cpp:243] Iteration 11190, loss = 7.74967
I0826 16:05:32.858914 25446 solver.cpp:259]     Train net output #0: center_loss = 105.333 (* 0.008 = 0.842662 loss)
I0826 16:05:32.858920 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.90701 (* 1 = 6.90701 loss)
I0826 16:05:32.858924 25446 sgd_solver.cpp:138] Iteration 11190, lr = 0.001
I0826 16:05:34.923106 25446 solver.cpp:243] Iteration 11200, loss = 7.4039
I0826 16:05:34.923132 25446 solver.cpp:259]     Train net output #0: center_loss = 138.54 (* 0.008 = 1.10832 loss)
I0826 16:05:34.923138 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.29557 (* 1 = 6.29557 loss)
I0826 16:05:34.923143 25446 sgd_solver.cpp:138] Iteration 11200, lr = 0.001
I0826 16:05:36.984154 25446 solver.cpp:243] Iteration 11210, loss = 8.1554
I0826 16:05:36.984180 25446 solver.cpp:259]     Train net output #0: center_loss = 102.991 (* 0.008 = 0.823926 loss)
I0826 16:05:36.984186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.33147 (* 1 = 7.33147 loss)
I0826 16:05:36.984191 25446 sgd_solver.cpp:138] Iteration 11210, lr = 0.001
I0826 16:05:39.044945 25446 solver.cpp:243] Iteration 11220, loss = 8.74194
I0826 16:05:39.044968 25446 solver.cpp:259]     Train net output #0: center_loss = 76.3903 (* 0.008 = 0.611122 loss)
I0826 16:05:39.044975 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.13082 (* 1 = 8.13082 loss)
I0826 16:05:39.044978 25446 sgd_solver.cpp:138] Iteration 11220, lr = 0.001
I0826 16:05:41.106959 25446 solver.cpp:243] Iteration 11230, loss = 7.748
I0826 16:05:41.106983 25446 solver.cpp:259]     Train net output #0: center_loss = 101.396 (* 0.008 = 0.811169 loss)
I0826 16:05:41.106990 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93683 (* 1 = 6.93683 loss)
I0826 16:05:41.106994 25446 sgd_solver.cpp:138] Iteration 11230, lr = 0.001
I0826 16:05:43.168372 25446 solver.cpp:243] Iteration 11240, loss = 7.47364
I0826 16:05:43.168396 25446 solver.cpp:259]     Train net output #0: center_loss = 136.97 (* 0.008 = 1.09576 loss)
I0826 16:05:43.168403 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.37787 (* 1 = 6.37787 loss)
I0826 16:05:43.168406 25446 sgd_solver.cpp:138] Iteration 11240, lr = 0.001
I0826 16:05:45.233669 25446 solver.cpp:243] Iteration 11250, loss = 7.60322
I0826 16:05:45.233692 25446 solver.cpp:259]     Train net output #0: center_loss = 67.8693 (* 0.008 = 0.542955 loss)
I0826 16:05:45.233698 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.06026 (* 1 = 7.06026 loss)
I0826 16:05:45.233702 25446 sgd_solver.cpp:138] Iteration 11250, lr = 0.001
I0826 16:05:47.295336 25446 solver.cpp:243] Iteration 11260, loss = 8.48698
I0826 16:05:47.295359 25446 solver.cpp:259]     Train net output #0: center_loss = 85.6075 (* 0.008 = 0.68486 loss)
I0826 16:05:47.295365 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.80212 (* 1 = 7.80212 loss)
I0826 16:05:47.295369 25446 sgd_solver.cpp:138] Iteration 11260, lr = 0.001
I0826 16:05:49.354151 25446 solver.cpp:243] Iteration 11270, loss = 8.82512
I0826 16:05:49.354176 25446 solver.cpp:259]     Train net output #0: center_loss = 125.208 (* 0.008 = 1.00166 loss)
I0826 16:05:49.354182 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.82346 (* 1 = 7.82346 loss)
I0826 16:05:49.354185 25446 sgd_solver.cpp:138] Iteration 11270, lr = 0.001
I0826 16:05:51.416263 25446 solver.cpp:243] Iteration 11280, loss = 7.8328
I0826 16:05:51.416386 25446 solver.cpp:259]     Train net output #0: center_loss = 87.8168 (* 0.008 = 0.702534 loss)
I0826 16:05:51.416406 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.13026 (* 1 = 7.13026 loss)
I0826 16:05:51.416410 25446 sgd_solver.cpp:138] Iteration 11280, lr = 0.001
I0826 16:05:53.479589 25446 solver.cpp:243] Iteration 11290, loss = 7.9657
I0826 16:05:53.479614 25446 solver.cpp:259]     Train net output #0: center_loss = 102.596 (* 0.008 = 0.820767 loss)
I0826 16:05:53.479620 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.14494 (* 1 = 7.14494 loss)
I0826 16:05:53.479624 25446 sgd_solver.cpp:138] Iteration 11290, lr = 0.001
I0826 16:05:55.537575 25446 solver.cpp:243] Iteration 11300, loss = 8.57051
I0826 16:05:55.537600 25446 solver.cpp:259]     Train net output #0: center_loss = 132.391 (* 0.008 = 1.05912 loss)
I0826 16:05:55.537606 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.51139 (* 1 = 7.51139 loss)
I0826 16:05:55.537611 25446 sgd_solver.cpp:138] Iteration 11300, lr = 0.001
I0826 16:05:57.602362 25446 solver.cpp:243] Iteration 11310, loss = 8.77314
I0826 16:05:57.602388 25446 solver.cpp:259]     Train net output #0: center_loss = 103.374 (* 0.008 = 0.826992 loss)
I0826 16:05:57.602394 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.94615 (* 1 = 7.94615 loss)
I0826 16:05:57.602398 25446 sgd_solver.cpp:138] Iteration 11310, lr = 0.001
I0826 16:05:59.661159 25446 solver.cpp:243] Iteration 11320, loss = 7.86277
I0826 16:05:59.661185 25446 solver.cpp:259]     Train net output #0: center_loss = 132.331 (* 0.008 = 1.05865 loss)
I0826 16:05:59.661191 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.80412 (* 1 = 6.80412 loss)
I0826 16:05:59.661195 25446 sgd_solver.cpp:138] Iteration 11320, lr = 0.001
I0826 16:06:01.721575 25446 solver.cpp:243] Iteration 11330, loss = 7.61589
I0826 16:06:01.721599 25446 solver.cpp:259]     Train net output #0: center_loss = 99.6637 (* 0.008 = 0.797309 loss)
I0826 16:06:01.721606 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.81858 (* 1 = 6.81858 loss)
I0826 16:06:01.721611 25446 sgd_solver.cpp:138] Iteration 11330, lr = 0.001
I0826 16:06:03.782598 25446 solver.cpp:243] Iteration 11340, loss = 8.10715
I0826 16:06:03.782624 25446 solver.cpp:259]     Train net output #0: center_loss = 99.4836 (* 0.008 = 0.795868 loss)
I0826 16:06:03.782630 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.31128 (* 1 = 7.31128 loss)
I0826 16:06:03.782634 25446 sgd_solver.cpp:138] Iteration 11340, lr = 0.001
I0826 16:06:05.844589 25446 solver.cpp:243] Iteration 11350, loss = 7.94163
I0826 16:06:05.844614 25446 solver.cpp:259]     Train net output #0: center_loss = 93.6375 (* 0.008 = 0.7491 loss)
I0826 16:06:05.844620 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.19253 (* 1 = 7.19253 loss)
I0826 16:06:05.844624 25446 sgd_solver.cpp:138] Iteration 11350, lr = 0.001
I0826 16:06:07.906992 25446 solver.cpp:243] Iteration 11360, loss = 7.61511
I0826 16:06:07.907016 25446 solver.cpp:259]     Train net output #0: center_loss = 118.602 (* 0.008 = 0.948816 loss)
I0826 16:06:07.907022 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.66629 (* 1 = 6.66629 loss)
I0826 16:06:07.907027 25446 sgd_solver.cpp:138] Iteration 11360, lr = 0.001
I0826 16:06:09.968540 25446 solver.cpp:243] Iteration 11370, loss = 7.53951
I0826 16:06:09.968565 25446 solver.cpp:259]     Train net output #0: center_loss = 101.726 (* 0.008 = 0.813811 loss)
I0826 16:06:09.968571 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.7257 (* 1 = 6.7257 loss)
I0826 16:06:09.968575 25446 sgd_solver.cpp:138] Iteration 11370, lr = 0.001
I0826 16:06:12.029633 25446 solver.cpp:243] Iteration 11380, loss = 8.03395
I0826 16:06:12.029659 25446 solver.cpp:259]     Train net output #0: center_loss = 114.036 (* 0.008 = 0.912284 loss)
I0826 16:06:12.029664 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.12167 (* 1 = 7.12167 loss)
I0826 16:06:12.029669 25446 sgd_solver.cpp:138] Iteration 11380, lr = 0.001
I0826 16:06:14.094059 25446 solver.cpp:243] Iteration 11390, loss = 7.51529
I0826 16:06:14.094084 25446 solver.cpp:259]     Train net output #0: center_loss = 116.236 (* 0.008 = 0.929886 loss)
I0826 16:06:14.094089 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.5854 (* 1 = 6.5854 loss)
I0826 16:06:14.094094 25446 sgd_solver.cpp:138] Iteration 11390, lr = 0.001
I0826 16:06:16.154629 25446 solver.cpp:243] Iteration 11400, loss = 7.61418
I0826 16:06:16.154654 25446 solver.cpp:259]     Train net output #0: center_loss = 121.457 (* 0.008 = 0.971653 loss)
I0826 16:06:16.154660 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.64253 (* 1 = 6.64253 loss)
I0826 16:06:16.154664 25446 sgd_solver.cpp:138] Iteration 11400, lr = 0.001
I0826 16:06:18.216372 25446 solver.cpp:243] Iteration 11410, loss = 7.50196
I0826 16:06:18.216398 25446 solver.cpp:259]     Train net output #0: center_loss = 94.3229 (* 0.008 = 0.754584 loss)
I0826 16:06:18.216403 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.74738 (* 1 = 6.74738 loss)
I0826 16:06:18.216408 25446 sgd_solver.cpp:138] Iteration 11410, lr = 0.001
I0826 16:06:20.279242 25446 solver.cpp:243] Iteration 11420, loss = 7.80915
I0826 16:06:20.279266 25446 solver.cpp:259]     Train net output #0: center_loss = 109.311 (* 0.008 = 0.874491 loss)
I0826 16:06:20.279273 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93466 (* 1 = 6.93466 loss)
I0826 16:06:20.279278 25446 sgd_solver.cpp:138] Iteration 11420, lr = 0.001
I0826 16:06:22.343165 25446 solver.cpp:243] Iteration 11430, loss = 7.52385
I0826 16:06:22.343293 25446 solver.cpp:259]     Train net output #0: center_loss = 94.4947 (* 0.008 = 0.755958 loss)
I0826 16:06:22.343302 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.76789 (* 1 = 6.76789 loss)
I0826 16:06:22.343305 25446 sgd_solver.cpp:138] Iteration 11430, lr = 0.001
I0826 16:06:24.402349 25446 solver.cpp:243] Iteration 11440, loss = 7.94429
I0826 16:06:24.402374 25446 solver.cpp:259]     Train net output #0: center_loss = 121.935 (* 0.008 = 0.975482 loss)
I0826 16:06:24.402380 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.96881 (* 1 = 6.96881 loss)
I0826 16:06:24.402384 25446 sgd_solver.cpp:138] Iteration 11440, lr = 0.001
I0826 16:06:26.466643 25446 solver.cpp:243] Iteration 11450, loss = 8.38581
I0826 16:06:26.466667 25446 solver.cpp:259]     Train net output #0: center_loss = 96.8786 (* 0.008 = 0.775029 loss)
I0826 16:06:26.466673 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.61078 (* 1 = 7.61078 loss)
I0826 16:06:26.466677 25446 sgd_solver.cpp:138] Iteration 11450, lr = 0.001
I0826 16:06:28.526871 25446 solver.cpp:243] Iteration 11460, loss = 7.86841
I0826 16:06:28.526895 25446 solver.cpp:259]     Train net output #0: center_loss = 104.672 (* 0.008 = 0.837374 loss)
I0826 16:06:28.526901 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.03103 (* 1 = 7.03103 loss)
I0826 16:06:28.526906 25446 sgd_solver.cpp:138] Iteration 11460, lr = 0.001
I0826 16:06:30.590088 25446 solver.cpp:243] Iteration 11470, loss = 8.24317
I0826 16:06:30.590112 25446 solver.cpp:259]     Train net output #0: center_loss = 127.291 (* 0.008 = 1.01833 loss)
I0826 16:06:30.590118 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.22485 (* 1 = 7.22485 loss)
I0826 16:06:30.590121 25446 sgd_solver.cpp:138] Iteration 11470, lr = 0.001
I0826 16:06:32.652974 25446 solver.cpp:243] Iteration 11480, loss = 7.56961
I0826 16:06:32.652998 25446 solver.cpp:259]     Train net output #0: center_loss = 121.569 (* 0.008 = 0.972553 loss)
I0826 16:06:32.653005 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.59706 (* 1 = 6.59706 loss)
I0826 16:06:32.653024 25446 sgd_solver.cpp:138] Iteration 11480, lr = 0.001
I0826 16:06:34.711552 25446 solver.cpp:243] Iteration 11490, loss = 7.853
I0826 16:06:34.711576 25446 solver.cpp:259]     Train net output #0: center_loss = 140.587 (* 0.008 = 1.1247 loss)
I0826 16:06:34.711582 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.72831 (* 1 = 6.72831 loss)
I0826 16:06:34.711601 25446 sgd_solver.cpp:138] Iteration 11490, lr = 0.001
I0826 16:06:36.773222 25446 solver.cpp:243] Iteration 11500, loss = 7.66715
I0826 16:06:36.773249 25446 solver.cpp:259]     Train net output #0: center_loss = 102.858 (* 0.008 = 0.822866 loss)
I0826 16:06:36.773255 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.84429 (* 1 = 6.84429 loss)
I0826 16:06:36.773259 25446 sgd_solver.cpp:138] Iteration 11500, lr = 0.001
I0826 16:06:38.835678 25446 solver.cpp:243] Iteration 11510, loss = 8.0664
I0826 16:06:38.835705 25446 solver.cpp:259]     Train net output #0: center_loss = 124.195 (* 0.008 = 0.993558 loss)
I0826 16:06:38.835711 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.07284 (* 1 = 7.07284 loss)
I0826 16:06:38.835714 25446 sgd_solver.cpp:138] Iteration 11510, lr = 0.001
I0826 16:06:40.900234 25446 solver.cpp:243] Iteration 11520, loss = 8.67421
I0826 16:06:40.900260 25446 solver.cpp:259]     Train net output #0: center_loss = 105.706 (* 0.008 = 0.845646 loss)
I0826 16:06:40.900266 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.82856 (* 1 = 7.82856 loss)
I0826 16:06:40.900270 25446 sgd_solver.cpp:138] Iteration 11520, lr = 0.001
I0826 16:06:42.961863 25446 solver.cpp:243] Iteration 11530, loss = 8.43744
I0826 16:06:42.961887 25446 solver.cpp:259]     Train net output #0: center_loss = 94.6102 (* 0.008 = 0.756881 loss)
I0826 16:06:42.961894 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.68056 (* 1 = 7.68056 loss)
I0826 16:06:42.961897 25446 sgd_solver.cpp:138] Iteration 11530, lr = 0.001
I0826 16:06:45.028053 25446 solver.cpp:243] Iteration 11540, loss = 7.36007
I0826 16:06:45.028079 25446 solver.cpp:259]     Train net output #0: center_loss = 131.754 (* 0.008 = 1.05403 loss)
I0826 16:06:45.028084 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.30604 (* 1 = 6.30604 loss)
I0826 16:06:45.028089 25446 sgd_solver.cpp:138] Iteration 11540, lr = 0.001
I0826 16:06:47.091023 25446 solver.cpp:243] Iteration 11550, loss = 8.48872
I0826 16:06:47.091048 25446 solver.cpp:259]     Train net output #0: center_loss = 108.983 (* 0.008 = 0.871865 loss)
I0826 16:06:47.091054 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.61686 (* 1 = 7.61686 loss)
I0826 16:06:47.091058 25446 sgd_solver.cpp:138] Iteration 11550, lr = 0.001
I0826 16:06:49.151660 25446 solver.cpp:243] Iteration 11560, loss = 8.01694
I0826 16:06:49.151685 25446 solver.cpp:259]     Train net output #0: center_loss = 103.354 (* 0.008 = 0.826832 loss)
I0826 16:06:49.151692 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.19011 (* 1 = 7.19011 loss)
I0826 16:06:49.151695 25446 sgd_solver.cpp:138] Iteration 11560, lr = 0.001
I0826 16:06:51.214848 25446 solver.cpp:243] Iteration 11570, loss = 6.56227
I0826 16:06:51.214874 25446 solver.cpp:259]     Train net output #0: center_loss = 155.218 (* 0.008 = 1.24174 loss)
I0826 16:06:51.214879 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.32053 (* 1 = 5.32053 loss)
I0826 16:06:51.214884 25446 sgd_solver.cpp:138] Iteration 11570, lr = 0.001
I0826 16:06:53.275705 25446 solver.cpp:243] Iteration 11580, loss = 8.03209
I0826 16:06:53.275859 25446 solver.cpp:259]     Train net output #0: center_loss = 96.0937 (* 0.008 = 0.76875 loss)
I0826 16:06:53.275878 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.26334 (* 1 = 7.26334 loss)
I0826 16:06:53.275882 25446 sgd_solver.cpp:138] Iteration 11580, lr = 0.001
I0826 16:06:55.340957 25446 solver.cpp:243] Iteration 11590, loss = 8.48204
I0826 16:06:55.340982 25446 solver.cpp:259]     Train net output #0: center_loss = 70.6512 (* 0.008 = 0.56521 loss)
I0826 16:06:55.340988 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91683 (* 1 = 7.91683 loss)
I0826 16:06:55.340991 25446 sgd_solver.cpp:138] Iteration 11590, lr = 0.001
I0826 16:06:57.403534 25446 solver.cpp:243] Iteration 11600, loss = 8.0955
I0826 16:06:57.403558 25446 solver.cpp:259]     Train net output #0: center_loss = 134.007 (* 0.008 = 1.07206 loss)
I0826 16:06:57.403564 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.02344 (* 1 = 7.02344 loss)
I0826 16:06:57.403568 25446 sgd_solver.cpp:138] Iteration 11600, lr = 0.001
I0826 16:06:59.466576 25446 solver.cpp:243] Iteration 11610, loss = 7.92414
I0826 16:06:59.466601 25446 solver.cpp:259]     Train net output #0: center_loss = 108.527 (* 0.008 = 0.868218 loss)
I0826 16:06:59.466609 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.05592 (* 1 = 7.05592 loss)
I0826 16:06:59.466612 25446 sgd_solver.cpp:138] Iteration 11610, lr = 0.001
I0826 16:07:01.527462 25446 solver.cpp:243] Iteration 11620, loss = 8.24198
I0826 16:07:01.527487 25446 solver.cpp:259]     Train net output #0: center_loss = 89.5761 (* 0.008 = 0.716609 loss)
I0826 16:07:01.527493 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.52537 (* 1 = 7.52537 loss)
I0826 16:07:01.527498 25446 sgd_solver.cpp:138] Iteration 11620, lr = 0.001
I0826 16:07:03.589789 25446 solver.cpp:243] Iteration 11630, loss = 7.92485
I0826 16:07:03.589814 25446 solver.cpp:259]     Train net output #0: center_loss = 128.001 (* 0.008 = 1.02401 loss)
I0826 16:07:03.589820 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.90084 (* 1 = 6.90084 loss)
I0826 16:07:03.589824 25446 sgd_solver.cpp:138] Iteration 11630, lr = 0.001
I0826 16:07:05.650092 25446 solver.cpp:243] Iteration 11640, loss = 8.0573
I0826 16:07:05.650117 25446 solver.cpp:259]     Train net output #0: center_loss = 102.411 (* 0.008 = 0.819284 loss)
I0826 16:07:05.650123 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.23801 (* 1 = 7.23801 loss)
I0826 16:07:05.650128 25446 sgd_solver.cpp:138] Iteration 11640, lr = 0.001
I0826 16:07:07.712157 25446 solver.cpp:243] Iteration 11650, loss = 7.90322
I0826 16:07:07.712183 25446 solver.cpp:259]     Train net output #0: center_loss = 123.12 (* 0.008 = 0.98496 loss)
I0826 16:07:07.712190 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.91826 (* 1 = 6.91826 loss)
I0826 16:07:07.712193 25446 sgd_solver.cpp:138] Iteration 11650, lr = 0.001
I0826 16:07:09.777206 25446 solver.cpp:243] Iteration 11660, loss = 8.29672
I0826 16:07:09.777230 25446 solver.cpp:259]     Train net output #0: center_loss = 104.374 (* 0.008 = 0.834991 loss)
I0826 16:07:09.777236 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.46173 (* 1 = 7.46173 loss)
I0826 16:07:09.777240 25446 sgd_solver.cpp:138] Iteration 11660, lr = 0.001
I0826 16:07:11.839562 25446 solver.cpp:243] Iteration 11670, loss = 7.60099
I0826 16:07:11.839586 25446 solver.cpp:259]     Train net output #0: center_loss = 124.189 (* 0.008 = 0.993511 loss)
I0826 16:07:11.839591 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.60748 (* 1 = 6.60748 loss)
I0826 16:07:11.839596 25446 sgd_solver.cpp:138] Iteration 11670, lr = 0.001
I0826 16:07:13.900794 25446 solver.cpp:243] Iteration 11680, loss = 7.70025
I0826 16:07:13.900818 25446 solver.cpp:259]     Train net output #0: center_loss = 130.132 (* 0.008 = 1.04106 loss)
I0826 16:07:13.900825 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.65919 (* 1 = 6.65919 loss)
I0826 16:07:13.900828 25446 sgd_solver.cpp:138] Iteration 11680, lr = 0.001
I0826 16:07:15.963732 25446 solver.cpp:243] Iteration 11690, loss = 7.68137
I0826 16:07:15.963757 25446 solver.cpp:259]     Train net output #0: center_loss = 113.428 (* 0.008 = 0.907423 loss)
I0826 16:07:15.963763 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.77394 (* 1 = 6.77394 loss)
I0826 16:07:15.963768 25446 sgd_solver.cpp:138] Iteration 11690, lr = 0.001
I0826 16:07:18.027361 25446 solver.cpp:243] Iteration 11700, loss = 8.69091
I0826 16:07:18.027386 25446 solver.cpp:259]     Train net output #0: center_loss = 96.5281 (* 0.008 = 0.772225 loss)
I0826 16:07:18.027392 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91868 (* 1 = 7.91868 loss)
I0826 16:07:18.027396 25446 sgd_solver.cpp:138] Iteration 11700, lr = 0.001
I0826 16:07:20.090485 25446 solver.cpp:243] Iteration 11710, loss = 7.93294
I0826 16:07:20.090510 25446 solver.cpp:259]     Train net output #0: center_loss = 125.454 (* 0.008 = 1.00363 loss)
I0826 16:07:20.090517 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.92931 (* 1 = 6.92931 loss)
I0826 16:07:20.090520 25446 sgd_solver.cpp:138] Iteration 11710, lr = 0.001
I0826 16:07:22.155683 25446 solver.cpp:243] Iteration 11720, loss = 8.25731
I0826 16:07:22.155706 25446 solver.cpp:259]     Train net output #0: center_loss = 109.036 (* 0.008 = 0.872288 loss)
I0826 16:07:22.155712 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.38503 (* 1 = 7.38503 loss)
I0826 16:07:22.155716 25446 sgd_solver.cpp:138] Iteration 11720, lr = 0.001
I0826 16:07:24.221071 25446 solver.cpp:243] Iteration 11730, loss = 8.30343
I0826 16:07:24.221197 25446 solver.cpp:259]     Train net output #0: center_loss = 109.343 (* 0.008 = 0.87474 loss)
I0826 16:07:24.221217 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.42869 (* 1 = 7.42869 loss)
I0826 16:07:24.221221 25446 sgd_solver.cpp:138] Iteration 11730, lr = 0.001
I0826 16:07:26.283550 25446 solver.cpp:243] Iteration 11740, loss = 8.14765
I0826 16:07:26.283573 25446 solver.cpp:259]     Train net output #0: center_loss = 74.9407 (* 0.008 = 0.599526 loss)
I0826 16:07:26.283579 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.54812 (* 1 = 7.54812 loss)
I0826 16:07:26.283582 25446 sgd_solver.cpp:138] Iteration 11740, lr = 0.001
I0826 16:07:28.347100 25446 solver.cpp:243] Iteration 11750, loss = 7.92939
I0826 16:07:28.347124 25446 solver.cpp:259]     Train net output #0: center_loss = 78.6616 (* 0.008 = 0.629293 loss)
I0826 16:07:28.347131 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.30009 (* 1 = 7.30009 loss)
I0826 16:07:28.347134 25446 sgd_solver.cpp:138] Iteration 11750, lr = 0.001
I0826 16:07:30.410079 25446 solver.cpp:243] Iteration 11760, loss = 8.61122
I0826 16:07:30.410105 25446 solver.cpp:259]     Train net output #0: center_loss = 87.4919 (* 0.008 = 0.699935 loss)
I0826 16:07:30.410111 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.91128 (* 1 = 7.91128 loss)
I0826 16:07:30.410115 25446 sgd_solver.cpp:138] Iteration 11760, lr = 0.001
I0826 16:07:32.471222 25446 solver.cpp:243] Iteration 11770, loss = 7.29853
I0826 16:07:32.471248 25446 solver.cpp:259]     Train net output #0: center_loss = 138.41 (* 0.008 = 1.10728 loss)
I0826 16:07:32.471253 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.19126 (* 1 = 6.19126 loss)
I0826 16:07:32.471258 25446 sgd_solver.cpp:138] Iteration 11770, lr = 0.001
I0826 16:07:34.535915 25446 solver.cpp:243] Iteration 11780, loss = 8.15
I0826 16:07:34.535939 25446 solver.cpp:259]     Train net output #0: center_loss = 96.2435 (* 0.008 = 0.769948 loss)
I0826 16:07:34.535945 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.38005 (* 1 = 7.38005 loss)
I0826 16:07:34.535949 25446 sgd_solver.cpp:138] Iteration 11780, lr = 0.001
I0826 16:07:36.595177 25446 solver.cpp:243] Iteration 11790, loss = 7.60207
I0826 16:07:36.595201 25446 solver.cpp:259]     Train net output #0: center_loss = 133.468 (* 0.008 = 1.06774 loss)
I0826 16:07:36.595207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.53433 (* 1 = 6.53433 loss)
I0826 16:07:36.595211 25446 sgd_solver.cpp:138] Iteration 11790, lr = 0.001
I0826 16:07:38.656186 25446 solver.cpp:243] Iteration 11800, loss = 7.90035
I0826 16:07:38.656211 25446 solver.cpp:259]     Train net output #0: center_loss = 86.9303 (* 0.008 = 0.695442 loss)
I0826 16:07:38.656217 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.20491 (* 1 = 7.20491 loss)
I0826 16:07:38.656221 25446 sgd_solver.cpp:138] Iteration 11800, lr = 0.001
I0826 16:07:40.717054 25446 solver.cpp:243] Iteration 11810, loss = 8.3531
I0826 16:07:40.717082 25446 solver.cpp:259]     Train net output #0: center_loss = 101.842 (* 0.008 = 0.814739 loss)
I0826 16:07:40.717087 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.53836 (* 1 = 7.53836 loss)
I0826 16:07:40.717092 25446 sgd_solver.cpp:138] Iteration 11810, lr = 0.001
I0826 16:07:42.778381 25446 solver.cpp:243] Iteration 11820, loss = 8.23217
I0826 16:07:42.778405 25446 solver.cpp:259]     Train net output #0: center_loss = 97.0994 (* 0.008 = 0.776795 loss)
I0826 16:07:42.778411 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.45538 (* 1 = 7.45538 loss)
I0826 16:07:42.778415 25446 sgd_solver.cpp:138] Iteration 11820, lr = 0.001
I0826 16:07:44.841897 25446 solver.cpp:243] Iteration 11830, loss = 7.20581
I0826 16:07:44.841922 25446 solver.cpp:259]     Train net output #0: center_loss = 116.94 (* 0.008 = 0.935516 loss)
I0826 16:07:44.841928 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.27029 (* 1 = 6.27029 loss)
I0826 16:07:44.841933 25446 sgd_solver.cpp:138] Iteration 11830, lr = 0.001
I0826 16:07:46.900988 25446 solver.cpp:243] Iteration 11840, loss = 7.82395
I0826 16:07:46.901012 25446 solver.cpp:259]     Train net output #0: center_loss = 119.319 (* 0.008 = 0.954551 loss)
I0826 16:07:46.901018 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.8694 (* 1 = 6.8694 loss)
I0826 16:07:46.901022 25446 sgd_solver.cpp:138] Iteration 11840, lr = 0.001
I0826 16:07:48.964977 25446 solver.cpp:243] Iteration 11850, loss = 8.1924
I0826 16:07:48.965000 25446 solver.cpp:259]     Train net output #0: center_loss = 94.9921 (* 0.008 = 0.759936 loss)
I0826 16:07:48.965006 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.43247 (* 1 = 7.43247 loss)
I0826 16:07:48.965010 25446 sgd_solver.cpp:138] Iteration 11850, lr = 0.001
I0826 16:07:51.022670 25446 solver.cpp:243] Iteration 11860, loss = 7.90658
I0826 16:07:51.022708 25446 solver.cpp:259]     Train net output #0: center_loss = 135.414 (* 0.008 = 1.08332 loss)
I0826 16:07:51.022716 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.82327 (* 1 = 6.82327 loss)
I0826 16:07:51.022719 25446 sgd_solver.cpp:138] Iteration 11860, lr = 0.001
I0826 16:07:53.085081 25446 solver.cpp:243] Iteration 11870, loss = 8.06963
I0826 16:07:53.085104 25446 solver.cpp:259]     Train net output #0: center_loss = 125.779 (* 0.008 = 1.00623 loss)
I0826 16:07:53.085110 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.0634 (* 1 = 7.0634 loss)
I0826 16:07:53.085114 25446 sgd_solver.cpp:138] Iteration 11870, lr = 0.001
I0826 16:07:55.147639 25446 solver.cpp:243] Iteration 11880, loss = 7.92249
I0826 16:07:55.147781 25446 solver.cpp:259]     Train net output #0: center_loss = 100.376 (* 0.008 = 0.80301 loss)
I0826 16:07:55.147801 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.11948 (* 1 = 7.11948 loss)
I0826 16:07:55.147820 25446 sgd_solver.cpp:138] Iteration 11880, lr = 0.001
I0826 16:07:57.212518 25446 solver.cpp:243] Iteration 11890, loss = 8.10882
I0826 16:07:57.212543 25446 solver.cpp:259]     Train net output #0: center_loss = 112.725 (* 0.008 = 0.901797 loss)
I0826 16:07:57.212548 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.20702 (* 1 = 7.20702 loss)
I0826 16:07:57.212553 25446 sgd_solver.cpp:138] Iteration 11890, lr = 0.001
I0826 16:07:59.273612 25446 solver.cpp:243] Iteration 11900, loss = 7.91045
I0826 16:07:59.273649 25446 solver.cpp:259]     Train net output #0: center_loss = 106.646 (* 0.008 = 0.85317 loss)
I0826 16:07:59.273655 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.05728 (* 1 = 7.05728 loss)
I0826 16:07:59.273659 25446 sgd_solver.cpp:138] Iteration 11900, lr = 0.001
I0826 16:08:01.337134 25446 solver.cpp:243] Iteration 11910, loss = 6.91057
I0826 16:08:01.337158 25446 solver.cpp:259]     Train net output #0: center_loss = 143.612 (* 0.008 = 1.14889 loss)
I0826 16:08:01.337164 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.76168 (* 1 = 5.76168 loss)
I0826 16:08:01.337168 25446 sgd_solver.cpp:138] Iteration 11910, lr = 0.001
I0826 16:08:03.396433 25446 solver.cpp:243] Iteration 11920, loss = 7.32292
I0826 16:08:03.396457 25446 solver.cpp:259]     Train net output #0: center_loss = 128.192 (* 0.008 = 1.02554 loss)
I0826 16:08:03.396464 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.29738 (* 1 = 6.29738 loss)
I0826 16:08:03.396468 25446 sgd_solver.cpp:138] Iteration 11920, lr = 0.001
I0826 16:08:05.454834 25446 solver.cpp:243] Iteration 11930, loss = 8.27496
I0826 16:08:05.454859 25446 solver.cpp:259]     Train net output #0: center_loss = 102.405 (* 0.008 = 0.819243 loss)
I0826 16:08:05.454864 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.45571 (* 1 = 7.45571 loss)
I0826 16:08:05.454869 25446 sgd_solver.cpp:138] Iteration 11930, lr = 0.001
I0826 16:08:07.516777 25446 solver.cpp:243] Iteration 11940, loss = 7.93064
I0826 16:08:07.516816 25446 solver.cpp:259]     Train net output #0: center_loss = 112.407 (* 0.008 = 0.899254 loss)
I0826 16:08:07.516824 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.03139 (* 1 = 7.03139 loss)
I0826 16:08:07.516827 25446 sgd_solver.cpp:138] Iteration 11940, lr = 0.001
I0826 16:08:09.576624 25446 solver.cpp:243] Iteration 11950, loss = 7.73685
I0826 16:08:09.576650 25446 solver.cpp:259]     Train net output #0: center_loss = 124.216 (* 0.008 = 0.993731 loss)
I0826 16:08:09.576656 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.74312 (* 1 = 6.74312 loss)
I0826 16:08:09.576660 25446 sgd_solver.cpp:138] Iteration 11950, lr = 0.001
I0826 16:08:11.635927 25446 solver.cpp:243] Iteration 11960, loss = 7.52506
I0826 16:08:11.635951 25446 solver.cpp:259]     Train net output #0: center_loss = 105.278 (* 0.008 = 0.842223 loss)
I0826 16:08:11.635957 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.68284 (* 1 = 6.68284 loss)
I0826 16:08:11.635962 25446 sgd_solver.cpp:138] Iteration 11960, lr = 0.001
I0826 16:08:13.698629 25446 solver.cpp:243] Iteration 11970, loss = 7.98078
I0826 16:08:13.698654 25446 solver.cpp:259]     Train net output #0: center_loss = 111.316 (* 0.008 = 0.890531 loss)
I0826 16:08:13.698660 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.09025 (* 1 = 7.09025 loss)
I0826 16:08:13.698664 25446 sgd_solver.cpp:138] Iteration 11970, lr = 0.001
I0826 16:08:15.760625 25446 solver.cpp:243] Iteration 11980, loss = 7.6261
I0826 16:08:15.760649 25446 solver.cpp:259]     Train net output #0: center_loss = 122.179 (* 0.008 = 0.977432 loss)
I0826 16:08:15.760655 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.64866 (* 1 = 6.64866 loss)
I0826 16:08:15.760659 25446 sgd_solver.cpp:138] Iteration 11980, lr = 0.001
I0826 16:08:17.819811 25446 solver.cpp:243] Iteration 11990, loss = 8.2958
I0826 16:08:17.819835 25446 solver.cpp:259]     Train net output #0: center_loss = 90.7014 (* 0.008 = 0.725611 loss)
I0826 16:08:17.819841 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.57018 (* 1 = 7.57018 loss)
I0826 16:08:17.819845 25446 sgd_solver.cpp:138] Iteration 11990, lr = 0.001
I0826 16:08:19.679378 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_12000.caffemodel
I0826 16:08:20.821460 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_12000.solverstate
I0826 16:08:21.152272 25446 solver.cpp:243] Iteration 12000, loss = 8.41074
I0826 16:08:21.152297 25446 solver.cpp:259]     Train net output #0: center_loss = 88.59 (* 0.008 = 0.70872 loss)
I0826 16:08:21.152302 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.70202 (* 1 = 7.70202 loss)
I0826 16:08:21.152307 25446 sgd_solver.cpp:138] Iteration 12000, lr = 0.001
I0826 16:08:23.212419 25446 solver.cpp:243] Iteration 12010, loss = 7.71756
I0826 16:08:23.212443 25446 solver.cpp:259]     Train net output #0: center_loss = 108.913 (* 0.008 = 0.871303 loss)
I0826 16:08:23.212450 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.84626 (* 1 = 6.84626 loss)
I0826 16:08:23.212453 25446 sgd_solver.cpp:138] Iteration 12010, lr = 0.001
I0826 16:08:25.273242 25446 solver.cpp:243] Iteration 12020, loss = 7.66617
I0826 16:08:25.273355 25446 solver.cpp:259]     Train net output #0: center_loss = 126.693 (* 0.008 = 1.01355 loss)
I0826 16:08:25.273375 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.65263 (* 1 = 6.65263 loss)
I0826 16:08:25.273378 25446 sgd_solver.cpp:138] Iteration 12020, lr = 0.001
I0826 16:08:27.333144 25446 solver.cpp:243] Iteration 12030, loss = 7.9028
I0826 16:08:27.333169 25446 solver.cpp:259]     Train net output #0: center_loss = 107.588 (* 0.008 = 0.860702 loss)
I0826 16:08:27.333175 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.0421 (* 1 = 7.0421 loss)
I0826 16:08:27.333179 25446 sgd_solver.cpp:138] Iteration 12030, lr = 0.001
I0826 16:08:29.398905 25446 solver.cpp:243] Iteration 12040, loss = 8.01666
I0826 16:08:29.398939 25446 solver.cpp:259]     Train net output #0: center_loss = 128.747 (* 0.008 = 1.02998 loss)
I0826 16:08:29.398946 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.98668 (* 1 = 6.98668 loss)
I0826 16:08:29.398949 25446 sgd_solver.cpp:138] Iteration 12040, lr = 0.001
I0826 16:08:31.457754 25446 solver.cpp:243] Iteration 12050, loss = 7.97779
I0826 16:08:31.457778 25446 solver.cpp:259]     Train net output #0: center_loss = 119.338 (* 0.008 = 0.954708 loss)
I0826 16:08:31.457784 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.02308 (* 1 = 7.02308 loss)
I0826 16:08:31.457788 25446 sgd_solver.cpp:138] Iteration 12050, lr = 0.001
I0826 16:08:33.515084 25446 solver.cpp:243] Iteration 12060, loss = 8.10461
I0826 16:08:33.515137 25446 solver.cpp:259]     Train net output #0: center_loss = 106.947 (* 0.008 = 0.855578 loss)
I0826 16:08:33.515144 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.24903 (* 1 = 7.24903 loss)
I0826 16:08:33.515148 25446 sgd_solver.cpp:138] Iteration 12060, lr = 0.001
I0826 16:08:35.578296 25446 solver.cpp:243] Iteration 12070, loss = 7.06409
I0826 16:08:35.578322 25446 solver.cpp:259]     Train net output #0: center_loss = 112.927 (* 0.008 = 0.903419 loss)
I0826 16:08:35.578330 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.16067 (* 1 = 6.16067 loss)
I0826 16:08:35.578333 25446 sgd_solver.cpp:138] Iteration 12070, lr = 0.001
I0826 16:08:37.638100 25446 solver.cpp:243] Iteration 12080, loss = 8.44792
I0826 16:08:37.638139 25446 solver.cpp:259]     Train net output #0: center_loss = 108.404 (* 0.008 = 0.867233 loss)
I0826 16:08:37.638145 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.58069 (* 1 = 7.58069 loss)
I0826 16:08:37.638149 25446 sgd_solver.cpp:138] Iteration 12080, lr = 0.001
I0826 16:08:39.702520 25446 solver.cpp:243] Iteration 12090, loss = 7.20099
I0826 16:08:39.702560 25446 solver.cpp:259]     Train net output #0: center_loss = 117.014 (* 0.008 = 0.936116 loss)
I0826 16:08:39.702567 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.26487 (* 1 = 6.26487 loss)
I0826 16:08:39.702571 25446 sgd_solver.cpp:138] Iteration 12090, lr = 0.001
I0826 16:08:41.762771 25446 solver.cpp:243] Iteration 12100, loss = 8.05956
I0826 16:08:41.762811 25446 solver.cpp:259]     Train net output #0: center_loss = 109.079 (* 0.008 = 0.872635 loss)
I0826 16:08:41.762817 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.18692 (* 1 = 7.18692 loss)
I0826 16:08:41.762821 25446 sgd_solver.cpp:138] Iteration 12100, lr = 0.001
I0826 16:08:43.825182 25446 solver.cpp:243] Iteration 12110, loss = 7.82369
I0826 16:08:43.825207 25446 solver.cpp:259]     Train net output #0: center_loss = 122.439 (* 0.008 = 0.97951 loss)
I0826 16:08:43.825213 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.84418 (* 1 = 6.84418 loss)
I0826 16:08:43.825217 25446 sgd_solver.cpp:138] Iteration 12110, lr = 0.001
I0826 16:08:45.887075 25446 solver.cpp:243] Iteration 12120, loss = 8.2241
I0826 16:08:45.887115 25446 solver.cpp:259]     Train net output #0: center_loss = 102.155 (* 0.008 = 0.81724 loss)
I0826 16:08:45.887120 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.40686 (* 1 = 7.40686 loss)
I0826 16:08:45.887125 25446 sgd_solver.cpp:138] Iteration 12120, lr = 0.001
I0826 16:08:47.950289 25446 solver.cpp:243] Iteration 12130, loss = 7.88827
I0826 16:08:47.950314 25446 solver.cpp:259]     Train net output #0: center_loss = 109.038 (* 0.008 = 0.872304 loss)
I0826 16:08:47.950318 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.01596 (* 1 = 7.01596 loss)
I0826 16:08:47.950323 25446 sgd_solver.cpp:138] Iteration 12130, lr = 0.001
I0826 16:08:50.007642 25446 solver.cpp:243] Iteration 12140, loss = 7.98048
I0826 16:08:50.007666 25446 solver.cpp:259]     Train net output #0: center_loss = 118.387 (* 0.008 = 0.947098 loss)
I0826 16:08:50.007673 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.03338 (* 1 = 7.03338 loss)
I0826 16:08:50.007675 25446 sgd_solver.cpp:138] Iteration 12140, lr = 0.001
I0826 16:08:52.069352 25446 solver.cpp:243] Iteration 12150, loss = 7.13984
I0826 16:08:52.069394 25446 solver.cpp:259]     Train net output #0: center_loss = 121.574 (* 0.008 = 0.972588 loss)
I0826 16:08:52.069401 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.16725 (* 1 = 6.16725 loss)
I0826 16:08:52.069406 25446 sgd_solver.cpp:138] Iteration 12150, lr = 0.001
I0826 16:08:54.132942 25446 solver.cpp:243] Iteration 12160, loss = 8.9836
I0826 16:08:54.132967 25446 solver.cpp:259]     Train net output #0: center_loss = 106.935 (* 0.008 = 0.855477 loss)
I0826 16:08:54.132973 25446 solver.cpp:259]     Train net output #1: softmax_loss = 8.12812 (* 1 = 8.12812 loss)
I0826 16:08:54.132977 25446 sgd_solver.cpp:138] Iteration 12160, lr = 0.001
I0826 16:08:56.194898 25446 solver.cpp:243] Iteration 12170, loss = 7.71417
I0826 16:08:56.195024 25446 solver.cpp:259]     Train net output #0: center_loss = 100.163 (* 0.008 = 0.801304 loss)
I0826 16:08:56.195045 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.91286 (* 1 = 6.91286 loss)
I0826 16:08:56.195050 25446 sgd_solver.cpp:138] Iteration 12170, lr = 0.001
I0826 16:08:58.254534 25446 solver.cpp:243] Iteration 12180, loss = 7.77527
I0826 16:08:58.254559 25446 solver.cpp:259]     Train net output #0: center_loss = 125.204 (* 0.008 = 1.00163 loss)
I0826 16:08:58.254565 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.77364 (* 1 = 6.77364 loss)
I0826 16:08:58.254568 25446 sgd_solver.cpp:138] Iteration 12180, lr = 0.001
I0826 16:09:00.321336 25446 solver.cpp:243] Iteration 12190, loss = 7.51904
I0826 16:09:00.321360 25446 solver.cpp:259]     Train net output #0: center_loss = 122.552 (* 0.008 = 0.980414 loss)
I0826 16:09:00.321367 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.53863 (* 1 = 6.53863 loss)
I0826 16:09:00.321370 25446 sgd_solver.cpp:138] Iteration 12190, lr = 0.001
I0826 16:09:02.381461 25446 solver.cpp:243] Iteration 12200, loss = 8.58274
I0826 16:09:02.381501 25446 solver.cpp:259]     Train net output #0: center_loss = 97.8126 (* 0.008 = 0.782501 loss)
I0826 16:09:02.381507 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.80024 (* 1 = 7.80024 loss)
I0826 16:09:02.381510 25446 sgd_solver.cpp:138] Iteration 12200, lr = 0.001
I0826 16:09:04.442840 25446 solver.cpp:243] Iteration 12210, loss = 8.10823
I0826 16:09:04.442881 25446 solver.cpp:259]     Train net output #0: center_loss = 100.71 (* 0.008 = 0.805684 loss)
I0826 16:09:04.442888 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.30255 (* 1 = 7.30255 loss)
I0826 16:09:04.442891 25446 sgd_solver.cpp:138] Iteration 12210, lr = 0.001
I0826 16:09:06.506906 25446 solver.cpp:243] Iteration 12220, loss = 8.12631
I0826 16:09:06.506944 25446 solver.cpp:259]     Train net output #0: center_loss = 134.253 (* 0.008 = 1.07402 loss)
I0826 16:09:06.506950 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.05229 (* 1 = 7.05229 loss)
I0826 16:09:06.506954 25446 sgd_solver.cpp:138] Iteration 12220, lr = 0.001
I0826 16:09:08.571511 25446 solver.cpp:243] Iteration 12230, loss = 8.07971
I0826 16:09:08.571550 25446 solver.cpp:259]     Train net output #0: center_loss = 101.788 (* 0.008 = 0.814302 loss)
I0826 16:09:08.571557 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.2654 (* 1 = 7.2654 loss)
I0826 16:09:08.571560 25446 sgd_solver.cpp:138] Iteration 12230, lr = 0.001
I0826 16:09:10.635576 25446 solver.cpp:243] Iteration 12240, loss = 7.90508
I0826 16:09:10.635615 25446 solver.cpp:259]     Train net output #0: center_loss = 112.587 (* 0.008 = 0.900693 loss)
I0826 16:09:10.635622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.00438 (* 1 = 7.00438 loss)
I0826 16:09:10.635625 25446 sgd_solver.cpp:138] Iteration 12240, lr = 0.001
I0826 16:09:12.702100 25446 solver.cpp:243] Iteration 12250, loss = 7.75958
I0826 16:09:12.702122 25446 solver.cpp:259]     Train net output #0: center_loss = 109.971 (* 0.008 = 0.879771 loss)
I0826 16:09:12.702128 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.87981 (* 1 = 6.87981 loss)
I0826 16:09:12.702132 25446 sgd_solver.cpp:138] Iteration 12250, lr = 0.001
I0826 16:09:14.764328 25446 solver.cpp:243] Iteration 12260, loss = 8.41273
I0826 16:09:14.764369 25446 solver.cpp:259]     Train net output #0: center_loss = 111.266 (* 0.008 = 0.890125 loss)
I0826 16:09:14.764374 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.52261 (* 1 = 7.52261 loss)
I0826 16:09:14.764377 25446 sgd_solver.cpp:138] Iteration 12260, lr = 0.001
I0826 16:09:16.822161 25446 solver.cpp:243] Iteration 12270, loss = 8.40244
I0826 16:09:16.822201 25446 solver.cpp:259]     Train net output #0: center_loss = 93.4947 (* 0.008 = 0.747957 loss)
I0826 16:09:16.822207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.65448 (* 1 = 7.65448 loss)
I0826 16:09:16.822211 25446 sgd_solver.cpp:138] Iteration 12270, lr = 0.001
I0826 16:09:18.884668 25446 solver.cpp:243] Iteration 12280, loss = 7.57077
I0826 16:09:18.884706 25446 solver.cpp:259]     Train net output #0: center_loss = 150.904 (* 0.008 = 1.20723 loss)
I0826 16:09:18.884712 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.36354 (* 1 = 6.36354 loss)
I0826 16:09:18.884716 25446 sgd_solver.cpp:138] Iteration 12280, lr = 0.001
I0826 16:09:20.946550 25446 solver.cpp:243] Iteration 12290, loss = 7.94162
I0826 16:09:20.946589 25446 solver.cpp:259]     Train net output #0: center_loss = 124.859 (* 0.008 = 0.998872 loss)
I0826 16:09:20.946595 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.94275 (* 1 = 6.94275 loss)
I0826 16:09:20.946599 25446 sgd_solver.cpp:138] Iteration 12290, lr = 0.001
I0826 16:09:23.009469 25446 solver.cpp:243] Iteration 12300, loss = 7.69881
I0826 16:09:23.009492 25446 solver.cpp:259]     Train net output #0: center_loss = 125.558 (* 0.008 = 1.00447 loss)
I0826 16:09:23.009498 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.69434 (* 1 = 6.69434 loss)
I0826 16:09:23.009502 25446 sgd_solver.cpp:138] Iteration 12300, lr = 0.001
I0826 16:09:25.070777 25446 solver.cpp:243] Iteration 12310, loss = 7.73299
I0826 16:09:25.070801 25446 solver.cpp:259]     Train net output #0: center_loss = 155.386 (* 0.008 = 1.24309 loss)
I0826 16:09:25.070807 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.4899 (* 1 = 6.4899 loss)
I0826 16:09:25.070811 25446 sgd_solver.cpp:138] Iteration 12310, lr = 0.001
I0826 16:09:27.131418 25446 solver.cpp:243] Iteration 12320, loss = 8.30583
I0826 16:09:27.131542 25446 solver.cpp:259]     Train net output #0: center_loss = 92.5544 (* 0.008 = 0.740435 loss)
I0826 16:09:27.131562 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.56539 (* 1 = 7.56539 loss)
I0826 16:09:27.131567 25446 sgd_solver.cpp:138] Iteration 12320, lr = 0.001
I0826 16:09:29.193526 25446 solver.cpp:243] Iteration 12330, loss = 8.01459
I0826 16:09:29.193549 25446 solver.cpp:259]     Train net output #0: center_loss = 106.838 (* 0.008 = 0.854701 loss)
I0826 16:09:29.193557 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.15989 (* 1 = 7.15989 loss)
I0826 16:09:29.193560 25446 sgd_solver.cpp:138] Iteration 12330, lr = 0.001
I0826 16:09:31.256844 25446 solver.cpp:243] Iteration 12340, loss = 7.77589
I0826 16:09:31.256868 25446 solver.cpp:259]     Train net output #0: center_loss = 94.0398 (* 0.008 = 0.752319 loss)
I0826 16:09:31.256875 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.02357 (* 1 = 7.02357 loss)
I0826 16:09:31.256878 25446 sgd_solver.cpp:138] Iteration 12340, lr = 0.001
I0826 16:09:33.316011 25446 solver.cpp:243] Iteration 12350, loss = 7.68341
I0826 16:09:33.316035 25446 solver.cpp:259]     Train net output #0: center_loss = 128.498 (* 0.008 = 1.02798 loss)
I0826 16:09:33.316041 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.65543 (* 1 = 6.65543 loss)
I0826 16:09:33.316045 25446 sgd_solver.cpp:138] Iteration 12350, lr = 0.001
I0826 16:09:35.375102 25446 solver.cpp:243] Iteration 12360, loss = 7.90628
I0826 16:09:35.375128 25446 solver.cpp:259]     Train net output #0: center_loss = 102.526 (* 0.008 = 0.82021 loss)
I0826 16:09:35.375133 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.08607 (* 1 = 7.08607 loss)
I0826 16:09:35.375138 25446 sgd_solver.cpp:138] Iteration 12360, lr = 0.001
I0826 16:09:37.433152 25446 solver.cpp:243] Iteration 12370, loss = 7.64981
I0826 16:09:37.433176 25446 solver.cpp:259]     Train net output #0: center_loss = 115.497 (* 0.008 = 0.923975 loss)
I0826 16:09:37.433182 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.72584 (* 1 = 6.72584 loss)
I0826 16:09:37.433187 25446 sgd_solver.cpp:138] Iteration 12370, lr = 0.001
I0826 16:09:39.493386 25446 solver.cpp:243] Iteration 12380, loss = 8.1334
I0826 16:09:39.493427 25446 solver.cpp:259]     Train net output #0: center_loss = 85.9971 (* 0.008 = 0.687977 loss)
I0826 16:09:39.493433 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.44542 (* 1 = 7.44542 loss)
I0826 16:09:39.493438 25446 sgd_solver.cpp:138] Iteration 12380, lr = 0.001
I0826 16:09:41.556069 25446 solver.cpp:243] Iteration 12390, loss = 7.08412
I0826 16:09:41.556093 25446 solver.cpp:259]     Train net output #0: center_loss = 136.684 (* 0.008 = 1.09347 loss)
I0826 16:09:41.556099 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.99064 (* 1 = 5.99064 loss)
I0826 16:09:41.556103 25446 sgd_solver.cpp:138] Iteration 12390, lr = 0.001
I0826 16:09:43.616793 25446 solver.cpp:243] Iteration 12400, loss = 7.46435
I0826 16:09:43.616817 25446 solver.cpp:259]     Train net output #0: center_loss = 131.825 (* 0.008 = 1.0546 loss)
I0826 16:09:43.616823 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.40975 (* 1 = 6.40975 loss)
I0826 16:09:43.616827 25446 sgd_solver.cpp:138] Iteration 12400, lr = 0.001
I0826 16:09:45.677992 25446 solver.cpp:243] Iteration 12410, loss = 7.75488
I0826 16:09:45.678016 25446 solver.cpp:259]     Train net output #0: center_loss = 117.281 (* 0.008 = 0.93825 loss)
I0826 16:09:45.678022 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.81663 (* 1 = 6.81663 loss)
I0826 16:09:45.678027 25446 sgd_solver.cpp:138] Iteration 12410, lr = 0.001
I0826 16:09:47.741706 25446 solver.cpp:243] Iteration 12420, loss = 7.7604
I0826 16:09:47.741730 25446 solver.cpp:259]     Train net output #0: center_loss = 149.409 (* 0.008 = 1.19527 loss)
I0826 16:09:47.741736 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.56513 (* 1 = 6.56513 loss)
I0826 16:09:47.741740 25446 sgd_solver.cpp:138] Iteration 12420, lr = 0.001
I0826 16:09:49.804275 25446 solver.cpp:243] Iteration 12430, loss = 8.19449
I0826 16:09:49.804301 25446 solver.cpp:259]     Train net output #0: center_loss = 98.8822 (* 0.008 = 0.791057 loss)
I0826 16:09:49.804306 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.40343 (* 1 = 7.40343 loss)
I0826 16:09:49.804309 25446 sgd_solver.cpp:138] Iteration 12430, lr = 0.001
I0826 16:09:51.865283 25446 solver.cpp:243] Iteration 12440, loss = 7.80343
I0826 16:09:51.865305 25446 solver.cpp:259]     Train net output #0: center_loss = 132.286 (* 0.008 = 1.05829 loss)
I0826 16:09:51.865311 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.74514 (* 1 = 6.74514 loss)
I0826 16:09:51.865315 25446 sgd_solver.cpp:138] Iteration 12440, lr = 0.001
I0826 16:09:53.930775 25446 solver.cpp:243] Iteration 12450, loss = 8.00929
I0826 16:09:53.930814 25446 solver.cpp:259]     Train net output #0: center_loss = 84.0709 (* 0.008 = 0.672567 loss)
I0826 16:09:53.930819 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.33672 (* 1 = 7.33672 loss)
I0826 16:09:53.930824 25446 sgd_solver.cpp:138] Iteration 12450, lr = 0.001
I0826 16:09:55.991101 25446 solver.cpp:243] Iteration 12460, loss = 7.5934
I0826 16:09:55.991125 25446 solver.cpp:259]     Train net output #0: center_loss = 144.636 (* 0.008 = 1.15709 loss)
I0826 16:09:55.991145 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.43631 (* 1 = 6.43631 loss)
I0826 16:09:55.991149 25446 sgd_solver.cpp:138] Iteration 12460, lr = 0.001
I0826 16:09:58.054024 25446 solver.cpp:243] Iteration 12470, loss = 8.56903
I0826 16:09:58.054162 25446 solver.cpp:259]     Train net output #0: center_loss = 88.4859 (* 0.008 = 0.707887 loss)
I0826 16:09:58.054183 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.86115 (* 1 = 7.86115 loss)
I0826 16:09:58.054188 25446 sgd_solver.cpp:138] Iteration 12470, lr = 0.001
I0826 16:10:00.118644 25446 solver.cpp:243] Iteration 12480, loss = 8.28229
I0826 16:10:00.118669 25446 solver.cpp:259]     Train net output #0: center_loss = 122.258 (* 0.008 = 0.978063 loss)
I0826 16:10:00.118675 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.30423 (* 1 = 7.30423 loss)
I0826 16:10:00.118680 25446 sgd_solver.cpp:138] Iteration 12480, lr = 0.001
I0826 16:10:02.180197 25446 solver.cpp:243] Iteration 12490, loss = 6.88739
I0826 16:10:02.180222 25446 solver.cpp:259]     Train net output #0: center_loss = 150.794 (* 0.008 = 1.20635 loss)
I0826 16:10:02.180227 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.68105 (* 1 = 5.68105 loss)
I0826 16:10:02.180232 25446 sgd_solver.cpp:138] Iteration 12490, lr = 0.001
I0826 16:10:04.242455 25446 solver.cpp:243] Iteration 12500, loss = 7.75898
I0826 16:10:04.242480 25446 solver.cpp:259]     Train net output #0: center_loss = 139.674 (* 0.008 = 1.11739 loss)
I0826 16:10:04.242486 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.64159 (* 1 = 6.64159 loss)
I0826 16:10:04.242489 25446 sgd_solver.cpp:138] Iteration 12500, lr = 0.001
I0826 16:10:06.304817 25446 solver.cpp:243] Iteration 12510, loss = 7.59061
I0826 16:10:06.304841 25446 solver.cpp:259]     Train net output #0: center_loss = 105.952 (* 0.008 = 0.847618 loss)
I0826 16:10:06.304848 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.74299 (* 1 = 6.74299 loss)
I0826 16:10:06.304852 25446 sgd_solver.cpp:138] Iteration 12510, lr = 0.001
I0826 16:10:08.366003 25446 solver.cpp:243] Iteration 12520, loss = 7.56127
I0826 16:10:08.366026 25446 solver.cpp:259]     Train net output #0: center_loss = 121.492 (* 0.008 = 0.971937 loss)
I0826 16:10:08.366032 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.58933 (* 1 = 6.58933 loss)
I0826 16:10:08.366036 25446 sgd_solver.cpp:138] Iteration 12520, lr = 0.001
I0826 16:10:10.424314 25446 solver.cpp:243] Iteration 12530, loss = 7.78681
I0826 16:10:10.424355 25446 solver.cpp:259]     Train net output #0: center_loss = 119.51 (* 0.008 = 0.956078 loss)
I0826 16:10:10.424360 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.83073 (* 1 = 6.83073 loss)
I0826 16:10:10.424365 25446 sgd_solver.cpp:138] Iteration 12530, lr = 0.001
I0826 16:10:12.488495 25446 solver.cpp:243] Iteration 12540, loss = 7.68456
I0826 16:10:12.488520 25446 solver.cpp:259]     Train net output #0: center_loss = 108.417 (* 0.008 = 0.867337 loss)
I0826 16:10:12.488526 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.81722 (* 1 = 6.81722 loss)
I0826 16:10:12.488529 25446 sgd_solver.cpp:138] Iteration 12540, lr = 0.001
I0826 16:10:14.550370 25446 solver.cpp:243] Iteration 12550, loss = 7.85711
I0826 16:10:14.550392 25446 solver.cpp:259]     Train net output #0: center_loss = 113.781 (* 0.008 = 0.910249 loss)
I0826 16:10:14.550398 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.94686 (* 1 = 6.94686 loss)
I0826 16:10:14.550402 25446 sgd_solver.cpp:138] Iteration 12550, lr = 0.001
I0826 16:10:16.612656 25446 solver.cpp:243] Iteration 12560, loss = 8.02644
I0826 16:10:16.612680 25446 solver.cpp:259]     Train net output #0: center_loss = 99.5286 (* 0.008 = 0.796229 loss)
I0826 16:10:16.612686 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.23021 (* 1 = 7.23021 loss)
I0826 16:10:16.612690 25446 sgd_solver.cpp:138] Iteration 12560, lr = 0.001
I0826 16:10:18.675333 25446 solver.cpp:243] Iteration 12570, loss = 7.763
I0826 16:10:18.675357 25446 solver.cpp:259]     Train net output #0: center_loss = 91.734 (* 0.008 = 0.733872 loss)
I0826 16:10:18.675364 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.02913 (* 1 = 7.02913 loss)
I0826 16:10:18.675367 25446 sgd_solver.cpp:138] Iteration 12570, lr = 0.001
I0826 16:10:20.740825 25446 solver.cpp:243] Iteration 12580, loss = 7.87554
I0826 16:10:20.740865 25446 solver.cpp:259]     Train net output #0: center_loss = 111.177 (* 0.008 = 0.889412 loss)
I0826 16:10:20.740871 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.98613 (* 1 = 6.98613 loss)
I0826 16:10:20.740875 25446 sgd_solver.cpp:138] Iteration 12580, lr = 0.001
I0826 16:10:22.800976 25446 solver.cpp:243] Iteration 12590, loss = 8.07963
I0826 16:10:22.801000 25446 solver.cpp:259]     Train net output #0: center_loss = 90.4373 (* 0.008 = 0.723498 loss)
I0826 16:10:22.801007 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.35614 (* 1 = 7.35614 loss)
I0826 16:10:22.801010 25446 sgd_solver.cpp:138] Iteration 12590, lr = 0.001
I0826 16:10:24.861519 25446 solver.cpp:243] Iteration 12600, loss = 7.73429
I0826 16:10:24.861557 25446 solver.cpp:259]     Train net output #0: center_loss = 117.218 (* 0.008 = 0.937742 loss)
I0826 16:10:24.861563 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.79655 (* 1 = 6.79655 loss)
I0826 16:10:24.861567 25446 sgd_solver.cpp:138] Iteration 12600, lr = 0.001
I0826 16:10:26.922708 25446 solver.cpp:243] Iteration 12610, loss = 7.92783
I0826 16:10:26.922745 25446 solver.cpp:259]     Train net output #0: center_loss = 121.225 (* 0.008 = 0.969796 loss)
I0826 16:10:26.922752 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.95803 (* 1 = 6.95803 loss)
I0826 16:10:26.922755 25446 sgd_solver.cpp:138] Iteration 12610, lr = 0.001
I0826 16:10:28.983693 25446 solver.cpp:243] Iteration 12620, loss = 7.80975
I0826 16:10:28.983844 25446 solver.cpp:259]     Train net output #0: center_loss = 97.7924 (* 0.008 = 0.782339 loss)
I0826 16:10:28.983851 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.02741 (* 1 = 7.02741 loss)
I0826 16:10:28.983856 25446 sgd_solver.cpp:138] Iteration 12620, lr = 0.001
I0826 16:10:31.045013 25446 solver.cpp:243] Iteration 12630, loss = 8.03411
I0826 16:10:31.045038 25446 solver.cpp:259]     Train net output #0: center_loss = 114.877 (* 0.008 = 0.919013 loss)
I0826 16:10:31.045044 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.11509 (* 1 = 7.11509 loss)
I0826 16:10:31.045048 25446 sgd_solver.cpp:138] Iteration 12630, lr = 0.001
I0826 16:10:33.107673 25446 solver.cpp:243] Iteration 12640, loss = 8.06313
I0826 16:10:33.107698 25446 solver.cpp:259]     Train net output #0: center_loss = 88.6546 (* 0.008 = 0.709237 loss)
I0826 16:10:33.107704 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.35389 (* 1 = 7.35389 loss)
I0826 16:10:33.107707 25446 sgd_solver.cpp:138] Iteration 12640, lr = 0.001
I0826 16:10:35.167647 25446 solver.cpp:243] Iteration 12650, loss = 7.52147
I0826 16:10:35.167670 25446 solver.cpp:259]     Train net output #0: center_loss = 132.174 (* 0.008 = 1.0574 loss)
I0826 16:10:35.167676 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.46408 (* 1 = 6.46408 loss)
I0826 16:10:35.167680 25446 sgd_solver.cpp:138] Iteration 12650, lr = 0.001
I0826 16:10:37.231441 25446 solver.cpp:243] Iteration 12660, loss = 8.30708
I0826 16:10:37.231467 25446 solver.cpp:259]     Train net output #0: center_loss = 99.2477 (* 0.008 = 0.793982 loss)
I0826 16:10:37.231473 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.5131 (* 1 = 7.5131 loss)
I0826 16:10:37.231477 25446 sgd_solver.cpp:138] Iteration 12660, lr = 0.001
I0826 16:10:39.292009 25446 solver.cpp:243] Iteration 12670, loss = 8.06476
I0826 16:10:39.292047 25446 solver.cpp:259]     Train net output #0: center_loss = 162.778 (* 0.008 = 1.30222 loss)
I0826 16:10:39.292054 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.76254 (* 1 = 6.76254 loss)
I0826 16:10:39.292057 25446 sgd_solver.cpp:138] Iteration 12670, lr = 0.001
I0826 16:10:41.351200 25446 solver.cpp:243] Iteration 12680, loss = 7.71755
I0826 16:10:41.351239 25446 solver.cpp:259]     Train net output #0: center_loss = 109.459 (* 0.008 = 0.875675 loss)
I0826 16:10:41.351245 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.84188 (* 1 = 6.84188 loss)
I0826 16:10:41.351249 25446 sgd_solver.cpp:138] Iteration 12680, lr = 0.001
I0826 16:10:43.409855 25446 solver.cpp:243] Iteration 12690, loss = 7.96526
I0826 16:10:43.409894 25446 solver.cpp:259]     Train net output #0: center_loss = 106.59 (* 0.008 = 0.85272 loss)
I0826 16:10:43.409901 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.11254 (* 1 = 7.11254 loss)
I0826 16:10:43.409904 25446 sgd_solver.cpp:138] Iteration 12690, lr = 0.001
I0826 16:10:45.470497 25446 solver.cpp:243] Iteration 12700, loss = 7.00089
I0826 16:10:45.470535 25446 solver.cpp:259]     Train net output #0: center_loss = 151.755 (* 0.008 = 1.21404 loss)
I0826 16:10:45.470542 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.78685 (* 1 = 5.78685 loss)
I0826 16:10:45.470546 25446 sgd_solver.cpp:138] Iteration 12700, lr = 0.001
I0826 16:10:47.530282 25446 solver.cpp:243] Iteration 12710, loss = 6.83709
I0826 16:10:47.530306 25446 solver.cpp:259]     Train net output #0: center_loss = 139.29 (* 0.008 = 1.11432 loss)
I0826 16:10:47.530313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.72277 (* 1 = 5.72277 loss)
I0826 16:10:47.530315 25446 sgd_solver.cpp:138] Iteration 12710, lr = 0.001
I0826 16:10:49.589478 25446 solver.cpp:243] Iteration 12720, loss = 7.01692
I0826 16:10:49.589517 25446 solver.cpp:259]     Train net output #0: center_loss = 135.229 (* 0.008 = 1.08183 loss)
I0826 16:10:49.589524 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.93509 (* 1 = 5.93509 loss)
I0826 16:10:49.589529 25446 sgd_solver.cpp:138] Iteration 12720, lr = 0.001
I0826 16:10:51.653138 25446 solver.cpp:243] Iteration 12730, loss = 7.06836
I0826 16:10:51.653178 25446 solver.cpp:259]     Train net output #0: center_loss = 156.694 (* 0.008 = 1.25355 loss)
I0826 16:10:51.653184 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.81481 (* 1 = 5.81481 loss)
I0826 16:10:51.653188 25446 sgd_solver.cpp:138] Iteration 12730, lr = 0.001
I0826 16:10:53.717293 25446 solver.cpp:243] Iteration 12740, loss = 7.64441
I0826 16:10:53.717342 25446 solver.cpp:259]     Train net output #0: center_loss = 121.674 (* 0.008 = 0.973392 loss)
I0826 16:10:53.717348 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.67101 (* 1 = 6.67101 loss)
I0826 16:10:53.717352 25446 sgd_solver.cpp:138] Iteration 12740, lr = 0.001
I0826 16:10:55.780261 25446 solver.cpp:243] Iteration 12750, loss = 7.09776
I0826 16:10:55.780285 25446 solver.cpp:259]     Train net output #0: center_loss = 133.918 (* 0.008 = 1.07134 loss)
I0826 16:10:55.780292 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.02641 (* 1 = 6.02641 loss)
I0826 16:10:55.780295 25446 sgd_solver.cpp:138] Iteration 12750, lr = 0.001
I0826 16:10:57.841629 25446 solver.cpp:243] Iteration 12760, loss = 7.88766
I0826 16:10:57.841651 25446 solver.cpp:259]     Train net output #0: center_loss = 121.577 (* 0.008 = 0.972616 loss)
I0826 16:10:57.841657 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.91505 (* 1 = 6.91505 loss)
I0826 16:10:57.841661 25446 sgd_solver.cpp:138] Iteration 12760, lr = 0.001
I0826 16:10:59.902931 25446 solver.cpp:243] Iteration 12770, loss = 7.31451
I0826 16:10:59.903043 25446 solver.cpp:259]     Train net output #0: center_loss = 156.651 (* 0.008 = 1.2532 loss)
I0826 16:10:59.903050 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.06131 (* 1 = 6.06131 loss)
I0826 16:10:59.903054 25446 sgd_solver.cpp:138] Iteration 12770, lr = 0.001
I0826 16:11:01.968701 25446 solver.cpp:243] Iteration 12780, loss = 7.59688
I0826 16:11:01.968724 25446 solver.cpp:259]     Train net output #0: center_loss = 112.119 (* 0.008 = 0.896953 loss)
I0826 16:11:01.968730 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.69992 (* 1 = 6.69992 loss)
I0826 16:11:01.968734 25446 sgd_solver.cpp:138] Iteration 12780, lr = 0.001
I0826 16:11:04.031388 25446 solver.cpp:243] Iteration 12790, loss = 7.49226
I0826 16:11:04.031411 25446 solver.cpp:259]     Train net output #0: center_loss = 130.387 (* 0.008 = 1.0431 loss)
I0826 16:11:04.031432 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.44916 (* 1 = 6.44916 loss)
I0826 16:11:04.031437 25446 sgd_solver.cpp:138] Iteration 12790, lr = 0.001
I0826 16:11:06.095743 25446 solver.cpp:243] Iteration 12800, loss = 7.36988
I0826 16:11:06.095767 25446 solver.cpp:259]     Train net output #0: center_loss = 136.65 (* 0.008 = 1.0932 loss)
I0826 16:11:06.095772 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.27668 (* 1 = 6.27668 loss)
I0826 16:11:06.095775 25446 sgd_solver.cpp:138] Iteration 12800, lr = 0.001
I0826 16:11:08.160173 25446 solver.cpp:243] Iteration 12810, loss = 7.85813
I0826 16:11:08.160212 25446 solver.cpp:259]     Train net output #0: center_loss = 162.18 (* 0.008 = 1.29744 loss)
I0826 16:11:08.160218 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.56069 (* 1 = 6.56069 loss)
I0826 16:11:08.160221 25446 sgd_solver.cpp:138] Iteration 12810, lr = 0.001
I0826 16:11:10.222509 25446 solver.cpp:243] Iteration 12820, loss = 8.25065
I0826 16:11:10.222551 25446 solver.cpp:259]     Train net output #0: center_loss = 96.5298 (* 0.008 = 0.772238 loss)
I0826 16:11:10.222558 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.47841 (* 1 = 7.47841 loss)
I0826 16:11:10.222561 25446 sgd_solver.cpp:138] Iteration 12820, lr = 0.001
I0826 16:11:12.284838 25446 solver.cpp:243] Iteration 12830, loss = 7.58567
I0826 16:11:12.284879 25446 solver.cpp:259]     Train net output #0: center_loss = 121.477 (* 0.008 = 0.971813 loss)
I0826 16:11:12.284885 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.61386 (* 1 = 6.61386 loss)
I0826 16:11:12.284889 25446 sgd_solver.cpp:138] Iteration 12830, lr = 0.001
I0826 16:11:14.346837 25446 solver.cpp:243] Iteration 12840, loss = 7.14807
I0826 16:11:14.346875 25446 solver.cpp:259]     Train net output #0: center_loss = 126.771 (* 0.008 = 1.01416 loss)
I0826 16:11:14.346881 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.13391 (* 1 = 6.13391 loss)
I0826 16:11:14.346885 25446 sgd_solver.cpp:138] Iteration 12840, lr = 0.001
I0826 16:11:16.410887 25446 solver.cpp:243] Iteration 12850, loss = 7.92738
I0826 16:11:16.410910 25446 solver.cpp:259]     Train net output #0: center_loss = 162.519 (* 0.008 = 1.30015 loss)
I0826 16:11:16.410917 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.62723 (* 1 = 6.62723 loss)
I0826 16:11:16.410920 25446 sgd_solver.cpp:138] Iteration 12850, lr = 0.001
I0826 16:11:18.475155 25446 solver.cpp:243] Iteration 12860, loss = 8.02201
I0826 16:11:18.475198 25446 solver.cpp:259]     Train net output #0: center_loss = 122.286 (* 0.008 = 0.978284 loss)
I0826 16:11:18.475203 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.04372 (* 1 = 7.04372 loss)
I0826 16:11:18.475208 25446 sgd_solver.cpp:138] Iteration 12860, lr = 0.001
I0826 16:11:20.536947 25446 solver.cpp:243] Iteration 12870, loss = 7.03072
I0826 16:11:20.536985 25446 solver.cpp:259]     Train net output #0: center_loss = 149.665 (* 0.008 = 1.19732 loss)
I0826 16:11:20.536991 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.8334 (* 1 = 5.8334 loss)
I0826 16:11:20.536995 25446 sgd_solver.cpp:138] Iteration 12870, lr = 0.001
I0826 16:11:22.598091 25446 solver.cpp:243] Iteration 12880, loss = 7.85762
I0826 16:11:22.598131 25446 solver.cpp:259]     Train net output #0: center_loss = 93.2024 (* 0.008 = 0.745619 loss)
I0826 16:11:22.598137 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.112 (* 1 = 7.112 loss)
I0826 16:11:22.598141 25446 sgd_solver.cpp:138] Iteration 12880, lr = 0.001
I0826 16:11:24.660003 25446 solver.cpp:243] Iteration 12890, loss = 7.38665
I0826 16:11:24.660043 25446 solver.cpp:259]     Train net output #0: center_loss = 162.807 (* 0.008 = 1.30245 loss)
I0826 16:11:24.660048 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.08419 (* 1 = 6.08419 loss)
I0826 16:11:24.660051 25446 sgd_solver.cpp:138] Iteration 12890, lr = 0.001
I0826 16:11:26.722404 25446 solver.cpp:243] Iteration 12900, loss = 7.5477
I0826 16:11:26.722426 25446 solver.cpp:259]     Train net output #0: center_loss = 148.167 (* 0.008 = 1.18534 loss)
I0826 16:11:26.722432 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.36236 (* 1 = 6.36236 loss)
I0826 16:11:26.722436 25446 sgd_solver.cpp:138] Iteration 12900, lr = 0.001
I0826 16:11:28.786957 25446 solver.cpp:243] Iteration 12910, loss = 7.44158
I0826 16:11:28.786981 25446 solver.cpp:259]     Train net output #0: center_loss = 134.359 (* 0.008 = 1.07487 loss)
I0826 16:11:28.786988 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.36671 (* 1 = 6.36671 loss)
I0826 16:11:28.786991 25446 sgd_solver.cpp:138] Iteration 12910, lr = 0.001
I0826 16:11:30.848827 25446 solver.cpp:243] Iteration 12920, loss = 7.86602
I0826 16:11:30.848966 25446 solver.cpp:259]     Train net output #0: center_loss = 159.831 (* 0.008 = 1.27865 loss)
I0826 16:11:30.848986 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.58737 (* 1 = 6.58737 loss)
I0826 16:11:30.848990 25446 sgd_solver.cpp:138] Iteration 12920, lr = 0.001
I0826 16:11:32.910733 25446 solver.cpp:243] Iteration 12930, loss = 6.85369
I0826 16:11:32.910756 25446 solver.cpp:259]     Train net output #0: center_loss = 141.04 (* 0.008 = 1.12832 loss)
I0826 16:11:32.910763 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.72537 (* 1 = 5.72537 loss)
I0826 16:11:32.910766 25446 sgd_solver.cpp:138] Iteration 12930, lr = 0.001
I0826 16:11:34.969936 25446 solver.cpp:243] Iteration 12940, loss = 8.16176
I0826 16:11:34.969959 25446 solver.cpp:259]     Train net output #0: center_loss = 128.522 (* 0.008 = 1.02818 loss)
I0826 16:11:34.969965 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.13358 (* 1 = 7.13358 loss)
I0826 16:11:34.969969 25446 sgd_solver.cpp:138] Iteration 12940, lr = 0.001
I0826 16:11:37.031714 25446 solver.cpp:243] Iteration 12950, loss = 8.01189
I0826 16:11:37.031738 25446 solver.cpp:259]     Train net output #0: center_loss = 134.693 (* 0.008 = 1.07754 loss)
I0826 16:11:37.031744 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93435 (* 1 = 6.93435 loss)
I0826 16:11:37.031747 25446 sgd_solver.cpp:138] Iteration 12950, lr = 0.001
I0826 16:11:39.095079 25446 solver.cpp:243] Iteration 12960, loss = 8.28511
I0826 16:11:39.095105 25446 solver.cpp:259]     Train net output #0: center_loss = 129.766 (* 0.008 = 1.03813 loss)
I0826 16:11:39.095110 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.24699 (* 1 = 7.24699 loss)
I0826 16:11:39.095114 25446 sgd_solver.cpp:138] Iteration 12960, lr = 0.001
I0826 16:11:41.157510 25446 solver.cpp:243] Iteration 12970, loss = 7.69712
I0826 16:11:41.157534 25446 solver.cpp:259]     Train net output #0: center_loss = 106.813 (* 0.008 = 0.854506 loss)
I0826 16:11:41.157541 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.84262 (* 1 = 6.84262 loss)
I0826 16:11:41.157544 25446 sgd_solver.cpp:138] Iteration 12970, lr = 0.001
I0826 16:11:43.219825 25446 solver.cpp:243] Iteration 12980, loss = 7.95049
I0826 16:11:43.219864 25446 solver.cpp:259]     Train net output #0: center_loss = 148.177 (* 0.008 = 1.18542 loss)
I0826 16:11:43.219871 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.76507 (* 1 = 6.76507 loss)
I0826 16:11:43.219874 25446 sgd_solver.cpp:138] Iteration 12980, lr = 0.001
I0826 16:11:45.283160 25446 solver.cpp:243] Iteration 12990, loss = 7.57709
I0826 16:11:45.283183 25446 solver.cpp:259]     Train net output #0: center_loss = 96.5045 (* 0.008 = 0.772036 loss)
I0826 16:11:45.283190 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.80505 (* 1 = 6.80505 loss)
I0826 16:11:45.283193 25446 sgd_solver.cpp:138] Iteration 12990, lr = 0.001
I0826 16:11:47.136932 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_13000.caffemodel
I0826 16:11:48.277369 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_13000.solverstate
I0826 16:11:48.603703 25446 solver.cpp:243] Iteration 13000, loss = 7.33488
I0826 16:11:48.603729 25446 solver.cpp:259]     Train net output #0: center_loss = 130.938 (* 0.008 = 1.04751 loss)
I0826 16:11:48.603735 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.28737 (* 1 = 6.28737 loss)
I0826 16:11:48.603739 25446 sgd_solver.cpp:138] Iteration 13000, lr = 0.001
I0826 16:11:50.661664 25446 solver.cpp:243] Iteration 13010, loss = 7.49501
I0826 16:11:50.661703 25446 solver.cpp:259]     Train net output #0: center_loss = 114.423 (* 0.008 = 0.91538 loss)
I0826 16:11:50.661710 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.57963 (* 1 = 6.57963 loss)
I0826 16:11:50.661715 25446 sgd_solver.cpp:138] Iteration 13010, lr = 0.001
I0826 16:11:52.723063 25446 solver.cpp:243] Iteration 13020, loss = 8.34803
I0826 16:11:52.723088 25446 solver.cpp:259]     Train net output #0: center_loss = 122.068 (* 0.008 = 0.976542 loss)
I0826 16:11:52.723119 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.37148 (* 1 = 7.37148 loss)
I0826 16:11:52.723124 25446 sgd_solver.cpp:138] Iteration 13020, lr = 0.001
I0826 16:11:54.786484 25446 solver.cpp:243] Iteration 13030, loss = 8.17229
I0826 16:11:54.786509 25446 solver.cpp:259]     Train net output #0: center_loss = 111.235 (* 0.008 = 0.889882 loss)
I0826 16:11:54.786514 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.28241 (* 1 = 7.28241 loss)
I0826 16:11:54.786518 25446 sgd_solver.cpp:138] Iteration 13030, lr = 0.001
I0826 16:11:56.851409 25446 solver.cpp:243] Iteration 13040, loss = 8.02363
I0826 16:11:56.851449 25446 solver.cpp:259]     Train net output #0: center_loss = 115.835 (* 0.008 = 0.926684 loss)
I0826 16:11:56.851455 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.09695 (* 1 = 7.09695 loss)
I0826 16:11:56.851459 25446 sgd_solver.cpp:138] Iteration 13040, lr = 0.001
I0826 16:11:58.912839 25446 solver.cpp:243] Iteration 13050, loss = 7.25427
I0826 16:11:58.912863 25446 solver.cpp:259]     Train net output #0: center_loss = 138.82 (* 0.008 = 1.11056 loss)
I0826 16:11:58.912869 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.14371 (* 1 = 6.14371 loss)
I0826 16:11:58.912873 25446 sgd_solver.cpp:138] Iteration 13050, lr = 0.001
I0826 16:12:00.978308 25446 solver.cpp:243] Iteration 13060, loss = 8.33015
I0826 16:12:00.978482 25446 solver.cpp:259]     Train net output #0: center_loss = 111.632 (* 0.008 = 0.893053 loss)
I0826 16:12:00.978490 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.4371 (* 1 = 7.4371 loss)
I0826 16:12:00.978507 25446 sgd_solver.cpp:138] Iteration 13060, lr = 0.001
I0826 16:12:03.038689 25446 solver.cpp:243] Iteration 13070, loss = 6.69965
I0826 16:12:03.038714 25446 solver.cpp:259]     Train net output #0: center_loss = 166.525 (* 0.008 = 1.3322 loss)
I0826 16:12:03.038720 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.36745 (* 1 = 5.36745 loss)
I0826 16:12:03.038723 25446 sgd_solver.cpp:138] Iteration 13070, lr = 0.001
I0826 16:12:05.105139 25446 solver.cpp:243] Iteration 13080, loss = 7.73427
I0826 16:12:05.105165 25446 solver.cpp:259]     Train net output #0: center_loss = 141.446 (* 0.008 = 1.13157 loss)
I0826 16:12:05.105170 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.6027 (* 1 = 6.6027 loss)
I0826 16:12:05.105175 25446 sgd_solver.cpp:138] Iteration 13080, lr = 0.001
I0826 16:12:07.168162 25446 solver.cpp:243] Iteration 13090, loss = 7.97089
I0826 16:12:07.168186 25446 solver.cpp:259]     Train net output #0: center_loss = 115.205 (* 0.008 = 0.921637 loss)
I0826 16:12:07.168192 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.04925 (* 1 = 7.04925 loss)
I0826 16:12:07.168196 25446 sgd_solver.cpp:138] Iteration 13090, lr = 0.001
I0826 16:12:09.230749 25446 solver.cpp:243] Iteration 13100, loss = 7.22379
I0826 16:12:09.230772 25446 solver.cpp:259]     Train net output #0: center_loss = 144.616 (* 0.008 = 1.15693 loss)
I0826 16:12:09.230778 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.06687 (* 1 = 6.06687 loss)
I0826 16:12:09.230782 25446 sgd_solver.cpp:138] Iteration 13100, lr = 0.001
I0826 16:12:11.289976 25446 solver.cpp:243] Iteration 13110, loss = 7.73619
I0826 16:12:11.290000 25446 solver.cpp:259]     Train net output #0: center_loss = 105.555 (* 0.008 = 0.844437 loss)
I0826 16:12:11.290006 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.89176 (* 1 = 6.89176 loss)
I0826 16:12:11.290010 25446 sgd_solver.cpp:138] Iteration 13110, lr = 0.001
I0826 16:12:13.348140 25446 solver.cpp:243] Iteration 13120, loss = 8.1111
I0826 16:12:13.348165 25446 solver.cpp:259]     Train net output #0: center_loss = 132.554 (* 0.008 = 1.06043 loss)
I0826 16:12:13.348186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.05067 (* 1 = 7.05067 loss)
I0826 16:12:13.348191 25446 sgd_solver.cpp:138] Iteration 13120, lr = 0.001
I0826 16:12:15.409708 25446 solver.cpp:243] Iteration 13130, loss = 7.98154
I0826 16:12:15.409731 25446 solver.cpp:259]     Train net output #0: center_loss = 116.99 (* 0.008 = 0.93592 loss)
I0826 16:12:15.409737 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.04562 (* 1 = 7.04562 loss)
I0826 16:12:15.409741 25446 sgd_solver.cpp:138] Iteration 13130, lr = 0.001
I0826 16:12:17.471341 25446 solver.cpp:243] Iteration 13140, loss = 7.83119
I0826 16:12:17.471379 25446 solver.cpp:259]     Train net output #0: center_loss = 118.326 (* 0.008 = 0.94661 loss)
I0826 16:12:17.471386 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.88458 (* 1 = 6.88458 loss)
I0826 16:12:17.471390 25446 sgd_solver.cpp:138] Iteration 13140, lr = 0.001
I0826 16:12:19.534862 25446 solver.cpp:243] Iteration 13150, loss = 7.29725
I0826 16:12:19.534901 25446 solver.cpp:259]     Train net output #0: center_loss = 124.084 (* 0.008 = 0.992668 loss)
I0826 16:12:19.534909 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.30458 (* 1 = 6.30458 loss)
I0826 16:12:19.534911 25446 sgd_solver.cpp:138] Iteration 13150, lr = 0.001
I0826 16:12:21.596977 25446 solver.cpp:243] Iteration 13160, loss = 7.28648
I0826 16:12:21.597016 25446 solver.cpp:259]     Train net output #0: center_loss = 122.384 (* 0.008 = 0.979074 loss)
I0826 16:12:21.597023 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.30741 (* 1 = 6.30741 loss)
I0826 16:12:21.597026 25446 sgd_solver.cpp:138] Iteration 13160, lr = 0.001
I0826 16:12:23.663019 25446 solver.cpp:243] Iteration 13170, loss = 8.2543
I0826 16:12:23.663044 25446 solver.cpp:259]     Train net output #0: center_loss = 103.067 (* 0.008 = 0.824537 loss)
I0826 16:12:23.663050 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.42976 (* 1 = 7.42976 loss)
I0826 16:12:23.663055 25446 sgd_solver.cpp:138] Iteration 13170, lr = 0.001
I0826 16:12:25.723907 25446 solver.cpp:243] Iteration 13180, loss = 8.23113
I0826 16:12:25.723932 25446 solver.cpp:259]     Train net output #0: center_loss = 146.314 (* 0.008 = 1.17051 loss)
I0826 16:12:25.723937 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.06061 (* 1 = 7.06061 loss)
I0826 16:12:25.723942 25446 sgd_solver.cpp:138] Iteration 13180, lr = 0.001
I0826 16:12:27.786707 25446 solver.cpp:243] Iteration 13190, loss = 7.75
I0826 16:12:27.786746 25446 solver.cpp:259]     Train net output #0: center_loss = 152.121 (* 0.008 = 1.21696 loss)
I0826 16:12:27.786752 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.53303 (* 1 = 6.53303 loss)
I0826 16:12:27.786756 25446 sgd_solver.cpp:138] Iteration 13190, lr = 0.001
I0826 16:12:29.847765 25446 solver.cpp:243] Iteration 13200, loss = 7.96296
I0826 16:12:29.847790 25446 solver.cpp:259]     Train net output #0: center_loss = 94.806 (* 0.008 = 0.758448 loss)
I0826 16:12:29.847796 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.20452 (* 1 = 7.20452 loss)
I0826 16:12:29.847800 25446 sgd_solver.cpp:138] Iteration 13200, lr = 0.001
I0826 16:12:31.910879 25446 solver.cpp:243] Iteration 13210, loss = 7.1754
I0826 16:12:31.910993 25446 solver.cpp:259]     Train net output #0: center_loss = 144.486 (* 0.008 = 1.15589 loss)
I0826 16:12:31.911000 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.01952 (* 1 = 6.01952 loss)
I0826 16:12:31.911005 25446 sgd_solver.cpp:138] Iteration 13210, lr = 0.001
I0826 16:12:33.973465 25446 solver.cpp:243] Iteration 13220, loss = 6.98115
I0826 16:12:33.973489 25446 solver.cpp:259]     Train net output #0: center_loss = 135.068 (* 0.008 = 1.08054 loss)
I0826 16:12:33.973495 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.90061 (* 1 = 5.90061 loss)
I0826 16:12:33.973500 25446 sgd_solver.cpp:138] Iteration 13220, lr = 0.001
I0826 16:12:36.033165 25446 solver.cpp:243] Iteration 13230, loss = 8.27371
I0826 16:12:36.033205 25446 solver.cpp:259]     Train net output #0: center_loss = 157.382 (* 0.008 = 1.25905 loss)
I0826 16:12:36.033210 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.01466 (* 1 = 7.01466 loss)
I0826 16:12:36.033215 25446 sgd_solver.cpp:138] Iteration 13230, lr = 0.001
I0826 16:12:38.091503 25446 solver.cpp:243] Iteration 13240, loss = 7.64017
I0826 16:12:38.091528 25446 solver.cpp:259]     Train net output #0: center_loss = 119.533 (* 0.008 = 0.956264 loss)
I0826 16:12:38.091536 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.68391 (* 1 = 6.68391 loss)
I0826 16:12:38.091539 25446 sgd_solver.cpp:138] Iteration 13240, lr = 0.001
I0826 16:12:40.153153 25446 solver.cpp:243] Iteration 13250, loss = 7.79693
I0826 16:12:40.153177 25446 solver.cpp:259]     Train net output #0: center_loss = 121.671 (* 0.008 = 0.973372 loss)
I0826 16:12:40.153183 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.82356 (* 1 = 6.82356 loss)
I0826 16:12:40.153187 25446 sgd_solver.cpp:138] Iteration 13250, lr = 0.001
I0826 16:12:42.215128 25446 solver.cpp:243] Iteration 13260, loss = 8.37606
I0826 16:12:42.215153 25446 solver.cpp:259]     Train net output #0: center_loss = 135.201 (* 0.008 = 1.08161 loss)
I0826 16:12:42.215159 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.29445 (* 1 = 7.29445 loss)
I0826 16:12:42.215163 25446 sgd_solver.cpp:138] Iteration 13260, lr = 0.001
I0826 16:12:44.275260 25446 solver.cpp:243] Iteration 13270, loss = 7.4056
I0826 16:12:44.275300 25446 solver.cpp:259]     Train net output #0: center_loss = 112.833 (* 0.008 = 0.902663 loss)
I0826 16:12:44.275306 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.50293 (* 1 = 6.50293 loss)
I0826 16:12:44.275310 25446 sgd_solver.cpp:138] Iteration 13270, lr = 0.001
I0826 16:12:46.336808 25446 solver.cpp:243] Iteration 13280, loss = 8.01645
I0826 16:12:46.336845 25446 solver.cpp:259]     Train net output #0: center_loss = 144.176 (* 0.008 = 1.15341 loss)
I0826 16:12:46.336868 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.86304 (* 1 = 6.86304 loss)
I0826 16:12:46.336871 25446 sgd_solver.cpp:138] Iteration 13280, lr = 0.001
I0826 16:12:48.399564 25446 solver.cpp:243] Iteration 13290, loss = 8.13823
I0826 16:12:48.399588 25446 solver.cpp:259]     Train net output #0: center_loss = 81.5625 (* 0.008 = 0.6525 loss)
I0826 16:12:48.399595 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.48573 (* 1 = 7.48573 loss)
I0826 16:12:48.399598 25446 sgd_solver.cpp:138] Iteration 13290, lr = 0.001
I0826 16:12:50.461980 25446 solver.cpp:243] Iteration 13300, loss = 7.59408
I0826 16:12:50.462020 25446 solver.cpp:259]     Train net output #0: center_loss = 149.468 (* 0.008 = 1.19575 loss)
I0826 16:12:50.462026 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.39833 (* 1 = 6.39833 loss)
I0826 16:12:50.462030 25446 sgd_solver.cpp:138] Iteration 13300, lr = 0.001
I0826 16:12:52.521677 25446 solver.cpp:243] Iteration 13310, loss = 8.10992
I0826 16:12:52.521715 25446 solver.cpp:259]     Train net output #0: center_loss = 116.497 (* 0.008 = 0.931974 loss)
I0826 16:12:52.521736 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.17795 (* 1 = 7.17795 loss)
I0826 16:12:52.521740 25446 sgd_solver.cpp:138] Iteration 13310, lr = 0.001
I0826 16:12:54.581746 25446 solver.cpp:243] Iteration 13320, loss = 7.10041
I0826 16:12:54.581770 25446 solver.cpp:259]     Train net output #0: center_loss = 144.58 (* 0.008 = 1.15664 loss)
I0826 16:12:54.581791 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.94376 (* 1 = 5.94376 loss)
I0826 16:12:54.581796 25446 sgd_solver.cpp:138] Iteration 13320, lr = 0.001
I0826 16:12:56.643223 25446 solver.cpp:243] Iteration 13330, loss = 7.50244
I0826 16:12:56.643262 25446 solver.cpp:259]     Train net output #0: center_loss = 149.4 (* 0.008 = 1.1952 loss)
I0826 16:12:56.643268 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.30724 (* 1 = 6.30724 loss)
I0826 16:12:56.643272 25446 sgd_solver.cpp:138] Iteration 13330, lr = 0.001
I0826 16:12:58.705754 25446 solver.cpp:243] Iteration 13340, loss = 7.19904
I0826 16:12:58.705793 25446 solver.cpp:259]     Train net output #0: center_loss = 129.74 (* 0.008 = 1.03792 loss)
I0826 16:12:58.705798 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.16113 (* 1 = 6.16113 loss)
I0826 16:12:58.705802 25446 sgd_solver.cpp:138] Iteration 13340, lr = 0.001
I0826 16:13:00.766489 25446 solver.cpp:243] Iteration 13350, loss = 7.25863
I0826 16:13:00.766511 25446 solver.cpp:259]     Train net output #0: center_loss = 150.075 (* 0.008 = 1.2006 loss)
I0826 16:13:00.766517 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.05803 (* 1 = 6.05803 loss)
I0826 16:13:00.766521 25446 sgd_solver.cpp:138] Iteration 13350, lr = 0.001
I0826 16:13:02.827631 25446 solver.cpp:243] Iteration 13360, loss = 7.67704
I0826 16:13:02.827809 25446 solver.cpp:259]     Train net output #0: center_loss = 158.078 (* 0.008 = 1.26463 loss)
I0826 16:13:02.827816 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.41242 (* 1 = 6.41242 loss)
I0826 16:13:02.827821 25446 sgd_solver.cpp:138] Iteration 13360, lr = 0.001
I0826 16:13:04.889268 25446 solver.cpp:243] Iteration 13370, loss = 7.78228
I0826 16:13:04.889307 25446 solver.cpp:259]     Train net output #0: center_loss = 104.204 (* 0.008 = 0.83363 loss)
I0826 16:13:04.889312 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.94865 (* 1 = 6.94865 loss)
I0826 16:13:04.889317 25446 sgd_solver.cpp:138] Iteration 13370, lr = 0.001
I0826 16:13:06.951457 25446 solver.cpp:243] Iteration 13380, loss = 8.14337
I0826 16:13:06.951494 25446 solver.cpp:259]     Train net output #0: center_loss = 133.924 (* 0.008 = 1.07139 loss)
I0826 16:13:06.951501 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.07197 (* 1 = 7.07197 loss)
I0826 16:13:06.951519 25446 sgd_solver.cpp:138] Iteration 13380, lr = 0.001
I0826 16:13:09.016371 25446 solver.cpp:243] Iteration 13390, loss = 8.34495
I0826 16:13:09.016396 25446 solver.cpp:259]     Train net output #0: center_loss = 152.574 (* 0.008 = 1.22059 loss)
I0826 16:13:09.016402 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.12435 (* 1 = 7.12435 loss)
I0826 16:13:09.016407 25446 sgd_solver.cpp:138] Iteration 13390, lr = 0.001
I0826 16:13:11.077004 25446 solver.cpp:243] Iteration 13400, loss = 6.95345
I0826 16:13:11.077028 25446 solver.cpp:259]     Train net output #0: center_loss = 121.602 (* 0.008 = 0.972812 loss)
I0826 16:13:11.077034 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.98064 (* 1 = 5.98064 loss)
I0826 16:13:11.077039 25446 sgd_solver.cpp:138] Iteration 13400, lr = 0.001
I0826 16:13:13.137794 25446 solver.cpp:243] Iteration 13410, loss = 7.6441
I0826 16:13:13.137832 25446 solver.cpp:259]     Train net output #0: center_loss = 158.625 (* 0.008 = 1.269 loss)
I0826 16:13:13.137838 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.3751 (* 1 = 6.3751 loss)
I0826 16:13:13.137841 25446 sgd_solver.cpp:138] Iteration 13410, lr = 0.001
I0826 16:13:15.199988 25446 solver.cpp:243] Iteration 13420, loss = 7.32721
I0826 16:13:15.200027 25446 solver.cpp:259]     Train net output #0: center_loss = 129.643 (* 0.008 = 1.03715 loss)
I0826 16:13:15.200033 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.29006 (* 1 = 6.29006 loss)
I0826 16:13:15.200037 25446 sgd_solver.cpp:138] Iteration 13420, lr = 0.001
I0826 16:13:17.260828 25446 solver.cpp:243] Iteration 13430, loss = 7.56706
I0826 16:13:17.260852 25446 solver.cpp:259]     Train net output #0: center_loss = 152.893 (* 0.008 = 1.22314 loss)
I0826 16:13:17.260859 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.34392 (* 1 = 6.34392 loss)
I0826 16:13:17.260862 25446 sgd_solver.cpp:138] Iteration 13430, lr = 0.001
I0826 16:13:19.324306 25446 solver.cpp:243] Iteration 13440, loss = 8.1047
I0826 16:13:19.324331 25446 solver.cpp:259]     Train net output #0: center_loss = 149.127 (* 0.008 = 1.19302 loss)
I0826 16:13:19.324338 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.91169 (* 1 = 6.91169 loss)
I0826 16:13:19.324342 25446 sgd_solver.cpp:138] Iteration 13440, lr = 0.001
I0826 16:13:21.386487 25446 solver.cpp:243] Iteration 13450, loss = 7.28593
I0826 16:13:21.386549 25446 solver.cpp:259]     Train net output #0: center_loss = 122.038 (* 0.008 = 0.9763 loss)
I0826 16:13:21.386570 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.30963 (* 1 = 6.30963 loss)
I0826 16:13:21.386574 25446 sgd_solver.cpp:138] Iteration 13450, lr = 0.001
I0826 16:13:23.446036 25446 solver.cpp:243] Iteration 13460, loss = 6.83153
I0826 16:13:23.446061 25446 solver.cpp:259]     Train net output #0: center_loss = 174.543 (* 0.008 = 1.39635 loss)
I0826 16:13:23.446067 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.43518 (* 1 = 5.43518 loss)
I0826 16:13:23.446071 25446 sgd_solver.cpp:138] Iteration 13460, lr = 0.001
I0826 16:13:25.504832 25446 solver.cpp:243] Iteration 13470, loss = 6.9933
I0826 16:13:25.504871 25446 solver.cpp:259]     Train net output #0: center_loss = 169.273 (* 0.008 = 1.35419 loss)
I0826 16:13:25.504878 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.63912 (* 1 = 5.63912 loss)
I0826 16:13:25.504880 25446 sgd_solver.cpp:138] Iteration 13470, lr = 0.001
I0826 16:13:27.567329 25446 solver.cpp:243] Iteration 13480, loss = 7.4726
I0826 16:13:27.567368 25446 solver.cpp:259]     Train net output #0: center_loss = 108.939 (* 0.008 = 0.871514 loss)
I0826 16:13:27.567374 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.60108 (* 1 = 6.60108 loss)
I0826 16:13:27.567378 25446 sgd_solver.cpp:138] Iteration 13480, lr = 0.001
I0826 16:13:29.632431 25446 solver.cpp:243] Iteration 13490, loss = 7.68995
I0826 16:13:29.632455 25446 solver.cpp:259]     Train net output #0: center_loss = 135.523 (* 0.008 = 1.08419 loss)
I0826 16:13:29.632462 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.60577 (* 1 = 6.60577 loss)
I0826 16:13:29.632464 25446 sgd_solver.cpp:138] Iteration 13490, lr = 0.001
I0826 16:13:31.694382 25446 solver.cpp:243] Iteration 13500, loss = 7.06511
I0826 16:13:31.694406 25446 solver.cpp:259]     Train net output #0: center_loss = 159.787 (* 0.008 = 1.27829 loss)
I0826 16:13:31.694412 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.78682 (* 1 = 5.78682 loss)
I0826 16:13:31.694416 25446 sgd_solver.cpp:138] Iteration 13500, lr = 0.001
I0826 16:13:33.755303 25446 solver.cpp:243] Iteration 13510, loss = 7.24514
I0826 16:13:33.755441 25446 solver.cpp:259]     Train net output #0: center_loss = 171.985 (* 0.008 = 1.37588 loss)
I0826 16:13:33.755462 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.86925 (* 1 = 5.86925 loss)
I0826 16:13:33.755466 25446 sgd_solver.cpp:138] Iteration 13510, lr = 0.001
I0826 16:13:35.810766 25446 solver.cpp:243] Iteration 13520, loss = 7.95033
I0826 16:13:35.810791 25446 solver.cpp:259]     Train net output #0: center_loss = 111.953 (* 0.008 = 0.895623 loss)
I0826 16:13:35.810797 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.0547 (* 1 = 7.0547 loss)
I0826 16:13:35.810801 25446 sgd_solver.cpp:138] Iteration 13520, lr = 0.001
I0826 16:13:37.872818 25446 solver.cpp:243] Iteration 13530, loss = 7.03226
I0826 16:13:37.872840 25446 solver.cpp:259]     Train net output #0: center_loss = 157.482 (* 0.008 = 1.25986 loss)
I0826 16:13:37.872846 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.7724 (* 1 = 5.7724 loss)
I0826 16:13:37.872849 25446 sgd_solver.cpp:138] Iteration 13530, lr = 0.001
I0826 16:13:39.935644 25446 solver.cpp:243] Iteration 13540, loss = 7.53577
I0826 16:13:39.935668 25446 solver.cpp:259]     Train net output #0: center_loss = 122.662 (* 0.008 = 0.981299 loss)
I0826 16:13:39.935674 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.55447 (* 1 = 6.55447 loss)
I0826 16:13:39.935678 25446 sgd_solver.cpp:138] Iteration 13540, lr = 0.001
I0826 16:13:41.993963 25446 solver.cpp:243] Iteration 13550, loss = 7.83854
I0826 16:13:41.993986 25446 solver.cpp:259]     Train net output #0: center_loss = 123.538 (* 0.008 = 0.988307 loss)
I0826 16:13:41.993993 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.85023 (* 1 = 6.85023 loss)
I0826 16:13:41.993996 25446 sgd_solver.cpp:138] Iteration 13550, lr = 0.001
I0826 16:13:44.056087 25446 solver.cpp:243] Iteration 13560, loss = 7.66124
I0826 16:13:44.056110 25446 solver.cpp:259]     Train net output #0: center_loss = 129.865 (* 0.008 = 1.03892 loss)
I0826 16:13:44.056116 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.62232 (* 1 = 6.62232 loss)
I0826 16:13:44.056120 25446 sgd_solver.cpp:138] Iteration 13560, lr = 0.001
I0826 16:13:46.123157 25446 solver.cpp:243] Iteration 13570, loss = 7.5725
I0826 16:13:46.123180 25446 solver.cpp:259]     Train net output #0: center_loss = 142.296 (* 0.008 = 1.13837 loss)
I0826 16:13:46.123186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.43413 (* 1 = 6.43413 loss)
I0826 16:13:46.123190 25446 sgd_solver.cpp:138] Iteration 13570, lr = 0.001
I0826 16:13:48.185657 25446 solver.cpp:243] Iteration 13580, loss = 7.45269
I0826 16:13:48.185683 25446 solver.cpp:259]     Train net output #0: center_loss = 119.653 (* 0.008 = 0.957228 loss)
I0826 16:13:48.185688 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.49547 (* 1 = 6.49547 loss)
I0826 16:13:48.185693 25446 sgd_solver.cpp:138] Iteration 13580, lr = 0.001
I0826 16:13:50.247653 25446 solver.cpp:243] Iteration 13590, loss = 7.3112
I0826 16:13:50.247675 25446 solver.cpp:259]     Train net output #0: center_loss = 161.682 (* 0.008 = 1.29346 loss)
I0826 16:13:50.247681 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.01775 (* 1 = 6.01775 loss)
I0826 16:13:50.247685 25446 sgd_solver.cpp:138] Iteration 13590, lr = 0.001
I0826 16:13:52.311301 25446 solver.cpp:243] Iteration 13600, loss = 7.57851
I0826 16:13:52.311326 25446 solver.cpp:259]     Train net output #0: center_loss = 119.629 (* 0.008 = 0.957033 loss)
I0826 16:13:52.311331 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.62148 (* 1 = 6.62148 loss)
I0826 16:13:52.311336 25446 sgd_solver.cpp:138] Iteration 13600, lr = 0.001
I0826 16:13:54.375897 25446 solver.cpp:243] Iteration 13610, loss = 7.47707
I0826 16:13:54.375921 25446 solver.cpp:259]     Train net output #0: center_loss = 125.423 (* 0.008 = 1.00338 loss)
I0826 16:13:54.375927 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.47368 (* 1 = 6.47368 loss)
I0826 16:13:54.375931 25446 sgd_solver.cpp:138] Iteration 13610, lr = 0.001
I0826 16:13:56.436578 25446 solver.cpp:243] Iteration 13620, loss = 7.4108
I0826 16:13:56.436602 25446 solver.cpp:259]     Train net output #0: center_loss = 159.139 (* 0.008 = 1.27311 loss)
I0826 16:13:56.436609 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.13769 (* 1 = 6.13769 loss)
I0826 16:13:56.436612 25446 sgd_solver.cpp:138] Iteration 13620, lr = 0.001
I0826 16:13:58.496541 25446 solver.cpp:243] Iteration 13630, loss = 6.88903
I0826 16:13:58.496582 25446 solver.cpp:259]     Train net output #0: center_loss = 153.707 (* 0.008 = 1.22965 loss)
I0826 16:13:58.496587 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.65937 (* 1 = 5.65937 loss)
I0826 16:13:58.496592 25446 sgd_solver.cpp:138] Iteration 13630, lr = 0.001
I0826 16:14:00.563153 25446 solver.cpp:243] Iteration 13640, loss = 7.75366
I0826 16:14:00.563191 25446 solver.cpp:259]     Train net output #0: center_loss = 135.805 (* 0.008 = 1.08644 loss)
I0826 16:14:00.563197 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.66722 (* 1 = 6.66722 loss)
I0826 16:14:00.563200 25446 sgd_solver.cpp:138] Iteration 13640, lr = 0.001
I0826 16:14:02.626385 25446 solver.cpp:243] Iteration 13650, loss = 7.69693
I0826 16:14:02.626425 25446 solver.cpp:259]     Train net output #0: center_loss = 141.86 (* 0.008 = 1.13488 loss)
I0826 16:14:02.626430 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.56205 (* 1 = 6.56205 loss)
I0826 16:14:02.626435 25446 sgd_solver.cpp:138] Iteration 13650, lr = 0.001
I0826 16:14:04.686715 25446 solver.cpp:243] Iteration 13660, loss = 8.16606
I0826 16:14:04.686827 25446 solver.cpp:259]     Train net output #0: center_loss = 135.602 (* 0.008 = 1.08482 loss)
I0826 16:14:04.686833 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.08124 (* 1 = 7.08124 loss)
I0826 16:14:04.686837 25446 sgd_solver.cpp:138] Iteration 13660, lr = 0.001
I0826 16:14:06.748224 25446 solver.cpp:243] Iteration 13670, loss = 7.46411
I0826 16:14:06.748261 25446 solver.cpp:259]     Train net output #0: center_loss = 141.152 (* 0.008 = 1.12921 loss)
I0826 16:14:06.748267 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.3349 (* 1 = 6.3349 loss)
I0826 16:14:06.748271 25446 sgd_solver.cpp:138] Iteration 13670, lr = 0.001
I0826 16:14:08.809846 25446 solver.cpp:243] Iteration 13680, loss = 6.98868
I0826 16:14:08.809870 25446 solver.cpp:259]     Train net output #0: center_loss = 154.022 (* 0.008 = 1.23217 loss)
I0826 16:14:08.809876 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.75651 (* 1 = 5.75651 loss)
I0826 16:14:08.809880 25446 sgd_solver.cpp:138] Iteration 13680, lr = 0.001
I0826 16:14:10.871140 25446 solver.cpp:243] Iteration 13690, loss = 7.88105
I0826 16:14:10.871162 25446 solver.cpp:259]     Train net output #0: center_loss = 120.741 (* 0.008 = 0.965926 loss)
I0826 16:14:10.871168 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.91512 (* 1 = 6.91512 loss)
I0826 16:14:10.871172 25446 sgd_solver.cpp:138] Iteration 13690, lr = 0.001
I0826 16:14:12.935120 25446 solver.cpp:243] Iteration 13700, loss = 7.29054
I0826 16:14:12.935158 25446 solver.cpp:259]     Train net output #0: center_loss = 130.493 (* 0.008 = 1.04394 loss)
I0826 16:14:12.935164 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.2466 (* 1 = 6.2466 loss)
I0826 16:14:12.935168 25446 sgd_solver.cpp:138] Iteration 13700, lr = 0.001
I0826 16:14:14.997192 25446 solver.cpp:243] Iteration 13710, loss = 7.23945
I0826 16:14:14.997231 25446 solver.cpp:259]     Train net output #0: center_loss = 169.481 (* 0.008 = 1.35585 loss)
I0826 16:14:14.997237 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.8836 (* 1 = 5.8836 loss)
I0826 16:14:14.997241 25446 sgd_solver.cpp:138] Iteration 13710, lr = 0.001
I0826 16:14:17.058984 25446 solver.cpp:243] Iteration 13720, loss = 7.63721
I0826 16:14:17.059007 25446 solver.cpp:259]     Train net output #0: center_loss = 156.119 (* 0.008 = 1.24896 loss)
I0826 16:14:17.059013 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.38826 (* 1 = 6.38826 loss)
I0826 16:14:17.059017 25446 sgd_solver.cpp:138] Iteration 13720, lr = 0.001
I0826 16:14:19.119424 25446 solver.cpp:243] Iteration 13730, loss = 6.41293
I0826 16:14:19.119447 25446 solver.cpp:259]     Train net output #0: center_loss = 162.701 (* 0.008 = 1.30161 loss)
I0826 16:14:19.119453 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.11132 (* 1 = 5.11132 loss)
I0826 16:14:19.119457 25446 sgd_solver.cpp:138] Iteration 13730, lr = 0.001
I0826 16:14:21.181145 25446 solver.cpp:243] Iteration 13740, loss = 7.84919
I0826 16:14:21.181169 25446 solver.cpp:259]     Train net output #0: center_loss = 139.114 (* 0.008 = 1.11292 loss)
I0826 16:14:21.181175 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.73628 (* 1 = 6.73628 loss)
I0826 16:14:21.181180 25446 sgd_solver.cpp:138] Iteration 13740, lr = 0.001
I0826 16:14:23.242642 25446 solver.cpp:243] Iteration 13750, loss = 7.00083
I0826 16:14:23.242681 25446 solver.cpp:259]     Train net output #0: center_loss = 168.705 (* 0.008 = 1.34964 loss)
I0826 16:14:23.242687 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.65119 (* 1 = 5.65119 loss)
I0826 16:14:23.242691 25446 sgd_solver.cpp:138] Iteration 13750, lr = 0.001
I0826 16:14:25.304533 25446 solver.cpp:243] Iteration 13760, loss = 7.90666
I0826 16:14:25.304558 25446 solver.cpp:259]     Train net output #0: center_loss = 125.32 (* 0.008 = 1.00256 loss)
I0826 16:14:25.304563 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.9041 (* 1 = 6.9041 loss)
I0826 16:14:25.304567 25446 sgd_solver.cpp:138] Iteration 13760, lr = 0.001
I0826 16:14:27.365186 25446 solver.cpp:243] Iteration 13770, loss = 7.06517
I0826 16:14:27.365211 25446 solver.cpp:259]     Train net output #0: center_loss = 132.6 (* 0.008 = 1.0608 loss)
I0826 16:14:27.365216 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.00437 (* 1 = 6.00437 loss)
I0826 16:14:27.365221 25446 sgd_solver.cpp:138] Iteration 13770, lr = 0.001
I0826 16:14:29.425429 25446 solver.cpp:243] Iteration 13780, loss = 6.3221
I0826 16:14:29.425453 25446 solver.cpp:259]     Train net output #0: center_loss = 164.836 (* 0.008 = 1.31869 loss)
I0826 16:14:29.425459 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.00342 (* 1 = 5.00342 loss)
I0826 16:14:29.425462 25446 sgd_solver.cpp:138] Iteration 13780, lr = 0.001
I0826 16:14:31.484539 25446 solver.cpp:243] Iteration 13790, loss = 6.79384
I0826 16:14:31.484563 25446 solver.cpp:259]     Train net output #0: center_loss = 131.651 (* 0.008 = 1.05321 loss)
I0826 16:14:31.484570 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.74063 (* 1 = 5.74063 loss)
I0826 16:14:31.484573 25446 sgd_solver.cpp:138] Iteration 13790, lr = 0.001
I0826 16:14:33.544894 25446 solver.cpp:243] Iteration 13800, loss = 7.45476
I0826 16:14:33.544919 25446 solver.cpp:259]     Train net output #0: center_loss = 152.69 (* 0.008 = 1.22152 loss)
I0826 16:14:33.544924 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.23324 (* 1 = 6.23324 loss)
I0826 16:14:33.544929 25446 sgd_solver.cpp:138] Iteration 13800, lr = 0.001
I0826 16:14:35.607836 25446 solver.cpp:243] Iteration 13810, loss = 7.67765
I0826 16:14:35.607969 25446 solver.cpp:259]     Train net output #0: center_loss = 127.868 (* 0.008 = 1.02294 loss)
I0826 16:14:35.608007 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.65471 (* 1 = 6.65471 loss)
I0826 16:14:35.608026 25446 sgd_solver.cpp:138] Iteration 13810, lr = 0.001
I0826 16:14:37.671859 25446 solver.cpp:243] Iteration 13820, loss = 6.92446
I0826 16:14:37.671898 25446 solver.cpp:259]     Train net output #0: center_loss = 151.899 (* 0.008 = 1.21519 loss)
I0826 16:14:37.671905 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.70927 (* 1 = 5.70927 loss)
I0826 16:14:37.671908 25446 sgd_solver.cpp:138] Iteration 13820, lr = 0.001
I0826 16:14:39.735062 25446 solver.cpp:243] Iteration 13830, loss = 7.56331
I0826 16:14:39.735087 25446 solver.cpp:259]     Train net output #0: center_loss = 145.233 (* 0.008 = 1.16186 loss)
I0826 16:14:39.735092 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.40145 (* 1 = 6.40145 loss)
I0826 16:14:39.735096 25446 sgd_solver.cpp:138] Iteration 13830, lr = 0.001
I0826 16:14:41.793735 25446 solver.cpp:243] Iteration 13840, loss = 7.62414
I0826 16:14:41.793758 25446 solver.cpp:259]     Train net output #0: center_loss = 130.398 (* 0.008 = 1.04319 loss)
I0826 16:14:41.793764 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.58095 (* 1 = 6.58095 loss)
I0826 16:14:41.793768 25446 sgd_solver.cpp:138] Iteration 13840, lr = 0.001
I0826 16:14:43.854252 25446 solver.cpp:243] Iteration 13850, loss = 8.13429
I0826 16:14:43.854292 25446 solver.cpp:259]     Train net output #0: center_loss = 125.93 (* 0.008 = 1.00744 loss)
I0826 16:14:43.854298 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.12685 (* 1 = 7.12685 loss)
I0826 16:14:43.854302 25446 sgd_solver.cpp:138] Iteration 13850, lr = 0.001
I0826 16:14:45.913369 25446 solver.cpp:243] Iteration 13860, loss = 7.44737
I0826 16:14:45.913408 25446 solver.cpp:259]     Train net output #0: center_loss = 153.294 (* 0.008 = 1.22635 loss)
I0826 16:14:45.913414 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.22102 (* 1 = 6.22102 loss)
I0826 16:14:45.913417 25446 sgd_solver.cpp:138] Iteration 13860, lr = 0.001
I0826 16:14:47.973141 25446 solver.cpp:243] Iteration 13870, loss = 7.90424
I0826 16:14:47.973178 25446 solver.cpp:259]     Train net output #0: center_loss = 123.471 (* 0.008 = 0.987765 loss)
I0826 16:14:47.973186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.91648 (* 1 = 6.91648 loss)
I0826 16:14:47.973189 25446 sgd_solver.cpp:138] Iteration 13870, lr = 0.001
I0826 16:14:50.030830 25446 solver.cpp:243] Iteration 13880, loss = 7.85179
I0826 16:14:50.030855 25446 solver.cpp:259]     Train net output #0: center_loss = 133.936 (* 0.008 = 1.07149 loss)
I0826 16:14:50.030861 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.7803 (* 1 = 6.7803 loss)
I0826 16:14:50.030865 25446 sgd_solver.cpp:138] Iteration 13880, lr = 0.001
I0826 16:14:52.093981 25446 solver.cpp:243] Iteration 13890, loss = 6.95327
I0826 16:14:52.094020 25446 solver.cpp:259]     Train net output #0: center_loss = 134.595 (* 0.008 = 1.07676 loss)
I0826 16:14:52.094027 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.87652 (* 1 = 5.87652 loss)
I0826 16:14:52.094030 25446 sgd_solver.cpp:138] Iteration 13890, lr = 0.001
I0826 16:14:54.156606 25446 solver.cpp:243] Iteration 13900, loss = 6.74277
I0826 16:14:54.156647 25446 solver.cpp:259]     Train net output #0: center_loss = 176.384 (* 0.008 = 1.41107 loss)
I0826 16:14:54.156653 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.33169 (* 1 = 5.33169 loss)
I0826 16:14:54.156657 25446 sgd_solver.cpp:138] Iteration 13900, lr = 0.001
I0826 16:14:56.221508 25446 solver.cpp:243] Iteration 13910, loss = 7.66813
I0826 16:14:56.221531 25446 solver.cpp:259]     Train net output #0: center_loss = 152.294 (* 0.008 = 1.21835 loss)
I0826 16:14:56.221537 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.44978 (* 1 = 6.44978 loss)
I0826 16:14:56.221541 25446 sgd_solver.cpp:138] Iteration 13910, lr = 0.001
I0826 16:14:58.280226 25446 solver.cpp:243] Iteration 13920, loss = 8.16733
I0826 16:14:58.280249 25446 solver.cpp:259]     Train net output #0: center_loss = 139.726 (* 0.008 = 1.11781 loss)
I0826 16:14:58.280254 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.04952 (* 1 = 7.04952 loss)
I0826 16:14:58.280258 25446 sgd_solver.cpp:138] Iteration 13920, lr = 0.001
I0826 16:15:00.345053 25446 solver.cpp:243] Iteration 13930, loss = 7.51152
I0826 16:15:00.345078 25446 solver.cpp:259]     Train net output #0: center_loss = 153.543 (* 0.008 = 1.22834 loss)
I0826 16:15:00.345083 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.28318 (* 1 = 6.28318 loss)
I0826 16:15:00.345088 25446 sgd_solver.cpp:138] Iteration 13930, lr = 0.001
I0826 16:15:02.406133 25446 solver.cpp:243] Iteration 13940, loss = 7.58026
I0826 16:15:02.406157 25446 solver.cpp:259]     Train net output #0: center_loss = 168.093 (* 0.008 = 1.34474 loss)
I0826 16:15:02.406163 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.23552 (* 1 = 6.23552 loss)
I0826 16:15:02.406167 25446 sgd_solver.cpp:138] Iteration 13940, lr = 0.001
I0826 16:15:04.469488 25446 solver.cpp:243] Iteration 13950, loss = 8.88083
I0826 16:15:04.469513 25446 solver.cpp:259]     Train net output #0: center_loss = 135.126 (* 0.008 = 1.08101 loss)
I0826 16:15:04.469519 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.79981 (* 1 = 7.79981 loss)
I0826 16:15:04.469523 25446 sgd_solver.cpp:138] Iteration 13950, lr = 0.001
I0826 16:15:06.533507 25446 solver.cpp:243] Iteration 13960, loss = 7.62929
I0826 16:15:06.533620 25446 solver.cpp:259]     Train net output #0: center_loss = 129.359 (* 0.008 = 1.03487 loss)
I0826 16:15:06.533627 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.59441 (* 1 = 6.59441 loss)
I0826 16:15:06.533644 25446 sgd_solver.cpp:138] Iteration 13960, lr = 0.001
I0826 16:15:08.596702 25446 solver.cpp:243] Iteration 13970, loss = 6.86279
I0826 16:15:08.596729 25446 solver.cpp:259]     Train net output #0: center_loss = 134.049 (* 0.008 = 1.07239 loss)
I0826 16:15:08.596760 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.79041 (* 1 = 5.79041 loss)
I0826 16:15:08.596765 25446 sgd_solver.cpp:138] Iteration 13970, lr = 0.001
I0826 16:15:10.794131 25446 solver.cpp:243] Iteration 13980, loss = 7.05507
I0826 16:15:10.794154 25446 solver.cpp:259]     Train net output #0: center_loss = 147.257 (* 0.008 = 1.17805 loss)
I0826 16:15:10.794160 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.87701 (* 1 = 5.87701 loss)
I0826 16:15:10.794164 25446 sgd_solver.cpp:138] Iteration 13980, lr = 0.001
I0826 16:15:13.015337 25446 solver.cpp:243] Iteration 13990, loss = 7.03382
I0826 16:15:13.015362 25446 solver.cpp:259]     Train net output #0: center_loss = 147.789 (* 0.008 = 1.18231 loss)
I0826 16:15:13.015367 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.85151 (* 1 = 5.85151 loss)
I0826 16:15:13.015372 25446 sgd_solver.cpp:138] Iteration 13990, lr = 0.001
I0826 16:15:14.966114 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_14000.caffemodel
I0826 16:15:16.131319 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_14000.solverstate
I0826 16:15:16.467221 25446 solver.cpp:243] Iteration 14000, loss = 7.70907
I0826 16:15:16.467247 25446 solver.cpp:259]     Train net output #0: center_loss = 143.155 (* 0.008 = 1.14524 loss)
I0826 16:15:16.467254 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.56383 (* 1 = 6.56383 loss)
I0826 16:15:16.467259 25446 sgd_solver.cpp:138] Iteration 14000, lr = 0.001
I0826 16:15:18.732290 25446 solver.cpp:243] Iteration 14010, loss = 7.6235
I0826 16:15:18.732314 25446 solver.cpp:259]     Train net output #0: center_loss = 139.43 (* 0.008 = 1.11544 loss)
I0826 16:15:18.732321 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.50806 (* 1 = 6.50806 loss)
I0826 16:15:18.732326 25446 sgd_solver.cpp:138] Iteration 14010, lr = 0.001
I0826 16:15:20.999819 25446 solver.cpp:243] Iteration 14020, loss = 7.93049
I0826 16:15:20.999845 25446 solver.cpp:259]     Train net output #0: center_loss = 136.136 (* 0.008 = 1.08909 loss)
I0826 16:15:20.999850 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.8414 (* 1 = 6.8414 loss)
I0826 16:15:20.999855 25446 sgd_solver.cpp:138] Iteration 14020, lr = 0.001
I0826 16:15:23.225354 25446 solver.cpp:243] Iteration 14030, loss = 7.68141
I0826 16:15:23.225380 25446 solver.cpp:259]     Train net output #0: center_loss = 115.919 (* 0.008 = 0.927354 loss)
I0826 16:15:23.225386 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.75405 (* 1 = 6.75405 loss)
I0826 16:15:23.225390 25446 sgd_solver.cpp:138] Iteration 14030, lr = 0.001
I0826 16:15:25.431474 25446 solver.cpp:243] Iteration 14040, loss = 8.43707
I0826 16:15:25.431514 25446 solver.cpp:259]     Train net output #0: center_loss = 130.756 (* 0.008 = 1.04605 loss)
I0826 16:15:25.431520 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.39102 (* 1 = 7.39102 loss)
I0826 16:15:25.431524 25446 sgd_solver.cpp:138] Iteration 14040, lr = 0.001
I0826 16:15:27.666013 25446 solver.cpp:243] Iteration 14050, loss = 7.57979
I0826 16:15:27.666035 25446 solver.cpp:259]     Train net output #0: center_loss = 137.697 (* 0.008 = 1.10158 loss)
I0826 16:15:27.666043 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.47821 (* 1 = 6.47821 loss)
I0826 16:15:27.666046 25446 sgd_solver.cpp:138] Iteration 14050, lr = 0.001
I0826 16:15:29.734103 25446 solver.cpp:243] Iteration 14060, loss = 7.2786
I0826 16:15:29.734125 25446 solver.cpp:259]     Train net output #0: center_loss = 157.655 (* 0.008 = 1.26124 loss)
I0826 16:15:29.734171 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.01735 (* 1 = 6.01735 loss)
I0826 16:15:29.734175 25446 sgd_solver.cpp:138] Iteration 14060, lr = 0.001
I0826 16:15:31.801935 25446 solver.cpp:243] Iteration 14070, loss = 7.66772
I0826 16:15:31.801978 25446 solver.cpp:259]     Train net output #0: center_loss = 127.002 (* 0.008 = 1.01601 loss)
I0826 16:15:31.801985 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.65171 (* 1 = 6.65171 loss)
I0826 16:15:31.801990 25446 sgd_solver.cpp:138] Iteration 14070, lr = 0.001
I0826 16:15:34.085927 25446 solver.cpp:243] Iteration 14080, loss = 7.4815
I0826 16:15:34.085968 25446 solver.cpp:259]     Train net output #0: center_loss = 121.378 (* 0.008 = 0.971024 loss)
I0826 16:15:34.085974 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.51048 (* 1 = 6.51048 loss)
I0826 16:15:34.085978 25446 sgd_solver.cpp:138] Iteration 14080, lr = 0.001
I0826 16:15:36.249127 25446 solver.cpp:243] Iteration 14090, loss = 7.20557
I0826 16:15:36.249166 25446 solver.cpp:259]     Train net output #0: center_loss = 174.484 (* 0.008 = 1.39587 loss)
I0826 16:15:36.249171 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.8097 (* 1 = 5.8097 loss)
I0826 16:15:36.249176 25446 sgd_solver.cpp:138] Iteration 14090, lr = 0.001
I0826 16:15:38.343631 25446 solver.cpp:243] Iteration 14100, loss = 6.96571
I0826 16:15:38.343752 25446 solver.cpp:259]     Train net output #0: center_loss = 141.212 (* 0.008 = 1.1297 loss)
I0826 16:15:38.343788 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.83601 (* 1 = 5.83601 loss)
I0826 16:15:38.343794 25446 sgd_solver.cpp:138] Iteration 14100, lr = 0.001
I0826 16:15:40.468086 25446 solver.cpp:243] Iteration 14110, loss = 6.72622
I0826 16:15:40.468123 25446 solver.cpp:259]     Train net output #0: center_loss = 154.87 (* 0.008 = 1.23896 loss)
I0826 16:15:40.468129 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.48727 (* 1 = 5.48727 loss)
I0826 16:15:40.468133 25446 sgd_solver.cpp:138] Iteration 14110, lr = 0.001
I0826 16:15:42.530138 25446 solver.cpp:243] Iteration 14120, loss = 7.52381
I0826 16:15:42.530161 25446 solver.cpp:259]     Train net output #0: center_loss = 133.094 (* 0.008 = 1.06475 loss)
I0826 16:15:42.530167 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.45905 (* 1 = 6.45905 loss)
I0826 16:15:42.530170 25446 sgd_solver.cpp:138] Iteration 14120, lr = 0.001
I0826 16:15:44.590108 25446 solver.cpp:243] Iteration 14130, loss = 7.33272
I0826 16:15:44.590132 25446 solver.cpp:259]     Train net output #0: center_loss = 130.453 (* 0.008 = 1.04362 loss)
I0826 16:15:44.590138 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.2891 (* 1 = 6.2891 loss)
I0826 16:15:44.590142 25446 sgd_solver.cpp:138] Iteration 14130, lr = 0.001
I0826 16:15:46.649188 25446 solver.cpp:243] Iteration 14140, loss = 7.47687
I0826 16:15:46.649212 25446 solver.cpp:259]     Train net output #0: center_loss = 133.494 (* 0.008 = 1.06795 loss)
I0826 16:15:46.649219 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.40892 (* 1 = 6.40892 loss)
I0826 16:15:46.649222 25446 sgd_solver.cpp:138] Iteration 14140, lr = 0.001
I0826 16:15:48.706733 25446 solver.cpp:243] Iteration 14150, loss = 6.57379
I0826 16:15:48.706763 25446 solver.cpp:259]     Train net output #0: center_loss = 169.411 (* 0.008 = 1.35529 loss)
I0826 16:15:48.706768 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.2185 (* 1 = 5.2185 loss)
I0826 16:15:48.706773 25446 sgd_solver.cpp:138] Iteration 14150, lr = 0.001
I0826 16:15:50.851805 25446 solver.cpp:243] Iteration 14160, loss = 7.27975
I0826 16:15:50.851846 25446 solver.cpp:259]     Train net output #0: center_loss = 167.39 (* 0.008 = 1.33912 loss)
I0826 16:15:50.851852 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.94063 (* 1 = 5.94063 loss)
I0826 16:15:50.851857 25446 sgd_solver.cpp:138] Iteration 14160, lr = 0.001
I0826 16:15:53.048465 25446 solver.cpp:243] Iteration 14170, loss = 8.06934
I0826 16:15:53.048491 25446 solver.cpp:259]     Train net output #0: center_loss = 141.24 (* 0.008 = 1.12992 loss)
I0826 16:15:53.048496 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93942 (* 1 = 6.93942 loss)
I0826 16:15:53.048501 25446 sgd_solver.cpp:138] Iteration 14170, lr = 0.001
I0826 16:15:55.148321 25446 solver.cpp:243] Iteration 14180, loss = 7.51857
I0826 16:15:55.148349 25446 solver.cpp:259]     Train net output #0: center_loss = 122.34 (* 0.008 = 0.978718 loss)
I0826 16:15:55.148355 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.53985 (* 1 = 6.53985 loss)
I0826 16:15:55.148360 25446 sgd_solver.cpp:138] Iteration 14180, lr = 0.001
I0826 16:15:57.273382 25446 solver.cpp:243] Iteration 14190, loss = 7.73041
I0826 16:15:57.273420 25446 solver.cpp:259]     Train net output #0: center_loss = 160.132 (* 0.008 = 1.28106 loss)
I0826 16:15:57.273427 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.44935 (* 1 = 6.44935 loss)
I0826 16:15:57.273430 25446 sgd_solver.cpp:138] Iteration 14190, lr = 0.001
I0826 16:15:59.330050 25446 solver.cpp:243] Iteration 14200, loss = 7.35366
I0826 16:15:59.330075 25446 solver.cpp:259]     Train net output #0: center_loss = 155.15 (* 0.008 = 1.2412 loss)
I0826 16:15:59.330081 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.11247 (* 1 = 6.11247 loss)
I0826 16:15:59.330085 25446 sgd_solver.cpp:138] Iteration 14200, lr = 0.001
I0826 16:16:01.392434 25446 solver.cpp:243] Iteration 14210, loss = 7.08727
I0826 16:16:01.392458 25446 solver.cpp:259]     Train net output #0: center_loss = 146.928 (* 0.008 = 1.17543 loss)
I0826 16:16:01.392464 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.91185 (* 1 = 5.91185 loss)
I0826 16:16:01.392468 25446 sgd_solver.cpp:138] Iteration 14210, lr = 0.001
I0826 16:16:03.453088 25446 solver.cpp:243] Iteration 14220, loss = 7.76733
I0826 16:16:03.453127 25446 solver.cpp:259]     Train net output #0: center_loss = 124.898 (* 0.008 = 0.999185 loss)
I0826 16:16:03.453133 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.76814 (* 1 = 6.76814 loss)
I0826 16:16:03.453137 25446 sgd_solver.cpp:138] Iteration 14220, lr = 0.001
I0826 16:16:05.513293 25446 solver.cpp:243] Iteration 14230, loss = 8.12601
I0826 16:16:05.513345 25446 solver.cpp:259]     Train net output #0: center_loss = 132.29 (* 0.008 = 1.05832 loss)
I0826 16:16:05.513350 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.06769 (* 1 = 7.06769 loss)
I0826 16:16:05.513353 25446 sgd_solver.cpp:138] Iteration 14230, lr = 0.001
I0826 16:16:07.570696 25446 solver.cpp:243] Iteration 14240, loss = 6.9618
I0826 16:16:07.570735 25446 solver.cpp:259]     Train net output #0: center_loss = 106.611 (* 0.008 = 0.852889 loss)
I0826 16:16:07.570741 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.10891 (* 1 = 6.10891 loss)
I0826 16:16:07.570745 25446 sgd_solver.cpp:138] Iteration 14240, lr = 0.001
I0826 16:16:09.631669 25446 solver.cpp:243] Iteration 14250, loss = 7.14802
I0826 16:16:09.631840 25446 solver.cpp:259]     Train net output #0: center_loss = 146.61 (* 0.008 = 1.17288 loss)
I0826 16:16:09.631861 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.97514 (* 1 = 5.97514 loss)
I0826 16:16:09.631865 25446 sgd_solver.cpp:138] Iteration 14250, lr = 0.001
I0826 16:16:11.686414 25446 solver.cpp:243] Iteration 14260, loss = 7.20844
I0826 16:16:11.686455 25446 solver.cpp:259]     Train net output #0: center_loss = 132.126 (* 0.008 = 1.05701 loss)
I0826 16:16:11.686461 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.15143 (* 1 = 6.15143 loss)
I0826 16:16:11.686465 25446 sgd_solver.cpp:138] Iteration 14260, lr = 0.001
I0826 16:16:13.746448 25446 solver.cpp:243] Iteration 14270, loss = 6.08936
I0826 16:16:13.746489 25446 solver.cpp:259]     Train net output #0: center_loss = 181.112 (* 0.008 = 1.4489 loss)
I0826 16:16:13.746495 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64046 (* 1 = 4.64046 loss)
I0826 16:16:13.746497 25446 sgd_solver.cpp:138] Iteration 14270, lr = 0.001
I0826 16:16:15.804754 25446 solver.cpp:243] Iteration 14280, loss = 7.6782
I0826 16:16:15.804793 25446 solver.cpp:259]     Train net output #0: center_loss = 128.591 (* 0.008 = 1.02873 loss)
I0826 16:16:15.804800 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.64948 (* 1 = 6.64948 loss)
I0826 16:16:15.804803 25446 sgd_solver.cpp:138] Iteration 14280, lr = 0.001
I0826 16:16:17.867357 25446 solver.cpp:243] Iteration 14290, loss = 6.93014
I0826 16:16:17.867394 25446 solver.cpp:259]     Train net output #0: center_loss = 151.413 (* 0.008 = 1.2113 loss)
I0826 16:16:17.867401 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71883 (* 1 = 5.71883 loss)
I0826 16:16:17.867405 25446 sgd_solver.cpp:138] Iteration 14290, lr = 0.001
I0826 16:16:19.926805 25446 solver.cpp:243] Iteration 14300, loss = 7.87478
I0826 16:16:19.926842 25446 solver.cpp:259]     Train net output #0: center_loss = 133.501 (* 0.008 = 1.06801 loss)
I0826 16:16:19.926848 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.80677 (* 1 = 6.80677 loss)
I0826 16:16:19.926852 25446 sgd_solver.cpp:138] Iteration 14300, lr = 0.001
I0826 16:16:21.988220 25446 solver.cpp:243] Iteration 14310, loss = 7.21027
I0826 16:16:21.988258 25446 solver.cpp:259]     Train net output #0: center_loss = 170.865 (* 0.008 = 1.36692 loss)
I0826 16:16:21.988265 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.84335 (* 1 = 5.84335 loss)
I0826 16:16:21.988268 25446 sgd_solver.cpp:138] Iteration 14310, lr = 0.001
I0826 16:16:24.047292 25446 solver.cpp:243] Iteration 14320, loss = 6.93388
I0826 16:16:24.047315 25446 solver.cpp:259]     Train net output #0: center_loss = 159.221 (* 0.008 = 1.27377 loss)
I0826 16:16:24.047322 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.66011 (* 1 = 5.66011 loss)
I0826 16:16:24.047324 25446 sgd_solver.cpp:138] Iteration 14320, lr = 0.001
I0826 16:16:26.102957 25446 solver.cpp:243] Iteration 14330, loss = 7.44626
I0826 16:16:26.102979 25446 solver.cpp:259]     Train net output #0: center_loss = 161.195 (* 0.008 = 1.28956 loss)
I0826 16:16:26.102985 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.1567 (* 1 = 6.1567 loss)
I0826 16:16:26.102988 25446 sgd_solver.cpp:138] Iteration 14330, lr = 0.001
I0826 16:16:28.160404 25446 solver.cpp:243] Iteration 14340, loss = 7.25312
I0826 16:16:28.160444 25446 solver.cpp:259]     Train net output #0: center_loss = 166.271 (* 0.008 = 1.33017 loss)
I0826 16:16:28.160450 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.92295 (* 1 = 5.92295 loss)
I0826 16:16:28.160454 25446 sgd_solver.cpp:138] Iteration 14340, lr = 0.001
I0826 16:16:30.218015 25446 solver.cpp:243] Iteration 14350, loss = 7.03933
I0826 16:16:30.218039 25446 solver.cpp:259]     Train net output #0: center_loss = 189.544 (* 0.008 = 1.51635 loss)
I0826 16:16:30.218046 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.52298 (* 1 = 5.52298 loss)
I0826 16:16:30.218050 25446 sgd_solver.cpp:138] Iteration 14350, lr = 0.001
I0826 16:16:32.412853 25446 solver.cpp:243] Iteration 14360, loss = 7.93571
I0826 16:16:32.412878 25446 solver.cpp:259]     Train net output #0: center_loss = 112.587 (* 0.008 = 0.900699 loss)
I0826 16:16:32.412883 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.03501 (* 1 = 7.03501 loss)
I0826 16:16:32.412887 25446 sgd_solver.cpp:138] Iteration 14360, lr = 0.001
I0826 16:16:34.551986 25446 solver.cpp:243] Iteration 14370, loss = 7.49036
I0826 16:16:34.552026 25446 solver.cpp:259]     Train net output #0: center_loss = 148.22 (* 0.008 = 1.18576 loss)
I0826 16:16:34.552031 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.3046 (* 1 = 6.3046 loss)
I0826 16:16:34.552036 25446 sgd_solver.cpp:138] Iteration 14370, lr = 0.001
I0826 16:16:36.613529 25446 solver.cpp:243] Iteration 14380, loss = 7.28723
I0826 16:16:36.613569 25446 solver.cpp:259]     Train net output #0: center_loss = 162.157 (* 0.008 = 1.29726 loss)
I0826 16:16:36.613574 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.98997 (* 1 = 5.98997 loss)
I0826 16:16:36.613579 25446 sgd_solver.cpp:138] Iteration 14380, lr = 0.001
I0826 16:16:38.673838 25446 solver.cpp:243] Iteration 14390, loss = 7.62316
I0826 16:16:38.673862 25446 solver.cpp:259]     Train net output #0: center_loss = 149.102 (* 0.008 = 1.19281 loss)
I0826 16:16:38.673868 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.43035 (* 1 = 6.43035 loss)
I0826 16:16:38.673872 25446 sgd_solver.cpp:138] Iteration 14390, lr = 0.001
I0826 16:16:40.732589 25446 solver.cpp:243] Iteration 14400, loss = 6.46428
I0826 16:16:40.732719 25446 solver.cpp:259]     Train net output #0: center_loss = 171.226 (* 0.008 = 1.3698 loss)
I0826 16:16:40.732726 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.09448 (* 1 = 5.09448 loss)
I0826 16:16:40.732729 25446 sgd_solver.cpp:138] Iteration 14400, lr = 0.001
I0826 16:16:42.790310 25446 solver.cpp:243] Iteration 14410, loss = 6.75321
I0826 16:16:42.790334 25446 solver.cpp:259]     Train net output #0: center_loss = 169.136 (* 0.008 = 1.35309 loss)
I0826 16:16:42.790340 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.40012 (* 1 = 5.40012 loss)
I0826 16:16:42.790344 25446 sgd_solver.cpp:138] Iteration 14410, lr = 0.001
I0826 16:16:44.850056 25446 solver.cpp:243] Iteration 14420, loss = 7.02789
I0826 16:16:44.850095 25446 solver.cpp:259]     Train net output #0: center_loss = 134.965 (* 0.008 = 1.07972 loss)
I0826 16:16:44.850101 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.94817 (* 1 = 5.94817 loss)
I0826 16:16:44.850106 25446 sgd_solver.cpp:138] Iteration 14420, lr = 0.001
I0826 16:16:46.911933 25446 solver.cpp:243] Iteration 14430, loss = 7.85575
I0826 16:16:46.911957 25446 solver.cpp:259]     Train net output #0: center_loss = 115.514 (* 0.008 = 0.924108 loss)
I0826 16:16:46.911963 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.93164 (* 1 = 6.93164 loss)
I0826 16:16:46.911967 25446 sgd_solver.cpp:138] Iteration 14430, lr = 0.001
I0826 16:16:48.972056 25446 solver.cpp:243] Iteration 14440, loss = 7.52562
I0826 16:16:48.972095 25446 solver.cpp:259]     Train net output #0: center_loss = 174.103 (* 0.008 = 1.39282 loss)
I0826 16:16:48.972101 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.1328 (* 1 = 6.1328 loss)
I0826 16:16:48.972105 25446 sgd_solver.cpp:138] Iteration 14440, lr = 0.001
I0826 16:16:51.029433 25446 solver.cpp:243] Iteration 14450, loss = 6.74167
I0826 16:16:51.029471 25446 solver.cpp:259]     Train net output #0: center_loss = 135.178 (* 0.008 = 1.08142 loss)
I0826 16:16:51.029477 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.66025 (* 1 = 5.66025 loss)
I0826 16:16:51.029481 25446 sgd_solver.cpp:138] Iteration 14450, lr = 0.001
I0826 16:16:53.089751 25446 solver.cpp:243] Iteration 14460, loss = 7.92357
I0826 16:16:53.089790 25446 solver.cpp:259]     Train net output #0: center_loss = 158.657 (* 0.008 = 1.26926 loss)
I0826 16:16:53.089797 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.65431 (* 1 = 6.65431 loss)
I0826 16:16:53.089800 25446 sgd_solver.cpp:138] Iteration 14460, lr = 0.001
I0826 16:16:55.150473 25446 solver.cpp:243] Iteration 14470, loss = 6.42613
I0826 16:16:55.150512 25446 solver.cpp:259]     Train net output #0: center_loss = 146.736 (* 0.008 = 1.17389 loss)
I0826 16:16:55.150518 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.25225 (* 1 = 5.25225 loss)
I0826 16:16:55.150522 25446 sgd_solver.cpp:138] Iteration 14470, lr = 0.001
I0826 16:16:57.214589 25446 solver.cpp:243] Iteration 14480, loss = 7.05903
I0826 16:16:57.214628 25446 solver.cpp:259]     Train net output #0: center_loss = 149.824 (* 0.008 = 1.19859 loss)
I0826 16:16:57.214634 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.86044 (* 1 = 5.86044 loss)
I0826 16:16:57.214638 25446 sgd_solver.cpp:138] Iteration 14480, lr = 0.001
I0826 16:16:59.277282 25446 solver.cpp:243] Iteration 14490, loss = 7.61494
I0826 16:16:59.277318 25446 solver.cpp:259]     Train net output #0: center_loss = 126.912 (* 0.008 = 1.01529 loss)
I0826 16:16:59.277339 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.59965 (* 1 = 6.59965 loss)
I0826 16:16:59.277343 25446 sgd_solver.cpp:138] Iteration 14490, lr = 0.001
I0826 16:17:01.336944 25446 solver.cpp:243] Iteration 14500, loss = 8.29699
I0826 16:17:01.336967 25446 solver.cpp:259]     Train net output #0: center_loss = 152.249 (* 0.008 = 1.21799 loss)
I0826 16:17:01.336973 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.079 (* 1 = 7.079 loss)
I0826 16:17:01.336977 25446 sgd_solver.cpp:138] Iteration 14500, lr = 0.001
I0826 16:17:03.394723 25446 solver.cpp:243] Iteration 14510, loss = 8.12916
I0826 16:17:03.394763 25446 solver.cpp:259]     Train net output #0: center_loss = 127.658 (* 0.008 = 1.02126 loss)
I0826 16:17:03.394769 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.1079 (* 1 = 7.1079 loss)
I0826 16:17:03.394773 25446 sgd_solver.cpp:138] Iteration 14510, lr = 0.001
I0826 16:17:05.455760 25446 solver.cpp:243] Iteration 14520, loss = 6.15418
I0826 16:17:05.455799 25446 solver.cpp:259]     Train net output #0: center_loss = 203.484 (* 0.008 = 1.62787 loss)
I0826 16:17:05.455806 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52631 (* 1 = 4.52631 loss)
I0826 16:17:05.455809 25446 sgd_solver.cpp:138] Iteration 14520, lr = 0.001
I0826 16:17:07.517057 25446 solver.cpp:243] Iteration 14530, loss = 6.95093
I0826 16:17:07.517083 25446 solver.cpp:259]     Train net output #0: center_loss = 136.846 (* 0.008 = 1.09477 loss)
I0826 16:17:07.517089 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.85616 (* 1 = 5.85616 loss)
I0826 16:17:07.517093 25446 sgd_solver.cpp:138] Iteration 14530, lr = 0.001
I0826 16:17:09.577689 25446 solver.cpp:243] Iteration 14540, loss = 6.87645
I0826 16:17:09.577728 25446 solver.cpp:259]     Train net output #0: center_loss = 148.918 (* 0.008 = 1.19135 loss)
I0826 16:17:09.577734 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.6851 (* 1 = 5.6851 loss)
I0826 16:17:09.577739 25446 sgd_solver.cpp:138] Iteration 14540, lr = 0.001
I0826 16:17:11.635843 25446 solver.cpp:243] Iteration 14550, loss = 7.04346
I0826 16:17:11.635974 25446 solver.cpp:259]     Train net output #0: center_loss = 182.331 (* 0.008 = 1.45865 loss)
I0826 16:17:11.635994 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.58481 (* 1 = 5.58481 loss)
I0826 16:17:11.635998 25446 sgd_solver.cpp:138] Iteration 14550, lr = 0.001
I0826 16:17:13.693717 25446 solver.cpp:243] Iteration 14560, loss = 7.30779
I0826 16:17:13.693740 25446 solver.cpp:259]     Train net output #0: center_loss = 163.152 (* 0.008 = 1.30521 loss)
I0826 16:17:13.693747 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.00257 (* 1 = 6.00257 loss)
I0826 16:17:13.693750 25446 sgd_solver.cpp:138] Iteration 14560, lr = 0.001
I0826 16:17:15.752126 25446 solver.cpp:243] Iteration 14570, loss = 7.47338
I0826 16:17:15.752151 25446 solver.cpp:259]     Train net output #0: center_loss = 145.794 (* 0.008 = 1.16635 loss)
I0826 16:17:15.752156 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.30703 (* 1 = 6.30703 loss)
I0826 16:17:15.752161 25446 sgd_solver.cpp:138] Iteration 14570, lr = 0.001
I0826 16:17:17.812095 25446 solver.cpp:243] Iteration 14580, loss = 7.99374
I0826 16:17:17.812135 25446 solver.cpp:259]     Train net output #0: center_loss = 148.781 (* 0.008 = 1.19025 loss)
I0826 16:17:17.812141 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.80349 (* 1 = 6.80349 loss)
I0826 16:17:17.812145 25446 sgd_solver.cpp:138] Iteration 14580, lr = 0.001
I0826 16:17:19.872665 25446 solver.cpp:243] Iteration 14590, loss = 8.15008
I0826 16:17:19.872704 25446 solver.cpp:259]     Train net output #0: center_loss = 138.774 (* 0.008 = 1.11019 loss)
I0826 16:17:19.872709 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.03989 (* 1 = 7.03989 loss)
I0826 16:17:19.872714 25446 sgd_solver.cpp:138] Iteration 14590, lr = 0.001
I0826 16:17:21.930689 25446 solver.cpp:243] Iteration 14600, loss = 7.6368
I0826 16:17:21.930727 25446 solver.cpp:259]     Train net output #0: center_loss = 156.314 (* 0.008 = 1.25051 loss)
I0826 16:17:21.930733 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.38629 (* 1 = 6.38629 loss)
I0826 16:17:21.930737 25446 sgd_solver.cpp:138] Iteration 14600, lr = 0.001
I0826 16:17:23.993253 25446 solver.cpp:243] Iteration 14610, loss = 7.15266
I0826 16:17:23.993290 25446 solver.cpp:259]     Train net output #0: center_loss = 152.09 (* 0.008 = 1.21672 loss)
I0826 16:17:23.993296 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.93594 (* 1 = 5.93594 loss)
I0826 16:17:23.993300 25446 sgd_solver.cpp:138] Iteration 14610, lr = 0.001
I0826 16:17:26.050611 25446 solver.cpp:243] Iteration 14620, loss = 6.1797
I0826 16:17:26.050649 25446 solver.cpp:259]     Train net output #0: center_loss = 164.968 (* 0.008 = 1.31975 loss)
I0826 16:17:26.050655 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.85995 (* 1 = 4.85995 loss)
I0826 16:17:26.050659 25446 sgd_solver.cpp:138] Iteration 14620, lr = 0.001
I0826 16:17:28.207690 25446 solver.cpp:243] Iteration 14630, loss = 6.73265
I0826 16:17:28.207716 25446 solver.cpp:259]     Train net output #0: center_loss = 193.474 (* 0.008 = 1.5478 loss)
I0826 16:17:28.207722 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.18486 (* 1 = 5.18486 loss)
I0826 16:17:28.207726 25446 sgd_solver.cpp:138] Iteration 14630, lr = 0.001
I0826 16:17:30.345039 25446 solver.cpp:243] Iteration 14640, loss = 7.18216
I0826 16:17:30.345078 25446 solver.cpp:259]     Train net output #0: center_loss = 173.22 (* 0.008 = 1.38576 loss)
I0826 16:17:30.345085 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.7964 (* 1 = 5.7964 loss)
I0826 16:17:30.345089 25446 sgd_solver.cpp:138] Iteration 14640, lr = 0.001
I0826 16:17:32.406189 25446 solver.cpp:243] Iteration 14650, loss = 7.94971
I0826 16:17:32.406227 25446 solver.cpp:259]     Train net output #0: center_loss = 152.023 (* 0.008 = 1.21618 loss)
I0826 16:17:32.406234 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.73353 (* 1 = 6.73353 loss)
I0826 16:17:32.406237 25446 sgd_solver.cpp:138] Iteration 14650, lr = 0.001
I0826 16:17:34.467836 25446 solver.cpp:243] Iteration 14660, loss = 6.72105
I0826 16:17:34.467875 25446 solver.cpp:259]     Train net output #0: center_loss = 176.249 (* 0.008 = 1.40999 loss)
I0826 16:17:34.467882 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.31106 (* 1 = 5.31106 loss)
I0826 16:17:34.467885 25446 sgd_solver.cpp:138] Iteration 14660, lr = 0.001
I0826 16:17:36.595150 25446 solver.cpp:243] Iteration 14670, loss = 7.40268
I0826 16:17:36.595190 25446 solver.cpp:259]     Train net output #0: center_loss = 136.795 (* 0.008 = 1.09436 loss)
I0826 16:17:36.595196 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.30832 (* 1 = 6.30832 loss)
I0826 16:17:36.595199 25446 sgd_solver.cpp:138] Iteration 14670, lr = 0.001
I0826 16:17:38.862741 25446 solver.cpp:243] Iteration 14680, loss = 7.83265
I0826 16:17:38.862781 25446 solver.cpp:259]     Train net output #0: center_loss = 123.07 (* 0.008 = 0.984557 loss)
I0826 16:17:38.862787 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.84809 (* 1 = 6.84809 loss)
I0826 16:17:38.862790 25446 sgd_solver.cpp:138] Iteration 14680, lr = 0.001
I0826 16:17:41.118099 25446 solver.cpp:243] Iteration 14690, loss = 7.35186
I0826 16:17:41.118139 25446 solver.cpp:259]     Train net output #0: center_loss = 116.648 (* 0.008 = 0.933186 loss)
I0826 16:17:41.118145 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.41867 (* 1 = 6.41867 loss)
I0826 16:17:41.118149 25446 sgd_solver.cpp:138] Iteration 14690, lr = 0.001
I0826 16:17:43.236310 25446 solver.cpp:243] Iteration 14700, loss = 6.89661
I0826 16:17:43.236459 25446 solver.cpp:259]     Train net output #0: center_loss = 146.378 (* 0.008 = 1.17103 loss)
I0826 16:17:43.236479 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.72559 (* 1 = 5.72559 loss)
I0826 16:17:43.236483 25446 sgd_solver.cpp:138] Iteration 14700, lr = 0.001
I0826 16:17:45.316273 25446 solver.cpp:243] Iteration 14710, loss = 7.71328
I0826 16:17:45.316313 25446 solver.cpp:259]     Train net output #0: center_loss = 135.75 (* 0.008 = 1.086 loss)
I0826 16:17:45.316319 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.62727 (* 1 = 6.62727 loss)
I0826 16:17:45.316323 25446 sgd_solver.cpp:138] Iteration 14710, lr = 0.001
I0826 16:17:47.376232 25446 solver.cpp:243] Iteration 14720, loss = 7.28635
I0826 16:17:47.376257 25446 solver.cpp:259]     Train net output #0: center_loss = 169.561 (* 0.008 = 1.35649 loss)
I0826 16:17:47.376263 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.92986 (* 1 = 5.92986 loss)
I0826 16:17:47.376267 25446 sgd_solver.cpp:138] Iteration 14720, lr = 0.001
I0826 16:17:49.437928 25446 solver.cpp:243] Iteration 14730, loss = 7.85005
I0826 16:17:49.437966 25446 solver.cpp:259]     Train net output #0: center_loss = 170.526 (* 0.008 = 1.3642 loss)
I0826 16:17:49.437973 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.48584 (* 1 = 6.48584 loss)
I0826 16:17:49.437976 25446 sgd_solver.cpp:138] Iteration 14730, lr = 0.001
I0826 16:17:51.494814 25446 solver.cpp:243] Iteration 14740, loss = 7.39562
I0826 16:17:51.494837 25446 solver.cpp:259]     Train net output #0: center_loss = 166.73 (* 0.008 = 1.33384 loss)
I0826 16:17:51.494843 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.06178 (* 1 = 6.06178 loss)
I0826 16:17:51.494848 25446 sgd_solver.cpp:138] Iteration 14740, lr = 0.001
I0826 16:17:53.551810 25446 solver.cpp:243] Iteration 14750, loss = 6.78723
I0826 16:17:53.551833 25446 solver.cpp:259]     Train net output #0: center_loss = 134.179 (* 0.008 = 1.07343 loss)
I0826 16:17:53.551839 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71379 (* 1 = 5.71379 loss)
I0826 16:17:53.551843 25446 sgd_solver.cpp:138] Iteration 14750, lr = 0.001
I0826 16:17:55.692515 25446 solver.cpp:243] Iteration 14760, loss = 7.93653
I0826 16:17:55.692539 25446 solver.cpp:259]     Train net output #0: center_loss = 135.076 (* 0.008 = 1.08061 loss)
I0826 16:17:55.692545 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.85592 (* 1 = 6.85592 loss)
I0826 16:17:55.692550 25446 sgd_solver.cpp:138] Iteration 14760, lr = 0.001
I0826 16:17:57.832188 25446 solver.cpp:243] Iteration 14770, loss = 7.31678
I0826 16:17:57.832227 25446 solver.cpp:259]     Train net output #0: center_loss = 151.726 (* 0.008 = 1.21381 loss)
I0826 16:17:57.832233 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.10297 (* 1 = 6.10297 loss)
I0826 16:17:57.832237 25446 sgd_solver.cpp:138] Iteration 14770, lr = 0.001
I0826 16:17:59.892304 25446 solver.cpp:243] Iteration 14780, loss = 8.09777
I0826 16:17:59.892343 25446 solver.cpp:259]     Train net output #0: center_loss = 151.579 (* 0.008 = 1.21263 loss)
I0826 16:17:59.892349 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.88513 (* 1 = 6.88513 loss)
I0826 16:17:59.892354 25446 sgd_solver.cpp:138] Iteration 14780, lr = 0.001
I0826 16:18:01.955044 25446 solver.cpp:243] Iteration 14790, loss = 7.69684
I0826 16:18:01.955067 25446 solver.cpp:259]     Train net output #0: center_loss = 170.31 (* 0.008 = 1.36248 loss)
I0826 16:18:01.955073 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.33436 (* 1 = 6.33436 loss)
I0826 16:18:01.955077 25446 sgd_solver.cpp:138] Iteration 14790, lr = 0.001
I0826 16:18:04.014204 25446 solver.cpp:243] Iteration 14800, loss = 7.27821
I0826 16:18:04.014242 25446 solver.cpp:259]     Train net output #0: center_loss = 165.768 (* 0.008 = 1.32615 loss)
I0826 16:18:04.014248 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.95207 (* 1 = 5.95207 loss)
I0826 16:18:04.014252 25446 sgd_solver.cpp:138] Iteration 14800, lr = 0.001
I0826 16:18:06.071125 25446 solver.cpp:243] Iteration 14810, loss = 7.75375
I0826 16:18:06.071148 25446 solver.cpp:259]     Train net output #0: center_loss = 179.166 (* 0.008 = 1.43333 loss)
I0826 16:18:06.071154 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.32042 (* 1 = 6.32042 loss)
I0826 16:18:06.071157 25446 sgd_solver.cpp:138] Iteration 14810, lr = 0.001
I0826 16:18:08.131330 25446 solver.cpp:243] Iteration 14820, loss = 6.86244
I0826 16:18:08.131381 25446 solver.cpp:259]     Train net output #0: center_loss = 137.536 (* 0.008 = 1.10029 loss)
I0826 16:18:08.131387 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.76215 (* 1 = 5.76215 loss)
I0826 16:18:08.131390 25446 sgd_solver.cpp:138] Iteration 14820, lr = 0.001
I0826 16:18:10.191334 25446 solver.cpp:243] Iteration 14830, loss = 7.47848
I0826 16:18:10.191359 25446 solver.cpp:259]     Train net output #0: center_loss = 163.497 (* 0.008 = 1.30797 loss)
I0826 16:18:10.191365 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.17051 (* 1 = 6.17051 loss)
I0826 16:18:10.191367 25446 sgd_solver.cpp:138] Iteration 14830, lr = 0.001
I0826 16:18:12.247045 25446 solver.cpp:243] Iteration 14840, loss = 7.71867
I0826 16:18:12.247084 25446 solver.cpp:259]     Train net output #0: center_loss = 99.1109 (* 0.008 = 0.792888 loss)
I0826 16:18:12.247090 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.92578 (* 1 = 6.92578 loss)
I0826 16:18:12.247094 25446 sgd_solver.cpp:138] Iteration 14840, lr = 0.001
I0826 16:18:14.308955 25446 solver.cpp:243] Iteration 14850, loss = 6.27169
I0826 16:18:14.309114 25446 solver.cpp:259]     Train net output #0: center_loss = 168.566 (* 0.008 = 1.34853 loss)
I0826 16:18:14.309121 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.92316 (* 1 = 4.92316 loss)
I0826 16:18:14.309124 25446 sgd_solver.cpp:138] Iteration 14850, lr = 0.001
I0826 16:18:16.366272 25446 solver.cpp:243] Iteration 14860, loss = 7.60441
I0826 16:18:16.366312 25446 solver.cpp:259]     Train net output #0: center_loss = 175.67 (* 0.008 = 1.40536 loss)
I0826 16:18:16.366318 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.19905 (* 1 = 6.19905 loss)
I0826 16:18:16.366322 25446 sgd_solver.cpp:138] Iteration 14860, lr = 0.001
I0826 16:18:18.426151 25446 solver.cpp:243] Iteration 14870, loss = 7.83624
I0826 16:18:18.426174 25446 solver.cpp:259]     Train net output #0: center_loss = 145.387 (* 0.008 = 1.1631 loss)
I0826 16:18:18.426182 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.67314 (* 1 = 6.67314 loss)
I0826 16:18:18.426185 25446 sgd_solver.cpp:138] Iteration 14870, lr = 0.001
I0826 16:18:20.488659 25446 solver.cpp:243] Iteration 14880, loss = 7.4559
I0826 16:18:20.488683 25446 solver.cpp:259]     Train net output #0: center_loss = 158.975 (* 0.008 = 1.2718 loss)
I0826 16:18:20.488689 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.1841 (* 1 = 6.1841 loss)
I0826 16:18:20.488692 25446 sgd_solver.cpp:138] Iteration 14880, lr = 0.001
I0826 16:18:22.548336 25446 solver.cpp:243] Iteration 14890, loss = 7.61907
I0826 16:18:22.548374 25446 solver.cpp:259]     Train net output #0: center_loss = 129.396 (* 0.008 = 1.03517 loss)
I0826 16:18:22.548382 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.5839 (* 1 = 6.5839 loss)
I0826 16:18:22.548384 25446 sgd_solver.cpp:138] Iteration 14890, lr = 0.001
I0826 16:18:24.607393 25446 solver.cpp:243] Iteration 14900, loss = 7.52428
I0826 16:18:24.607415 25446 solver.cpp:259]     Train net output #0: center_loss = 144.413 (* 0.008 = 1.1553 loss)
I0826 16:18:24.607421 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.36898 (* 1 = 6.36898 loss)
I0826 16:18:24.607425 25446 sgd_solver.cpp:138] Iteration 14900, lr = 0.001
I0826 16:18:26.667218 25446 solver.cpp:243] Iteration 14910, loss = 6.86729
I0826 16:18:26.667256 25446 solver.cpp:259]     Train net output #0: center_loss = 168.803 (* 0.008 = 1.35043 loss)
I0826 16:18:26.667263 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.51687 (* 1 = 5.51687 loss)
I0826 16:18:26.667266 25446 sgd_solver.cpp:138] Iteration 14910, lr = 0.001
I0826 16:18:28.727468 25446 solver.cpp:243] Iteration 14920, loss = 6.19994
I0826 16:18:28.727491 25446 solver.cpp:259]     Train net output #0: center_loss = 178.998 (* 0.008 = 1.43198 loss)
I0826 16:18:28.727497 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.76796 (* 1 = 4.76796 loss)
I0826 16:18:28.727500 25446 sgd_solver.cpp:138] Iteration 14920, lr = 0.001
I0826 16:18:30.783926 25446 solver.cpp:243] Iteration 14930, loss = 8.08709
I0826 16:18:30.783967 25446 solver.cpp:259]     Train net output #0: center_loss = 120.005 (* 0.008 = 0.960037 loss)
I0826 16:18:30.783972 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.12705 (* 1 = 7.12705 loss)
I0826 16:18:30.783975 25446 sgd_solver.cpp:138] Iteration 14930, lr = 0.001
I0826 16:18:32.997632 25446 solver.cpp:243] Iteration 14940, loss = 6.04556
I0826 16:18:32.997655 25446 solver.cpp:259]     Train net output #0: center_loss = 175.002 (* 0.008 = 1.40001 loss)
I0826 16:18:32.997661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64555 (* 1 = 4.64555 loss)
I0826 16:18:32.997665 25446 sgd_solver.cpp:138] Iteration 14940, lr = 0.001
I0826 16:18:35.209698 25446 solver.cpp:243] Iteration 14950, loss = 7.76479
I0826 16:18:35.209722 25446 solver.cpp:259]     Train net output #0: center_loss = 154.962 (* 0.008 = 1.2397 loss)
I0826 16:18:35.209728 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.52509 (* 1 = 6.52509 loss)
I0826 16:18:35.209733 25446 sgd_solver.cpp:138] Iteration 14950, lr = 0.001
I0826 16:18:37.472831 25446 solver.cpp:243] Iteration 14960, loss = 7.23361
I0826 16:18:37.472857 25446 solver.cpp:259]     Train net output #0: center_loss = 153.958 (* 0.008 = 1.23167 loss)
I0826 16:18:37.472863 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.00195 (* 1 = 6.00195 loss)
I0826 16:18:37.472868 25446 sgd_solver.cpp:138] Iteration 14960, lr = 0.001
I0826 16:18:39.608486 25446 solver.cpp:243] Iteration 14970, loss = 6.89686
I0826 16:18:39.608525 25446 solver.cpp:259]     Train net output #0: center_loss = 147.251 (* 0.008 = 1.178 loss)
I0826 16:18:39.608531 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71886 (* 1 = 5.71886 loss)
I0826 16:18:39.608536 25446 sgd_solver.cpp:138] Iteration 14970, lr = 0.001
I0826 16:18:41.751049 25446 solver.cpp:243] Iteration 14980, loss = 6.77427
I0826 16:18:41.751088 25446 solver.cpp:259]     Train net output #0: center_loss = 172.167 (* 0.008 = 1.37733 loss)
I0826 16:18:41.751094 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.39693 (* 1 = 5.39693 loss)
I0826 16:18:41.751098 25446 sgd_solver.cpp:138] Iteration 14980, lr = 0.001
I0826 16:18:43.811239 25446 solver.cpp:243] Iteration 14990, loss = 7.74856
I0826 16:18:43.811278 25446 solver.cpp:259]     Train net output #0: center_loss = 148.438 (* 0.008 = 1.18751 loss)
I0826 16:18:43.811285 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.56105 (* 1 = 6.56105 loss)
I0826 16:18:43.811287 25446 sgd_solver.cpp:138] Iteration 14990, lr = 0.001
I0826 16:18:45.666855 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_15000.caffemodel
I0826 16:18:46.801527 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_15000.solverstate
I0826 16:18:47.129590 25446 solver.cpp:243] Iteration 15000, loss = 6.87063
I0826 16:18:47.129614 25446 solver.cpp:259]     Train net output #0: center_loss = 179.434 (* 0.008 = 1.43547 loss)
I0826 16:18:47.129621 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.43516 (* 1 = 5.43516 loss)
I0826 16:18:47.129624 25446 sgd_solver.cpp:138] Iteration 15000, lr = 0.001
I0826 16:18:49.190196 25446 solver.cpp:243] Iteration 15010, loss = 7.47618
I0826 16:18:49.190234 25446 solver.cpp:259]     Train net output #0: center_loss = 148.048 (* 0.008 = 1.18438 loss)
I0826 16:18:49.190240 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.29179 (* 1 = 6.29179 loss)
I0826 16:18:49.190244 25446 sgd_solver.cpp:138] Iteration 15010, lr = 0.001
I0826 16:18:51.249698 25446 solver.cpp:243] Iteration 15020, loss = 7.30869
I0826 16:18:51.249737 25446 solver.cpp:259]     Train net output #0: center_loss = 150.801 (* 0.008 = 1.20641 loss)
I0826 16:18:51.249743 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.10228 (* 1 = 6.10228 loss)
I0826 16:18:51.249747 25446 sgd_solver.cpp:138] Iteration 15020, lr = 0.001
I0826 16:18:53.308763 25446 solver.cpp:243] Iteration 15030, loss = 7.58658
I0826 16:18:53.308786 25446 solver.cpp:259]     Train net output #0: center_loss = 175.073 (* 0.008 = 1.40059 loss)
I0826 16:18:53.308792 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.18599 (* 1 = 6.18599 loss)
I0826 16:18:53.308796 25446 sgd_solver.cpp:138] Iteration 15030, lr = 0.001
I0826 16:18:55.364758 25446 solver.cpp:243] Iteration 15040, loss = 7.67221
I0826 16:18:55.364799 25446 solver.cpp:259]     Train net output #0: center_loss = 151.801 (* 0.008 = 1.21441 loss)
I0826 16:18:55.364804 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.4578 (* 1 = 6.4578 loss)
I0826 16:18:55.364809 25446 sgd_solver.cpp:138] Iteration 15040, lr = 0.001
I0826 16:18:57.423570 25446 solver.cpp:243] Iteration 15050, loss = 7.18551
I0826 16:18:57.423610 25446 solver.cpp:259]     Train net output #0: center_loss = 135.433 (* 0.008 = 1.08347 loss)
I0826 16:18:57.423616 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.10204 (* 1 = 6.10204 loss)
I0826 16:18:57.423620 25446 sgd_solver.cpp:138] Iteration 15050, lr = 0.001
I0826 16:18:59.483209 25446 solver.cpp:243] Iteration 15060, loss = 6.86877
I0826 16:18:59.483248 25446 solver.cpp:259]     Train net output #0: center_loss = 189.616 (* 0.008 = 1.51693 loss)
I0826 16:18:59.483255 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.35184 (* 1 = 5.35184 loss)
I0826 16:18:59.483258 25446 sgd_solver.cpp:138] Iteration 15060, lr = 0.001
I0826 16:19:01.546897 25446 solver.cpp:243] Iteration 15070, loss = 7.34356
I0826 16:19:01.546936 25446 solver.cpp:259]     Train net output #0: center_loss = 166.661 (* 0.008 = 1.33328 loss)
I0826 16:19:01.546942 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.01027 (* 1 = 6.01027 loss)
I0826 16:19:01.546947 25446 sgd_solver.cpp:138] Iteration 15070, lr = 0.001
I0826 16:19:03.605950 25446 solver.cpp:243] Iteration 15080, loss = 6.05379
I0826 16:19:03.605974 25446 solver.cpp:259]     Train net output #0: center_loss = 182.962 (* 0.008 = 1.46369 loss)
I0826 16:19:03.605980 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.59009 (* 1 = 4.59009 loss)
I0826 16:19:03.605984 25446 sgd_solver.cpp:138] Iteration 15080, lr = 0.001
I0826 16:19:05.662288 25446 solver.cpp:243] Iteration 15090, loss = 6.97022
I0826 16:19:05.662328 25446 solver.cpp:259]     Train net output #0: center_loss = 163.967 (* 0.008 = 1.31174 loss)
I0826 16:19:05.662334 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.65848 (* 1 = 5.65848 loss)
I0826 16:19:05.662338 25446 sgd_solver.cpp:138] Iteration 15090, lr = 0.001
I0826 16:19:07.725688 25446 solver.cpp:243] Iteration 15100, loss = 7.34724
I0826 16:19:07.725711 25446 solver.cpp:259]     Train net output #0: center_loss = 138.686 (* 0.008 = 1.10948 loss)
I0826 16:19:07.725757 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.23776 (* 1 = 6.23776 loss)
I0826 16:19:07.725761 25446 sgd_solver.cpp:138] Iteration 15100, lr = 0.001
I0826 16:19:09.782737 25446 solver.cpp:243] Iteration 15110, loss = 6.9925
I0826 16:19:09.782760 25446 solver.cpp:259]     Train net output #0: center_loss = 161.471 (* 0.008 = 1.29176 loss)
I0826 16:19:09.782766 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.70074 (* 1 = 5.70074 loss)
I0826 16:19:09.782770 25446 sgd_solver.cpp:138] Iteration 15110, lr = 0.001
I0826 16:19:11.842144 25446 solver.cpp:243] Iteration 15120, loss = 7.03776
I0826 16:19:11.842167 25446 solver.cpp:259]     Train net output #0: center_loss = 152.28 (* 0.008 = 1.21824 loss)
I0826 16:19:11.842187 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.81952 (* 1 = 5.81952 loss)
I0826 16:19:11.842191 25446 sgd_solver.cpp:138] Iteration 15120, lr = 0.001
I0826 16:19:13.896510 25446 solver.cpp:243] Iteration 15130, loss = 7.66377
I0826 16:19:13.896548 25446 solver.cpp:259]     Train net output #0: center_loss = 143.498 (* 0.008 = 1.14798 loss)
I0826 16:19:13.896554 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.51579 (* 1 = 6.51579 loss)
I0826 16:19:13.896559 25446 sgd_solver.cpp:138] Iteration 15130, lr = 0.001
I0826 16:19:15.957648 25446 solver.cpp:243] Iteration 15140, loss = 7.60553
I0826 16:19:15.957796 25446 solver.cpp:259]     Train net output #0: center_loss = 159.164 (* 0.008 = 1.27331 loss)
I0826 16:19:15.957804 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.33222 (* 1 = 6.33222 loss)
I0826 16:19:15.957808 25446 sgd_solver.cpp:138] Iteration 15140, lr = 0.001
I0826 16:19:18.013648 25446 solver.cpp:243] Iteration 15150, loss = 7.54131
I0826 16:19:18.013686 25446 solver.cpp:259]     Train net output #0: center_loss = 158.2 (* 0.008 = 1.2656 loss)
I0826 16:19:18.013692 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.27571 (* 1 = 6.27571 loss)
I0826 16:19:18.013696 25446 sgd_solver.cpp:138] Iteration 15150, lr = 0.001
I0826 16:19:20.071209 25446 solver.cpp:243] Iteration 15160, loss = 6.89342
I0826 16:19:20.071238 25446 solver.cpp:259]     Train net output #0: center_loss = 144.753 (* 0.008 = 1.15803 loss)
I0826 16:19:20.071244 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.7354 (* 1 = 5.7354 loss)
I0826 16:19:20.071249 25446 sgd_solver.cpp:138] Iteration 15160, lr = 0.001
I0826 16:19:22.129101 25446 solver.cpp:243] Iteration 15170, loss = 7.24754
I0826 16:19:22.129125 25446 solver.cpp:259]     Train net output #0: center_loss = 161.706 (* 0.008 = 1.29365 loss)
I0826 16:19:22.129132 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.95389 (* 1 = 5.95389 loss)
I0826 16:19:22.129135 25446 sgd_solver.cpp:138] Iteration 15170, lr = 0.001
I0826 16:19:24.188146 25446 solver.cpp:243] Iteration 15180, loss = 5.49978
I0826 16:19:24.188169 25446 solver.cpp:259]     Train net output #0: center_loss = 213.984 (* 0.008 = 1.71187 loss)
I0826 16:19:24.188175 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.78791 (* 1 = 3.78791 loss)
I0826 16:19:24.188179 25446 sgd_solver.cpp:138] Iteration 15180, lr = 0.001
I0826 16:19:26.241653 25446 solver.cpp:243] Iteration 15190, loss = 6.86623
I0826 16:19:26.241693 25446 solver.cpp:259]     Train net output #0: center_loss = 158.811 (* 0.008 = 1.27049 loss)
I0826 16:19:26.241698 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.59574 (* 1 = 5.59574 loss)
I0826 16:19:26.241703 25446 sgd_solver.cpp:138] Iteration 15190, lr = 0.001
I0826 16:19:28.303576 25446 solver.cpp:243] Iteration 15200, loss = 7.16702
I0826 16:19:28.303617 25446 solver.cpp:259]     Train net output #0: center_loss = 134.947 (* 0.008 = 1.07958 loss)
I0826 16:19:28.303622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.08744 (* 1 = 6.08744 loss)
I0826 16:19:28.303627 25446 sgd_solver.cpp:138] Iteration 15200, lr = 0.001
I0826 16:19:30.364212 25446 solver.cpp:243] Iteration 15210, loss = 6.92879
I0826 16:19:30.364235 25446 solver.cpp:259]     Train net output #0: center_loss = 166.912 (* 0.008 = 1.33529 loss)
I0826 16:19:30.364241 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.5935 (* 1 = 5.5935 loss)
I0826 16:19:30.364245 25446 sgd_solver.cpp:138] Iteration 15210, lr = 0.001
I0826 16:19:32.506261 25446 solver.cpp:243] Iteration 15220, loss = 7.78549
I0826 16:19:32.506285 25446 solver.cpp:259]     Train net output #0: center_loss = 133.097 (* 0.008 = 1.06478 loss)
I0826 16:19:32.506292 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.72071 (* 1 = 6.72071 loss)
I0826 16:19:32.506295 25446 sgd_solver.cpp:138] Iteration 15220, lr = 0.001
I0826 16:19:34.723839 25446 solver.cpp:243] Iteration 15230, loss = 7.45224
I0826 16:19:34.723862 25446 solver.cpp:259]     Train net output #0: center_loss = 172.008 (* 0.008 = 1.37607 loss)
I0826 16:19:34.723870 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.07617 (* 1 = 6.07617 loss)
I0826 16:19:34.723872 25446 sgd_solver.cpp:138] Iteration 15230, lr = 0.001
I0826 16:19:36.864125 25446 solver.cpp:243] Iteration 15240, loss = 6.66415
I0826 16:19:36.864147 25446 solver.cpp:259]     Train net output #0: center_loss = 153.222 (* 0.008 = 1.22578 loss)
I0826 16:19:36.864153 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.43838 (* 1 = 5.43838 loss)
I0826 16:19:36.864157 25446 sgd_solver.cpp:138] Iteration 15240, lr = 0.001
I0826 16:19:38.921744 25446 solver.cpp:243] Iteration 15250, loss = 7.58963
I0826 16:19:38.921767 25446 solver.cpp:259]     Train net output #0: center_loss = 129.117 (* 0.008 = 1.03294 loss)
I0826 16:19:38.921773 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.55669 (* 1 = 6.55669 loss)
I0826 16:19:38.921777 25446 sgd_solver.cpp:138] Iteration 15250, lr = 0.001
I0826 16:19:41.012519 25446 solver.cpp:243] Iteration 15260, loss = 7.50668
I0826 16:19:41.012545 25446 solver.cpp:259]     Train net output #0: center_loss = 174.636 (* 0.008 = 1.39709 loss)
I0826 16:19:41.012552 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.10959 (* 1 = 6.10959 loss)
I0826 16:19:41.012555 25446 sgd_solver.cpp:138] Iteration 15260, lr = 0.001
I0826 16:19:43.193212 25446 solver.cpp:243] Iteration 15270, loss = 7.50762
I0826 16:19:43.193236 25446 solver.cpp:259]     Train net output #0: center_loss = 168.424 (* 0.008 = 1.34739 loss)
I0826 16:19:43.193243 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.16023 (* 1 = 6.16023 loss)
I0826 16:19:43.193250 25446 sgd_solver.cpp:138] Iteration 15270, lr = 0.001
I0826 16:19:45.344080 25446 solver.cpp:243] Iteration 15280, loss = 6.99194
I0826 16:19:45.344106 25446 solver.cpp:259]     Train net output #0: center_loss = 153.063 (* 0.008 = 1.2245 loss)
I0826 16:19:45.344112 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.76743 (* 1 = 5.76743 loss)
I0826 16:19:45.344117 25446 sgd_solver.cpp:138] Iteration 15280, lr = 0.001
I0826 16:19:47.544337 25446 solver.cpp:243] Iteration 15290, loss = 6.7079
I0826 16:19:47.544502 25446 solver.cpp:259]     Train net output #0: center_loss = 150.396 (* 0.008 = 1.20317 loss)
I0826 16:19:47.544510 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.50473 (* 1 = 5.50473 loss)
I0826 16:19:47.544528 25446 sgd_solver.cpp:138] Iteration 15290, lr = 0.001
I0826 16:19:49.737892 25446 solver.cpp:243] Iteration 15300, loss = 6.9
I0826 16:19:49.737917 25446 solver.cpp:259]     Train net output #0: center_loss = 212.684 (* 0.008 = 1.70147 loss)
I0826 16:19:49.737924 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.19854 (* 1 = 5.19854 loss)
I0826 16:19:49.737928 25446 sgd_solver.cpp:138] Iteration 15300, lr = 0.001
I0826 16:19:51.925709 25446 solver.cpp:243] Iteration 15310, loss = 6.61101
I0826 16:19:51.925734 25446 solver.cpp:259]     Train net output #0: center_loss = 158.786 (* 0.008 = 1.27029 loss)
I0826 16:19:51.925741 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.34071 (* 1 = 5.34071 loss)
I0826 16:19:51.925745 25446 sgd_solver.cpp:138] Iteration 15310, lr = 0.001
I0826 16:19:54.117033 25446 solver.cpp:243] Iteration 15320, loss = 6.91427
I0826 16:19:54.117063 25446 solver.cpp:259]     Train net output #0: center_loss = 180.191 (* 0.008 = 1.44153 loss)
I0826 16:19:54.117069 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.47274 (* 1 = 5.47274 loss)
I0826 16:19:54.117072 25446 sgd_solver.cpp:138] Iteration 15320, lr = 0.001
I0826 16:19:56.395948 25446 solver.cpp:243] Iteration 15330, loss = 8.30767
I0826 16:19:56.395987 25446 solver.cpp:259]     Train net output #0: center_loss = 155.057 (* 0.008 = 1.24046 loss)
I0826 16:19:56.395993 25446 solver.cpp:259]     Train net output #1: softmax_loss = 7.06721 (* 1 = 7.06721 loss)
I0826 16:19:56.395998 25446 sgd_solver.cpp:138] Iteration 15330, lr = 0.001
I0826 16:19:58.482607 25446 solver.cpp:243] Iteration 15340, loss = 6.46508
I0826 16:19:58.482631 25446 solver.cpp:259]     Train net output #0: center_loss = 160.205 (* 0.008 = 1.28164 loss)
I0826 16:19:58.482637 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.18344 (* 1 = 5.18344 loss)
I0826 16:19:58.482641 25446 sgd_solver.cpp:138] Iteration 15340, lr = 0.001
I0826 16:20:00.709903 25446 solver.cpp:243] Iteration 15350, loss = 7.21156
I0826 16:20:00.709928 25446 solver.cpp:259]     Train net output #0: center_loss = 194.082 (* 0.008 = 1.55266 loss)
I0826 16:20:00.709933 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.6589 (* 1 = 5.6589 loss)
I0826 16:20:00.709939 25446 sgd_solver.cpp:138] Iteration 15350, lr = 0.001
I0826 16:20:02.894542 25446 solver.cpp:243] Iteration 15360, loss = 7.08305
I0826 16:20:02.894568 25446 solver.cpp:259]     Train net output #0: center_loss = 148.652 (* 0.008 = 1.18922 loss)
I0826 16:20:02.894573 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.89383 (* 1 = 5.89383 loss)
I0826 16:20:02.894578 25446 sgd_solver.cpp:138] Iteration 15360, lr = 0.001
I0826 16:20:05.017495 25446 solver.cpp:243] Iteration 15370, loss = 7.16183
I0826 16:20:05.017519 25446 solver.cpp:259]     Train net output #0: center_loss = 153.713 (* 0.008 = 1.2297 loss)
I0826 16:20:05.017525 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.93213 (* 1 = 5.93213 loss)
I0826 16:20:05.017529 25446 sgd_solver.cpp:138] Iteration 15370, lr = 0.001
I0826 16:20:07.159847 25446 solver.cpp:243] Iteration 15380, loss = 6.77
I0826 16:20:07.159884 25446 solver.cpp:259]     Train net output #0: center_loss = 151.608 (* 0.008 = 1.21287 loss)
I0826 16:20:07.159890 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.55713 (* 1 = 5.55713 loss)
I0826 16:20:07.159894 25446 sgd_solver.cpp:138] Iteration 15380, lr = 0.001
I0826 16:20:09.378953 25446 solver.cpp:243] Iteration 15390, loss = 7.5034
I0826 16:20:09.378978 25446 solver.cpp:259]     Train net output #0: center_loss = 115.561 (* 0.008 = 0.924492 loss)
I0826 16:20:09.378984 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.57891 (* 1 = 6.57891 loss)
I0826 16:20:09.378989 25446 sgd_solver.cpp:138] Iteration 15390, lr = 0.001
I0826 16:20:11.658740 25446 solver.cpp:243] Iteration 15400, loss = 6.54334
I0826 16:20:11.658766 25446 solver.cpp:259]     Train net output #0: center_loss = 177.975 (* 0.008 = 1.4238 loss)
I0826 16:20:11.658772 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.11955 (* 1 = 5.11955 loss)
I0826 16:20:11.658777 25446 sgd_solver.cpp:138] Iteration 15400, lr = 0.001
I0826 16:20:13.889353 25446 solver.cpp:243] Iteration 15410, loss = 7.75962
I0826 16:20:13.889379 25446 solver.cpp:259]     Train net output #0: center_loss = 164.377 (* 0.008 = 1.31502 loss)
I0826 16:20:13.889384 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.44461 (* 1 = 6.44461 loss)
I0826 16:20:13.889389 25446 sgd_solver.cpp:138] Iteration 15410, lr = 0.001
I0826 16:20:16.050230 25446 solver.cpp:243] Iteration 15420, loss = 7.8843
I0826 16:20:16.050254 25446 solver.cpp:259]     Train net output #0: center_loss = 145.371 (* 0.008 = 1.16297 loss)
I0826 16:20:16.050261 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.72133 (* 1 = 6.72133 loss)
I0826 16:20:16.050266 25446 sgd_solver.cpp:138] Iteration 15420, lr = 0.001
I0826 16:20:18.123528 25446 solver.cpp:243] Iteration 15430, loss = 6.9159
I0826 16:20:18.123678 25446 solver.cpp:259]     Train net output #0: center_loss = 156.129 (* 0.008 = 1.24903 loss)
I0826 16:20:18.123685 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.66687 (* 1 = 5.66687 loss)
I0826 16:20:18.123690 25446 sgd_solver.cpp:138] Iteration 15430, lr = 0.001
I0826 16:20:20.196877 25446 solver.cpp:243] Iteration 15440, loss = 6.74124
I0826 16:20:20.196902 25446 solver.cpp:259]     Train net output #0: center_loss = 162.586 (* 0.008 = 1.30069 loss)
I0826 16:20:20.196907 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.44055 (* 1 = 5.44055 loss)
I0826 16:20:20.196911 25446 sgd_solver.cpp:138] Iteration 15440, lr = 0.001
I0826 16:20:22.256001 25446 solver.cpp:243] Iteration 15450, loss = 7.17158
I0826 16:20:22.256024 25446 solver.cpp:259]     Train net output #0: center_loss = 168.037 (* 0.008 = 1.34429 loss)
I0826 16:20:22.256029 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.82728 (* 1 = 5.82728 loss)
I0826 16:20:22.256033 25446 sgd_solver.cpp:138] Iteration 15450, lr = 0.001
I0826 16:20:24.327517 25446 solver.cpp:243] Iteration 15460, loss = 7.75534
I0826 16:20:24.327558 25446 solver.cpp:259]     Train net output #0: center_loss = 124.771 (* 0.008 = 0.998171 loss)
I0826 16:20:24.327564 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.75717 (* 1 = 6.75717 loss)
I0826 16:20:24.327569 25446 sgd_solver.cpp:138] Iteration 15460, lr = 0.001
I0826 16:20:26.413086 25446 solver.cpp:243] Iteration 15470, loss = 8.03874
I0826 16:20:26.413110 25446 solver.cpp:259]     Train net output #0: center_loss = 178.905 (* 0.008 = 1.43124 loss)
I0826 16:20:26.413117 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.6075 (* 1 = 6.6075 loss)
I0826 16:20:26.413121 25446 sgd_solver.cpp:138] Iteration 15470, lr = 0.001
I0826 16:20:28.482861 25446 solver.cpp:243] Iteration 15480, loss = 6.25797
I0826 16:20:28.482884 25446 solver.cpp:259]     Train net output #0: center_loss = 149.624 (* 0.008 = 1.19699 loss)
I0826 16:20:28.482892 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.06098 (* 1 = 5.06098 loss)
I0826 16:20:28.482895 25446 sgd_solver.cpp:138] Iteration 15480, lr = 0.001
I0826 16:20:30.552000 25446 solver.cpp:243] Iteration 15490, loss = 6.8635
I0826 16:20:30.552023 25446 solver.cpp:259]     Train net output #0: center_loss = 162.826 (* 0.008 = 1.30261 loss)
I0826 16:20:30.552029 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.56089 (* 1 = 5.56089 loss)
I0826 16:20:30.552033 25446 sgd_solver.cpp:138] Iteration 15490, lr = 0.001
I0826 16:20:32.618719 25446 solver.cpp:243] Iteration 15500, loss = 6.28082
I0826 16:20:32.618759 25446 solver.cpp:259]     Train net output #0: center_loss = 180.119 (* 0.008 = 1.44096 loss)
I0826 16:20:32.618765 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.83987 (* 1 = 4.83987 loss)
I0826 16:20:32.618769 25446 sgd_solver.cpp:138] Iteration 15500, lr = 0.001
I0826 16:20:34.681682 25446 solver.cpp:243] Iteration 15510, loss = 7.08937
I0826 16:20:34.681707 25446 solver.cpp:259]     Train net output #0: center_loss = 135.696 (* 0.008 = 1.08557 loss)
I0826 16:20:34.681713 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.0038 (* 1 = 6.0038 loss)
I0826 16:20:34.681717 25446 sgd_solver.cpp:138] Iteration 15510, lr = 0.001
I0826 16:20:36.745326 25446 solver.cpp:243] Iteration 15520, loss = 7.17589
I0826 16:20:36.745376 25446 solver.cpp:259]     Train net output #0: center_loss = 173.554 (* 0.008 = 1.38843 loss)
I0826 16:20:36.745383 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.78746 (* 1 = 5.78746 loss)
I0826 16:20:36.745386 25446 sgd_solver.cpp:138] Iteration 15520, lr = 0.001
I0826 16:20:38.809473 25446 solver.cpp:243] Iteration 15530, loss = 7.20179
I0826 16:20:38.809499 25446 solver.cpp:259]     Train net output #0: center_loss = 143.868 (* 0.008 = 1.15095 loss)
I0826 16:20:38.809505 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.05085 (* 1 = 6.05085 loss)
I0826 16:20:38.809509 25446 sgd_solver.cpp:138] Iteration 15530, lr = 0.001
I0826 16:20:41.004576 25446 solver.cpp:243] Iteration 15540, loss = 6.88432
I0826 16:20:41.004603 25446 solver.cpp:259]     Train net output #0: center_loss = 233.577 (* 0.008 = 1.86862 loss)
I0826 16:20:41.004609 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.0157 (* 1 = 5.0157 loss)
I0826 16:20:41.004614 25446 sgd_solver.cpp:138] Iteration 15540, lr = 0.001
I0826 16:20:43.207413 25446 solver.cpp:243] Iteration 15550, loss = 6.5602
I0826 16:20:43.207437 25446 solver.cpp:259]     Train net output #0: center_loss = 161.42 (* 0.008 = 1.29136 loss)
I0826 16:20:43.207442 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.26884 (* 1 = 5.26884 loss)
I0826 16:20:43.207446 25446 sgd_solver.cpp:138] Iteration 15550, lr = 0.001
I0826 16:20:45.342689 25446 solver.cpp:243] Iteration 15560, loss = 6.63351
I0826 16:20:45.342713 25446 solver.cpp:259]     Train net output #0: center_loss = 192.176 (* 0.008 = 1.53741 loss)
I0826 16:20:45.342720 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.0961 (* 1 = 5.0961 loss)
I0826 16:20:45.342723 25446 sgd_solver.cpp:138] Iteration 15560, lr = 0.001
I0826 16:20:47.401348 25446 solver.cpp:243] Iteration 15570, loss = 6.98089
I0826 16:20:47.401372 25446 solver.cpp:259]     Train net output #0: center_loss = 158.128 (* 0.008 = 1.26502 loss)
I0826 16:20:47.401377 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71587 (* 1 = 5.71587 loss)
I0826 16:20:47.401381 25446 sgd_solver.cpp:138] Iteration 15570, lr = 0.001
I0826 16:20:49.461642 25446 solver.cpp:243] Iteration 15580, loss = 7.3208
I0826 16:20:49.461776 25446 solver.cpp:259]     Train net output #0: center_loss = 201.248 (* 0.008 = 1.60999 loss)
I0826 16:20:49.461796 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71081 (* 1 = 5.71081 loss)
I0826 16:20:49.461800 25446 sgd_solver.cpp:138] Iteration 15580, lr = 0.001
I0826 16:20:51.608374 25446 solver.cpp:243] Iteration 15590, loss = 6.62862
I0826 16:20:51.608399 25446 solver.cpp:259]     Train net output #0: center_loss = 188.365 (* 0.008 = 1.50692 loss)
I0826 16:20:51.608405 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.1217 (* 1 = 5.1217 loss)
I0826 16:20:51.608409 25446 sgd_solver.cpp:138] Iteration 15590, lr = 0.001
I0826 16:20:53.811468 25446 solver.cpp:243] Iteration 15600, loss = 7.35451
I0826 16:20:53.811493 25446 solver.cpp:259]     Train net output #0: center_loss = 142.908 (* 0.008 = 1.14326 loss)
I0826 16:20:53.811499 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.21125 (* 1 = 6.21125 loss)
I0826 16:20:53.811503 25446 sgd_solver.cpp:138] Iteration 15600, lr = 0.001
I0826 16:20:56.072978 25446 solver.cpp:243] Iteration 15610, loss = 6.66801
I0826 16:20:56.073002 25446 solver.cpp:259]     Train net output #0: center_loss = 165.851 (* 0.008 = 1.32681 loss)
I0826 16:20:56.073009 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.3412 (* 1 = 5.3412 loss)
I0826 16:20:56.073014 25446 sgd_solver.cpp:138] Iteration 15610, lr = 0.001
I0826 16:20:58.307490 25446 solver.cpp:243] Iteration 15620, loss = 7.54576
I0826 16:20:58.307515 25446 solver.cpp:259]     Train net output #0: center_loss = 152.77 (* 0.008 = 1.22216 loss)
I0826 16:20:58.307523 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.3236 (* 1 = 6.3236 loss)
I0826 16:20:58.307528 25446 sgd_solver.cpp:138] Iteration 15620, lr = 0.001
I0826 16:21:00.477674 25446 solver.cpp:243] Iteration 15630, loss = 6.84118
I0826 16:21:00.477699 25446 solver.cpp:259]     Train net output #0: center_loss = 169.643 (* 0.008 = 1.35714 loss)
I0826 16:21:00.477705 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.48403 (* 1 = 5.48403 loss)
I0826 16:21:00.477710 25446 sgd_solver.cpp:138] Iteration 15630, lr = 0.001
I0826 16:21:02.619007 25446 solver.cpp:243] Iteration 15640, loss = 6.18617
I0826 16:21:02.619032 25446 solver.cpp:259]     Train net output #0: center_loss = 182.362 (* 0.008 = 1.45889 loss)
I0826 16:21:02.619038 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.72728 (* 1 = 4.72728 loss)
I0826 16:21:02.619042 25446 sgd_solver.cpp:138] Iteration 15640, lr = 0.001
I0826 16:21:04.675201 25446 solver.cpp:243] Iteration 15650, loss = 6.75344
I0826 16:21:04.675225 25446 solver.cpp:259]     Train net output #0: center_loss = 159.691 (* 0.008 = 1.27752 loss)
I0826 16:21:04.675231 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.47591 (* 1 = 5.47591 loss)
I0826 16:21:04.675235 25446 sgd_solver.cpp:138] Iteration 15650, lr = 0.001
I0826 16:21:06.733732 25446 solver.cpp:243] Iteration 15660, loss = 6.8883
I0826 16:21:06.733757 25446 solver.cpp:259]     Train net output #0: center_loss = 180.893 (* 0.008 = 1.44714 loss)
I0826 16:21:06.733763 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.44116 (* 1 = 5.44116 loss)
I0826 16:21:06.733767 25446 sgd_solver.cpp:138] Iteration 15660, lr = 0.001
I0826 16:21:08.863816 25446 solver.cpp:243] Iteration 15670, loss = 6.05211
I0826 16:21:08.863842 25446 solver.cpp:259]     Train net output #0: center_loss = 167.748 (* 0.008 = 1.34198 loss)
I0826 16:21:08.863848 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.71012 (* 1 = 4.71012 loss)
I0826 16:21:08.863853 25446 sgd_solver.cpp:138] Iteration 15670, lr = 0.001
I0826 16:21:10.931345 25446 solver.cpp:243] Iteration 15680, loss = 7.45102
I0826 16:21:10.931368 25446 solver.cpp:259]     Train net output #0: center_loss = 131.45 (* 0.008 = 1.0516 loss)
I0826 16:21:10.931375 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.39942 (* 1 = 6.39942 loss)
I0826 16:21:10.931380 25446 sgd_solver.cpp:138] Iteration 15680, lr = 0.001
I0826 16:21:13.034196 25446 solver.cpp:243] Iteration 15690, loss = 6.34393
I0826 16:21:13.034221 25446 solver.cpp:259]     Train net output #0: center_loss = 159.3 (* 0.008 = 1.2744 loss)
I0826 16:21:13.034227 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.06953 (* 1 = 5.06953 loss)
I0826 16:21:13.034232 25446 sgd_solver.cpp:138] Iteration 15690, lr = 0.001
I0826 16:21:15.155627 25446 solver.cpp:243] Iteration 15700, loss = 6.20464
I0826 16:21:15.155653 25446 solver.cpp:259]     Train net output #0: center_loss = 195.442 (* 0.008 = 1.56353 loss)
I0826 16:21:15.155659 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64111 (* 1 = 4.64111 loss)
I0826 16:21:15.155663 25446 sgd_solver.cpp:138] Iteration 15700, lr = 0.001
I0826 16:21:17.330619 25446 solver.cpp:243] Iteration 15710, loss = 7.83287
I0826 16:21:17.330659 25446 solver.cpp:259]     Train net output #0: center_loss = 149.772 (* 0.008 = 1.19817 loss)
I0826 16:21:17.330665 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.6347 (* 1 = 6.6347 loss)
I0826 16:21:17.330669 25446 sgd_solver.cpp:138] Iteration 15710, lr = 0.001
I0826 16:21:19.491410 25446 solver.cpp:243] Iteration 15720, loss = 6.4706
I0826 16:21:19.491549 25446 solver.cpp:259]     Train net output #0: center_loss = 151.851 (* 0.008 = 1.21481 loss)
I0826 16:21:19.491556 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.25579 (* 1 = 5.25579 loss)
I0826 16:21:19.491560 25446 sgd_solver.cpp:138] Iteration 15720, lr = 0.001
I0826 16:21:21.626792 25446 solver.cpp:243] Iteration 15730, loss = 7.23137
I0826 16:21:21.626832 25446 solver.cpp:259]     Train net output #0: center_loss = 160.82 (* 0.008 = 1.28656 loss)
I0826 16:21:21.626838 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.94481 (* 1 = 5.94481 loss)
I0826 16:21:21.626842 25446 sgd_solver.cpp:138] Iteration 15730, lr = 0.001
I0826 16:21:23.685302 25446 solver.cpp:243] Iteration 15740, loss = 7.0888
I0826 16:21:23.685326 25446 solver.cpp:259]     Train net output #0: center_loss = 166.579 (* 0.008 = 1.33263 loss)
I0826 16:21:23.685333 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.75616 (* 1 = 5.75616 loss)
I0826 16:21:23.685336 25446 sgd_solver.cpp:138] Iteration 15740, lr = 0.001
I0826 16:21:25.745720 25446 solver.cpp:243] Iteration 15750, loss = 7.00634
I0826 16:21:25.745745 25446 solver.cpp:259]     Train net output #0: center_loss = 172.18 (* 0.008 = 1.37744 loss)
I0826 16:21:25.745751 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.6289 (* 1 = 5.6289 loss)
I0826 16:21:25.745755 25446 sgd_solver.cpp:138] Iteration 15750, lr = 0.001
I0826 16:21:27.806604 25446 solver.cpp:243] Iteration 15760, loss = 6.99728
I0826 16:21:27.806629 25446 solver.cpp:259]     Train net output #0: center_loss = 172.843 (* 0.008 = 1.38274 loss)
I0826 16:21:27.806635 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.61454 (* 1 = 5.61454 loss)
I0826 16:21:27.806639 25446 sgd_solver.cpp:138] Iteration 15760, lr = 0.001
I0826 16:21:29.866230 25446 solver.cpp:243] Iteration 15770, loss = 7.40734
I0826 16:21:29.866268 25446 solver.cpp:259]     Train net output #0: center_loss = 163.209 (* 0.008 = 1.30567 loss)
I0826 16:21:29.866274 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.10166 (* 1 = 6.10166 loss)
I0826 16:21:29.866278 25446 sgd_solver.cpp:138] Iteration 15770, lr = 0.001
I0826 16:21:32.070338 25446 solver.cpp:243] Iteration 15780, loss = 6.44051
I0826 16:21:32.070363 25446 solver.cpp:259]     Train net output #0: center_loss = 179.91 (* 0.008 = 1.43928 loss)
I0826 16:21:32.070369 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.00124 (* 1 = 5.00124 loss)
I0826 16:21:32.070372 25446 sgd_solver.cpp:138] Iteration 15780, lr = 0.001
I0826 16:21:34.304721 25446 solver.cpp:243] Iteration 15790, loss = 6.92616
I0826 16:21:34.304745 25446 solver.cpp:259]     Train net output #0: center_loss = 161.511 (* 0.008 = 1.29209 loss)
I0826 16:21:34.304751 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.63406 (* 1 = 5.63406 loss)
I0826 16:21:34.304756 25446 sgd_solver.cpp:138] Iteration 15790, lr = 0.001
I0826 16:21:36.363196 25446 solver.cpp:243] Iteration 15800, loss = 7.36784
I0826 16:21:36.363221 25446 solver.cpp:259]     Train net output #0: center_loss = 149.64 (* 0.008 = 1.19712 loss)
I0826 16:21:36.363227 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.17072 (* 1 = 6.17072 loss)
I0826 16:21:36.363232 25446 sgd_solver.cpp:138] Iteration 15800, lr = 0.001
I0826 16:21:38.458734 25446 solver.cpp:243] Iteration 15810, loss = 6.10876
I0826 16:21:38.458760 25446 solver.cpp:259]     Train net output #0: center_loss = 181.619 (* 0.008 = 1.45295 loss)
I0826 16:21:38.458766 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65581 (* 1 = 4.65581 loss)
I0826 16:21:38.458771 25446 sgd_solver.cpp:138] Iteration 15810, lr = 0.001
I0826 16:21:40.562248 25446 solver.cpp:243] Iteration 15820, loss = 7.19101
I0826 16:21:40.562286 25446 solver.cpp:259]     Train net output #0: center_loss = 146.055 (* 0.008 = 1.16844 loss)
I0826 16:21:40.562294 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.02257 (* 1 = 6.02257 loss)
I0826 16:21:40.562296 25446 sgd_solver.cpp:138] Iteration 15820, lr = 0.001
I0826 16:21:42.622035 25446 solver.cpp:243] Iteration 15830, loss = 7.39781
I0826 16:21:42.622059 25446 solver.cpp:259]     Train net output #0: center_loss = 134.695 (* 0.008 = 1.07756 loss)
I0826 16:21:42.622066 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.32024 (* 1 = 6.32024 loss)
I0826 16:21:42.622069 25446 sgd_solver.cpp:138] Iteration 15830, lr = 0.001
I0826 16:21:44.680433 25446 solver.cpp:243] Iteration 15840, loss = 6.09272
I0826 16:21:44.680474 25446 solver.cpp:259]     Train net output #0: center_loss = 212.869 (* 0.008 = 1.70295 loss)
I0826 16:21:44.680480 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.38976 (* 1 = 4.38976 loss)
I0826 16:21:44.680483 25446 sgd_solver.cpp:138] Iteration 15840, lr = 0.001
I0826 16:21:46.739714 25446 solver.cpp:243] Iteration 15850, loss = 6.36123
I0826 16:21:46.739754 25446 solver.cpp:259]     Train net output #0: center_loss = 180.432 (* 0.008 = 1.44345 loss)
I0826 16:21:46.739759 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.91778 (* 1 = 4.91778 loss)
I0826 16:21:46.739763 25446 sgd_solver.cpp:138] Iteration 15850, lr = 0.001
I0826 16:21:48.794315 25446 solver.cpp:243] Iteration 15860, loss = 7.31699
I0826 16:21:48.794354 25446 solver.cpp:259]     Train net output #0: center_loss = 154.395 (* 0.008 = 1.23516 loss)
I0826 16:21:48.794360 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.08182 (* 1 = 6.08182 loss)
I0826 16:21:48.794364 25446 sgd_solver.cpp:138] Iteration 15860, lr = 0.001
I0826 16:21:50.851327 25446 solver.cpp:243] Iteration 15870, loss = 6.90231
I0826 16:21:50.851459 25446 solver.cpp:259]     Train net output #0: center_loss = 138.401 (* 0.008 = 1.10721 loss)
I0826 16:21:50.851465 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.7951 (* 1 = 5.7951 loss)
I0826 16:21:50.851482 25446 sgd_solver.cpp:138] Iteration 15870, lr = 0.001
I0826 16:21:52.909780 25446 solver.cpp:243] Iteration 15880, loss = 6.22009
I0826 16:21:52.909803 25446 solver.cpp:259]     Train net output #0: center_loss = 173.832 (* 0.008 = 1.39066 loss)
I0826 16:21:52.909809 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82944 (* 1 = 4.82944 loss)
I0826 16:21:52.909812 25446 sgd_solver.cpp:138] Iteration 15880, lr = 0.001
I0826 16:21:54.968173 25446 solver.cpp:243] Iteration 15890, loss = 6.62629
I0826 16:21:54.968212 25446 solver.cpp:259]     Train net output #0: center_loss = 148.863 (* 0.008 = 1.19091 loss)
I0826 16:21:54.968219 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.43538 (* 1 = 5.43538 loss)
I0826 16:21:54.968222 25446 sgd_solver.cpp:138] Iteration 15890, lr = 0.001
I0826 16:21:57.026419 25446 solver.cpp:243] Iteration 15900, loss = 7.17368
I0826 16:21:57.026443 25446 solver.cpp:259]     Train net output #0: center_loss = 182.32 (* 0.008 = 1.45856 loss)
I0826 16:21:57.026448 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71513 (* 1 = 5.71513 loss)
I0826 16:21:57.026451 25446 sgd_solver.cpp:138] Iteration 15900, lr = 0.001
I0826 16:21:59.086170 25446 solver.cpp:243] Iteration 15910, loss = 7.15331
I0826 16:21:59.086194 25446 solver.cpp:259]     Train net output #0: center_loss = 163.181 (* 0.008 = 1.30545 loss)
I0826 16:21:59.086199 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.84786 (* 1 = 5.84786 loss)
I0826 16:21:59.086203 25446 sgd_solver.cpp:138] Iteration 15910, lr = 0.001
I0826 16:22:01.144428 25446 solver.cpp:243] Iteration 15920, loss = 6.50098
I0826 16:22:01.144452 25446 solver.cpp:259]     Train net output #0: center_loss = 165.271 (* 0.008 = 1.32217 loss)
I0826 16:22:01.144459 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.17881 (* 1 = 5.17881 loss)
I0826 16:22:01.144464 25446 sgd_solver.cpp:138] Iteration 15920, lr = 0.001
I0826 16:22:03.202627 25446 solver.cpp:243] Iteration 15930, loss = 6.69099
I0826 16:22:03.202666 25446 solver.cpp:259]     Train net output #0: center_loss = 179.117 (* 0.008 = 1.43294 loss)
I0826 16:22:03.202672 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.25806 (* 1 = 5.25806 loss)
I0826 16:22:03.202675 25446 sgd_solver.cpp:138] Iteration 15930, lr = 0.001
I0826 16:22:05.260938 25446 solver.cpp:243] Iteration 15940, loss = 6.49981
I0826 16:22:05.260977 25446 solver.cpp:259]     Train net output #0: center_loss = 157.347 (* 0.008 = 1.25878 loss)
I0826 16:22:05.260983 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.24103 (* 1 = 5.24103 loss)
I0826 16:22:05.260987 25446 sgd_solver.cpp:138] Iteration 15940, lr = 0.001
I0826 16:22:07.318445 25446 solver.cpp:243] Iteration 15950, loss = 6.94185
I0826 16:22:07.318469 25446 solver.cpp:259]     Train net output #0: center_loss = 180.003 (* 0.008 = 1.44002 loss)
I0826 16:22:07.318475 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.50182 (* 1 = 5.50182 loss)
I0826 16:22:07.318478 25446 sgd_solver.cpp:138] Iteration 15950, lr = 0.001
I0826 16:22:09.379488 25446 solver.cpp:243] Iteration 15960, loss = 6.55854
I0826 16:22:09.379528 25446 solver.cpp:259]     Train net output #0: center_loss = 181.071 (* 0.008 = 1.44857 loss)
I0826 16:22:09.379534 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.10998 (* 1 = 5.10998 loss)
I0826 16:22:09.379537 25446 sgd_solver.cpp:138] Iteration 15960, lr = 0.001
I0826 16:22:11.437146 25446 solver.cpp:243] Iteration 15970, loss = 6.68931
I0826 16:22:11.437186 25446 solver.cpp:259]     Train net output #0: center_loss = 197.994 (* 0.008 = 1.58395 loss)
I0826 16:22:11.437192 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.10536 (* 1 = 5.10536 loss)
I0826 16:22:11.437196 25446 sgd_solver.cpp:138] Iteration 15970, lr = 0.001
I0826 16:22:13.495362 25446 solver.cpp:243] Iteration 15980, loss = 7.35636
I0826 16:22:13.495402 25446 solver.cpp:259]     Train net output #0: center_loss = 171.044 (* 0.008 = 1.36835 loss)
I0826 16:22:13.495409 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.98801 (* 1 = 5.98801 loss)
I0826 16:22:13.495414 25446 sgd_solver.cpp:138] Iteration 15980, lr = 0.001
I0826 16:22:15.600363 25446 solver.cpp:243] Iteration 15990, loss = 6.21546
I0826 16:22:15.600390 25446 solver.cpp:259]     Train net output #0: center_loss = 198.402 (* 0.008 = 1.58722 loss)
I0826 16:22:15.600396 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.62825 (* 1 = 4.62825 loss)
I0826 16:22:15.600401 25446 sgd_solver.cpp:138] Iteration 15990, lr = 0.001
I0826 16:22:17.525640 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_16000.caffemodel
I0826 16:22:18.683035 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_16000.solverstate
I0826 16:22:19.012542 25446 solver.cpp:243] Iteration 16000, loss = 7.26729
I0826 16:22:19.012581 25446 solver.cpp:259]     Train net output #0: center_loss = 162.338 (* 0.008 = 1.2987 loss)
I0826 16:22:19.012588 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.96859 (* 1 = 5.96859 loss)
I0826 16:22:19.012591 25446 sgd_solver.cpp:47] MultiStep Status: Iteration 16000, step = 1
I0826 16:22:19.012593 25446 sgd_solver.cpp:138] Iteration 16000, lr = 0.0001
I0826 16:22:21.073873 25446 solver.cpp:243] Iteration 16010, loss = 6.34662
I0826 16:22:21.073993 25446 solver.cpp:259]     Train net output #0: center_loss = 191.493 (* 0.008 = 1.53195 loss)
I0826 16:22:21.074000 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.81467 (* 1 = 4.81467 loss)
I0826 16:22:21.074018 25446 sgd_solver.cpp:138] Iteration 16010, lr = 0.0001
I0826 16:22:23.132551 25446 solver.cpp:243] Iteration 16020, loss = 7.18334
I0826 16:22:23.132575 25446 solver.cpp:259]     Train net output #0: center_loss = 151.175 (* 0.008 = 1.2094 loss)
I0826 16:22:23.132581 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.97394 (* 1 = 5.97394 loss)
I0826 16:22:23.132584 25446 sgd_solver.cpp:138] Iteration 16020, lr = 0.0001
I0826 16:22:25.189831 25446 solver.cpp:243] Iteration 16030, loss = 7.18345
I0826 16:22:25.189854 25446 solver.cpp:259]     Train net output #0: center_loss = 140.21 (* 0.008 = 1.12168 loss)
I0826 16:22:25.189860 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.06177 (* 1 = 6.06177 loss)
I0826 16:22:25.189864 25446 sgd_solver.cpp:138] Iteration 16030, lr = 0.0001
I0826 16:22:27.249524 25446 solver.cpp:243] Iteration 16040, loss = 6.77123
I0826 16:22:27.249548 25446 solver.cpp:259]     Train net output #0: center_loss = 165.306 (* 0.008 = 1.32245 loss)
I0826 16:22:27.249554 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.44879 (* 1 = 5.44879 loss)
I0826 16:22:27.249558 25446 sgd_solver.cpp:138] Iteration 16040, lr = 0.0001
I0826 16:22:29.307809 25446 solver.cpp:243] Iteration 16050, loss = 7.27606
I0826 16:22:29.307832 25446 solver.cpp:259]     Train net output #0: center_loss = 151.239 (* 0.008 = 1.20991 loss)
I0826 16:22:29.307838 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.06615 (* 1 = 6.06615 loss)
I0826 16:22:29.307842 25446 sgd_solver.cpp:138] Iteration 16050, lr = 0.0001
I0826 16:22:31.366020 25446 solver.cpp:243] Iteration 16060, loss = 6.12223
I0826 16:22:31.366045 25446 solver.cpp:259]     Train net output #0: center_loss = 179.466 (* 0.008 = 1.43573 loss)
I0826 16:22:31.366051 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.6865 (* 1 = 4.6865 loss)
I0826 16:22:31.366055 25446 sgd_solver.cpp:138] Iteration 16060, lr = 0.0001
I0826 16:22:33.426653 25446 solver.cpp:243] Iteration 16070, loss = 6.59103
I0826 16:22:33.426692 25446 solver.cpp:259]     Train net output #0: center_loss = 182.168 (* 0.008 = 1.45734 loss)
I0826 16:22:33.426697 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.13368 (* 1 = 5.13368 loss)
I0826 16:22:33.426702 25446 sgd_solver.cpp:138] Iteration 16070, lr = 0.0001
I0826 16:22:35.487267 25446 solver.cpp:243] Iteration 16080, loss = 6.9945
I0826 16:22:35.487308 25446 solver.cpp:259]     Train net output #0: center_loss = 161.852 (* 0.008 = 1.29482 loss)
I0826 16:22:35.487313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.69968 (* 1 = 5.69968 loss)
I0826 16:22:35.487316 25446 sgd_solver.cpp:138] Iteration 16080, lr = 0.0001
I0826 16:22:37.546372 25446 solver.cpp:243] Iteration 16090, loss = 7.2584
I0826 16:22:37.546396 25446 solver.cpp:259]     Train net output #0: center_loss = 157.027 (* 0.008 = 1.25621 loss)
I0826 16:22:37.546402 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.00219 (* 1 = 6.00219 loss)
I0826 16:22:37.546406 25446 sgd_solver.cpp:138] Iteration 16090, lr = 0.0001
I0826 16:22:39.634899 25446 solver.cpp:243] Iteration 16100, loss = 6.26302
I0826 16:22:39.634927 25446 solver.cpp:259]     Train net output #0: center_loss = 172.378 (* 0.008 = 1.37903 loss)
I0826 16:22:39.634932 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.884 (* 1 = 4.884 loss)
I0826 16:22:39.634937 25446 sgd_solver.cpp:138] Iteration 16100, lr = 0.0001
I0826 16:22:41.830667 25446 solver.cpp:243] Iteration 16110, loss = 7.35952
I0826 16:22:41.830705 25446 solver.cpp:259]     Train net output #0: center_loss = 176.634 (* 0.008 = 1.41307 loss)
I0826 16:22:41.830711 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.94645 (* 1 = 5.94645 loss)
I0826 16:22:41.830716 25446 sgd_solver.cpp:138] Iteration 16110, lr = 0.0001
I0826 16:22:43.959568 25446 solver.cpp:243] Iteration 16120, loss = 7.04563
I0826 16:22:43.959592 25446 solver.cpp:259]     Train net output #0: center_loss = 182.194 (* 0.008 = 1.45755 loss)
I0826 16:22:43.959599 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.58808 (* 1 = 5.58808 loss)
I0826 16:22:43.959604 25446 sgd_solver.cpp:138] Iteration 16120, lr = 0.0001
I0826 16:22:46.084527 25446 solver.cpp:243] Iteration 16130, loss = 6.36249
I0826 16:22:46.084564 25446 solver.cpp:259]     Train net output #0: center_loss = 190.635 (* 0.008 = 1.52508 loss)
I0826 16:22:46.084570 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.83741 (* 1 = 4.83741 loss)
I0826 16:22:46.084574 25446 sgd_solver.cpp:138] Iteration 16130, lr = 0.0001
I0826 16:22:48.141360 25446 solver.cpp:243] Iteration 16140, loss = 6.88
I0826 16:22:48.141383 25446 solver.cpp:259]     Train net output #0: center_loss = 172.086 (* 0.008 = 1.37669 loss)
I0826 16:22:48.141389 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.50331 (* 1 = 5.50331 loss)
I0826 16:22:48.141393 25446 sgd_solver.cpp:138] Iteration 16140, lr = 0.0001
I0826 16:22:50.200666 25446 solver.cpp:243] Iteration 16150, loss = 6.46929
I0826 16:22:50.200688 25446 solver.cpp:259]     Train net output #0: center_loss = 155.834 (* 0.008 = 1.24668 loss)
I0826 16:22:50.200695 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.22261 (* 1 = 5.22261 loss)
I0826 16:22:50.200698 25446 sgd_solver.cpp:138] Iteration 16150, lr = 0.0001
I0826 16:22:52.261736 25446 solver.cpp:243] Iteration 16160, loss = 7.63981
I0826 16:22:52.261853 25446 solver.cpp:259]     Train net output #0: center_loss = 179.046 (* 0.008 = 1.43237 loss)
I0826 16:22:52.261860 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.20744 (* 1 = 6.20744 loss)
I0826 16:22:52.261888 25446 sgd_solver.cpp:138] Iteration 16160, lr = 0.0001
I0826 16:22:54.321194 25446 solver.cpp:243] Iteration 16170, loss = 6.58799
I0826 16:22:54.321218 25446 solver.cpp:259]     Train net output #0: center_loss = 194.48 (* 0.008 = 1.55584 loss)
I0826 16:22:54.321223 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.03215 (* 1 = 5.03215 loss)
I0826 16:22:54.321228 25446 sgd_solver.cpp:138] Iteration 16170, lr = 0.0001
I0826 16:22:56.382262 25446 solver.cpp:243] Iteration 16180, loss = 7.02023
I0826 16:22:56.382288 25446 solver.cpp:259]     Train net output #0: center_loss = 180.821 (* 0.008 = 1.44657 loss)
I0826 16:22:56.382294 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.57366 (* 1 = 5.57366 loss)
I0826 16:22:56.382298 25446 sgd_solver.cpp:138] Iteration 16180, lr = 0.0001
I0826 16:22:58.441372 25446 solver.cpp:243] Iteration 16190, loss = 8.16929
I0826 16:22:58.441396 25446 solver.cpp:259]     Train net output #0: center_loss = 153.066 (* 0.008 = 1.22453 loss)
I0826 16:22:58.441401 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.94476 (* 1 = 6.94476 loss)
I0826 16:22:58.441406 25446 sgd_solver.cpp:138] Iteration 16190, lr = 0.0001
I0826 16:23:00.502228 25446 solver.cpp:243] Iteration 16200, loss = 6.2556
I0826 16:23:00.502254 25446 solver.cpp:259]     Train net output #0: center_loss = 185.632 (* 0.008 = 1.48506 loss)
I0826 16:23:00.502275 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77054 (* 1 = 4.77054 loss)
I0826 16:23:00.502279 25446 sgd_solver.cpp:138] Iteration 16200, lr = 0.0001
I0826 16:23:02.563796 25446 solver.cpp:243] Iteration 16210, loss = 6.93153
I0826 16:23:02.563819 25446 solver.cpp:259]     Train net output #0: center_loss = 159.723 (* 0.008 = 1.27779 loss)
I0826 16:23:02.563840 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.65375 (* 1 = 5.65375 loss)
I0826 16:23:02.563844 25446 sgd_solver.cpp:138] Iteration 16210, lr = 0.0001
I0826 16:23:04.621969 25446 solver.cpp:243] Iteration 16220, loss = 5.36662
I0826 16:23:04.622009 25446 solver.cpp:259]     Train net output #0: center_loss = 204.517 (* 0.008 = 1.63614 loss)
I0826 16:23:04.622015 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.73048 (* 1 = 3.73048 loss)
I0826 16:23:04.622018 25446 sgd_solver.cpp:138] Iteration 16220, lr = 0.0001
I0826 16:23:06.685851 25446 solver.cpp:243] Iteration 16230, loss = 6.7972
I0826 16:23:06.685875 25446 solver.cpp:259]     Train net output #0: center_loss = 161.897 (* 0.008 = 1.29517 loss)
I0826 16:23:06.685881 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.50203 (* 1 = 5.50203 loss)
I0826 16:23:06.685885 25446 sgd_solver.cpp:138] Iteration 16230, lr = 0.0001
I0826 16:23:08.742275 25446 solver.cpp:243] Iteration 16240, loss = 7.30484
I0826 16:23:08.742316 25446 solver.cpp:259]     Train net output #0: center_loss = 154.433 (* 0.008 = 1.23546 loss)
I0826 16:23:08.742321 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.06938 (* 1 = 6.06938 loss)
I0826 16:23:08.742326 25446 sgd_solver.cpp:138] Iteration 16240, lr = 0.0001
I0826 16:23:10.801590 25446 solver.cpp:243] Iteration 16250, loss = 6.58205
I0826 16:23:10.801616 25446 solver.cpp:259]     Train net output #0: center_loss = 175.094 (* 0.008 = 1.40075 loss)
I0826 16:23:10.801622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.1813 (* 1 = 5.1813 loss)
I0826 16:23:10.801625 25446 sgd_solver.cpp:138] Iteration 16250, lr = 0.0001
I0826 16:23:12.859972 25446 solver.cpp:243] Iteration 16260, loss = 6.76905
I0826 16:23:12.860009 25446 solver.cpp:259]     Train net output #0: center_loss = 189.9 (* 0.008 = 1.5192 loss)
I0826 16:23:12.860015 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.24985 (* 1 = 5.24985 loss)
I0826 16:23:12.860019 25446 sgd_solver.cpp:138] Iteration 16260, lr = 0.0001
I0826 16:23:14.918674 25446 solver.cpp:243] Iteration 16270, loss = 6.1585
I0826 16:23:14.918712 25446 solver.cpp:259]     Train net output #0: center_loss = 198.371 (* 0.008 = 1.58697 loss)
I0826 16:23:14.918718 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.57153 (* 1 = 4.57153 loss)
I0826 16:23:14.918722 25446 sgd_solver.cpp:138] Iteration 16270, lr = 0.0001
I0826 16:23:16.973742 25446 solver.cpp:243] Iteration 16280, loss = 7.27892
I0826 16:23:16.973780 25446 solver.cpp:259]     Train net output #0: center_loss = 174.229 (* 0.008 = 1.39383 loss)
I0826 16:23:16.973786 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.88509 (* 1 = 5.88509 loss)
I0826 16:23:16.973789 25446 sgd_solver.cpp:138] Iteration 16280, lr = 0.0001
I0826 16:23:19.032052 25446 solver.cpp:243] Iteration 16290, loss = 6.75917
I0826 16:23:19.032091 25446 solver.cpp:259]     Train net output #0: center_loss = 205.124 (* 0.008 = 1.64099 loss)
I0826 16:23:19.032097 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.11818 (* 1 = 5.11818 loss)
I0826 16:23:19.032101 25446 sgd_solver.cpp:138] Iteration 16290, lr = 0.0001
I0826 16:23:21.091869 25446 solver.cpp:243] Iteration 16300, loss = 7.21731
I0826 16:23:21.091908 25446 solver.cpp:259]     Train net output #0: center_loss = 166.809 (* 0.008 = 1.33447 loss)
I0826 16:23:21.091914 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.88283 (* 1 = 5.88283 loss)
I0826 16:23:21.091918 25446 sgd_solver.cpp:138] Iteration 16300, lr = 0.0001
I0826 16:23:23.154052 25446 solver.cpp:243] Iteration 16310, loss = 6.28962
I0826 16:23:23.154184 25446 solver.cpp:259]     Train net output #0: center_loss = 193.271 (* 0.008 = 1.54617 loss)
I0826 16:23:23.154191 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.74345 (* 1 = 4.74345 loss)
I0826 16:23:23.154196 25446 sgd_solver.cpp:138] Iteration 16310, lr = 0.0001
I0826 16:23:25.214427 25446 solver.cpp:243] Iteration 16320, loss = 6.80287
I0826 16:23:25.214468 25446 solver.cpp:259]     Train net output #0: center_loss = 185.189 (* 0.008 = 1.48151 loss)
I0826 16:23:25.214473 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.32136 (* 1 = 5.32136 loss)
I0826 16:23:25.214476 25446 sgd_solver.cpp:138] Iteration 16320, lr = 0.0001
I0826 16:23:27.272840 25446 solver.cpp:243] Iteration 16330, loss = 6.93169
I0826 16:23:27.272863 25446 solver.cpp:259]     Train net output #0: center_loss = 187.882 (* 0.008 = 1.50306 loss)
I0826 16:23:27.272869 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.42863 (* 1 = 5.42863 loss)
I0826 16:23:27.272873 25446 sgd_solver.cpp:138] Iteration 16330, lr = 0.0001
I0826 16:23:29.330405 25446 solver.cpp:243] Iteration 16340, loss = 6.24592
I0826 16:23:29.330443 25446 solver.cpp:259]     Train net output #0: center_loss = 170.944 (* 0.008 = 1.36755 loss)
I0826 16:23:29.330449 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.87837 (* 1 = 4.87837 loss)
I0826 16:23:29.330453 25446 sgd_solver.cpp:138] Iteration 16340, lr = 0.0001
I0826 16:23:31.390558 25446 solver.cpp:243] Iteration 16350, loss = 6.07401
I0826 16:23:31.390583 25446 solver.cpp:259]     Train net output #0: center_loss = 189.607 (* 0.008 = 1.51685 loss)
I0826 16:23:31.390589 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.55715 (* 1 = 4.55715 loss)
I0826 16:23:31.390594 25446 sgd_solver.cpp:138] Iteration 16350, lr = 0.0001
I0826 16:23:33.447350 25446 solver.cpp:243] Iteration 16360, loss = 6.68797
I0826 16:23:33.447387 25446 solver.cpp:259]     Train net output #0: center_loss = 200.047 (* 0.008 = 1.60037 loss)
I0826 16:23:33.447392 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.0876 (* 1 = 5.0876 loss)
I0826 16:23:33.447396 25446 sgd_solver.cpp:138] Iteration 16360, lr = 0.0001
I0826 16:23:35.512338 25446 solver.cpp:243] Iteration 16370, loss = 7.30629
I0826 16:23:35.512362 25446 solver.cpp:259]     Train net output #0: center_loss = 162.147 (* 0.008 = 1.29718 loss)
I0826 16:23:35.512368 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.00911 (* 1 = 6.00911 loss)
I0826 16:23:35.512372 25446 sgd_solver.cpp:138] Iteration 16370, lr = 0.0001
I0826 16:23:37.573930 25446 solver.cpp:243] Iteration 16380, loss = 6.95
I0826 16:23:37.573952 25446 solver.cpp:259]     Train net output #0: center_loss = 172.115 (* 0.008 = 1.37692 loss)
I0826 16:23:37.573958 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.57309 (* 1 = 5.57309 loss)
I0826 16:23:37.573962 25446 sgd_solver.cpp:138] Iteration 16380, lr = 0.0001
I0826 16:23:39.633193 25446 solver.cpp:243] Iteration 16390, loss = 6.67049
I0826 16:23:39.633215 25446 solver.cpp:259]     Train net output #0: center_loss = 180.649 (* 0.008 = 1.44519 loss)
I0826 16:23:39.633221 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.2253 (* 1 = 5.2253 loss)
I0826 16:23:39.633225 25446 sgd_solver.cpp:138] Iteration 16390, lr = 0.0001
I0826 16:23:41.688750 25446 solver.cpp:243] Iteration 16400, loss = 6.32768
I0826 16:23:41.688789 25446 solver.cpp:259]     Train net output #0: center_loss = 174.696 (* 0.008 = 1.39757 loss)
I0826 16:23:41.688796 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.93011 (* 1 = 4.93011 loss)
I0826 16:23:41.688799 25446 sgd_solver.cpp:138] Iteration 16400, lr = 0.0001
I0826 16:23:43.750391 25446 solver.cpp:243] Iteration 16410, loss = 6.27806
I0826 16:23:43.750430 25446 solver.cpp:259]     Train net output #0: center_loss = 161.469 (* 0.008 = 1.29175 loss)
I0826 16:23:43.750437 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.98631 (* 1 = 4.98631 loss)
I0826 16:23:43.750440 25446 sgd_solver.cpp:138] Iteration 16410, lr = 0.0001
I0826 16:23:45.808982 25446 solver.cpp:243] Iteration 16420, loss = 6.29155
I0826 16:23:45.809020 25446 solver.cpp:259]     Train net output #0: center_loss = 202.964 (* 0.008 = 1.62371 loss)
I0826 16:23:45.809026 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.66784 (* 1 = 4.66784 loss)
I0826 16:23:45.809031 25446 sgd_solver.cpp:138] Iteration 16420, lr = 0.0001
I0826 16:23:47.870309 25446 solver.cpp:243] Iteration 16430, loss = 6.39387
I0826 16:23:47.870347 25446 solver.cpp:259]     Train net output #0: center_loss = 201.12 (* 0.008 = 1.60896 loss)
I0826 16:23:47.870353 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.78491 (* 1 = 4.78491 loss)
I0826 16:23:47.870357 25446 sgd_solver.cpp:138] Iteration 16430, lr = 0.0001
I0826 16:23:49.926172 25446 solver.cpp:243] Iteration 16440, loss = 6.62801
I0826 16:23:49.926209 25446 solver.cpp:259]     Train net output #0: center_loss = 163.139 (* 0.008 = 1.30512 loss)
I0826 16:23:49.926231 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.32289 (* 1 = 5.32289 loss)
I0826 16:23:49.926234 25446 sgd_solver.cpp:138] Iteration 16440, lr = 0.0001
I0826 16:23:52.156900 25446 solver.cpp:243] Iteration 16450, loss = 5.64192
I0826 16:23:52.156925 25446 solver.cpp:259]     Train net output #0: center_loss = 199.772 (* 0.008 = 1.59817 loss)
I0826 16:23:52.156931 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04375 (* 1 = 4.04375 loss)
I0826 16:23:52.156935 25446 sgd_solver.cpp:138] Iteration 16450, lr = 0.0001
I0826 16:23:54.420483 25446 solver.cpp:243] Iteration 16460, loss = 6.49702
I0826 16:23:54.420603 25446 solver.cpp:259]     Train net output #0: center_loss = 185.488 (* 0.008 = 1.48391 loss)
I0826 16:23:54.420624 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.01311 (* 1 = 5.01311 loss)
I0826 16:23:54.420642 25446 sgd_solver.cpp:138] Iteration 16460, lr = 0.0001
I0826 16:23:56.584882 25446 solver.cpp:243] Iteration 16470, loss = 6.09591
I0826 16:23:56.584921 25446 solver.cpp:259]     Train net output #0: center_loss = 186.408 (* 0.008 = 1.49126 loss)
I0826 16:23:56.584928 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.60465 (* 1 = 4.60465 loss)
I0826 16:23:56.584931 25446 sgd_solver.cpp:138] Iteration 16470, lr = 0.0001
I0826 16:23:58.745615 25446 solver.cpp:243] Iteration 16480, loss = 6.23096
I0826 16:23:58.745654 25446 solver.cpp:259]     Train net output #0: center_loss = 182.066 (* 0.008 = 1.45653 loss)
I0826 16:23:58.745659 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77444 (* 1 = 4.77444 loss)
I0826 16:23:58.745663 25446 sgd_solver.cpp:138] Iteration 16480, lr = 0.0001
I0826 16:24:00.805063 25446 solver.cpp:243] Iteration 16490, loss = 7.07836
I0826 16:24:00.805086 25446 solver.cpp:259]     Train net output #0: center_loss = 170.577 (* 0.008 = 1.36462 loss)
I0826 16:24:00.805092 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71374 (* 1 = 5.71374 loss)
I0826 16:24:00.805096 25446 sgd_solver.cpp:138] Iteration 16490, lr = 0.0001
I0826 16:24:02.867270 25446 solver.cpp:243] Iteration 16500, loss = 6.97889
I0826 16:24:02.867293 25446 solver.cpp:259]     Train net output #0: center_loss = 183.058 (* 0.008 = 1.46446 loss)
I0826 16:24:02.867300 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.51443 (* 1 = 5.51443 loss)
I0826 16:24:02.867303 25446 sgd_solver.cpp:138] Iteration 16500, lr = 0.0001
I0826 16:24:04.929121 25446 solver.cpp:243] Iteration 16510, loss = 5.65474
I0826 16:24:04.929145 25446 solver.cpp:259]     Train net output #0: center_loss = 193.131 (* 0.008 = 1.54505 loss)
I0826 16:24:04.929152 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.10969 (* 1 = 4.10969 loss)
I0826 16:24:04.929155 25446 sgd_solver.cpp:138] Iteration 16510, lr = 0.0001
I0826 16:24:06.986076 25446 solver.cpp:243] Iteration 16520, loss = 6.73338
I0826 16:24:06.986101 25446 solver.cpp:259]     Train net output #0: center_loss = 185.654 (* 0.008 = 1.48523 loss)
I0826 16:24:06.986107 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.24815 (* 1 = 5.24815 loss)
I0826 16:24:06.986126 25446 sgd_solver.cpp:138] Iteration 16520, lr = 0.0001
I0826 16:24:09.045469 25446 solver.cpp:243] Iteration 16530, loss = 6.46533
I0826 16:24:09.045490 25446 solver.cpp:259]     Train net output #0: center_loss = 166.619 (* 0.008 = 1.33295 loss)
I0826 16:24:09.045496 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.13238 (* 1 = 5.13238 loss)
I0826 16:24:09.045500 25446 sgd_solver.cpp:138] Iteration 16530, lr = 0.0001
I0826 16:24:11.102174 25446 solver.cpp:243] Iteration 16540, loss = 6.57056
I0826 16:24:11.102197 25446 solver.cpp:259]     Train net output #0: center_loss = 193.401 (* 0.008 = 1.54721 loss)
I0826 16:24:11.102203 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02335 (* 1 = 5.02335 loss)
I0826 16:24:11.102206 25446 sgd_solver.cpp:138] Iteration 16540, lr = 0.0001
I0826 16:24:13.163918 25446 solver.cpp:243] Iteration 16550, loss = 6.15854
I0826 16:24:13.163941 25446 solver.cpp:259]     Train net output #0: center_loss = 166.518 (* 0.008 = 1.33215 loss)
I0826 16:24:13.163947 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82639 (* 1 = 4.82639 loss)
I0826 16:24:13.163951 25446 sgd_solver.cpp:138] Iteration 16550, lr = 0.0001
I0826 16:24:15.225749 25446 solver.cpp:243] Iteration 16560, loss = 6.57965
I0826 16:24:15.225772 25446 solver.cpp:259]     Train net output #0: center_loss = 179.251 (* 0.008 = 1.43401 loss)
I0826 16:24:15.225778 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.14564 (* 1 = 5.14564 loss)
I0826 16:24:15.225781 25446 sgd_solver.cpp:138] Iteration 16560, lr = 0.0001
I0826 16:24:17.286914 25446 solver.cpp:243] Iteration 16570, loss = 6.15964
I0826 16:24:17.286938 25446 solver.cpp:259]     Train net output #0: center_loss = 197.998 (* 0.008 = 1.58398 loss)
I0826 16:24:17.286944 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.57566 (* 1 = 4.57566 loss)
I0826 16:24:17.286948 25446 sgd_solver.cpp:138] Iteration 16570, lr = 0.0001
I0826 16:24:19.345803 25446 solver.cpp:243] Iteration 16580, loss = 6.72723
I0826 16:24:19.345841 25446 solver.cpp:259]     Train net output #0: center_loss = 190.383 (* 0.008 = 1.52307 loss)
I0826 16:24:19.345847 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.20416 (* 1 = 5.20416 loss)
I0826 16:24:19.345851 25446 sgd_solver.cpp:138] Iteration 16580, lr = 0.0001
I0826 16:24:21.407152 25446 solver.cpp:243] Iteration 16590, loss = 7.25516
I0826 16:24:21.407176 25446 solver.cpp:259]     Train net output #0: center_loss = 178.451 (* 0.008 = 1.42761 loss)
I0826 16:24:21.407183 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.82755 (* 1 = 5.82755 loss)
I0826 16:24:21.407186 25446 sgd_solver.cpp:138] Iteration 16590, lr = 0.0001
I0826 16:24:23.467869 25446 solver.cpp:243] Iteration 16600, loss = 6.02894
I0826 16:24:23.467892 25446 solver.cpp:259]     Train net output #0: center_loss = 203.69 (* 0.008 = 1.62952 loss)
I0826 16:24:23.467898 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.39942 (* 1 = 4.39942 loss)
I0826 16:24:23.467902 25446 sgd_solver.cpp:138] Iteration 16600, lr = 0.0001
I0826 16:24:25.527169 25446 solver.cpp:243] Iteration 16610, loss = 6.98338
I0826 16:24:25.527310 25446 solver.cpp:259]     Train net output #0: center_loss = 180.387 (* 0.008 = 1.4431 loss)
I0826 16:24:25.527330 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.54029 (* 1 = 5.54029 loss)
I0826 16:24:25.527334 25446 sgd_solver.cpp:138] Iteration 16610, lr = 0.0001
I0826 16:24:27.579607 25446 solver.cpp:243] Iteration 16620, loss = 6.79871
I0826 16:24:27.579630 25446 solver.cpp:259]     Train net output #0: center_loss = 196.848 (* 0.008 = 1.57478 loss)
I0826 16:24:27.579636 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.22393 (* 1 = 5.22393 loss)
I0826 16:24:27.579640 25446 sgd_solver.cpp:138] Iteration 16620, lr = 0.0001
I0826 16:24:29.638767 25446 solver.cpp:243] Iteration 16630, loss = 7.06694
I0826 16:24:29.638805 25446 solver.cpp:259]     Train net output #0: center_loss = 185.359 (* 0.008 = 1.48287 loss)
I0826 16:24:29.638811 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.58406 (* 1 = 5.58406 loss)
I0826 16:24:29.638815 25446 sgd_solver.cpp:138] Iteration 16630, lr = 0.0001
I0826 16:24:31.695868 25446 solver.cpp:243] Iteration 16640, loss = 7.21174
I0826 16:24:31.695909 25446 solver.cpp:259]     Train net output #0: center_loss = 155.74 (* 0.008 = 1.24592 loss)
I0826 16:24:31.695914 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.96582 (* 1 = 5.96582 loss)
I0826 16:24:31.695917 25446 sgd_solver.cpp:138] Iteration 16640, lr = 0.0001
I0826 16:24:33.753758 25446 solver.cpp:243] Iteration 16650, loss = 6.72274
I0826 16:24:33.753783 25446 solver.cpp:259]     Train net output #0: center_loss = 179.201 (* 0.008 = 1.4336 loss)
I0826 16:24:33.753790 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.28914 (* 1 = 5.28914 loss)
I0826 16:24:33.753808 25446 sgd_solver.cpp:138] Iteration 16650, lr = 0.0001
I0826 16:24:35.812192 25446 solver.cpp:243] Iteration 16660, loss = 6.43149
I0826 16:24:35.812217 25446 solver.cpp:259]     Train net output #0: center_loss = 175.111 (* 0.008 = 1.40089 loss)
I0826 16:24:35.812223 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.0306 (* 1 = 5.0306 loss)
I0826 16:24:35.812228 25446 sgd_solver.cpp:138] Iteration 16660, lr = 0.0001
I0826 16:24:37.871598 25446 solver.cpp:243] Iteration 16670, loss = 6.93571
I0826 16:24:37.871636 25446 solver.cpp:259]     Train net output #0: center_loss = 164.638 (* 0.008 = 1.3171 loss)
I0826 16:24:37.871642 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.6186 (* 1 = 5.6186 loss)
I0826 16:24:37.871645 25446 sgd_solver.cpp:138] Iteration 16670, lr = 0.0001
I0826 16:24:39.928395 25446 solver.cpp:243] Iteration 16680, loss = 6.79539
I0826 16:24:39.928436 25446 solver.cpp:259]     Train net output #0: center_loss = 174.393 (* 0.008 = 1.39514 loss)
I0826 16:24:39.928442 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.40025 (* 1 = 5.40025 loss)
I0826 16:24:39.928445 25446 sgd_solver.cpp:138] Iteration 16680, lr = 0.0001
I0826 16:24:41.991400 25446 solver.cpp:243] Iteration 16690, loss = 7.27121
I0826 16:24:41.991423 25446 solver.cpp:259]     Train net output #0: center_loss = 176.367 (* 0.008 = 1.41093 loss)
I0826 16:24:41.991430 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.86028 (* 1 = 5.86028 loss)
I0826 16:24:41.991433 25446 sgd_solver.cpp:138] Iteration 16690, lr = 0.0001
I0826 16:24:44.054073 25446 solver.cpp:243] Iteration 16700, loss = 6.91483
I0826 16:24:44.054112 25446 solver.cpp:259]     Train net output #0: center_loss = 178.716 (* 0.008 = 1.42973 loss)
I0826 16:24:44.054118 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.4851 (* 1 = 5.4851 loss)
I0826 16:24:44.054122 25446 sgd_solver.cpp:138] Iteration 16700, lr = 0.0001
I0826 16:24:46.113662 25446 solver.cpp:243] Iteration 16710, loss = 6.81361
I0826 16:24:46.113701 25446 solver.cpp:259]     Train net output #0: center_loss = 156.525 (* 0.008 = 1.2522 loss)
I0826 16:24:46.113708 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.56141 (* 1 = 5.56141 loss)
I0826 16:24:46.113711 25446 sgd_solver.cpp:138] Iteration 16710, lr = 0.0001
I0826 16:24:48.177203 25446 solver.cpp:243] Iteration 16720, loss = 5.70174
I0826 16:24:48.177242 25446 solver.cpp:259]     Train net output #0: center_loss = 202.755 (* 0.008 = 1.62204 loss)
I0826 16:24:48.177268 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.0797 (* 1 = 4.0797 loss)
I0826 16:24:48.177271 25446 sgd_solver.cpp:138] Iteration 16720, lr = 0.0001
I0826 16:24:50.230613 25446 solver.cpp:243] Iteration 16730, loss = 7.40964
I0826 16:24:50.230654 25446 solver.cpp:259]     Train net output #0: center_loss = 155.583 (* 0.008 = 1.24466 loss)
I0826 16:24:50.230659 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.16498 (* 1 = 6.16498 loss)
I0826 16:24:50.230664 25446 sgd_solver.cpp:138] Iteration 16730, lr = 0.0001
I0826 16:24:52.291988 25446 solver.cpp:243] Iteration 16740, loss = 6.67271
I0826 16:24:52.292013 25446 solver.cpp:259]     Train net output #0: center_loss = 147.134 (* 0.008 = 1.17707 loss)
I0826 16:24:52.292019 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.49564 (* 1 = 5.49564 loss)
I0826 16:24:52.292023 25446 sgd_solver.cpp:138] Iteration 16740, lr = 0.0001
I0826 16:24:54.354329 25446 solver.cpp:243] Iteration 16750, loss = 7.20734
I0826 16:24:54.354352 25446 solver.cpp:259]     Train net output #0: center_loss = 159.253 (* 0.008 = 1.27403 loss)
I0826 16:24:54.354358 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.93332 (* 1 = 5.93332 loss)
I0826 16:24:54.354362 25446 sgd_solver.cpp:138] Iteration 16750, lr = 0.0001
I0826 16:24:56.410871 25446 solver.cpp:243] Iteration 16760, loss = 7.22402
I0826 16:24:56.410976 25446 solver.cpp:259]     Train net output #0: center_loss = 180.811 (* 0.008 = 1.44649 loss)
I0826 16:24:56.410984 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.77753 (* 1 = 5.77753 loss)
I0826 16:24:56.410987 25446 sgd_solver.cpp:138] Iteration 16760, lr = 0.0001
I0826 16:24:58.468961 25446 solver.cpp:243] Iteration 16770, loss = 6.74932
I0826 16:24:58.468986 25446 solver.cpp:259]     Train net output #0: center_loss = 186.821 (* 0.008 = 1.49457 loss)
I0826 16:24:58.468992 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.25476 (* 1 = 5.25476 loss)
I0826 16:24:58.468996 25446 sgd_solver.cpp:138] Iteration 16770, lr = 0.0001
I0826 16:25:00.527204 25446 solver.cpp:243] Iteration 16780, loss = 6.3552
I0826 16:25:00.527230 25446 solver.cpp:259]     Train net output #0: center_loss = 192.929 (* 0.008 = 1.54343 loss)
I0826 16:25:00.527235 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.81177 (* 1 = 4.81177 loss)
I0826 16:25:00.527238 25446 sgd_solver.cpp:138] Iteration 16780, lr = 0.0001
I0826 16:25:02.588176 25446 solver.cpp:243] Iteration 16790, loss = 6.819
I0826 16:25:02.588201 25446 solver.cpp:259]     Train net output #0: center_loss = 171.396 (* 0.008 = 1.37117 loss)
I0826 16:25:02.588207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.44784 (* 1 = 5.44784 loss)
I0826 16:25:02.588225 25446 sgd_solver.cpp:138] Iteration 16790, lr = 0.0001
I0826 16:25:04.649206 25446 solver.cpp:243] Iteration 16800, loss = 6.7851
I0826 16:25:04.649250 25446 solver.cpp:259]     Train net output #0: center_loss = 174.495 (* 0.008 = 1.39596 loss)
I0826 16:25:04.649256 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.38914 (* 1 = 5.38914 loss)
I0826 16:25:04.649260 25446 sgd_solver.cpp:138] Iteration 16800, lr = 0.0001
I0826 16:25:06.709511 25446 solver.cpp:243] Iteration 16810, loss = 6.43284
I0826 16:25:06.709534 25446 solver.cpp:259]     Train net output #0: center_loss = 187.177 (* 0.008 = 1.49742 loss)
I0826 16:25:06.709539 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.93543 (* 1 = 4.93543 loss)
I0826 16:25:06.709543 25446 sgd_solver.cpp:138] Iteration 16810, lr = 0.0001
I0826 16:25:08.773296 25446 solver.cpp:243] Iteration 16820, loss = 6.6878
I0826 16:25:08.773320 25446 solver.cpp:259]     Train net output #0: center_loss = 198.816 (* 0.008 = 1.59052 loss)
I0826 16:25:08.773327 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.09728 (* 1 = 5.09728 loss)
I0826 16:25:08.773331 25446 sgd_solver.cpp:138] Iteration 16820, lr = 0.0001
I0826 16:25:10.832677 25446 solver.cpp:243] Iteration 16830, loss = 6.46489
I0826 16:25:10.832702 25446 solver.cpp:259]     Train net output #0: center_loss = 180.147 (* 0.008 = 1.44117 loss)
I0826 16:25:10.832707 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02371 (* 1 = 5.02371 loss)
I0826 16:25:10.832711 25446 sgd_solver.cpp:138] Iteration 16830, lr = 0.0001
I0826 16:25:12.895282 25446 solver.cpp:243] Iteration 16840, loss = 5.75432
I0826 16:25:12.895303 25446 solver.cpp:259]     Train net output #0: center_loss = 201.753 (* 0.008 = 1.61402 loss)
I0826 16:25:12.895310 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.1403 (* 1 = 4.1403 loss)
I0826 16:25:12.895313 25446 sgd_solver.cpp:138] Iteration 16840, lr = 0.0001
I0826 16:25:14.956323 25446 solver.cpp:243] Iteration 16850, loss = 5.95324
I0826 16:25:14.956360 25446 solver.cpp:259]     Train net output #0: center_loss = 179.347 (* 0.008 = 1.43478 loss)
I0826 16:25:14.956367 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.51847 (* 1 = 4.51847 loss)
I0826 16:25:14.956370 25446 sgd_solver.cpp:138] Iteration 16850, lr = 0.0001
I0826 16:25:17.017457 25446 solver.cpp:243] Iteration 16860, loss = 6.92557
I0826 16:25:17.017479 25446 solver.cpp:259]     Train net output #0: center_loss = 178.163 (* 0.008 = 1.4253 loss)
I0826 16:25:17.017485 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.50026 (* 1 = 5.50026 loss)
I0826 16:25:17.017489 25446 sgd_solver.cpp:138] Iteration 16860, lr = 0.0001
I0826 16:25:19.079475 25446 solver.cpp:243] Iteration 16870, loss = 7.21119
I0826 16:25:19.079515 25446 solver.cpp:259]     Train net output #0: center_loss = 178.028 (* 0.008 = 1.42422 loss)
I0826 16:25:19.079521 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.78697 (* 1 = 5.78697 loss)
I0826 16:25:19.079525 25446 sgd_solver.cpp:138] Iteration 16870, lr = 0.0001
I0826 16:25:21.142720 25446 solver.cpp:243] Iteration 16880, loss = 6.73535
I0826 16:25:21.142745 25446 solver.cpp:259]     Train net output #0: center_loss = 194.035 (* 0.008 = 1.55228 loss)
I0826 16:25:21.142751 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.18307 (* 1 = 5.18307 loss)
I0826 16:25:21.142755 25446 sgd_solver.cpp:138] Iteration 16880, lr = 0.0001
I0826 16:25:23.201162 25446 solver.cpp:243] Iteration 16890, loss = 6.65227
I0826 16:25:23.201201 25446 solver.cpp:259]     Train net output #0: center_loss = 193.958 (* 0.008 = 1.55166 loss)
I0826 16:25:23.201207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.1006 (* 1 = 5.1006 loss)
I0826 16:25:23.201211 25446 sgd_solver.cpp:138] Iteration 16890, lr = 0.0001
I0826 16:25:25.261768 25446 solver.cpp:243] Iteration 16900, loss = 5.86497
I0826 16:25:25.261792 25446 solver.cpp:259]     Train net output #0: center_loss = 182.219 (* 0.008 = 1.45775 loss)
I0826 16:25:25.261799 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40722 (* 1 = 4.40722 loss)
I0826 16:25:25.261802 25446 sgd_solver.cpp:138] Iteration 16900, lr = 0.0001
I0826 16:25:27.320525 25446 solver.cpp:243] Iteration 16910, loss = 6.51746
I0826 16:25:27.320643 25446 solver.cpp:259]     Train net output #0: center_loss = 185.824 (* 0.008 = 1.48659 loss)
I0826 16:25:27.320652 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.03086 (* 1 = 5.03086 loss)
I0826 16:25:27.320668 25446 sgd_solver.cpp:138] Iteration 16910, lr = 0.0001
I0826 16:25:29.511471 25446 solver.cpp:243] Iteration 16920, loss = 6.77592
I0826 16:25:29.511495 25446 solver.cpp:259]     Train net output #0: center_loss = 187.014 (* 0.008 = 1.49611 loss)
I0826 16:25:29.511502 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.27981 (* 1 = 5.27981 loss)
I0826 16:25:29.511505 25446 sgd_solver.cpp:138] Iteration 16920, lr = 0.0001
I0826 16:25:31.669138 25446 solver.cpp:243] Iteration 16930, loss = 6.40176
I0826 16:25:31.669162 25446 solver.cpp:259]     Train net output #0: center_loss = 202.798 (* 0.008 = 1.62238 loss)
I0826 16:25:31.669169 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77938 (* 1 = 4.77938 loss)
I0826 16:25:31.669173 25446 sgd_solver.cpp:138] Iteration 16930, lr = 0.0001
I0826 16:25:33.818558 25446 solver.cpp:243] Iteration 16940, loss = 6.53483
I0826 16:25:33.818583 25446 solver.cpp:259]     Train net output #0: center_loss = 162.953 (* 0.008 = 1.30363 loss)
I0826 16:25:33.818590 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.2312 (* 1 = 5.2312 loss)
I0826 16:25:33.818593 25446 sgd_solver.cpp:138] Iteration 16940, lr = 0.0001
I0826 16:25:35.878137 25446 solver.cpp:243] Iteration 16950, loss = 6.59481
I0826 16:25:35.878161 25446 solver.cpp:259]     Train net output #0: center_loss = 174.094 (* 0.008 = 1.39275 loss)
I0826 16:25:35.878182 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.20206 (* 1 = 5.20206 loss)
I0826 16:25:35.878186 25446 sgd_solver.cpp:138] Iteration 16950, lr = 0.0001
I0826 16:25:37.934079 25446 solver.cpp:243] Iteration 16960, loss = 6.44716
I0826 16:25:37.934118 25446 solver.cpp:259]     Train net output #0: center_loss = 197.687 (* 0.008 = 1.58149 loss)
I0826 16:25:37.934124 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.86567 (* 1 = 4.86567 loss)
I0826 16:25:37.934128 25446 sgd_solver.cpp:138] Iteration 16960, lr = 0.0001
I0826 16:25:40.119190 25446 solver.cpp:243] Iteration 16970, loss = 6.0448
I0826 16:25:40.119217 25446 solver.cpp:259]     Train net output #0: center_loss = 196.498 (* 0.008 = 1.57198 loss)
I0826 16:25:40.119223 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47282 (* 1 = 4.47282 loss)
I0826 16:25:40.119227 25446 sgd_solver.cpp:138] Iteration 16970, lr = 0.0001
I0826 16:25:42.399346 25446 solver.cpp:243] Iteration 16980, loss = 6.95317
I0826 16:25:42.399371 25446 solver.cpp:259]     Train net output #0: center_loss = 174.316 (* 0.008 = 1.39453 loss)
I0826 16:25:42.399377 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.55864 (* 1 = 5.55864 loss)
I0826 16:25:42.399381 25446 sgd_solver.cpp:138] Iteration 16980, lr = 0.0001
I0826 16:25:44.575006 25446 solver.cpp:243] Iteration 16990, loss = 6.31868
I0826 16:25:44.575044 25446 solver.cpp:259]     Train net output #0: center_loss = 190.904 (* 0.008 = 1.52723 loss)
I0826 16:25:44.575050 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79145 (* 1 = 4.79145 loss)
I0826 16:25:44.575054 25446 sgd_solver.cpp:138] Iteration 16990, lr = 0.0001
I0826 16:25:46.505756 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_17000.caffemodel
I0826 16:25:47.632014 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_17000.solverstate
I0826 16:25:47.960430 25446 solver.cpp:243] Iteration 17000, loss = 6.21348
I0826 16:25:47.960456 25446 solver.cpp:259]     Train net output #0: center_loss = 183.921 (* 0.008 = 1.47136 loss)
I0826 16:25:47.960463 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.74211 (* 1 = 4.74211 loss)
I0826 16:25:47.960467 25446 sgd_solver.cpp:138] Iteration 17000, lr = 0.0001
I0826 16:25:50.017709 25446 solver.cpp:243] Iteration 17010, loss = 7.02282
I0826 16:25:50.017748 25446 solver.cpp:259]     Train net output #0: center_loss = 162.86 (* 0.008 = 1.30288 loss)
I0826 16:25:50.017796 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.71994 (* 1 = 5.71994 loss)
I0826 16:25:50.017801 25446 sgd_solver.cpp:138] Iteration 17010, lr = 0.0001
I0826 16:25:52.077450 25446 solver.cpp:243] Iteration 17020, loss = 7.3894
I0826 16:25:52.077487 25446 solver.cpp:259]     Train net output #0: center_loss = 163.248 (* 0.008 = 1.30598 loss)
I0826 16:25:52.077493 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.08342 (* 1 = 6.08342 loss)
I0826 16:25:52.077497 25446 sgd_solver.cpp:138] Iteration 17020, lr = 0.0001
I0826 16:25:54.135380 25446 solver.cpp:243] Iteration 17030, loss = 7.30957
I0826 16:25:54.135404 25446 solver.cpp:259]     Train net output #0: center_loss = 167.092 (* 0.008 = 1.33674 loss)
I0826 16:25:54.135411 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.97283 (* 1 = 5.97283 loss)
I0826 16:25:54.135413 25446 sgd_solver.cpp:138] Iteration 17030, lr = 0.0001
I0826 16:25:56.193720 25446 solver.cpp:243] Iteration 17040, loss = 5.66936
I0826 16:25:56.193760 25446 solver.cpp:259]     Train net output #0: center_loss = 210.99 (* 0.008 = 1.68792 loss)
I0826 16:25:56.193766 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.98144 (* 1 = 3.98144 loss)
I0826 16:25:56.193769 25446 sgd_solver.cpp:138] Iteration 17040, lr = 0.0001
I0826 16:25:58.253577 25446 solver.cpp:243] Iteration 17050, loss = 6.99899
I0826 16:25:58.253768 25446 solver.cpp:259]     Train net output #0: center_loss = 168.272 (* 0.008 = 1.34618 loss)
I0826 16:25:58.253788 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.65281 (* 1 = 5.65281 loss)
I0826 16:25:58.253793 25446 sgd_solver.cpp:138] Iteration 17050, lr = 0.0001
I0826 16:26:00.312566 25446 solver.cpp:243] Iteration 17060, loss = 6.19742
I0826 16:26:00.312590 25446 solver.cpp:259]     Train net output #0: center_loss = 183.684 (* 0.008 = 1.46947 loss)
I0826 16:26:00.312597 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.72796 (* 1 = 4.72796 loss)
I0826 16:26:00.312600 25446 sgd_solver.cpp:138] Iteration 17060, lr = 0.0001
I0826 16:26:02.374099 25446 solver.cpp:243] Iteration 17070, loss = 7.54472
I0826 16:26:02.374136 25446 solver.cpp:259]     Train net output #0: center_loss = 153.712 (* 0.008 = 1.2297 loss)
I0826 16:26:02.374142 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.31503 (* 1 = 6.31503 loss)
I0826 16:26:02.374146 25446 sgd_solver.cpp:138] Iteration 17070, lr = 0.0001
I0826 16:26:04.433986 25446 solver.cpp:243] Iteration 17080, loss = 6.3776
I0826 16:26:04.434012 25446 solver.cpp:259]     Train net output #0: center_loss = 169.246 (* 0.008 = 1.35397 loss)
I0826 16:26:04.434020 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02363 (* 1 = 5.02363 loss)
I0826 16:26:04.434023 25446 sgd_solver.cpp:138] Iteration 17080, lr = 0.0001
I0826 16:26:06.491873 25446 solver.cpp:243] Iteration 17090, loss = 6.21368
I0826 16:26:06.491896 25446 solver.cpp:259]     Train net output #0: center_loss = 207.316 (* 0.008 = 1.65853 loss)
I0826 16:26:06.491902 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.55515 (* 1 = 4.55515 loss)
I0826 16:26:06.491906 25446 sgd_solver.cpp:138] Iteration 17090, lr = 0.0001
I0826 16:26:08.550379 25446 solver.cpp:243] Iteration 17100, loss = 7.7902
I0826 16:26:08.550420 25446 solver.cpp:259]     Train net output #0: center_loss = 177.625 (* 0.008 = 1.421 loss)
I0826 16:26:08.550426 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.3692 (* 1 = 6.3692 loss)
I0826 16:26:08.550428 25446 sgd_solver.cpp:138] Iteration 17100, lr = 0.0001
I0826 16:26:10.612771 25446 solver.cpp:243] Iteration 17110, loss = 6.08241
I0826 16:26:10.612794 25446 solver.cpp:259]     Train net output #0: center_loss = 180.456 (* 0.008 = 1.44365 loss)
I0826 16:26:10.612800 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.63876 (* 1 = 4.63876 loss)
I0826 16:26:10.612804 25446 sgd_solver.cpp:138] Iteration 17110, lr = 0.0001
I0826 16:26:12.670188 25446 solver.cpp:243] Iteration 17120, loss = 7.01574
I0826 16:26:12.670228 25446 solver.cpp:259]     Train net output #0: center_loss = 178.244 (* 0.008 = 1.42595 loss)
I0826 16:26:12.670235 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.58979 (* 1 = 5.58979 loss)
I0826 16:26:12.670239 25446 sgd_solver.cpp:138] Iteration 17120, lr = 0.0001
I0826 16:26:14.729622 25446 solver.cpp:243] Iteration 17130, loss = 6.81996
I0826 16:26:14.729646 25446 solver.cpp:259]     Train net output #0: center_loss = 178.63 (* 0.008 = 1.42904 loss)
I0826 16:26:14.729652 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.39091 (* 1 = 5.39091 loss)
I0826 16:26:14.729656 25446 sgd_solver.cpp:138] Iteration 17130, lr = 0.0001
I0826 16:26:16.786139 25446 solver.cpp:243] Iteration 17140, loss = 6.70325
I0826 16:26:16.786180 25446 solver.cpp:259]     Train net output #0: center_loss = 169.922 (* 0.008 = 1.35937 loss)
I0826 16:26:16.786186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.34388 (* 1 = 5.34388 loss)
I0826 16:26:16.786190 25446 sgd_solver.cpp:138] Iteration 17140, lr = 0.0001
I0826 16:26:18.844728 25446 solver.cpp:243] Iteration 17150, loss = 6.82533
I0826 16:26:18.844753 25446 solver.cpp:259]     Train net output #0: center_loss = 182.223 (* 0.008 = 1.45779 loss)
I0826 16:26:18.844758 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.36754 (* 1 = 5.36754 loss)
I0826 16:26:18.844763 25446 sgd_solver.cpp:138] Iteration 17150, lr = 0.0001
I0826 16:26:20.901664 25446 solver.cpp:243] Iteration 17160, loss = 6.66108
I0826 16:26:20.901687 25446 solver.cpp:259]     Train net output #0: center_loss = 177.095 (* 0.008 = 1.41676 loss)
I0826 16:26:20.901693 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.24432 (* 1 = 5.24432 loss)
I0826 16:26:20.901697 25446 sgd_solver.cpp:138] Iteration 17160, lr = 0.0001
I0826 16:26:22.962538 25446 solver.cpp:243] Iteration 17170, loss = 6.22093
I0826 16:26:22.962575 25446 solver.cpp:259]     Train net output #0: center_loss = 186.296 (* 0.008 = 1.49037 loss)
I0826 16:26:22.962581 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.73056 (* 1 = 4.73056 loss)
I0826 16:26:22.962584 25446 sgd_solver.cpp:138] Iteration 17170, lr = 0.0001
I0826 16:26:25.021487 25446 solver.cpp:243] Iteration 17180, loss = 6.04748
I0826 16:26:25.021512 25446 solver.cpp:259]     Train net output #0: center_loss = 202.652 (* 0.008 = 1.62121 loss)
I0826 16:26:25.021517 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.42626 (* 1 = 4.42626 loss)
I0826 16:26:25.021522 25446 sgd_solver.cpp:138] Iteration 17180, lr = 0.0001
I0826 16:26:27.080937 25446 solver.cpp:243] Iteration 17190, loss = 6.7564
I0826 16:26:27.080976 25446 solver.cpp:259]     Train net output #0: center_loss = 183.352 (* 0.008 = 1.46682 loss)
I0826 16:26:27.080981 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.28959 (* 1 = 5.28959 loss)
I0826 16:26:27.080986 25446 sgd_solver.cpp:138] Iteration 17190, lr = 0.0001
I0826 16:26:29.143505 25446 solver.cpp:243] Iteration 17200, loss = 5.97491
I0826 16:26:29.143658 25446 solver.cpp:259]     Train net output #0: center_loss = 207.62 (* 0.008 = 1.66096 loss)
I0826 16:26:29.143666 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.31395 (* 1 = 4.31395 loss)
I0826 16:26:29.143682 25446 sgd_solver.cpp:138] Iteration 17200, lr = 0.0001
I0826 16:26:31.202195 25446 solver.cpp:243] Iteration 17210, loss = 6.3958
I0826 16:26:31.202219 25446 solver.cpp:259]     Train net output #0: center_loss = 159.895 (* 0.008 = 1.27916 loss)
I0826 16:26:31.202225 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.11663 (* 1 = 5.11663 loss)
I0826 16:26:31.202229 25446 sgd_solver.cpp:138] Iteration 17210, lr = 0.0001
I0826 16:26:33.260861 25446 solver.cpp:243] Iteration 17220, loss = 7.27223
I0826 16:26:33.260885 25446 solver.cpp:259]     Train net output #0: center_loss = 171.751 (* 0.008 = 1.37401 loss)
I0826 16:26:33.260891 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.89822 (* 1 = 5.89822 loss)
I0826 16:26:33.260895 25446 sgd_solver.cpp:138] Iteration 17220, lr = 0.0001
I0826 16:26:35.321233 25446 solver.cpp:243] Iteration 17230, loss = 6.43944
I0826 16:26:35.321260 25446 solver.cpp:259]     Train net output #0: center_loss = 189.102 (* 0.008 = 1.51282 loss)
I0826 16:26:35.321267 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.92662 (* 1 = 4.92662 loss)
I0826 16:26:35.321271 25446 sgd_solver.cpp:138] Iteration 17230, lr = 0.0001
I0826 16:26:37.381652 25446 solver.cpp:243] Iteration 17240, loss = 6.15854
I0826 16:26:37.381677 25446 solver.cpp:259]     Train net output #0: center_loss = 192.477 (* 0.008 = 1.53982 loss)
I0826 16:26:37.381683 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.61872 (* 1 = 4.61872 loss)
I0826 16:26:37.381688 25446 sgd_solver.cpp:138] Iteration 17240, lr = 0.0001
I0826 16:26:39.440016 25446 solver.cpp:243] Iteration 17250, loss = 6.07022
I0826 16:26:39.440039 25446 solver.cpp:259]     Train net output #0: center_loss = 190.616 (* 0.008 = 1.52493 loss)
I0826 16:26:39.440045 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.54529 (* 1 = 4.54529 loss)
I0826 16:26:39.440049 25446 sgd_solver.cpp:138] Iteration 17250, lr = 0.0001
I0826 16:26:41.500229 25446 solver.cpp:243] Iteration 17260, loss = 5.86147
I0826 16:26:41.500269 25446 solver.cpp:259]     Train net output #0: center_loss = 192.643 (* 0.008 = 1.54115 loss)
I0826 16:26:41.500275 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.32033 (* 1 = 4.32033 loss)
I0826 16:26:41.500279 25446 sgd_solver.cpp:138] Iteration 17260, lr = 0.0001
I0826 16:26:43.560756 25446 solver.cpp:243] Iteration 17270, loss = 5.89496
I0826 16:26:43.560782 25446 solver.cpp:259]     Train net output #0: center_loss = 186.335 (* 0.008 = 1.49068 loss)
I0826 16:26:43.560788 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40427 (* 1 = 4.40427 loss)
I0826 16:26:43.560792 25446 sgd_solver.cpp:138] Iteration 17270, lr = 0.0001
I0826 16:26:45.621268 25446 solver.cpp:243] Iteration 17280, loss = 7.26279
I0826 16:26:45.621294 25446 solver.cpp:259]     Train net output #0: center_loss = 190.421 (* 0.008 = 1.52337 loss)
I0826 16:26:45.621299 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.73943 (* 1 = 5.73943 loss)
I0826 16:26:45.621304 25446 sgd_solver.cpp:138] Iteration 17280, lr = 0.0001
I0826 16:26:47.680543 25446 solver.cpp:243] Iteration 17290, loss = 6.7274
I0826 16:26:47.680583 25446 solver.cpp:259]     Train net output #0: center_loss = 169.167 (* 0.008 = 1.35334 loss)
I0826 16:26:47.680588 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.37406 (* 1 = 5.37406 loss)
I0826 16:26:47.680593 25446 sgd_solver.cpp:138] Iteration 17290, lr = 0.0001
I0826 16:26:49.737768 25446 solver.cpp:243] Iteration 17300, loss = 6.73754
I0826 16:26:49.737793 25446 solver.cpp:259]     Train net output #0: center_loss = 175.804 (* 0.008 = 1.40643 loss)
I0826 16:26:49.737799 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.33111 (* 1 = 5.33111 loss)
I0826 16:26:49.737803 25446 sgd_solver.cpp:138] Iteration 17300, lr = 0.0001
I0826 16:26:51.798087 25446 solver.cpp:243] Iteration 17310, loss = 5.93689
I0826 16:26:51.798111 25446 solver.cpp:259]     Train net output #0: center_loss = 169.381 (* 0.008 = 1.35505 loss)
I0826 16:26:51.798117 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.58184 (* 1 = 4.58184 loss)
I0826 16:26:51.798121 25446 sgd_solver.cpp:138] Iteration 17310, lr = 0.0001
I0826 16:26:53.858669 25446 solver.cpp:243] Iteration 17320, loss = 6.13931
I0826 16:26:53.858692 25446 solver.cpp:259]     Train net output #0: center_loss = 204.635 (* 0.008 = 1.63708 loss)
I0826 16:26:53.858698 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50223 (* 1 = 4.50223 loss)
I0826 16:26:53.858702 25446 sgd_solver.cpp:138] Iteration 17320, lr = 0.0001
I0826 16:26:55.916013 25446 solver.cpp:243] Iteration 17330, loss = 6.48882
I0826 16:26:55.916036 25446 solver.cpp:259]     Train net output #0: center_loss = 183.014 (* 0.008 = 1.46411 loss)
I0826 16:26:55.916043 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02471 (* 1 = 5.02471 loss)
I0826 16:26:55.916046 25446 sgd_solver.cpp:138] Iteration 17330, lr = 0.0001
I0826 16:26:57.976022 25446 solver.cpp:243] Iteration 17340, loss = 5.94696
I0826 16:26:57.976047 25446 solver.cpp:259]     Train net output #0: center_loss = 213.164 (* 0.008 = 1.70531 loss)
I0826 16:26:57.976052 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.24165 (* 1 = 4.24165 loss)
I0826 16:26:57.976056 25446 sgd_solver.cpp:138] Iteration 17340, lr = 0.0001
I0826 16:27:00.036475 25446 solver.cpp:243] Iteration 17350, loss = 5.96626
I0826 16:27:00.036614 25446 solver.cpp:259]     Train net output #0: center_loss = 186.18 (* 0.008 = 1.48944 loss)
I0826 16:27:00.036622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47682 (* 1 = 4.47682 loss)
I0826 16:27:00.036626 25446 sgd_solver.cpp:138] Iteration 17350, lr = 0.0001
I0826 16:27:02.093422 25446 solver.cpp:243] Iteration 17360, loss = 6.7404
I0826 16:27:02.093463 25446 solver.cpp:259]     Train net output #0: center_loss = 189.803 (* 0.008 = 1.51843 loss)
I0826 16:27:02.093469 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.22198 (* 1 = 5.22198 loss)
I0826 16:27:02.093473 25446 sgd_solver.cpp:138] Iteration 17360, lr = 0.0001
I0826 16:27:04.152650 25446 solver.cpp:243] Iteration 17370, loss = 5.94922
I0826 16:27:04.152689 25446 solver.cpp:259]     Train net output #0: center_loss = 204.204 (* 0.008 = 1.63363 loss)
I0826 16:27:04.152695 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.31558 (* 1 = 4.31558 loss)
I0826 16:27:04.152699 25446 sgd_solver.cpp:138] Iteration 17370, lr = 0.0001
I0826 16:27:06.208322 25446 solver.cpp:243] Iteration 17380, loss = 7.46663
I0826 16:27:06.208348 25446 solver.cpp:259]     Train net output #0: center_loss = 190.108 (* 0.008 = 1.52086 loss)
I0826 16:27:06.208354 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.94577 (* 1 = 5.94577 loss)
I0826 16:27:06.208359 25446 sgd_solver.cpp:138] Iteration 17380, lr = 0.0001
I0826 16:27:08.269201 25446 solver.cpp:243] Iteration 17390, loss = 6.01467
I0826 16:27:08.269242 25446 solver.cpp:259]     Train net output #0: center_loss = 197.33 (* 0.008 = 1.57864 loss)
I0826 16:27:08.269266 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43603 (* 1 = 4.43603 loss)
I0826 16:27:08.269271 25446 sgd_solver.cpp:138] Iteration 17390, lr = 0.0001
I0826 16:27:10.330163 25446 solver.cpp:243] Iteration 17400, loss = 6.71535
I0826 16:27:10.330189 25446 solver.cpp:259]     Train net output #0: center_loss = 194.734 (* 0.008 = 1.55787 loss)
I0826 16:27:10.330196 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.15748 (* 1 = 5.15748 loss)
I0826 16:27:10.330201 25446 sgd_solver.cpp:138] Iteration 17400, lr = 0.0001
I0826 16:27:12.388017 25446 solver.cpp:243] Iteration 17410, loss = 6.2206
I0826 16:27:12.388042 25446 solver.cpp:259]     Train net output #0: center_loss = 203.926 (* 0.008 = 1.63141 loss)
I0826 16:27:12.388048 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.58919 (* 1 = 4.58919 loss)
I0826 16:27:12.388052 25446 sgd_solver.cpp:138] Iteration 17410, lr = 0.0001
I0826 16:27:14.448153 25446 solver.cpp:243] Iteration 17420, loss = 5.87558
I0826 16:27:14.448192 25446 solver.cpp:259]     Train net output #0: center_loss = 180.71 (* 0.008 = 1.44568 loss)
I0826 16:27:14.448199 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.4299 (* 1 = 4.4299 loss)
I0826 16:27:14.448202 25446 sgd_solver.cpp:138] Iteration 17420, lr = 0.0001
I0826 16:27:16.592476 25446 solver.cpp:243] Iteration 17430, loss = 6.40418
I0826 16:27:16.592515 25446 solver.cpp:259]     Train net output #0: center_loss = 190.667 (* 0.008 = 1.52534 loss)
I0826 16:27:16.592521 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.87884 (* 1 = 4.87884 loss)
I0826 16:27:16.592525 25446 sgd_solver.cpp:138] Iteration 17430, lr = 0.0001
I0826 16:27:18.730818 25446 solver.cpp:243] Iteration 17440, loss = 6.21908
I0826 16:27:18.730842 25446 solver.cpp:259]     Train net output #0: center_loss = 188.024 (* 0.008 = 1.50419 loss)
I0826 16:27:18.730849 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.71489 (* 1 = 4.71489 loss)
I0826 16:27:18.730852 25446 sgd_solver.cpp:138] Iteration 17440, lr = 0.0001
I0826 16:27:20.905297 25446 solver.cpp:243] Iteration 17450, loss = 6.83147
I0826 16:27:20.905349 25446 solver.cpp:259]     Train net output #0: center_loss = 191.282 (* 0.008 = 1.53025 loss)
I0826 16:27:20.905354 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.30121 (* 1 = 5.30121 loss)
I0826 16:27:20.905359 25446 sgd_solver.cpp:138] Iteration 17450, lr = 0.0001
I0826 16:27:23.038923 25446 solver.cpp:243] Iteration 17460, loss = 6.73266
I0826 16:27:23.038949 25446 solver.cpp:259]     Train net output #0: center_loss = 173.615 (* 0.008 = 1.38892 loss)
I0826 16:27:23.038954 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.34374 (* 1 = 5.34374 loss)
I0826 16:27:23.038959 25446 sgd_solver.cpp:138] Iteration 17460, lr = 0.0001
I0826 16:27:25.180647 25446 solver.cpp:243] Iteration 17470, loss = 6.58238
I0826 16:27:25.180673 25446 solver.cpp:259]     Train net output #0: center_loss = 189.339 (* 0.008 = 1.51472 loss)
I0826 16:27:25.180680 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.06767 (* 1 = 5.06767 loss)
I0826 16:27:25.180683 25446 sgd_solver.cpp:138] Iteration 17470, lr = 0.0001
I0826 16:27:27.237687 25446 solver.cpp:243] Iteration 17480, loss = 5.87543
I0826 16:27:27.237712 25446 solver.cpp:259]     Train net output #0: center_loss = 173.583 (* 0.008 = 1.38866 loss)
I0826 16:27:27.237718 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.48676 (* 1 = 4.48676 loss)
I0826 16:27:27.237722 25446 sgd_solver.cpp:138] Iteration 17480, lr = 0.0001
I0826 16:27:29.298463 25446 solver.cpp:243] Iteration 17490, loss = 6.15977
I0826 16:27:29.298487 25446 solver.cpp:259]     Train net output #0: center_loss = 199.141 (* 0.008 = 1.59313 loss)
I0826 16:27:29.298493 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.56664 (* 1 = 4.56664 loss)
I0826 16:27:29.298497 25446 sgd_solver.cpp:138] Iteration 17490, lr = 0.0001
I0826 16:27:31.357390 25446 solver.cpp:243] Iteration 17500, loss = 6.80648
I0826 16:27:31.357532 25446 solver.cpp:259]     Train net output #0: center_loss = 195.694 (* 0.008 = 1.56555 loss)
I0826 16:27:31.357538 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.24093 (* 1 = 5.24093 loss)
I0826 16:27:31.357542 25446 sgd_solver.cpp:138] Iteration 17500, lr = 0.0001
I0826 16:27:33.416183 25446 solver.cpp:243] Iteration 17510, loss = 6.31366
I0826 16:27:33.416224 25446 solver.cpp:259]     Train net output #0: center_loss = 202.076 (* 0.008 = 1.61661 loss)
I0826 16:27:33.416230 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.69705 (* 1 = 4.69705 loss)
I0826 16:27:33.416234 25446 sgd_solver.cpp:138] Iteration 17510, lr = 0.0001
I0826 16:27:35.549013 25446 solver.cpp:243] Iteration 17520, loss = 7.0908
I0826 16:27:35.549041 25446 solver.cpp:259]     Train net output #0: center_loss = 211.192 (* 0.008 = 1.68954 loss)
I0826 16:27:35.549047 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.40126 (* 1 = 5.40126 loss)
I0826 16:27:35.549052 25446 sgd_solver.cpp:138] Iteration 17520, lr = 0.0001
I0826 16:27:37.698578 25446 solver.cpp:243] Iteration 17530, loss = 6.9157
I0826 16:27:37.698603 25446 solver.cpp:259]     Train net output #0: center_loss = 194.011 (* 0.008 = 1.55209 loss)
I0826 16:27:37.698611 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.36361 (* 1 = 5.36361 loss)
I0826 16:27:37.698616 25446 sgd_solver.cpp:138] Iteration 17530, lr = 0.0001
I0826 16:27:39.757547 25446 solver.cpp:243] Iteration 17540, loss = 5.83977
I0826 16:27:39.757586 25446 solver.cpp:259]     Train net output #0: center_loss = 209.051 (* 0.008 = 1.67241 loss)
I0826 16:27:39.757593 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.16737 (* 1 = 4.16737 loss)
I0826 16:27:39.757596 25446 sgd_solver.cpp:138] Iteration 17540, lr = 0.0001
I0826 16:27:41.818509 25446 solver.cpp:243] Iteration 17550, loss = 7.13956
I0826 16:27:41.818549 25446 solver.cpp:259]     Train net output #0: center_loss = 196.711 (* 0.008 = 1.57369 loss)
I0826 16:27:41.818555 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.56587 (* 1 = 5.56587 loss)
I0826 16:27:41.818559 25446 sgd_solver.cpp:138] Iteration 17550, lr = 0.0001
I0826 16:27:43.880437 25446 solver.cpp:243] Iteration 17560, loss = 5.05615
I0826 16:27:43.880475 25446 solver.cpp:259]     Train net output #0: center_loss = 198.349 (* 0.008 = 1.58679 loss)
I0826 16:27:43.880481 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.46936 (* 1 = 3.46936 loss)
I0826 16:27:43.880486 25446 sgd_solver.cpp:138] Iteration 17560, lr = 0.0001
I0826 16:27:45.943048 25446 solver.cpp:243] Iteration 17570, loss = 7.04596
I0826 16:27:45.943087 25446 solver.cpp:259]     Train net output #0: center_loss = 155.32 (* 0.008 = 1.24256 loss)
I0826 16:27:45.943094 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.8034 (* 1 = 5.8034 loss)
I0826 16:27:45.943097 25446 sgd_solver.cpp:138] Iteration 17570, lr = 0.0001
I0826 16:27:48.002072 25446 solver.cpp:243] Iteration 17580, loss = 6.90242
I0826 16:27:48.002112 25446 solver.cpp:259]     Train net output #0: center_loss = 167.775 (* 0.008 = 1.3422 loss)
I0826 16:27:48.002118 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.56022 (* 1 = 5.56022 loss)
I0826 16:27:48.002122 25446 sgd_solver.cpp:138] Iteration 17580, lr = 0.0001
I0826 16:27:50.062567 25446 solver.cpp:243] Iteration 17590, loss = 6.32865
I0826 16:27:50.062608 25446 solver.cpp:259]     Train net output #0: center_loss = 200.909 (* 0.008 = 1.60727 loss)
I0826 16:27:50.062613 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.72139 (* 1 = 4.72139 loss)
I0826 16:27:50.062618 25446 sgd_solver.cpp:138] Iteration 17590, lr = 0.0001
I0826 16:27:52.123116 25446 solver.cpp:243] Iteration 17600, loss = 6.46191
I0826 16:27:52.123157 25446 solver.cpp:259]     Train net output #0: center_loss = 220.004 (* 0.008 = 1.76003 loss)
I0826 16:27:52.123162 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70187 (* 1 = 4.70187 loss)
I0826 16:27:52.123167 25446 sgd_solver.cpp:138] Iteration 17600, lr = 0.0001
I0826 16:27:54.182242 25446 solver.cpp:243] Iteration 17610, loss = 6.02768
I0826 16:27:54.182283 25446 solver.cpp:259]     Train net output #0: center_loss = 208.705 (* 0.008 = 1.66964 loss)
I0826 16:27:54.182289 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.35804 (* 1 = 4.35804 loss)
I0826 16:27:54.182293 25446 sgd_solver.cpp:138] Iteration 17610, lr = 0.0001
I0826 16:27:56.244138 25446 solver.cpp:243] Iteration 17620, loss = 7.05839
I0826 16:27:56.244161 25446 solver.cpp:259]     Train net output #0: center_loss = 174.254 (* 0.008 = 1.39403 loss)
I0826 16:27:56.244168 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.66436 (* 1 = 5.66436 loss)
I0826 16:27:56.244171 25446 sgd_solver.cpp:138] Iteration 17620, lr = 0.0001
I0826 16:27:58.302659 25446 solver.cpp:243] Iteration 17630, loss = 6.6053
I0826 16:27:58.302683 25446 solver.cpp:259]     Train net output #0: center_loss = 205.982 (* 0.008 = 1.64785 loss)
I0826 16:27:58.302690 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.95745 (* 1 = 4.95745 loss)
I0826 16:27:58.302693 25446 sgd_solver.cpp:138] Iteration 17630, lr = 0.0001
I0826 16:28:00.365932 25446 solver.cpp:243] Iteration 17640, loss = 6.51428
I0826 16:28:00.365958 25446 solver.cpp:259]     Train net output #0: center_loss = 182.203 (* 0.008 = 1.45763 loss)
I0826 16:28:00.365978 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.05665 (* 1 = 5.05665 loss)
I0826 16:28:00.365983 25446 sgd_solver.cpp:138] Iteration 17640, lr = 0.0001
I0826 16:28:02.427633 25446 solver.cpp:243] Iteration 17650, loss = 6.53214
I0826 16:28:02.427793 25446 solver.cpp:259]     Train net output #0: center_loss = 204.815 (* 0.008 = 1.63852 loss)
I0826 16:28:02.427799 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.89362 (* 1 = 4.89362 loss)
I0826 16:28:02.427816 25446 sgd_solver.cpp:138] Iteration 17650, lr = 0.0001
I0826 16:28:04.489387 25446 solver.cpp:243] Iteration 17660, loss = 6.46594
I0826 16:28:04.489428 25446 solver.cpp:259]     Train net output #0: center_loss = 186.129 (* 0.008 = 1.48904 loss)
I0826 16:28:04.489434 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.97691 (* 1 = 4.97691 loss)
I0826 16:28:04.489437 25446 sgd_solver.cpp:138] Iteration 17660, lr = 0.0001
I0826 16:28:06.545866 25446 solver.cpp:243] Iteration 17670, loss = 6.78823
I0826 16:28:06.545904 25446 solver.cpp:259]     Train net output #0: center_loss = 177.366 (* 0.008 = 1.41893 loss)
I0826 16:28:06.545912 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.3693 (* 1 = 5.3693 loss)
I0826 16:28:06.545915 25446 sgd_solver.cpp:138] Iteration 17670, lr = 0.0001
I0826 16:28:08.605525 25446 solver.cpp:243] Iteration 17680, loss = 5.77336
I0826 16:28:08.605566 25446 solver.cpp:259]     Train net output #0: center_loss = 196.721 (* 0.008 = 1.57377 loss)
I0826 16:28:08.605571 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.19959 (* 1 = 4.19959 loss)
I0826 16:28:08.605574 25446 sgd_solver.cpp:138] Iteration 17680, lr = 0.0001
I0826 16:28:10.667044 25446 solver.cpp:243] Iteration 17690, loss = 6.13334
I0826 16:28:10.667083 25446 solver.cpp:259]     Train net output #0: center_loss = 179.789 (* 0.008 = 1.43831 loss)
I0826 16:28:10.667089 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.69503 (* 1 = 4.69503 loss)
I0826 16:28:10.667093 25446 sgd_solver.cpp:138] Iteration 17690, lr = 0.0001
I0826 16:28:12.729948 25446 solver.cpp:243] Iteration 17700, loss = 6.00411
I0826 16:28:12.729971 25446 solver.cpp:259]     Train net output #0: center_loss = 203.417 (* 0.008 = 1.62734 loss)
I0826 16:28:12.729977 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.37677 (* 1 = 4.37677 loss)
I0826 16:28:12.729981 25446 sgd_solver.cpp:138] Iteration 17700, lr = 0.0001
I0826 16:28:14.786655 25446 solver.cpp:243] Iteration 17710, loss = 5.79073
I0826 16:28:14.786693 25446 solver.cpp:259]     Train net output #0: center_loss = 213.805 (* 0.008 = 1.71044 loss)
I0826 16:28:14.786700 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.0803 (* 1 = 4.0803 loss)
I0826 16:28:14.786703 25446 sgd_solver.cpp:138] Iteration 17710, lr = 0.0001
I0826 16:28:16.845388 25446 solver.cpp:243] Iteration 17720, loss = 6.95171
I0826 16:28:16.845412 25446 solver.cpp:259]     Train net output #0: center_loss = 179.306 (* 0.008 = 1.43445 loss)
I0826 16:28:16.845418 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.51727 (* 1 = 5.51727 loss)
I0826 16:28:16.845422 25446 sgd_solver.cpp:138] Iteration 17720, lr = 0.0001
I0826 16:28:18.995682 25446 solver.cpp:243] Iteration 17730, loss = 6.24473
I0826 16:28:18.995712 25446 solver.cpp:259]     Train net output #0: center_loss = 185.755 (* 0.008 = 1.48604 loss)
I0826 16:28:18.995718 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.75869 (* 1 = 4.75869 loss)
I0826 16:28:18.995723 25446 sgd_solver.cpp:138] Iteration 17730, lr = 0.0001
I0826 16:28:21.268303 25446 solver.cpp:243] Iteration 17740, loss = 6.39046
I0826 16:28:21.268329 25446 solver.cpp:259]     Train net output #0: center_loss = 177.063 (* 0.008 = 1.4165 loss)
I0826 16:28:21.268335 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.97396 (* 1 = 4.97396 loss)
I0826 16:28:21.268340 25446 sgd_solver.cpp:138] Iteration 17740, lr = 0.0001
I0826 16:28:23.414674 25446 solver.cpp:243] Iteration 17750, loss = 7.0751
I0826 16:28:23.414714 25446 solver.cpp:259]     Train net output #0: center_loss = 174.622 (* 0.008 = 1.39698 loss)
I0826 16:28:23.414721 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.67812 (* 1 = 5.67812 loss)
I0826 16:28:23.414726 25446 sgd_solver.cpp:138] Iteration 17750, lr = 0.0001
I0826 16:28:25.608119 25446 solver.cpp:243] Iteration 17760, loss = 5.93764
I0826 16:28:25.608144 25446 solver.cpp:259]     Train net output #0: center_loss = 187.806 (* 0.008 = 1.50245 loss)
I0826 16:28:25.608150 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43519 (* 1 = 4.43519 loss)
I0826 16:28:25.608155 25446 sgd_solver.cpp:138] Iteration 17760, lr = 0.0001
I0826 16:28:27.737607 25446 solver.cpp:243] Iteration 17770, loss = 6.58985
I0826 16:28:27.737632 25446 solver.cpp:259]     Train net output #0: center_loss = 179.394 (* 0.008 = 1.43515 loss)
I0826 16:28:27.737637 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.1547 (* 1 = 5.1547 loss)
I0826 16:28:27.737641 25446 sgd_solver.cpp:138] Iteration 17770, lr = 0.0001
I0826 16:28:29.876432 25446 solver.cpp:243] Iteration 17780, loss = 6.34866
I0826 16:28:29.876471 25446 solver.cpp:259]     Train net output #0: center_loss = 170.459 (* 0.008 = 1.36367 loss)
I0826 16:28:29.876477 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.98499 (* 1 = 4.98499 loss)
I0826 16:28:29.876480 25446 sgd_solver.cpp:138] Iteration 17780, lr = 0.0001
I0826 16:28:31.932776 25446 solver.cpp:243] Iteration 17790, loss = 6.10345
I0826 16:28:31.932816 25446 solver.cpp:259]     Train net output #0: center_loss = 192.469 (* 0.008 = 1.53975 loss)
I0826 16:28:31.932822 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.5637 (* 1 = 4.5637 loss)
I0826 16:28:31.932826 25446 sgd_solver.cpp:138] Iteration 17790, lr = 0.0001
I0826 16:28:33.991766 25446 solver.cpp:243] Iteration 17800, loss = 6.08407
I0826 16:28:33.991900 25446 solver.cpp:259]     Train net output #0: center_loss = 178.204 (* 0.008 = 1.42564 loss)
I0826 16:28:33.991907 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65844 (* 1 = 4.65844 loss)
I0826 16:28:33.991910 25446 sgd_solver.cpp:138] Iteration 17800, lr = 0.0001
I0826 16:28:36.221562 25446 solver.cpp:243] Iteration 17810, loss = 7.12822
I0826 16:28:36.221602 25446 solver.cpp:259]     Train net output #0: center_loss = 180.858 (* 0.008 = 1.44686 loss)
I0826 16:28:36.221608 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.68136 (* 1 = 5.68136 loss)
I0826 16:28:36.221613 25446 sgd_solver.cpp:138] Iteration 17810, lr = 0.0001
I0826 16:28:38.324111 25446 solver.cpp:243] Iteration 17820, loss = 6.20675
I0826 16:28:38.324137 25446 solver.cpp:259]     Train net output #0: center_loss = 197.124 (* 0.008 = 1.57699 loss)
I0826 16:28:38.324143 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.62976 (* 1 = 4.62976 loss)
I0826 16:28:38.324148 25446 sgd_solver.cpp:138] Iteration 17820, lr = 0.0001
I0826 16:28:40.421298 25446 solver.cpp:243] Iteration 17830, loss = 6.20111
I0826 16:28:40.421322 25446 solver.cpp:259]     Train net output #0: center_loss = 182.456 (* 0.008 = 1.45965 loss)
I0826 16:28:40.421329 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.74145 (* 1 = 4.74145 loss)
I0826 16:28:40.421332 25446 sgd_solver.cpp:138] Iteration 17830, lr = 0.0001
I0826 16:28:42.485702 25446 solver.cpp:243] Iteration 17840, loss = 5.91622
I0826 16:28:42.485741 25446 solver.cpp:259]     Train net output #0: center_loss = 219.455 (* 0.008 = 1.75564 loss)
I0826 16:28:42.485747 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.16058 (* 1 = 4.16058 loss)
I0826 16:28:42.485751 25446 sgd_solver.cpp:138] Iteration 17840, lr = 0.0001
I0826 16:28:44.545848 25446 solver.cpp:243] Iteration 17850, loss = 6.186
I0826 16:28:44.545887 25446 solver.cpp:259]     Train net output #0: center_loss = 166.79 (* 0.008 = 1.33432 loss)
I0826 16:28:44.545893 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.85168 (* 1 = 4.85168 loss)
I0826 16:28:44.545897 25446 sgd_solver.cpp:138] Iteration 17850, lr = 0.0001
I0826 16:28:46.608146 25446 solver.cpp:243] Iteration 17860, loss = 5.77915
I0826 16:28:46.608186 25446 solver.cpp:259]     Train net output #0: center_loss = 180.16 (* 0.008 = 1.44128 loss)
I0826 16:28:46.608191 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.33786 (* 1 = 4.33786 loss)
I0826 16:28:46.608196 25446 sgd_solver.cpp:138] Iteration 17860, lr = 0.0001
I0826 16:28:48.668748 25446 solver.cpp:243] Iteration 17870, loss = 6.28086
I0826 16:28:48.668773 25446 solver.cpp:259]     Train net output #0: center_loss = 181.948 (* 0.008 = 1.45558 loss)
I0826 16:28:48.668779 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82527 (* 1 = 4.82527 loss)
I0826 16:28:48.668783 25446 sgd_solver.cpp:138] Iteration 17870, lr = 0.0001
I0826 16:28:50.728305 25446 solver.cpp:243] Iteration 17880, loss = 6.72987
I0826 16:28:50.728330 25446 solver.cpp:259]     Train net output #0: center_loss = 176.289 (* 0.008 = 1.41031 loss)
I0826 16:28:50.728336 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.31956 (* 1 = 5.31956 loss)
I0826 16:28:50.728340 25446 sgd_solver.cpp:138] Iteration 17880, lr = 0.0001
I0826 16:28:52.787926 25446 solver.cpp:243] Iteration 17890, loss = 5.34121
I0826 16:28:52.787966 25446 solver.cpp:259]     Train net output #0: center_loss = 193.67 (* 0.008 = 1.54936 loss)
I0826 16:28:52.787971 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.79185 (* 1 = 3.79185 loss)
I0826 16:28:52.787976 25446 sgd_solver.cpp:138] Iteration 17890, lr = 0.0001
I0826 16:28:54.845657 25446 solver.cpp:243] Iteration 17900, loss = 6.93515
I0826 16:28:54.845680 25446 solver.cpp:259]     Train net output #0: center_loss = 192.288 (* 0.008 = 1.5383 loss)
I0826 16:28:54.845685 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.39684 (* 1 = 5.39684 loss)
I0826 16:28:54.845690 25446 sgd_solver.cpp:138] Iteration 17900, lr = 0.0001
I0826 16:28:56.903759 25446 solver.cpp:243] Iteration 17910, loss = 5.79439
I0826 16:28:56.903798 25446 solver.cpp:259]     Train net output #0: center_loss = 216.715 (* 0.008 = 1.73372 loss)
I0826 16:28:56.903805 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.06067 (* 1 = 4.06067 loss)
I0826 16:28:56.903808 25446 sgd_solver.cpp:138] Iteration 17910, lr = 0.0001
I0826 16:28:58.964226 25446 solver.cpp:243] Iteration 17920, loss = 7.2423
I0826 16:28:58.964264 25446 solver.cpp:259]     Train net output #0: center_loss = 178.477 (* 0.008 = 1.42782 loss)
I0826 16:28:58.964272 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.81448 (* 1 = 5.81448 loss)
I0826 16:28:58.964274 25446 sgd_solver.cpp:138] Iteration 17920, lr = 0.0001
I0826 16:29:01.026582 25446 solver.cpp:243] Iteration 17930, loss = 6.23658
I0826 16:29:01.026607 25446 solver.cpp:259]     Train net output #0: center_loss = 179.656 (* 0.008 = 1.43725 loss)
I0826 16:29:01.026613 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79933 (* 1 = 4.79933 loss)
I0826 16:29:01.026616 25446 sgd_solver.cpp:138] Iteration 17930, lr = 0.0001
I0826 16:29:03.084460 25446 solver.cpp:243] Iteration 17940, loss = 6.22241
I0826 16:29:03.084484 25446 solver.cpp:259]     Train net output #0: center_loss = 218.028 (* 0.008 = 1.74423 loss)
I0826 16:29:03.084491 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47819 (* 1 = 4.47819 loss)
I0826 16:29:03.084494 25446 sgd_solver.cpp:138] Iteration 17940, lr = 0.0001
I0826 16:29:05.143775 25446 solver.cpp:243] Iteration 17950, loss = 6.36357
I0826 16:29:05.143908 25446 solver.cpp:259]     Train net output #0: center_loss = 196.519 (* 0.008 = 1.57215 loss)
I0826 16:29:05.143929 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79142 (* 1 = 4.79142 loss)
I0826 16:29:05.143932 25446 sgd_solver.cpp:138] Iteration 17950, lr = 0.0001
I0826 16:29:07.204167 25446 solver.cpp:243] Iteration 17960, loss = 6.71514
I0826 16:29:07.204191 25446 solver.cpp:259]     Train net output #0: center_loss = 173.603 (* 0.008 = 1.38883 loss)
I0826 16:29:07.204197 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.32632 (* 1 = 5.32632 loss)
I0826 16:29:07.204201 25446 sgd_solver.cpp:138] Iteration 17960, lr = 0.0001
I0826 16:29:09.265585 25446 solver.cpp:243] Iteration 17970, loss = 7.42457
I0826 16:29:09.265609 25446 solver.cpp:259]     Train net output #0: center_loss = 153.694 (* 0.008 = 1.22955 loss)
I0826 16:29:09.265615 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.19502 (* 1 = 6.19502 loss)
I0826 16:29:09.265619 25446 sgd_solver.cpp:138] Iteration 17970, lr = 0.0001
I0826 16:29:11.327837 25446 solver.cpp:243] Iteration 17980, loss = 6.43771
I0826 16:29:11.327862 25446 solver.cpp:259]     Train net output #0: center_loss = 199.145 (* 0.008 = 1.59316 loss)
I0826 16:29:11.327867 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.84455 (* 1 = 4.84455 loss)
I0826 16:29:11.327872 25446 sgd_solver.cpp:138] Iteration 17980, lr = 0.0001
I0826 16:29:13.389614 25446 solver.cpp:243] Iteration 17990, loss = 6.19739
I0826 16:29:13.389638 25446 solver.cpp:259]     Train net output #0: center_loss = 177.386 (* 0.008 = 1.41909 loss)
I0826 16:29:13.389644 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.7783 (* 1 = 4.7783 loss)
I0826 16:29:13.389649 25446 sgd_solver.cpp:138] Iteration 17990, lr = 0.0001
I0826 16:29:15.245347 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_18000.caffemodel
I0826 16:29:16.372218 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_18000.solverstate
I0826 16:29:16.719673 25446 solver.cpp:243] Iteration 18000, loss = 6.79877
I0826 16:29:16.719702 25446 solver.cpp:259]     Train net output #0: center_loss = 199.347 (* 0.008 = 1.59478 loss)
I0826 16:29:16.719708 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.20399 (* 1 = 5.20399 loss)
I0826 16:29:16.719712 25446 sgd_solver.cpp:138] Iteration 18000, lr = 0.0001
I0826 16:29:18.776032 25446 solver.cpp:243] Iteration 18010, loss = 6.71214
I0826 16:29:18.776055 25446 solver.cpp:259]     Train net output #0: center_loss = 200.163 (* 0.008 = 1.60131 loss)
I0826 16:29:18.776062 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.11083 (* 1 = 5.11083 loss)
I0826 16:29:18.776065 25446 sgd_solver.cpp:138] Iteration 18010, lr = 0.0001
I0826 16:29:20.833155 25446 solver.cpp:243] Iteration 18020, loss = 6.62183
I0826 16:29:20.833195 25446 solver.cpp:259]     Train net output #0: center_loss = 192.44 (* 0.008 = 1.53952 loss)
I0826 16:29:20.833202 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.08231 (* 1 = 5.08231 loss)
I0826 16:29:20.833205 25446 sgd_solver.cpp:138] Iteration 18020, lr = 0.0001
I0826 16:29:22.897245 25446 solver.cpp:243] Iteration 18030, loss = 6.09458
I0826 16:29:22.897301 25446 solver.cpp:259]     Train net output #0: center_loss = 206.046 (* 0.008 = 1.64837 loss)
I0826 16:29:22.897320 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.44622 (* 1 = 4.44622 loss)
I0826 16:29:22.897325 25446 sgd_solver.cpp:138] Iteration 18030, lr = 0.0001
I0826 16:29:24.957437 25446 solver.cpp:243] Iteration 18040, loss = 6.25587
I0826 16:29:24.957474 25446 solver.cpp:259]     Train net output #0: center_loss = 204.622 (* 0.008 = 1.63697 loss)
I0826 16:29:24.957480 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.61889 (* 1 = 4.61889 loss)
I0826 16:29:24.957484 25446 sgd_solver.cpp:138] Iteration 18040, lr = 0.0001
I0826 16:29:27.016705 25446 solver.cpp:243] Iteration 18050, loss = 6.58053
I0826 16:29:27.016727 25446 solver.cpp:259]     Train net output #0: center_loss = 181.973 (* 0.008 = 1.45579 loss)
I0826 16:29:27.016774 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.12475 (* 1 = 5.12475 loss)
I0826 16:29:27.016779 25446 sgd_solver.cpp:138] Iteration 18050, lr = 0.0001
I0826 16:29:29.076581 25446 solver.cpp:243] Iteration 18060, loss = 6.29784
I0826 16:29:29.076619 25446 solver.cpp:259]     Train net output #0: center_loss = 178.899 (* 0.008 = 1.43119 loss)
I0826 16:29:29.076627 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.86665 (* 1 = 4.86665 loss)
I0826 16:29:29.076629 25446 sgd_solver.cpp:138] Iteration 18060, lr = 0.0001
I0826 16:29:31.136883 25446 solver.cpp:243] Iteration 18070, loss = 6.1171
I0826 16:29:31.136909 25446 solver.cpp:259]     Train net output #0: center_loss = 201.53 (* 0.008 = 1.61224 loss)
I0826 16:29:31.136914 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50486 (* 1 = 4.50486 loss)
I0826 16:29:31.136919 25446 sgd_solver.cpp:138] Iteration 18070, lr = 0.0001
I0826 16:29:33.196491 25446 solver.cpp:243] Iteration 18080, loss = 6.05611
I0826 16:29:33.196514 25446 solver.cpp:259]     Train net output #0: center_loss = 200.848 (* 0.008 = 1.60678 loss)
I0826 16:29:33.196521 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.44933 (* 1 = 4.44933 loss)
I0826 16:29:33.196524 25446 sgd_solver.cpp:138] Iteration 18080, lr = 0.0001
I0826 16:29:35.254150 25446 solver.cpp:243] Iteration 18090, loss = 6.18897
I0826 16:29:35.254266 25446 solver.cpp:259]     Train net output #0: center_loss = 221.956 (* 0.008 = 1.77565 loss)
I0826 16:29:35.254274 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.41333 (* 1 = 4.41333 loss)
I0826 16:29:35.254293 25446 sgd_solver.cpp:138] Iteration 18090, lr = 0.0001
I0826 16:29:37.316017 25446 solver.cpp:243] Iteration 18100, loss = 5.60843
I0826 16:29:37.316041 25446 solver.cpp:259]     Train net output #0: center_loss = 201.975 (* 0.008 = 1.6158 loss)
I0826 16:29:37.316047 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.99263 (* 1 = 3.99263 loss)
I0826 16:29:37.316051 25446 sgd_solver.cpp:138] Iteration 18100, lr = 0.0001
I0826 16:29:39.378898 25446 solver.cpp:243] Iteration 18110, loss = 6.44294
I0826 16:29:39.378923 25446 solver.cpp:259]     Train net output #0: center_loss = 176.71 (* 0.008 = 1.41368 loss)
I0826 16:29:39.378929 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02926 (* 1 = 5.02926 loss)
I0826 16:29:39.378933 25446 sgd_solver.cpp:138] Iteration 18110, lr = 0.0001
I0826 16:29:41.438000 25446 solver.cpp:243] Iteration 18120, loss = 6.52099
I0826 16:29:41.438038 25446 solver.cpp:259]     Train net output #0: center_loss = 179.688 (* 0.008 = 1.4375 loss)
I0826 16:29:41.438045 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.08349 (* 1 = 5.08349 loss)
I0826 16:29:41.438050 25446 sgd_solver.cpp:138] Iteration 18120, lr = 0.0001
I0826 16:29:43.493680 25446 solver.cpp:243] Iteration 18130, loss = 6.31475
I0826 16:29:43.493705 25446 solver.cpp:259]     Train net output #0: center_loss = 176.296 (* 0.008 = 1.41037 loss)
I0826 16:29:43.493710 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.90438 (* 1 = 4.90438 loss)
I0826 16:29:43.493715 25446 sgd_solver.cpp:138] Iteration 18130, lr = 0.0001
I0826 16:29:45.554299 25446 solver.cpp:243] Iteration 18140, loss = 6.09972
I0826 16:29:45.554323 25446 solver.cpp:259]     Train net output #0: center_loss = 192.079 (* 0.008 = 1.53663 loss)
I0826 16:29:45.554329 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.56309 (* 1 = 4.56309 loss)
I0826 16:29:45.554333 25446 sgd_solver.cpp:138] Iteration 18140, lr = 0.0001
I0826 16:29:47.610836 25446 solver.cpp:243] Iteration 18150, loss = 6.80588
I0826 16:29:47.610859 25446 solver.cpp:259]     Train net output #0: center_loss = 173.609 (* 0.008 = 1.38887 loss)
I0826 16:29:47.610865 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.41701 (* 1 = 5.41701 loss)
I0826 16:29:47.610869 25446 sgd_solver.cpp:138] Iteration 18150, lr = 0.0001
I0826 16:29:49.671522 25446 solver.cpp:243] Iteration 18160, loss = 6.01811
I0826 16:29:49.671547 25446 solver.cpp:259]     Train net output #0: center_loss = 195.213 (* 0.008 = 1.56171 loss)
I0826 16:29:49.671553 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.45641 (* 1 = 4.45641 loss)
I0826 16:29:49.671557 25446 sgd_solver.cpp:138] Iteration 18160, lr = 0.0001
I0826 16:29:51.732354 25446 solver.cpp:243] Iteration 18170, loss = 6.34993
I0826 16:29:51.732379 25446 solver.cpp:259]     Train net output #0: center_loss = 195.613 (* 0.008 = 1.5649 loss)
I0826 16:29:51.732385 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.78503 (* 1 = 4.78503 loss)
I0826 16:29:51.732389 25446 sgd_solver.cpp:138] Iteration 18170, lr = 0.0001
I0826 16:29:53.788409 25446 solver.cpp:243] Iteration 18180, loss = 6.65247
I0826 16:29:53.788450 25446 solver.cpp:259]     Train net output #0: center_loss = 194.614 (* 0.008 = 1.55691 loss)
I0826 16:29:53.788456 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.09556 (* 1 = 5.09556 loss)
I0826 16:29:53.788460 25446 sgd_solver.cpp:138] Iteration 18180, lr = 0.0001
I0826 16:29:55.847921 25446 solver.cpp:243] Iteration 18190, loss = 6.4616
I0826 16:29:55.847944 25446 solver.cpp:259]     Train net output #0: center_loss = 190.403 (* 0.008 = 1.52322 loss)
I0826 16:29:55.847950 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.93837 (* 1 = 4.93837 loss)
I0826 16:29:55.847954 25446 sgd_solver.cpp:138] Iteration 18190, lr = 0.0001
I0826 16:29:57.908594 25446 solver.cpp:243] Iteration 18200, loss = 6.10812
I0826 16:29:57.908619 25446 solver.cpp:259]     Train net output #0: center_loss = 227.095 (* 0.008 = 1.81676 loss)
I0826 16:29:57.908625 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29136 (* 1 = 4.29136 loss)
I0826 16:29:57.908629 25446 sgd_solver.cpp:138] Iteration 18200, lr = 0.0001
I0826 16:29:59.963552 25446 solver.cpp:243] Iteration 18210, loss = 7.22608
I0826 16:29:59.963591 25446 solver.cpp:259]     Train net output #0: center_loss = 178.036 (* 0.008 = 1.42429 loss)
I0826 16:29:59.963598 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.80179 (* 1 = 5.80179 loss)
I0826 16:29:59.963600 25446 sgd_solver.cpp:138] Iteration 18210, lr = 0.0001
I0826 16:30:02.026023 25446 solver.cpp:243] Iteration 18220, loss = 6.16313
I0826 16:30:02.026046 25446 solver.cpp:259]     Train net output #0: center_loss = 207.811 (* 0.008 = 1.66249 loss)
I0826 16:30:02.026052 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50064 (* 1 = 4.50064 loss)
I0826 16:30:02.026057 25446 sgd_solver.cpp:138] Iteration 18220, lr = 0.0001
I0826 16:30:04.084448 25446 solver.cpp:243] Iteration 18230, loss = 6.18107
I0826 16:30:04.084472 25446 solver.cpp:259]     Train net output #0: center_loss = 199.34 (* 0.008 = 1.59472 loss)
I0826 16:30:04.084478 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.58635 (* 1 = 4.58635 loss)
I0826 16:30:04.084482 25446 sgd_solver.cpp:138] Iteration 18230, lr = 0.0001
I0826 16:30:06.146342 25446 solver.cpp:243] Iteration 18240, loss = 7.46609
I0826 16:30:06.146454 25446 solver.cpp:259]     Train net output #0: center_loss = 166.718 (* 0.008 = 1.33375 loss)
I0826 16:30:06.146474 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.13234 (* 1 = 6.13234 loss)
I0826 16:30:06.146478 25446 sgd_solver.cpp:138] Iteration 18240, lr = 0.0001
I0826 16:30:08.210841 25446 solver.cpp:243] Iteration 18250, loss = 5.32873
I0826 16:30:08.210882 25446 solver.cpp:259]     Train net output #0: center_loss = 195.824 (* 0.008 = 1.56659 loss)
I0826 16:30:08.210888 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.76214 (* 1 = 3.76214 loss)
I0826 16:30:08.210892 25446 sgd_solver.cpp:138] Iteration 18250, lr = 0.0001
I0826 16:30:10.436175 25446 solver.cpp:243] Iteration 18260, loss = 5.4099
I0826 16:30:10.436216 25446 solver.cpp:259]     Train net output #0: center_loss = 226.043 (* 0.008 = 1.80834 loss)
I0826 16:30:10.436223 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.60156 (* 1 = 3.60156 loss)
I0826 16:30:10.436228 25446 sgd_solver.cpp:138] Iteration 18260, lr = 0.0001
I0826 16:30:12.527210 25446 solver.cpp:243] Iteration 18270, loss = 7.59161
I0826 16:30:12.527235 25446 solver.cpp:259]     Train net output #0: center_loss = 193.492 (* 0.008 = 1.54793 loss)
I0826 16:30:12.527241 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.04368 (* 1 = 6.04368 loss)
I0826 16:30:12.527246 25446 sgd_solver.cpp:138] Iteration 18270, lr = 0.0001
I0826 16:30:14.638456 25446 solver.cpp:243] Iteration 18280, loss = 6.68349
I0826 16:30:14.638480 25446 solver.cpp:259]     Train net output #0: center_loss = 177.491 (* 0.008 = 1.41993 loss)
I0826 16:30:14.638501 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.26356 (* 1 = 5.26356 loss)
I0826 16:30:14.638505 25446 sgd_solver.cpp:138] Iteration 18280, lr = 0.0001
I0826 16:30:16.702469 25446 solver.cpp:243] Iteration 18290, loss = 7.39104
I0826 16:30:16.702494 25446 solver.cpp:259]     Train net output #0: center_loss = 183.23 (* 0.008 = 1.46584 loss)
I0826 16:30:16.702502 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.9252 (* 1 = 5.9252 loss)
I0826 16:30:16.702504 25446 sgd_solver.cpp:138] Iteration 18290, lr = 0.0001
I0826 16:30:18.760567 25446 solver.cpp:243] Iteration 18300, loss = 5.27188
I0826 16:30:18.760607 25446 solver.cpp:259]     Train net output #0: center_loss = 206.882 (* 0.008 = 1.65506 loss)
I0826 16:30:18.760613 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.61682 (* 1 = 3.61682 loss)
I0826 16:30:18.760619 25446 sgd_solver.cpp:138] Iteration 18300, lr = 0.0001
I0826 16:30:20.818434 25446 solver.cpp:243] Iteration 18310, loss = 6.87974
I0826 16:30:20.818473 25446 solver.cpp:259]     Train net output #0: center_loss = 197.731 (* 0.008 = 1.58185 loss)
I0826 16:30:20.818480 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.29789 (* 1 = 5.29789 loss)
I0826 16:30:20.818483 25446 sgd_solver.cpp:138] Iteration 18310, lr = 0.0001
I0826 16:30:22.960165 25446 solver.cpp:243] Iteration 18320, loss = 6.70885
I0826 16:30:22.960204 25446 solver.cpp:259]     Train net output #0: center_loss = 172.943 (* 0.008 = 1.38355 loss)
I0826 16:30:22.960211 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.3253 (* 1 = 5.3253 loss)
I0826 16:30:22.960216 25446 sgd_solver.cpp:138] Iteration 18320, lr = 0.0001
I0826 16:30:25.104143 25446 solver.cpp:243] Iteration 18330, loss = 6.47249
I0826 16:30:25.104167 25446 solver.cpp:259]     Train net output #0: center_loss = 198.254 (* 0.008 = 1.58603 loss)
I0826 16:30:25.104173 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.88646 (* 1 = 4.88646 loss)
I0826 16:30:25.104177 25446 sgd_solver.cpp:138] Iteration 18330, lr = 0.0001
I0826 16:30:27.376241 25446 solver.cpp:243] Iteration 18340, loss = 6.61481
I0826 16:30:27.376282 25446 solver.cpp:259]     Train net output #0: center_loss = 201.927 (* 0.008 = 1.61541 loss)
I0826 16:30:27.376288 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.99939 (* 1 = 4.99939 loss)
I0826 16:30:27.376292 25446 sgd_solver.cpp:138] Iteration 18340, lr = 0.0001
I0826 16:30:29.566169 25446 solver.cpp:243] Iteration 18350, loss = 7.26786
I0826 16:30:29.566207 25446 solver.cpp:259]     Train net output #0: center_loss = 164.745 (* 0.008 = 1.31796 loss)
I0826 16:30:29.566215 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.9499 (* 1 = 5.9499 loss)
I0826 16:30:29.566217 25446 sgd_solver.cpp:138] Iteration 18350, lr = 0.0001
I0826 16:30:31.721771 25446 solver.cpp:243] Iteration 18360, loss = 6.39612
I0826 16:30:31.721794 25446 solver.cpp:259]     Train net output #0: center_loss = 187.94 (* 0.008 = 1.50352 loss)
I0826 16:30:31.721801 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.8926 (* 1 = 4.8926 loss)
I0826 16:30:31.721805 25446 sgd_solver.cpp:138] Iteration 18360, lr = 0.0001
I0826 16:30:33.781891 25446 solver.cpp:243] Iteration 18370, loss = 6.46755
I0826 16:30:33.781916 25446 solver.cpp:259]     Train net output #0: center_loss = 188.799 (* 0.008 = 1.51039 loss)
I0826 16:30:33.781922 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.95716 (* 1 = 4.95716 loss)
I0826 16:30:33.781926 25446 sgd_solver.cpp:138] Iteration 18370, lr = 0.0001
I0826 16:30:35.841588 25446 solver.cpp:243] Iteration 18380, loss = 6.15147
I0826 16:30:35.841614 25446 solver.cpp:259]     Train net output #0: center_loss = 184.581 (* 0.008 = 1.47665 loss)
I0826 16:30:35.841619 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.67482 (* 1 = 4.67482 loss)
I0826 16:30:35.841624 25446 sgd_solver.cpp:138] Iteration 18380, lr = 0.0001
I0826 16:30:37.902140 25446 solver.cpp:243] Iteration 18390, loss = 6.15905
I0826 16:30:37.902268 25446 solver.cpp:259]     Train net output #0: center_loss = 181.949 (* 0.008 = 1.4556 loss)
I0826 16:30:37.902276 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70346 (* 1 = 4.70346 loss)
I0826 16:30:37.902293 25446 sgd_solver.cpp:138] Iteration 18390, lr = 0.0001
I0826 16:30:39.960363 25446 solver.cpp:243] Iteration 18400, loss = 6.50379
I0826 16:30:39.960386 25446 solver.cpp:259]     Train net output #0: center_loss = 181.148 (* 0.008 = 1.44918 loss)
I0826 16:30:39.960392 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.05461 (* 1 = 5.05461 loss)
I0826 16:30:39.960397 25446 sgd_solver.cpp:138] Iteration 18400, lr = 0.0001
I0826 16:30:42.021857 25446 solver.cpp:243] Iteration 18410, loss = 5.61761
I0826 16:30:42.021881 25446 solver.cpp:259]     Train net output #0: center_loss = 215.949 (* 0.008 = 1.72759 loss)
I0826 16:30:42.021888 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.89001 (* 1 = 3.89001 loss)
I0826 16:30:42.021891 25446 sgd_solver.cpp:138] Iteration 18410, lr = 0.0001
I0826 16:30:44.082772 25446 solver.cpp:243] Iteration 18420, loss = 6.33891
I0826 16:30:44.082813 25446 solver.cpp:259]     Train net output #0: center_loss = 201.768 (* 0.008 = 1.61414 loss)
I0826 16:30:44.082819 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.72477 (* 1 = 4.72477 loss)
I0826 16:30:44.082823 25446 sgd_solver.cpp:138] Iteration 18420, lr = 0.0001
I0826 16:30:46.143998 25446 solver.cpp:243] Iteration 18430, loss = 6.29455
I0826 16:30:46.144037 25446 solver.cpp:259]     Train net output #0: center_loss = 193.942 (* 0.008 = 1.55154 loss)
I0826 16:30:46.144043 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.74301 (* 1 = 4.74301 loss)
I0826 16:30:46.144047 25446 sgd_solver.cpp:138] Iteration 18430, lr = 0.0001
I0826 16:30:48.204368 25446 solver.cpp:243] Iteration 18440, loss = 5.83497
I0826 16:30:48.204408 25446 solver.cpp:259]     Train net output #0: center_loss = 191.832 (* 0.008 = 1.53466 loss)
I0826 16:30:48.204414 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.30031 (* 1 = 4.30031 loss)
I0826 16:30:48.204418 25446 sgd_solver.cpp:138] Iteration 18440, lr = 0.0001
I0826 16:30:50.262545 25446 solver.cpp:243] Iteration 18450, loss = 5.95775
I0826 16:30:50.262569 25446 solver.cpp:259]     Train net output #0: center_loss = 205.107 (* 0.008 = 1.64086 loss)
I0826 16:30:50.262575 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.31689 (* 1 = 4.31689 loss)
I0826 16:30:50.262578 25446 sgd_solver.cpp:138] Iteration 18450, lr = 0.0001
I0826 16:30:52.323567 25446 solver.cpp:243] Iteration 18460, loss = 6.62759
I0826 16:30:52.323607 25446 solver.cpp:259]     Train net output #0: center_loss = 161.457 (* 0.008 = 1.29166 loss)
I0826 16:30:52.323613 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.33593 (* 1 = 5.33593 loss)
I0826 16:30:52.323616 25446 sgd_solver.cpp:138] Iteration 18460, lr = 0.0001
I0826 16:30:54.381184 25446 solver.cpp:243] Iteration 18470, loss = 6.34988
I0826 16:30:54.381209 25446 solver.cpp:259]     Train net output #0: center_loss = 186.662 (* 0.008 = 1.4933 loss)
I0826 16:30:54.381215 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.85659 (* 1 = 4.85659 loss)
I0826 16:30:54.381219 25446 sgd_solver.cpp:138] Iteration 18470, lr = 0.0001
I0826 16:30:56.441574 25446 solver.cpp:243] Iteration 18480, loss = 5.48276
I0826 16:30:56.441599 25446 solver.cpp:259]     Train net output #0: center_loss = 227.603 (* 0.008 = 1.82082 loss)
I0826 16:30:56.441606 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.66194 (* 1 = 3.66194 loss)
I0826 16:30:56.441609 25446 sgd_solver.cpp:138] Iteration 18480, lr = 0.0001
I0826 16:30:58.498255 25446 solver.cpp:243] Iteration 18490, loss = 5.91494
I0826 16:30:58.498278 25446 solver.cpp:259]     Train net output #0: center_loss = 217.22 (* 0.008 = 1.73776 loss)
I0826 16:30:58.498284 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.17718 (* 1 = 4.17718 loss)
I0826 16:30:58.498288 25446 sgd_solver.cpp:138] Iteration 18490, lr = 0.0001
I0826 16:31:00.561769 25446 solver.cpp:243] Iteration 18500, loss = 6.69752
I0826 16:31:00.561794 25446 solver.cpp:259]     Train net output #0: center_loss = 179.911 (* 0.008 = 1.43929 loss)
I0826 16:31:00.561800 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.25823 (* 1 = 5.25823 loss)
I0826 16:31:00.561803 25446 sgd_solver.cpp:138] Iteration 18500, lr = 0.0001
I0826 16:31:02.624003 25446 solver.cpp:243] Iteration 18510, loss = 6.3573
I0826 16:31:02.624028 25446 solver.cpp:259]     Train net output #0: center_loss = 194.878 (* 0.008 = 1.55903 loss)
I0826 16:31:02.624034 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79827 (* 1 = 4.79827 loss)
I0826 16:31:02.624038 25446 sgd_solver.cpp:138] Iteration 18510, lr = 0.0001
I0826 16:31:04.682832 25446 solver.cpp:243] Iteration 18520, loss = 7.61914
I0826 16:31:04.682854 25446 solver.cpp:259]     Train net output #0: center_loss = 147.163 (* 0.008 = 1.1773 loss)
I0826 16:31:04.682860 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.44184 (* 1 = 6.44184 loss)
I0826 16:31:04.682864 25446 sgd_solver.cpp:138] Iteration 18520, lr = 0.0001
I0826 16:31:06.744264 25446 solver.cpp:243] Iteration 18530, loss = 6.06759
I0826 16:31:06.744304 25446 solver.cpp:259]     Train net output #0: center_loss = 198.459 (* 0.008 = 1.58767 loss)
I0826 16:31:06.744310 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47991 (* 1 = 4.47991 loss)
I0826 16:31:06.744314 25446 sgd_solver.cpp:138] Iteration 18530, lr = 0.0001
I0826 16:31:08.802098 25446 solver.cpp:243] Iteration 18540, loss = 7.4536
I0826 16:31:08.802214 25446 solver.cpp:259]     Train net output #0: center_loss = 189.789 (* 0.008 = 1.51831 loss)
I0826 16:31:08.802222 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.93529 (* 1 = 5.93529 loss)
I0826 16:31:08.802225 25446 sgd_solver.cpp:138] Iteration 18540, lr = 0.0001
I0826 16:31:10.863211 25446 solver.cpp:243] Iteration 18550, loss = 6.35821
I0826 16:31:10.863234 25446 solver.cpp:259]     Train net output #0: center_loss = 197.355 (* 0.008 = 1.57884 loss)
I0826 16:31:10.863240 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77937 (* 1 = 4.77937 loss)
I0826 16:31:10.863245 25446 sgd_solver.cpp:138] Iteration 18550, lr = 0.0001
I0826 16:31:12.920290 25446 solver.cpp:243] Iteration 18560, loss = 5.71089
I0826 16:31:12.920313 25446 solver.cpp:259]     Train net output #0: center_loss = 200.122 (* 0.008 = 1.60098 loss)
I0826 16:31:12.920320 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.10991 (* 1 = 4.10991 loss)
I0826 16:31:12.920323 25446 sgd_solver.cpp:138] Iteration 18560, lr = 0.0001
I0826 16:31:14.981343 25446 solver.cpp:243] Iteration 18570, loss = 5.57597
I0826 16:31:14.981367 25446 solver.cpp:259]     Train net output #0: center_loss = 209.399 (* 0.008 = 1.6752 loss)
I0826 16:31:14.981374 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.90077 (* 1 = 3.90077 loss)
I0826 16:31:14.981376 25446 sgd_solver.cpp:138] Iteration 18570, lr = 0.0001
I0826 16:31:17.040874 25446 solver.cpp:243] Iteration 18580, loss = 6.02329
I0826 16:31:17.040897 25446 solver.cpp:259]     Train net output #0: center_loss = 202.083 (* 0.008 = 1.61666 loss)
I0826 16:31:17.040904 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40663 (* 1 = 4.40663 loss)
I0826 16:31:17.040907 25446 sgd_solver.cpp:138] Iteration 18580, lr = 0.0001
I0826 16:31:19.100057 25446 solver.cpp:243] Iteration 18590, loss = 5.76295
I0826 16:31:19.100081 25446 solver.cpp:259]     Train net output #0: center_loss = 213.744 (* 0.008 = 1.70995 loss)
I0826 16:31:19.100088 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.053 (* 1 = 4.053 loss)
I0826 16:31:19.100091 25446 sgd_solver.cpp:138] Iteration 18590, lr = 0.0001
I0826 16:31:21.231783 25446 solver.cpp:243] Iteration 18600, loss = 5.89949
I0826 16:31:21.231808 25446 solver.cpp:259]     Train net output #0: center_loss = 201.027 (* 0.008 = 1.60821 loss)
I0826 16:31:21.231814 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29128 (* 1 = 4.29128 loss)
I0826 16:31:21.231819 25446 sgd_solver.cpp:138] Iteration 18600, lr = 0.0001
I0826 16:31:23.414237 25446 solver.cpp:243] Iteration 18610, loss = 6.13846
I0826 16:31:23.414263 25446 solver.cpp:259]     Train net output #0: center_loss = 203.988 (* 0.008 = 1.6319 loss)
I0826 16:31:23.414268 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50656 (* 1 = 4.50656 loss)
I0826 16:31:23.414273 25446 sgd_solver.cpp:138] Iteration 18610, lr = 0.0001
I0826 16:31:25.567041 25446 solver.cpp:243] Iteration 18620, loss = 7.36041
I0826 16:31:25.567066 25446 solver.cpp:259]     Train net output #0: center_loss = 181.422 (* 0.008 = 1.45137 loss)
I0826 16:31:25.567072 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.90904 (* 1 = 5.90904 loss)
I0826 16:31:25.567076 25446 sgd_solver.cpp:138] Iteration 18620, lr = 0.0001
I0826 16:31:27.627943 25446 solver.cpp:243] Iteration 18630, loss = 6.91752
I0826 16:31:27.627966 25446 solver.cpp:259]     Train net output #0: center_loss = 181.296 (* 0.008 = 1.45037 loss)
I0826 16:31:27.627972 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.46715 (* 1 = 5.46715 loss)
I0826 16:31:27.627976 25446 sgd_solver.cpp:138] Iteration 18630, lr = 0.0001
I0826 16:31:29.687563 25446 solver.cpp:243] Iteration 18640, loss = 5.36016
I0826 16:31:29.687588 25446 solver.cpp:259]     Train net output #0: center_loss = 214.187 (* 0.008 = 1.71349 loss)
I0826 16:31:29.687594 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.64667 (* 1 = 3.64667 loss)
I0826 16:31:29.687598 25446 sgd_solver.cpp:138] Iteration 18640, lr = 0.0001
I0826 16:31:31.748862 25446 solver.cpp:243] Iteration 18650, loss = 5.99648
I0826 16:31:31.748885 25446 solver.cpp:259]     Train net output #0: center_loss = 206.63 (* 0.008 = 1.65304 loss)
I0826 16:31:31.748893 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.34344 (* 1 = 4.34344 loss)
I0826 16:31:31.748896 25446 sgd_solver.cpp:138] Iteration 18650, lr = 0.0001
I0826 16:31:33.975244 25446 solver.cpp:243] Iteration 18660, loss = 6.89556
I0826 16:31:33.975268 25446 solver.cpp:259]     Train net output #0: center_loss = 179.405 (* 0.008 = 1.43524 loss)
I0826 16:31:33.975275 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.46033 (* 1 = 5.46033 loss)
I0826 16:31:33.975278 25446 sgd_solver.cpp:138] Iteration 18660, lr = 0.0001
I0826 16:31:36.116487 25446 solver.cpp:243] Iteration 18670, loss = 6.33516
I0826 16:31:36.116513 25446 solver.cpp:259]     Train net output #0: center_loss = 197.962 (* 0.008 = 1.5837 loss)
I0826 16:31:36.116518 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.75146 (* 1 = 4.75146 loss)
I0826 16:31:36.116523 25446 sgd_solver.cpp:138] Iteration 18670, lr = 0.0001
I0826 16:31:38.177814 25446 solver.cpp:243] Iteration 18680, loss = 6.17576
I0826 16:31:38.177839 25446 solver.cpp:259]     Train net output #0: center_loss = 191.47 (* 0.008 = 1.53176 loss)
I0826 16:31:38.177845 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.644 (* 1 = 4.644 loss)
I0826 16:31:38.177848 25446 sgd_solver.cpp:138] Iteration 18680, lr = 0.0001
I0826 16:31:40.295120 25446 solver.cpp:243] Iteration 18690, loss = 7.03185
I0826 16:31:40.295248 25446 solver.cpp:259]     Train net output #0: center_loss = 185.763 (* 0.008 = 1.4861 loss)
I0826 16:31:40.295255 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.54575 (* 1 = 5.54575 loss)
I0826 16:31:40.295260 25446 sgd_solver.cpp:138] Iteration 18690, lr = 0.0001
I0826 16:31:42.449571 25446 solver.cpp:243] Iteration 18700, loss = 7.51739
I0826 16:31:42.449611 25446 solver.cpp:259]     Train net output #0: center_loss = 156.469 (* 0.008 = 1.25176 loss)
I0826 16:31:42.449617 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.26564 (* 1 = 6.26564 loss)
I0826 16:31:42.449621 25446 sgd_solver.cpp:138] Iteration 18700, lr = 0.0001
I0826 16:31:44.577284 25446 solver.cpp:243] Iteration 18710, loss = 6.22219
I0826 16:31:44.577307 25446 solver.cpp:259]     Train net output #0: center_loss = 199.406 (* 0.008 = 1.59525 loss)
I0826 16:31:44.577313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.62695 (* 1 = 4.62695 loss)
I0826 16:31:44.577317 25446 sgd_solver.cpp:138] Iteration 18710, lr = 0.0001
I0826 16:31:46.719579 25446 solver.cpp:243] Iteration 18720, loss = 6.18915
I0826 16:31:46.719617 25446 solver.cpp:259]     Train net output #0: center_loss = 196.816 (* 0.008 = 1.57453 loss)
I0826 16:31:46.719624 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.61462 (* 1 = 4.61462 loss)
I0826 16:31:46.719627 25446 sgd_solver.cpp:138] Iteration 18720, lr = 0.0001
I0826 16:31:48.776034 25446 solver.cpp:243] Iteration 18730, loss = 6.85404
I0826 16:31:48.776058 25446 solver.cpp:259]     Train net output #0: center_loss = 191.9 (* 0.008 = 1.5352 loss)
I0826 16:31:48.776064 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.31884 (* 1 = 5.31884 loss)
I0826 16:31:48.776068 25446 sgd_solver.cpp:138] Iteration 18730, lr = 0.0001
I0826 16:31:50.835562 25446 solver.cpp:243] Iteration 18740, loss = 6.6313
I0826 16:31:50.835587 25446 solver.cpp:259]     Train net output #0: center_loss = 177.98 (* 0.008 = 1.42384 loss)
I0826 16:31:50.835593 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.20745 (* 1 = 5.20745 loss)
I0826 16:31:50.835597 25446 sgd_solver.cpp:138] Iteration 18740, lr = 0.0001
I0826 16:31:52.893779 25446 solver.cpp:243] Iteration 18750, loss = 6.76421
I0826 16:31:52.893802 25446 solver.cpp:259]     Train net output #0: center_loss = 189.877 (* 0.008 = 1.51901 loss)
I0826 16:31:52.893808 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.2452 (* 1 = 5.2452 loss)
I0826 16:31:52.893811 25446 sgd_solver.cpp:138] Iteration 18750, lr = 0.0001
I0826 16:31:54.951056 25446 solver.cpp:243] Iteration 18760, loss = 6.23081
I0826 16:31:54.951081 25446 solver.cpp:259]     Train net output #0: center_loss = 182.232 (* 0.008 = 1.45785 loss)
I0826 16:31:54.951086 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77296 (* 1 = 4.77296 loss)
I0826 16:31:54.951089 25446 sgd_solver.cpp:138] Iteration 18760, lr = 0.0001
I0826 16:31:57.013530 25446 solver.cpp:243] Iteration 18770, loss = 6.63078
I0826 16:31:57.013553 25446 solver.cpp:259]     Train net output #0: center_loss = 199.568 (* 0.008 = 1.59654 loss)
I0826 16:31:57.013559 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.03424 (* 1 = 5.03424 loss)
I0826 16:31:57.013563 25446 sgd_solver.cpp:138] Iteration 18770, lr = 0.0001
I0826 16:31:59.068117 25446 solver.cpp:243] Iteration 18780, loss = 6.39521
I0826 16:31:59.068141 25446 solver.cpp:259]     Train net output #0: center_loss = 182.83 (* 0.008 = 1.46264 loss)
I0826 16:31:59.068147 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.93257 (* 1 = 4.93257 loss)
I0826 16:31:59.068151 25446 sgd_solver.cpp:138] Iteration 18780, lr = 0.0001
I0826 16:32:01.303336 25446 solver.cpp:243] Iteration 18790, loss = 6.18647
I0826 16:32:01.303360 25446 solver.cpp:259]     Train net output #0: center_loss = 184.602 (* 0.008 = 1.47682 loss)
I0826 16:32:01.303366 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70965 (* 1 = 4.70965 loss)
I0826 16:32:01.303371 25446 sgd_solver.cpp:138] Iteration 18790, lr = 0.0001
I0826 16:32:03.567205 25446 solver.cpp:243] Iteration 18800, loss = 5.55966
I0826 16:32:03.567245 25446 solver.cpp:259]     Train net output #0: center_loss = 187.108 (* 0.008 = 1.49686 loss)
I0826 16:32:03.567250 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.0628 (* 1 = 4.0628 loss)
I0826 16:32:03.567255 25446 sgd_solver.cpp:138] Iteration 18800, lr = 0.0001
I0826 16:32:05.810523 25446 solver.cpp:243] Iteration 18810, loss = 5.30472
I0826 16:32:05.810549 25446 solver.cpp:259]     Train net output #0: center_loss = 213.108 (* 0.008 = 1.70486 loss)
I0826 16:32:05.810554 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.59986 (* 1 = 3.59986 loss)
I0826 16:32:05.810559 25446 sgd_solver.cpp:138] Iteration 18810, lr = 0.0001
I0826 16:32:07.983342 25446 solver.cpp:243] Iteration 18820, loss = 4.9496
I0826 16:32:07.983366 25446 solver.cpp:259]     Train net output #0: center_loss = 211.258 (* 0.008 = 1.69006 loss)
I0826 16:32:07.983372 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.25954 (* 1 = 3.25954 loss)
I0826 16:32:07.983376 25446 sgd_solver.cpp:138] Iteration 18820, lr = 0.0001
I0826 16:32:10.147938 25446 solver.cpp:243] Iteration 18830, loss = 6.44537
I0826 16:32:10.147963 25446 solver.cpp:259]     Train net output #0: center_loss = 180.077 (* 0.008 = 1.44062 loss)
I0826 16:32:10.147969 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.00476 (* 1 = 5.00476 loss)
I0826 16:32:10.147972 25446 sgd_solver.cpp:138] Iteration 18830, lr = 0.0001
I0826 16:32:12.204689 25446 solver.cpp:243] Iteration 18840, loss = 5.82702
I0826 16:32:12.204845 25446 solver.cpp:259]     Train net output #0: center_loss = 196.093 (* 0.008 = 1.56874 loss)
I0826 16:32:12.204854 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.25828 (* 1 = 4.25828 loss)
I0826 16:32:12.204870 25446 sgd_solver.cpp:138] Iteration 18840, lr = 0.0001
I0826 16:32:14.264748 25446 solver.cpp:243] Iteration 18850, loss = 7.14383
I0826 16:32:14.264775 25446 solver.cpp:259]     Train net output #0: center_loss = 181.792 (* 0.008 = 1.45433 loss)
I0826 16:32:14.264780 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.6895 (* 1 = 5.6895 loss)
I0826 16:32:14.264786 25446 sgd_solver.cpp:138] Iteration 18850, lr = 0.0001
I0826 16:32:16.370673 25446 solver.cpp:243] Iteration 18860, loss = 5.85591
I0826 16:32:16.370702 25446 solver.cpp:259]     Train net output #0: center_loss = 224.882 (* 0.008 = 1.79906 loss)
I0826 16:32:16.370707 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.05685 (* 1 = 4.05685 loss)
I0826 16:32:16.370712 25446 sgd_solver.cpp:138] Iteration 18860, lr = 0.0001
I0826 16:32:18.541200 25446 solver.cpp:243] Iteration 18870, loss = 6.44869
I0826 16:32:18.541226 25446 solver.cpp:259]     Train net output #0: center_loss = 202.032 (* 0.008 = 1.61625 loss)
I0826 16:32:18.541232 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.83244 (* 1 = 4.83244 loss)
I0826 16:32:18.541236 25446 sgd_solver.cpp:138] Iteration 18870, lr = 0.0001
I0826 16:32:20.638712 25446 solver.cpp:243] Iteration 18880, loss = 5.79835
I0826 16:32:20.638751 25446 solver.cpp:259]     Train net output #0: center_loss = 206.638 (* 0.008 = 1.65311 loss)
I0826 16:32:20.638756 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.14524 (* 1 = 4.14524 loss)
I0826 16:32:20.638773 25446 sgd_solver.cpp:138] Iteration 18880, lr = 0.0001
I0826 16:32:22.697971 25446 solver.cpp:243] Iteration 18890, loss = 6.52332
I0826 16:32:22.697998 25446 solver.cpp:259]     Train net output #0: center_loss = 187.509 (* 0.008 = 1.50007 loss)
I0826 16:32:22.698004 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02324 (* 1 = 5.02324 loss)
I0826 16:32:22.698007 25446 sgd_solver.cpp:138] Iteration 18890, lr = 0.0001
I0826 16:32:24.759007 25446 solver.cpp:243] Iteration 18900, loss = 6.30349
I0826 16:32:24.759032 25446 solver.cpp:259]     Train net output #0: center_loss = 185.128 (* 0.008 = 1.48102 loss)
I0826 16:32:24.759037 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82247 (* 1 = 4.82247 loss)
I0826 16:32:24.759042 25446 sgd_solver.cpp:138] Iteration 18900, lr = 0.0001
I0826 16:32:26.819095 25446 solver.cpp:243] Iteration 18910, loss = 6.65553
I0826 16:32:26.819120 25446 solver.cpp:259]     Train net output #0: center_loss = 178.974 (* 0.008 = 1.4318 loss)
I0826 16:32:26.819125 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.22373 (* 1 = 5.22373 loss)
I0826 16:32:26.819130 25446 sgd_solver.cpp:138] Iteration 18910, lr = 0.0001
I0826 16:32:28.876580 25446 solver.cpp:243] Iteration 18920, loss = 6.08918
I0826 16:32:28.876602 25446 solver.cpp:259]     Train net output #0: center_loss = 210.638 (* 0.008 = 1.6851 loss)
I0826 16:32:28.876608 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40408 (* 1 = 4.40408 loss)
I0826 16:32:28.876612 25446 sgd_solver.cpp:138] Iteration 18920, lr = 0.0001
I0826 16:32:30.938661 25446 solver.cpp:243] Iteration 18930, loss = 5.71947
I0826 16:32:30.938700 25446 solver.cpp:259]     Train net output #0: center_loss = 173.296 (* 0.008 = 1.38636 loss)
I0826 16:32:30.938706 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.3331 (* 1 = 4.3331 loss)
I0826 16:32:30.938710 25446 sgd_solver.cpp:138] Iteration 18930, lr = 0.0001
I0826 16:32:33.004245 25446 solver.cpp:243] Iteration 18940, loss = 6.94408
I0826 16:32:33.004269 25446 solver.cpp:259]     Train net output #0: center_loss = 196.177 (* 0.008 = 1.56942 loss)
I0826 16:32:33.004276 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.37466 (* 1 = 5.37466 loss)
I0826 16:32:33.004279 25446 sgd_solver.cpp:138] Iteration 18940, lr = 0.0001
I0826 16:32:35.063093 25446 solver.cpp:243] Iteration 18950, loss = 6.5977
I0826 16:32:35.063117 25446 solver.cpp:259]     Train net output #0: center_loss = 172.339 (* 0.008 = 1.37871 loss)
I0826 16:32:35.063123 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.21899 (* 1 = 5.21899 loss)
I0826 16:32:35.063127 25446 sgd_solver.cpp:138] Iteration 18950, lr = 0.0001
I0826 16:32:37.122367 25446 solver.cpp:243] Iteration 18960, loss = 5.62908
I0826 16:32:37.122391 25446 solver.cpp:259]     Train net output #0: center_loss = 195.555 (* 0.008 = 1.56444 loss)
I0826 16:32:37.122397 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.06464 (* 1 = 4.06464 loss)
I0826 16:32:37.122401 25446 sgd_solver.cpp:138] Iteration 18960, lr = 0.0001
I0826 16:32:39.186233 25446 solver.cpp:243] Iteration 18970, loss = 4.85895
I0826 16:32:39.186257 25446 solver.cpp:259]     Train net output #0: center_loss = 232.441 (* 0.008 = 1.85953 loss)
I0826 16:32:39.186264 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.99942 (* 1 = 2.99942 loss)
I0826 16:32:39.186269 25446 sgd_solver.cpp:138] Iteration 18970, lr = 0.0001
I0826 16:32:41.244050 25446 solver.cpp:243] Iteration 18980, loss = 6.18896
I0826 16:32:41.244073 25446 solver.cpp:259]     Train net output #0: center_loss = 208.788 (* 0.008 = 1.6703 loss)
I0826 16:32:41.244079 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.51865 (* 1 = 4.51865 loss)
I0826 16:32:41.244083 25446 sgd_solver.cpp:138] Iteration 18980, lr = 0.0001
I0826 16:32:43.302652 25446 solver.cpp:243] Iteration 18990, loss = 5.31911
I0826 16:32:43.302762 25446 solver.cpp:259]     Train net output #0: center_loss = 203.792 (* 0.008 = 1.63033 loss)
I0826 16:32:43.302770 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.68878 (* 1 = 3.68878 loss)
I0826 16:32:43.302788 25446 sgd_solver.cpp:138] Iteration 18990, lr = 0.0001
I0826 16:32:45.158177 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_19000.caffemodel
I0826 16:32:46.299721 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_19000.solverstate
I0826 16:32:46.626905 25446 solver.cpp:243] Iteration 19000, loss = 6.41403
I0826 16:32:46.626929 25446 solver.cpp:259]     Train net output #0: center_loss = 187.742 (* 0.008 = 1.50194 loss)
I0826 16:32:46.626935 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.91209 (* 1 = 4.91209 loss)
I0826 16:32:46.626940 25446 sgd_solver.cpp:138] Iteration 19000, lr = 0.0001
I0826 16:32:48.685690 25446 solver.cpp:243] Iteration 19010, loss = 6.50342
I0826 16:32:48.685714 25446 solver.cpp:259]     Train net output #0: center_loss = 188.321 (* 0.008 = 1.50657 loss)
I0826 16:32:48.685720 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.99686 (* 1 = 4.99686 loss)
I0826 16:32:48.685724 25446 sgd_solver.cpp:138] Iteration 19010, lr = 0.0001
I0826 16:32:50.746333 25446 solver.cpp:243] Iteration 19020, loss = 6.38108
I0826 16:32:50.746357 25446 solver.cpp:259]     Train net output #0: center_loss = 197.639 (* 0.008 = 1.58111 loss)
I0826 16:32:50.746363 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79997 (* 1 = 4.79997 loss)
I0826 16:32:50.746367 25446 sgd_solver.cpp:138] Iteration 19020, lr = 0.0001
I0826 16:32:52.803910 25446 solver.cpp:243] Iteration 19030, loss = 6.42098
I0826 16:32:52.803934 25446 solver.cpp:259]     Train net output #0: center_loss = 175.912 (* 0.008 = 1.4073 loss)
I0826 16:32:52.803941 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.01369 (* 1 = 5.01369 loss)
I0826 16:32:52.803943 25446 sgd_solver.cpp:138] Iteration 19030, lr = 0.0001
I0826 16:32:54.860258 25446 solver.cpp:243] Iteration 19040, loss = 6.93757
I0826 16:32:54.860281 25446 solver.cpp:259]     Train net output #0: center_loss = 197.994 (* 0.008 = 1.58395 loss)
I0826 16:32:54.860287 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.35362 (* 1 = 5.35362 loss)
I0826 16:32:54.860291 25446 sgd_solver.cpp:138] Iteration 19040, lr = 0.0001
I0826 16:32:56.919221 25446 solver.cpp:243] Iteration 19050, loss = 6.68938
I0826 16:32:56.919245 25446 solver.cpp:259]     Train net output #0: center_loss = 170.419 (* 0.008 = 1.36335 loss)
I0826 16:32:56.919251 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.32603 (* 1 = 5.32603 loss)
I0826 16:32:56.919255 25446 sgd_solver.cpp:138] Iteration 19050, lr = 0.0001
I0826 16:32:59.035874 25446 solver.cpp:243] Iteration 19060, loss = 5.93334
I0826 16:32:59.035902 25446 solver.cpp:259]     Train net output #0: center_loss = 218.685 (* 0.008 = 1.74948 loss)
I0826 16:32:59.035908 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.18387 (* 1 = 4.18387 loss)
I0826 16:32:59.035913 25446 sgd_solver.cpp:138] Iteration 19060, lr = 0.0001
I0826 16:33:01.280627 25446 solver.cpp:243] Iteration 19070, loss = 6.59128
I0826 16:33:01.280649 25446 solver.cpp:259]     Train net output #0: center_loss = 183.752 (* 0.008 = 1.47001 loss)
I0826 16:33:01.280656 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.12127 (* 1 = 5.12127 loss)
I0826 16:33:01.280659 25446 sgd_solver.cpp:138] Iteration 19070, lr = 0.0001
I0826 16:33:03.541559 25446 solver.cpp:243] Iteration 19080, loss = 5.27027
I0826 16:33:03.541582 25446 solver.cpp:259]     Train net output #0: center_loss = 216.509 (* 0.008 = 1.73207 loss)
I0826 16:33:03.541589 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.5382 (* 1 = 3.5382 loss)
I0826 16:33:03.541592 25446 sgd_solver.cpp:138] Iteration 19080, lr = 0.0001
I0826 16:33:05.667014 25446 solver.cpp:243] Iteration 19090, loss = 5.63892
I0826 16:33:05.667042 25446 solver.cpp:259]     Train net output #0: center_loss = 233.022 (* 0.008 = 1.86418 loss)
I0826 16:33:05.667073 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77474 (* 1 = 3.77474 loss)
I0826 16:33:05.667078 25446 sgd_solver.cpp:138] Iteration 19090, lr = 0.0001
I0826 16:33:07.835351 25446 solver.cpp:243] Iteration 19100, loss = 6.09643
I0826 16:33:07.835377 25446 solver.cpp:259]     Train net output #0: center_loss = 200.294 (* 0.008 = 1.60235 loss)
I0826 16:33:07.835382 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.49408 (* 1 = 4.49408 loss)
I0826 16:33:07.835387 25446 sgd_solver.cpp:138] Iteration 19100, lr = 0.0001
I0826 16:33:10.071557 25446 solver.cpp:243] Iteration 19110, loss = 5.70187
I0826 16:33:10.071583 25446 solver.cpp:259]     Train net output #0: center_loss = 210.221 (* 0.008 = 1.68177 loss)
I0826 16:33:10.071589 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.0201 (* 1 = 4.0201 loss)
I0826 16:33:10.071593 25446 sgd_solver.cpp:138] Iteration 19110, lr = 0.0001
I0826 16:33:12.157786 25446 solver.cpp:243] Iteration 19120, loss = 6.94605
I0826 16:33:12.157809 25446 solver.cpp:259]     Train net output #0: center_loss = 192.676 (* 0.008 = 1.54141 loss)
I0826 16:33:12.157815 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.40464 (* 1 = 5.40464 loss)
I0826 16:33:12.157819 25446 sgd_solver.cpp:138] Iteration 19120, lr = 0.0001
I0826 16:33:14.219547 25446 solver.cpp:243] Iteration 19130, loss = 6.77272
I0826 16:33:14.219691 25446 solver.cpp:259]     Train net output #0: center_loss = 190.545 (* 0.008 = 1.52436 loss)
I0826 16:33:14.219698 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.24835 (* 1 = 5.24835 loss)
I0826 16:33:14.219703 25446 sgd_solver.cpp:138] Iteration 19130, lr = 0.0001
I0826 16:33:16.279757 25446 solver.cpp:243] Iteration 19140, loss = 6.75698
I0826 16:33:16.279781 25446 solver.cpp:259]     Train net output #0: center_loss = 154.859 (* 0.008 = 1.23887 loss)
I0826 16:33:16.279788 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.51811 (* 1 = 5.51811 loss)
I0826 16:33:16.279791 25446 sgd_solver.cpp:138] Iteration 19140, lr = 0.0001
I0826 16:33:18.452576 25446 solver.cpp:243] Iteration 19150, loss = 6.0204
I0826 16:33:18.452602 25446 solver.cpp:259]     Train net output #0: center_loss = 214.497 (* 0.008 = 1.71598 loss)
I0826 16:33:18.452608 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.30442 (* 1 = 4.30442 loss)
I0826 16:33:18.452612 25446 sgd_solver.cpp:138] Iteration 19150, lr = 0.0001
I0826 16:33:20.510954 25446 solver.cpp:243] Iteration 19160, loss = 6.20154
I0826 16:33:20.510978 25446 solver.cpp:259]     Train net output #0: center_loss = 192.8 (* 0.008 = 1.5424 loss)
I0826 16:33:20.510984 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65914 (* 1 = 4.65914 loss)
I0826 16:33:20.510988 25446 sgd_solver.cpp:138] Iteration 19160, lr = 0.0001
I0826 16:33:22.769055 25446 solver.cpp:243] Iteration 19170, loss = 6.77864
I0826 16:33:22.769079 25446 solver.cpp:259]     Train net output #0: center_loss = 186.492 (* 0.008 = 1.49193 loss)
I0826 16:33:22.769085 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.2867 (* 1 = 5.2867 loss)
I0826 16:33:22.769090 25446 sgd_solver.cpp:138] Iteration 19170, lr = 0.0001
I0826 16:33:25.049274 25446 solver.cpp:243] Iteration 19180, loss = 5.91985
I0826 16:33:25.049315 25446 solver.cpp:259]     Train net output #0: center_loss = 203.161 (* 0.008 = 1.62529 loss)
I0826 16:33:25.049321 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29456 (* 1 = 4.29456 loss)
I0826 16:33:25.049325 25446 sgd_solver.cpp:138] Iteration 19180, lr = 0.0001
I0826 16:33:27.261646 25446 solver.cpp:243] Iteration 19190, loss = 6.46789
I0826 16:33:27.261685 25446 solver.cpp:259]     Train net output #0: center_loss = 191.016 (* 0.008 = 1.52813 loss)
I0826 16:33:27.261692 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.93976 (* 1 = 4.93976 loss)
I0826 16:33:27.261695 25446 sgd_solver.cpp:138] Iteration 19190, lr = 0.0001
I0826 16:33:29.401937 25446 solver.cpp:243] Iteration 19200, loss = 5.2448
I0826 16:33:29.401962 25446 solver.cpp:259]     Train net output #0: center_loss = 205.114 (* 0.008 = 1.64091 loss)
I0826 16:33:29.401968 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.60388 (* 1 = 3.60388 loss)
I0826 16:33:29.401971 25446 sgd_solver.cpp:138] Iteration 19200, lr = 0.0001
I0826 16:33:31.460959 25446 solver.cpp:243] Iteration 19210, loss = 5.85983
I0826 16:33:31.461000 25446 solver.cpp:259]     Train net output #0: center_loss = 180.09 (* 0.008 = 1.44072 loss)
I0826 16:33:31.461006 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.41911 (* 1 = 4.41911 loss)
I0826 16:33:31.461010 25446 sgd_solver.cpp:138] Iteration 19210, lr = 0.0001
I0826 16:33:33.521414 25446 solver.cpp:243] Iteration 19220, loss = 6.32493
I0826 16:33:33.521440 25446 solver.cpp:259]     Train net output #0: center_loss = 195.32 (* 0.008 = 1.56256 loss)
I0826 16:33:33.521445 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.76237 (* 1 = 4.76237 loss)
I0826 16:33:33.521448 25446 sgd_solver.cpp:138] Iteration 19220, lr = 0.0001
I0826 16:33:35.580659 25446 solver.cpp:243] Iteration 19230, loss = 6.43716
I0826 16:33:35.580684 25446 solver.cpp:259]     Train net output #0: center_loss = 206.295 (* 0.008 = 1.65036 loss)
I0826 16:33:35.580690 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.7868 (* 1 = 4.7868 loss)
I0826 16:33:35.580694 25446 sgd_solver.cpp:138] Iteration 19230, lr = 0.0001
I0826 16:33:37.641686 25446 solver.cpp:243] Iteration 19240, loss = 6.35112
I0826 16:33:37.641726 25446 solver.cpp:259]     Train net output #0: center_loss = 215.909 (* 0.008 = 1.72727 loss)
I0826 16:33:37.641732 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.62385 (* 1 = 4.62385 loss)
I0826 16:33:37.641736 25446 sgd_solver.cpp:138] Iteration 19240, lr = 0.0001
I0826 16:33:39.700738 25446 solver.cpp:243] Iteration 19250, loss = 6.58043
I0826 16:33:39.700763 25446 solver.cpp:259]     Train net output #0: center_loss = 181.892 (* 0.008 = 1.45513 loss)
I0826 16:33:39.700768 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.1253 (* 1 = 5.1253 loss)
I0826 16:33:39.700773 25446 sgd_solver.cpp:138] Iteration 19250, lr = 0.0001
I0826 16:33:41.759109 25446 solver.cpp:243] Iteration 19260, loss = 6.16413
I0826 16:33:41.759135 25446 solver.cpp:259]     Train net output #0: center_loss = 203.065 (* 0.008 = 1.62452 loss)
I0826 16:33:41.759141 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.53961 (* 1 = 4.53961 loss)
I0826 16:33:41.759145 25446 sgd_solver.cpp:138] Iteration 19260, lr = 0.0001
I0826 16:33:43.817816 25446 solver.cpp:243] Iteration 19270, loss = 5.83367
I0826 16:33:43.817839 25446 solver.cpp:259]     Train net output #0: center_loss = 179.03 (* 0.008 = 1.43224 loss)
I0826 16:33:43.817845 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40142 (* 1 = 4.40142 loss)
I0826 16:33:43.817849 25446 sgd_solver.cpp:138] Iteration 19270, lr = 0.0001
I0826 16:33:45.874941 25446 solver.cpp:243] Iteration 19280, loss = 6.51792
I0826 16:33:45.875066 25446 solver.cpp:259]     Train net output #0: center_loss = 186.366 (* 0.008 = 1.49093 loss)
I0826 16:33:45.875073 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02699 (* 1 = 5.02699 loss)
I0826 16:33:45.875078 25446 sgd_solver.cpp:138] Iteration 19280, lr = 0.0001
I0826 16:33:47.992925 25446 solver.cpp:243] Iteration 19290, loss = 5.88036
I0826 16:33:47.992949 25446 solver.cpp:259]     Train net output #0: center_loss = 210.143 (* 0.008 = 1.68114 loss)
I0826 16:33:47.992956 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.19922 (* 1 = 4.19922 loss)
I0826 16:33:47.992960 25446 sgd_solver.cpp:138] Iteration 19290, lr = 0.0001
I0826 16:33:50.277674 25446 solver.cpp:243] Iteration 19300, loss = 5.73714
I0826 16:33:50.277712 25446 solver.cpp:259]     Train net output #0: center_loss = 221.976 (* 0.008 = 1.77581 loss)
I0826 16:33:50.277719 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.96134 (* 1 = 3.96134 loss)
I0826 16:33:50.277724 25446 sgd_solver.cpp:138] Iteration 19300, lr = 0.0001
I0826 16:33:52.402390 25446 solver.cpp:243] Iteration 19310, loss = 6.13121
I0826 16:33:52.402415 25446 solver.cpp:259]     Train net output #0: center_loss = 174.76 (* 0.008 = 1.39808 loss)
I0826 16:33:52.402420 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.73313 (* 1 = 4.73313 loss)
I0826 16:33:52.402424 25446 sgd_solver.cpp:138] Iteration 19310, lr = 0.0001
I0826 16:33:54.455658 25446 solver.cpp:243] Iteration 19320, loss = 5.99244
I0826 16:33:54.455684 25446 solver.cpp:259]     Train net output #0: center_loss = 221.795 (* 0.008 = 1.77436 loss)
I0826 16:33:54.455690 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.21808 (* 1 = 4.21808 loss)
I0826 16:33:54.455694 25446 sgd_solver.cpp:138] Iteration 19320, lr = 0.0001
I0826 16:33:56.607259 25446 solver.cpp:243] Iteration 19330, loss = 6.40645
I0826 16:33:56.607298 25446 solver.cpp:259]     Train net output #0: center_loss = 195.151 (* 0.008 = 1.56121 loss)
I0826 16:33:56.607304 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.84524 (* 1 = 4.84524 loss)
I0826 16:33:56.607307 25446 sgd_solver.cpp:138] Iteration 19330, lr = 0.0001
I0826 16:33:58.667918 25446 solver.cpp:243] Iteration 19340, loss = 7.09892
I0826 16:33:58.667958 25446 solver.cpp:259]     Train net output #0: center_loss = 181.533 (* 0.008 = 1.45226 loss)
I0826 16:33:58.667980 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.64665 (* 1 = 5.64665 loss)
I0826 16:33:58.667984 25446 sgd_solver.cpp:138] Iteration 19340, lr = 0.0001
I0826 16:34:00.730249 25446 solver.cpp:243] Iteration 19350, loss = 5.58491
I0826 16:34:00.730289 25446 solver.cpp:259]     Train net output #0: center_loss = 205.558 (* 0.008 = 1.64446 loss)
I0826 16:34:00.730295 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.94045 (* 1 = 3.94045 loss)
I0826 16:34:00.730299 25446 sgd_solver.cpp:138] Iteration 19350, lr = 0.0001
I0826 16:34:02.788724 25446 solver.cpp:243] Iteration 19360, loss = 5.30484
I0826 16:34:02.788748 25446 solver.cpp:259]     Train net output #0: center_loss = 209.226 (* 0.008 = 1.6738 loss)
I0826 16:34:02.788754 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.63104 (* 1 = 3.63104 loss)
I0826 16:34:02.788758 25446 sgd_solver.cpp:138] Iteration 19360, lr = 0.0001
I0826 16:34:04.999897 25446 solver.cpp:243] Iteration 19370, loss = 6.50409
I0826 16:34:04.999935 25446 solver.cpp:259]     Train net output #0: center_loss = 203.703 (* 0.008 = 1.62963 loss)
I0826 16:34:04.999943 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.87446 (* 1 = 4.87446 loss)
I0826 16:34:04.999946 25446 sgd_solver.cpp:138] Iteration 19370, lr = 0.0001
I0826 16:34:07.157378 25446 solver.cpp:243] Iteration 19380, loss = 6.11672
I0826 16:34:07.157418 25446 solver.cpp:259]     Train net output #0: center_loss = 202.136 (* 0.008 = 1.61709 loss)
I0826 16:34:07.157423 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.49963 (* 1 = 4.49963 loss)
I0826 16:34:07.157428 25446 sgd_solver.cpp:138] Iteration 19380, lr = 0.0001
I0826 16:34:09.338688 25446 solver.cpp:243] Iteration 19390, loss = 6.95791
I0826 16:34:09.338714 25446 solver.cpp:259]     Train net output #0: center_loss = 193.2 (* 0.008 = 1.5456 loss)
I0826 16:34:09.338721 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.41231 (* 1 = 5.41231 loss)
I0826 16:34:09.338724 25446 sgd_solver.cpp:138] Iteration 19390, lr = 0.0001
I0826 16:34:11.487924 25446 solver.cpp:243] Iteration 19400, loss = 6.16482
I0826 16:34:11.487949 25446 solver.cpp:259]     Train net output #0: center_loss = 200.08 (* 0.008 = 1.60064 loss)
I0826 16:34:11.487956 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.56417 (* 1 = 4.56417 loss)
I0826 16:34:11.487960 25446 sgd_solver.cpp:138] Iteration 19400, lr = 0.0001
I0826 16:34:13.629971 25446 solver.cpp:243] Iteration 19410, loss = 6.55479
I0826 16:34:13.629997 25446 solver.cpp:259]     Train net output #0: center_loss = 177.396 (* 0.008 = 1.41917 loss)
I0826 16:34:13.630003 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.13562 (* 1 = 5.13562 loss)
I0826 16:34:13.630007 25446 sgd_solver.cpp:138] Iteration 19410, lr = 0.0001
I0826 16:34:15.689515 25446 solver.cpp:243] Iteration 19420, loss = 6.102
I0826 16:34:15.689539 25446 solver.cpp:259]     Train net output #0: center_loss = 199.002 (* 0.008 = 1.59201 loss)
I0826 16:34:15.689545 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50998 (* 1 = 4.50998 loss)
I0826 16:34:15.689548 25446 sgd_solver.cpp:138] Iteration 19420, lr = 0.0001
I0826 16:34:17.748833 25446 solver.cpp:243] Iteration 19430, loss = 7.28318
I0826 16:34:17.748951 25446 solver.cpp:259]     Train net output #0: center_loss = 189.279 (* 0.008 = 1.51423 loss)
I0826 16:34:17.748971 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.76895 (* 1 = 5.76895 loss)
I0826 16:34:17.748975 25446 sgd_solver.cpp:138] Iteration 19430, lr = 0.0001
I0826 16:34:19.809386 25446 solver.cpp:243] Iteration 19440, loss = 5.85588
I0826 16:34:19.809412 25446 solver.cpp:259]     Train net output #0: center_loss = 204.485 (* 0.008 = 1.63588 loss)
I0826 16:34:19.809417 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.22 (* 1 = 4.22 loss)
I0826 16:34:19.809422 25446 sgd_solver.cpp:138] Iteration 19440, lr = 0.0001
I0826 16:34:21.869408 25446 solver.cpp:243] Iteration 19450, loss = 6.08408
I0826 16:34:21.869447 25446 solver.cpp:259]     Train net output #0: center_loss = 184.125 (* 0.008 = 1.473 loss)
I0826 16:34:21.869453 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.61107 (* 1 = 4.61107 loss)
I0826 16:34:21.869457 25446 sgd_solver.cpp:138] Iteration 19450, lr = 0.0001
I0826 16:34:23.930586 25446 solver.cpp:243] Iteration 19460, loss = 5.45037
I0826 16:34:23.930625 25446 solver.cpp:259]     Train net output #0: center_loss = 201.225 (* 0.008 = 1.6098 loss)
I0826 16:34:23.930631 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.84057 (* 1 = 3.84057 loss)
I0826 16:34:23.930635 25446 sgd_solver.cpp:138] Iteration 19460, lr = 0.0001
I0826 16:34:25.992429 25446 solver.cpp:243] Iteration 19470, loss = 5.83719
I0826 16:34:25.992455 25446 solver.cpp:259]     Train net output #0: center_loss = 207.376 (* 0.008 = 1.659 loss)
I0826 16:34:25.992460 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.17819 (* 1 = 4.17819 loss)
I0826 16:34:25.992465 25446 sgd_solver.cpp:138] Iteration 19470, lr = 0.0001
I0826 16:34:28.054183 25446 solver.cpp:243] Iteration 19480, loss = 6.67525
I0826 16:34:28.054222 25446 solver.cpp:259]     Train net output #0: center_loss = 171.195 (* 0.008 = 1.36956 loss)
I0826 16:34:28.054229 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.3057 (* 1 = 5.3057 loss)
I0826 16:34:28.054232 25446 sgd_solver.cpp:138] Iteration 19480, lr = 0.0001
I0826 16:34:30.113744 25446 solver.cpp:243] Iteration 19490, loss = 6.16947
I0826 16:34:30.113767 25446 solver.cpp:259]     Train net output #0: center_loss = 200.832 (* 0.008 = 1.60665 loss)
I0826 16:34:30.113773 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.56282 (* 1 = 4.56282 loss)
I0826 16:34:30.113777 25446 sgd_solver.cpp:138] Iteration 19490, lr = 0.0001
I0826 16:34:32.175002 25446 solver.cpp:243] Iteration 19500, loss = 5.54514
I0826 16:34:32.175026 25446 solver.cpp:259]     Train net output #0: center_loss = 193.382 (* 0.008 = 1.54706 loss)
I0826 16:34:32.175032 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.99808 (* 1 = 3.99808 loss)
I0826 16:34:32.175036 25446 sgd_solver.cpp:138] Iteration 19500, lr = 0.0001
I0826 16:34:34.235981 25446 solver.cpp:243] Iteration 19510, loss = 6.53966
I0826 16:34:34.236006 25446 solver.cpp:259]     Train net output #0: center_loss = 166.091 (* 0.008 = 1.32873 loss)
I0826 16:34:34.236012 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.21093 (* 1 = 5.21093 loss)
I0826 16:34:34.236016 25446 sgd_solver.cpp:138] Iteration 19510, lr = 0.0001
I0826 16:34:36.291008 25446 solver.cpp:243] Iteration 19520, loss = 5.83644
I0826 16:34:36.291033 25446 solver.cpp:259]     Train net output #0: center_loss = 190.165 (* 0.008 = 1.52132 loss)
I0826 16:34:36.291039 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.31512 (* 1 = 4.31512 loss)
I0826 16:34:36.291043 25446 sgd_solver.cpp:138] Iteration 19520, lr = 0.0001
I0826 16:34:38.351014 25446 solver.cpp:243] Iteration 19530, loss = 6.6628
I0826 16:34:38.351054 25446 solver.cpp:259]     Train net output #0: center_loss = 197.812 (* 0.008 = 1.58249 loss)
I0826 16:34:38.351060 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.08031 (* 1 = 5.08031 loss)
I0826 16:34:38.351064 25446 sgd_solver.cpp:138] Iteration 19530, lr = 0.0001
I0826 16:34:40.407933 25446 solver.cpp:243] Iteration 19540, loss = 6.32715
I0826 16:34:40.407972 25446 solver.cpp:259]     Train net output #0: center_loss = 222.073 (* 0.008 = 1.77659 loss)
I0826 16:34:40.407979 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.55056 (* 1 = 4.55056 loss)
I0826 16:34:40.407982 25446 sgd_solver.cpp:138] Iteration 19540, lr = 0.0001
I0826 16:34:42.468658 25446 solver.cpp:243] Iteration 19550, loss = 5.97929
I0826 16:34:42.468698 25446 solver.cpp:259]     Train net output #0: center_loss = 205.883 (* 0.008 = 1.64706 loss)
I0826 16:34:42.468704 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.33223 (* 1 = 4.33223 loss)
I0826 16:34:42.468708 25446 sgd_solver.cpp:138] Iteration 19550, lr = 0.0001
I0826 16:34:44.522505 25446 solver.cpp:243] Iteration 19560, loss = 5.04276
I0826 16:34:44.522544 25446 solver.cpp:259]     Train net output #0: center_loss = 206.419 (* 0.008 = 1.65135 loss)
I0826 16:34:44.522550 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.39141 (* 1 = 3.39141 loss)
I0826 16:34:44.522554 25446 sgd_solver.cpp:138] Iteration 19560, lr = 0.0001
I0826 16:34:46.578311 25446 solver.cpp:243] Iteration 19570, loss = 5.67869
I0826 16:34:46.578351 25446 solver.cpp:259]     Train net output #0: center_loss = 218.682 (* 0.008 = 1.74945 loss)
I0826 16:34:46.578357 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.92924 (* 1 = 3.92924 loss)
I0826 16:34:46.578361 25446 sgd_solver.cpp:138] Iteration 19570, lr = 0.0001
I0826 16:34:48.639734 25446 solver.cpp:243] Iteration 19580, loss = 5.00185
I0826 16:34:48.639871 25446 solver.cpp:259]     Train net output #0: center_loss = 211.682 (* 0.008 = 1.69346 loss)
I0826 16:34:48.639879 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.30839 (* 1 = 3.30839 loss)
I0826 16:34:48.639899 25446 sgd_solver.cpp:138] Iteration 19580, lr = 0.0001
I0826 16:34:50.697566 25446 solver.cpp:243] Iteration 19590, loss = 6.12397
I0826 16:34:50.697592 25446 solver.cpp:259]     Train net output #0: center_loss = 184.042 (* 0.008 = 1.47234 loss)
I0826 16:34:50.697597 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65163 (* 1 = 4.65163 loss)
I0826 16:34:50.697602 25446 sgd_solver.cpp:138] Iteration 19590, lr = 0.0001
I0826 16:34:52.756613 25446 solver.cpp:243] Iteration 19600, loss = 6.13401
I0826 16:34:52.756654 25446 solver.cpp:259]     Train net output #0: center_loss = 211.937 (* 0.008 = 1.6955 loss)
I0826 16:34:52.756660 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43851 (* 1 = 4.43851 loss)
I0826 16:34:52.756664 25446 sgd_solver.cpp:138] Iteration 19600, lr = 0.0001
I0826 16:34:54.818895 25446 solver.cpp:243] Iteration 19610, loss = 6.82343
I0826 16:34:54.818919 25446 solver.cpp:259]     Train net output #0: center_loss = 188.071 (* 0.008 = 1.50457 loss)
I0826 16:34:54.818925 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.31886 (* 1 = 5.31886 loss)
I0826 16:34:54.818929 25446 sgd_solver.cpp:138] Iteration 19610, lr = 0.0001
I0826 16:34:56.876060 25446 solver.cpp:243] Iteration 19620, loss = 6.69178
I0826 16:34:56.876098 25446 solver.cpp:259]     Train net output #0: center_loss = 184.043 (* 0.008 = 1.47234 loss)
I0826 16:34:56.876103 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.21944 (* 1 = 5.21944 loss)
I0826 16:34:56.876107 25446 sgd_solver.cpp:138] Iteration 19620, lr = 0.0001
I0826 16:34:58.937500 25446 solver.cpp:243] Iteration 19630, loss = 6.09157
I0826 16:34:58.937521 25446 solver.cpp:259]     Train net output #0: center_loss = 214.762 (* 0.008 = 1.71809 loss)
I0826 16:34:58.937527 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.37348 (* 1 = 4.37348 loss)
I0826 16:34:58.937530 25446 sgd_solver.cpp:138] Iteration 19630, lr = 0.0001
I0826 16:35:00.996278 25446 solver.cpp:243] Iteration 19640, loss = 6.2516
I0826 16:35:00.996301 25446 solver.cpp:259]     Train net output #0: center_loss = 193.542 (* 0.008 = 1.54834 loss)
I0826 16:35:00.996306 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70326 (* 1 = 4.70326 loss)
I0826 16:35:00.996310 25446 sgd_solver.cpp:138] Iteration 19640, lr = 0.0001
I0826 16:35:03.057158 25446 solver.cpp:243] Iteration 19650, loss = 6.99585
I0826 16:35:03.057183 25446 solver.cpp:259]     Train net output #0: center_loss = 170.052 (* 0.008 = 1.36042 loss)
I0826 16:35:03.057188 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.63543 (* 1 = 5.63543 loss)
I0826 16:35:03.057193 25446 sgd_solver.cpp:138] Iteration 19650, lr = 0.0001
I0826 16:35:05.118489 25446 solver.cpp:243] Iteration 19660, loss = 6.98981
I0826 16:35:05.118513 25446 solver.cpp:259]     Train net output #0: center_loss = 168.806 (* 0.008 = 1.35045 loss)
I0826 16:35:05.118533 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.63937 (* 1 = 5.63937 loss)
I0826 16:35:05.118537 25446 sgd_solver.cpp:138] Iteration 19660, lr = 0.0001
I0826 16:35:07.177879 25446 solver.cpp:243] Iteration 19670, loss = 6.14884
I0826 16:35:07.177918 25446 solver.cpp:259]     Train net output #0: center_loss = 192.632 (* 0.008 = 1.54105 loss)
I0826 16:35:07.177924 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.60778 (* 1 = 4.60778 loss)
I0826 16:35:07.177928 25446 sgd_solver.cpp:138] Iteration 19670, lr = 0.0001
I0826 16:35:09.237525 25446 solver.cpp:243] Iteration 19680, loss = 5.90565
I0826 16:35:09.237548 25446 solver.cpp:259]     Train net output #0: center_loss = 209.869 (* 0.008 = 1.67895 loss)
I0826 16:35:09.237555 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.2267 (* 1 = 4.2267 loss)
I0826 16:35:09.237558 25446 sgd_solver.cpp:138] Iteration 19680, lr = 0.0001
I0826 16:35:11.296303 25446 solver.cpp:243] Iteration 19690, loss = 6.808
I0826 16:35:11.296340 25446 solver.cpp:259]     Train net output #0: center_loss = 187.328 (* 0.008 = 1.49862 loss)
I0826 16:35:11.296346 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.30938 (* 1 = 5.30938 loss)
I0826 16:35:11.296350 25446 sgd_solver.cpp:138] Iteration 19690, lr = 0.0001
I0826 16:35:13.358127 25446 solver.cpp:243] Iteration 19700, loss = 5.38595
I0826 16:35:13.358166 25446 solver.cpp:259]     Train net output #0: center_loss = 189.23 (* 0.008 = 1.51384 loss)
I0826 16:35:13.358172 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.87212 (* 1 = 3.87212 loss)
I0826 16:35:13.358176 25446 sgd_solver.cpp:138] Iteration 19700, lr = 0.0001
I0826 16:35:15.417312 25446 solver.cpp:243] Iteration 19710, loss = 5.36084
I0826 16:35:15.417338 25446 solver.cpp:259]     Train net output #0: center_loss = 218.82 (* 0.008 = 1.75056 loss)
I0826 16:35:15.417345 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.61028 (* 1 = 3.61028 loss)
I0826 16:35:15.417348 25446 sgd_solver.cpp:138] Iteration 19710, lr = 0.0001
I0826 16:35:17.475805 25446 solver.cpp:243] Iteration 19720, loss = 5.61522
I0826 16:35:17.475845 25446 solver.cpp:259]     Train net output #0: center_loss = 211.318 (* 0.008 = 1.69055 loss)
I0826 16:35:17.475852 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.92467 (* 1 = 3.92467 loss)
I0826 16:35:17.475855 25446 sgd_solver.cpp:138] Iteration 19720, lr = 0.0001
I0826 16:35:19.536144 25446 solver.cpp:243] Iteration 19730, loss = 5.56367
I0826 16:35:19.536252 25446 solver.cpp:259]     Train net output #0: center_loss = 183.967 (* 0.008 = 1.47173 loss)
I0826 16:35:19.536258 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.09193 (* 1 = 4.09193 loss)
I0826 16:35:19.536262 25446 sgd_solver.cpp:138] Iteration 19730, lr = 0.0001
I0826 16:35:21.594936 25446 solver.cpp:243] Iteration 19740, loss = 7.13684
I0826 16:35:21.594962 25446 solver.cpp:259]     Train net output #0: center_loss = 205.306 (* 0.008 = 1.64245 loss)
I0826 16:35:21.594969 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.49439 (* 1 = 5.49439 loss)
I0826 16:35:21.594972 25446 sgd_solver.cpp:138] Iteration 19740, lr = 0.0001
I0826 16:35:23.652933 25446 solver.cpp:243] Iteration 19750, loss = 5.67822
I0826 16:35:23.652958 25446 solver.cpp:259]     Train net output #0: center_loss = 233.081 (* 0.008 = 1.86465 loss)
I0826 16:35:23.652964 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81357 (* 1 = 3.81357 loss)
I0826 16:35:23.652968 25446 sgd_solver.cpp:138] Iteration 19750, lr = 0.0001
I0826 16:35:25.715410 25446 solver.cpp:243] Iteration 19760, loss = 6.50426
I0826 16:35:25.715451 25446 solver.cpp:259]     Train net output #0: center_loss = 196.904 (* 0.008 = 1.57524 loss)
I0826 16:35:25.715456 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.92903 (* 1 = 4.92903 loss)
I0826 16:35:25.715461 25446 sgd_solver.cpp:138] Iteration 19760, lr = 0.0001
I0826 16:35:27.774622 25446 solver.cpp:243] Iteration 19770, loss = 6.38337
I0826 16:35:27.774662 25446 solver.cpp:259]     Train net output #0: center_loss = 180.391 (* 0.008 = 1.44312 loss)
I0826 16:35:27.774668 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.94025 (* 1 = 4.94025 loss)
I0826 16:35:27.774672 25446 sgd_solver.cpp:138] Iteration 19770, lr = 0.0001
I0826 16:35:29.833788 25446 solver.cpp:243] Iteration 19780, loss = 6.58823
I0826 16:35:29.833828 25446 solver.cpp:259]     Train net output #0: center_loss = 196.314 (* 0.008 = 1.57051 loss)
I0826 16:35:29.833834 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.01772 (* 1 = 5.01772 loss)
I0826 16:35:29.833838 25446 sgd_solver.cpp:138] Iteration 19780, lr = 0.0001
I0826 16:35:31.894985 25446 solver.cpp:243] Iteration 19790, loss = 6.92403
I0826 16:35:31.895025 25446 solver.cpp:259]     Train net output #0: center_loss = 206.6 (* 0.008 = 1.6528 loss)
I0826 16:35:31.895030 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.27123 (* 1 = 5.27123 loss)
I0826 16:35:31.895035 25446 sgd_solver.cpp:138] Iteration 19790, lr = 0.0001
I0826 16:35:33.951156 25446 solver.cpp:243] Iteration 19800, loss = 7.05564
I0826 16:35:33.951195 25446 solver.cpp:259]     Train net output #0: center_loss = 164.423 (* 0.008 = 1.31538 loss)
I0826 16:35:33.951200 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.74026 (* 1 = 5.74026 loss)
I0826 16:35:33.951205 25446 sgd_solver.cpp:138] Iteration 19800, lr = 0.0001
I0826 16:35:36.010161 25446 solver.cpp:243] Iteration 19810, loss = 4.8248
I0826 16:35:36.010185 25446 solver.cpp:259]     Train net output #0: center_loss = 219.744 (* 0.008 = 1.75796 loss)
I0826 16:35:36.010191 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.06684 (* 1 = 3.06684 loss)
I0826 16:35:36.010195 25446 sgd_solver.cpp:138] Iteration 19810, lr = 0.0001
I0826 16:35:38.070802 25446 solver.cpp:243] Iteration 19820, loss = 5.6554
I0826 16:35:38.070827 25446 solver.cpp:259]     Train net output #0: center_loss = 217.307 (* 0.008 = 1.73845 loss)
I0826 16:35:38.070832 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91695 (* 1 = 3.91695 loss)
I0826 16:35:38.070837 25446 sgd_solver.cpp:138] Iteration 19820, lr = 0.0001
I0826 16:35:40.126722 25446 solver.cpp:243] Iteration 19830, loss = 6.24592
I0826 16:35:40.126762 25446 solver.cpp:259]     Train net output #0: center_loss = 199.067 (* 0.008 = 1.59254 loss)
I0826 16:35:40.126768 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65339 (* 1 = 4.65339 loss)
I0826 16:35:40.126771 25446 sgd_solver.cpp:138] Iteration 19830, lr = 0.0001
I0826 16:35:42.184399 25446 solver.cpp:243] Iteration 19840, loss = 6.19041
I0826 16:35:42.184437 25446 solver.cpp:259]     Train net output #0: center_loss = 211.938 (* 0.008 = 1.6955 loss)
I0826 16:35:42.184443 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.4949 (* 1 = 4.4949 loss)
I0826 16:35:42.184446 25446 sgd_solver.cpp:138] Iteration 19840, lr = 0.0001
I0826 16:35:44.246155 25446 solver.cpp:243] Iteration 19850, loss = 6.37631
I0826 16:35:44.246181 25446 solver.cpp:259]     Train net output #0: center_loss = 200.458 (* 0.008 = 1.60366 loss)
I0826 16:35:44.246186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77264 (* 1 = 4.77264 loss)
I0826 16:35:44.246191 25446 sgd_solver.cpp:138] Iteration 19850, lr = 0.0001
I0826 16:35:46.310272 25446 solver.cpp:243] Iteration 19860, loss = 5.30736
I0826 16:35:46.310297 25446 solver.cpp:259]     Train net output #0: center_loss = 205.45 (* 0.008 = 1.6436 loss)
I0826 16:35:46.310302 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.66376 (* 1 = 3.66376 loss)
I0826 16:35:46.310307 25446 sgd_solver.cpp:138] Iteration 19860, lr = 0.0001
I0826 16:35:48.368233 25446 solver.cpp:243] Iteration 19870, loss = 5.76588
I0826 16:35:48.368273 25446 solver.cpp:259]     Train net output #0: center_loss = 208.55 (* 0.008 = 1.6684 loss)
I0826 16:35:48.368279 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.09748 (* 1 = 4.09748 loss)
I0826 16:35:48.368283 25446 sgd_solver.cpp:138] Iteration 19870, lr = 0.0001
I0826 16:35:50.428889 25446 solver.cpp:243] Iteration 19880, loss = 5.84407
I0826 16:35:50.429049 25446 solver.cpp:259]     Train net output #0: center_loss = 214.51 (* 0.008 = 1.71608 loss)
I0826 16:35:50.429056 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.12799 (* 1 = 4.12799 loss)
I0826 16:35:50.429060 25446 sgd_solver.cpp:138] Iteration 19880, lr = 0.0001
I0826 16:35:52.488657 25446 solver.cpp:243] Iteration 19890, loss = 7.14711
I0826 16:35:52.488682 25446 solver.cpp:259]     Train net output #0: center_loss = 185.445 (* 0.008 = 1.48356 loss)
I0826 16:35:52.488687 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.66355 (* 1 = 5.66355 loss)
I0826 16:35:52.488692 25446 sgd_solver.cpp:138] Iteration 19890, lr = 0.0001
I0826 16:35:54.547631 25446 solver.cpp:243] Iteration 19900, loss = 7.6257
I0826 16:35:54.547670 25446 solver.cpp:259]     Train net output #0: center_loss = 188.395 (* 0.008 = 1.50716 loss)
I0826 16:35:54.547677 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.11854 (* 1 = 6.11854 loss)
I0826 16:35:54.547680 25446 sgd_solver.cpp:138] Iteration 19900, lr = 0.0001
I0826 16:35:56.605370 25446 solver.cpp:243] Iteration 19910, loss = 6.85201
I0826 16:35:56.605394 25446 solver.cpp:259]     Train net output #0: center_loss = 191.058 (* 0.008 = 1.52847 loss)
I0826 16:35:56.605399 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.32354 (* 1 = 5.32354 loss)
I0826 16:35:56.605403 25446 sgd_solver.cpp:138] Iteration 19910, lr = 0.0001
I0826 16:35:58.663801 25446 solver.cpp:243] Iteration 19920, loss = 6.87987
I0826 16:35:58.663827 25446 solver.cpp:259]     Train net output #0: center_loss = 196.642 (* 0.008 = 1.57314 loss)
I0826 16:35:58.663833 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.30673 (* 1 = 5.30673 loss)
I0826 16:35:58.663837 25446 sgd_solver.cpp:138] Iteration 19920, lr = 0.0001
I0826 16:36:00.726404 25446 solver.cpp:243] Iteration 19930, loss = 5.73209
I0826 16:36:00.726444 25446 solver.cpp:259]     Train net output #0: center_loss = 194.776 (* 0.008 = 1.55821 loss)
I0826 16:36:00.726449 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.17389 (* 1 = 4.17389 loss)
I0826 16:36:00.726452 25446 sgd_solver.cpp:138] Iteration 19930, lr = 0.0001
I0826 16:36:02.784759 25446 solver.cpp:243] Iteration 19940, loss = 6.00363
I0826 16:36:02.784798 25446 solver.cpp:259]     Train net output #0: center_loss = 203.074 (* 0.008 = 1.62459 loss)
I0826 16:36:02.784804 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.37903 (* 1 = 4.37903 loss)
I0826 16:36:02.784808 25446 sgd_solver.cpp:138] Iteration 19940, lr = 0.0001
I0826 16:36:04.841109 25446 solver.cpp:243] Iteration 19950, loss = 5.0857
I0826 16:36:04.841147 25446 solver.cpp:259]     Train net output #0: center_loss = 199.233 (* 0.008 = 1.59387 loss)
I0826 16:36:04.841153 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.49183 (* 1 = 3.49183 loss)
I0826 16:36:04.841157 25446 sgd_solver.cpp:138] Iteration 19950, lr = 0.0001
I0826 16:36:06.898406 25446 solver.cpp:243] Iteration 19960, loss = 5.79082
I0826 16:36:06.898445 25446 solver.cpp:259]     Train net output #0: center_loss = 205.91 (* 0.008 = 1.64728 loss)
I0826 16:36:06.898452 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.14354 (* 1 = 4.14354 loss)
I0826 16:36:06.898454 25446 sgd_solver.cpp:138] Iteration 19960, lr = 0.0001
I0826 16:36:08.956252 25446 solver.cpp:243] Iteration 19970, loss = 4.97483
I0826 16:36:08.956290 25446 solver.cpp:259]     Train net output #0: center_loss = 227.725 (* 0.008 = 1.8218 loss)
I0826 16:36:08.956296 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.15303 (* 1 = 3.15303 loss)
I0826 16:36:08.956300 25446 sgd_solver.cpp:138] Iteration 19970, lr = 0.0001
I0826 16:36:11.015053 25446 solver.cpp:243] Iteration 19980, loss = 6.92698
I0826 16:36:11.015091 25446 solver.cpp:259]     Train net output #0: center_loss = 205.83 (* 0.008 = 1.64664 loss)
I0826 16:36:11.015097 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.28034 (* 1 = 5.28034 loss)
I0826 16:36:11.015101 25446 sgd_solver.cpp:138] Iteration 19980, lr = 0.0001
I0826 16:36:13.073294 25446 solver.cpp:243] Iteration 19990, loss = 6.56307
I0826 16:36:13.073334 25446 solver.cpp:259]     Train net output #0: center_loss = 203.748 (* 0.008 = 1.62999 loss)
I0826 16:36:13.073340 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.93309 (* 1 = 4.93309 loss)
I0826 16:36:13.073344 25446 sgd_solver.cpp:138] Iteration 19990, lr = 0.0001
I0826 16:36:14.932127 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_20000.caffemodel
I0826 16:36:16.074326 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_20000.solverstate
I0826 16:36:16.399286 25446 solver.cpp:243] Iteration 20000, loss = 6.1909
I0826 16:36:16.399310 25446 solver.cpp:259]     Train net output #0: center_loss = 207.4 (* 0.008 = 1.6592 loss)
I0826 16:36:16.399317 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.5317 (* 1 = 4.5317 loss)
I0826 16:36:16.399322 25446 sgd_solver.cpp:138] Iteration 20000, lr = 0.0001
I0826 16:36:18.461598 25446 solver.cpp:243] Iteration 20010, loss = 7.01142
I0826 16:36:18.461640 25446 solver.cpp:259]     Train net output #0: center_loss = 181.368 (* 0.008 = 1.45094 loss)
I0826 16:36:18.461647 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.56047 (* 1 = 5.56047 loss)
I0826 16:36:18.461649 25446 sgd_solver.cpp:138] Iteration 20010, lr = 0.0001
I0826 16:36:20.523548 25446 solver.cpp:243] Iteration 20020, loss = 5.90533
I0826 16:36:20.523669 25446 solver.cpp:259]     Train net output #0: center_loss = 204.316 (* 0.008 = 1.63453 loss)
I0826 16:36:20.523675 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.2708 (* 1 = 4.2708 loss)
I0826 16:36:20.523679 25446 sgd_solver.cpp:138] Iteration 20020, lr = 0.0001
I0826 16:36:22.586576 25446 solver.cpp:243] Iteration 20030, loss = 5.88562
I0826 16:36:22.586616 25446 solver.cpp:259]     Train net output #0: center_loss = 174.929 (* 0.008 = 1.39943 loss)
I0826 16:36:22.586622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.48619 (* 1 = 4.48619 loss)
I0826 16:36:22.586625 25446 sgd_solver.cpp:138] Iteration 20030, lr = 0.0001
I0826 16:36:24.649364 25446 solver.cpp:243] Iteration 20040, loss = 6.90246
I0826 16:36:24.649403 25446 solver.cpp:259]     Train net output #0: center_loss = 189.257 (* 0.008 = 1.51406 loss)
I0826 16:36:24.649410 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.3884 (* 1 = 5.3884 loss)
I0826 16:36:24.649415 25446 sgd_solver.cpp:138] Iteration 20040, lr = 0.0001
I0826 16:36:26.715111 25446 solver.cpp:243] Iteration 20050, loss = 6.08013
I0826 16:36:26.715135 25446 solver.cpp:259]     Train net output #0: center_loss = 201.984 (* 0.008 = 1.61587 loss)
I0826 16:36:26.715142 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.46426 (* 1 = 4.46426 loss)
I0826 16:36:26.715145 25446 sgd_solver.cpp:138] Iteration 20050, lr = 0.0001
I0826 16:36:28.776918 25446 solver.cpp:243] Iteration 20060, loss = 5.91778
I0826 16:36:28.776943 25446 solver.cpp:259]     Train net output #0: center_loss = 185.652 (* 0.008 = 1.48522 loss)
I0826 16:36:28.776948 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43256 (* 1 = 4.43256 loss)
I0826 16:36:28.776952 25446 sgd_solver.cpp:138] Iteration 20060, lr = 0.0001
I0826 16:36:30.837847 25446 solver.cpp:243] Iteration 20070, loss = 6.0179
I0826 16:36:30.837886 25446 solver.cpp:259]     Train net output #0: center_loss = 187.06 (* 0.008 = 1.49648 loss)
I0826 16:36:30.837893 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52142 (* 1 = 4.52142 loss)
I0826 16:36:30.837896 25446 sgd_solver.cpp:138] Iteration 20070, lr = 0.0001
I0826 16:36:32.896719 25446 solver.cpp:243] Iteration 20080, loss = 5.62383
I0826 16:36:32.896757 25446 solver.cpp:259]     Train net output #0: center_loss = 226.054 (* 0.008 = 1.80843 loss)
I0826 16:36:32.896764 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81539 (* 1 = 3.81539 loss)
I0826 16:36:32.896767 25446 sgd_solver.cpp:138] Iteration 20080, lr = 0.0001
I0826 16:36:34.958292 25446 solver.cpp:243] Iteration 20090, loss = 6.31579
I0826 16:36:34.958329 25446 solver.cpp:259]     Train net output #0: center_loss = 193.841 (* 0.008 = 1.55073 loss)
I0826 16:36:34.958336 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.76506 (* 1 = 4.76506 loss)
I0826 16:36:34.958340 25446 sgd_solver.cpp:138] Iteration 20090, lr = 0.0001
I0826 16:36:37.019750 25446 solver.cpp:243] Iteration 20100, loss = 7.18051
I0826 16:36:37.019791 25446 solver.cpp:259]     Train net output #0: center_loss = 190.072 (* 0.008 = 1.52058 loss)
I0826 16:36:37.019798 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.65993 (* 1 = 5.65993 loss)
I0826 16:36:37.019801 25446 sgd_solver.cpp:138] Iteration 20100, lr = 0.0001
I0826 16:36:39.083578 25446 solver.cpp:243] Iteration 20110, loss = 5.78301
I0826 16:36:39.083616 25446 solver.cpp:259]     Train net output #0: center_loss = 225.234 (* 0.008 = 1.80187 loss)
I0826 16:36:39.083622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.98114 (* 1 = 3.98114 loss)
I0826 16:36:39.083626 25446 sgd_solver.cpp:138] Iteration 20110, lr = 0.0001
I0826 16:36:41.141691 25446 solver.cpp:243] Iteration 20120, loss = 6.84534
I0826 16:36:41.141716 25446 solver.cpp:259]     Train net output #0: center_loss = 205.608 (* 0.008 = 1.64487 loss)
I0826 16:36:41.141721 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.20047 (* 1 = 5.20047 loss)
I0826 16:36:41.141726 25446 sgd_solver.cpp:138] Iteration 20120, lr = 0.0001
I0826 16:36:43.203650 25446 solver.cpp:243] Iteration 20130, loss = 7.2362
I0826 16:36:43.203689 25446 solver.cpp:259]     Train net output #0: center_loss = 176.224 (* 0.008 = 1.40979 loss)
I0826 16:36:43.203696 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.82642 (* 1 = 5.82642 loss)
I0826 16:36:43.203699 25446 sgd_solver.cpp:138] Iteration 20130, lr = 0.0001
I0826 16:36:45.265996 25446 solver.cpp:243] Iteration 20140, loss = 5.2712
I0826 16:36:45.266021 25446 solver.cpp:259]     Train net output #0: center_loss = 228.478 (* 0.008 = 1.82783 loss)
I0826 16:36:45.266026 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.44337 (* 1 = 3.44337 loss)
I0826 16:36:45.266031 25446 sgd_solver.cpp:138] Iteration 20140, lr = 0.0001
I0826 16:36:47.328490 25446 solver.cpp:243] Iteration 20150, loss = 5.3735
I0826 16:36:47.328542 25446 solver.cpp:259]     Train net output #0: center_loss = 235.985 (* 0.008 = 1.88788 loss)
I0826 16:36:47.328548 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.48562 (* 1 = 3.48562 loss)
I0826 16:36:47.328552 25446 sgd_solver.cpp:138] Iteration 20150, lr = 0.0001
I0826 16:36:49.386965 25446 solver.cpp:243] Iteration 20160, loss = 6.48422
I0826 16:36:49.386993 25446 solver.cpp:259]     Train net output #0: center_loss = 189.746 (* 0.008 = 1.51797 loss)
I0826 16:36:49.387001 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.96625 (* 1 = 4.96625 loss)
I0826 16:36:49.387004 25446 sgd_solver.cpp:138] Iteration 20160, lr = 0.0001
I0826 16:36:51.450829 25446 solver.cpp:243] Iteration 20170, loss = 6.32604
I0826 16:36:51.450969 25446 solver.cpp:259]     Train net output #0: center_loss = 209.816 (* 0.008 = 1.67853 loss)
I0826 16:36:51.450976 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64751 (* 1 = 4.64751 loss)
I0826 16:36:51.450980 25446 sgd_solver.cpp:138] Iteration 20170, lr = 0.0001
I0826 16:36:53.515220 25446 solver.cpp:243] Iteration 20180, loss = 6.35464
I0826 16:36:53.515259 25446 solver.cpp:259]     Train net output #0: center_loss = 208.828 (* 0.008 = 1.67062 loss)
I0826 16:36:53.515265 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.68402 (* 1 = 4.68402 loss)
I0826 16:36:53.515269 25446 sgd_solver.cpp:138] Iteration 20180, lr = 0.0001
I0826 16:36:55.575234 25446 solver.cpp:243] Iteration 20190, loss = 6.33398
I0826 16:36:55.575258 25446 solver.cpp:259]     Train net output #0: center_loss = 195.208 (* 0.008 = 1.56166 loss)
I0826 16:36:55.575264 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77231 (* 1 = 4.77231 loss)
I0826 16:36:55.575268 25446 sgd_solver.cpp:138] Iteration 20190, lr = 0.0001
I0826 16:36:57.637876 25446 solver.cpp:243] Iteration 20200, loss = 6.90529
I0826 16:36:57.637915 25446 solver.cpp:259]     Train net output #0: center_loss = 156.596 (* 0.008 = 1.25277 loss)
I0826 16:36:57.637921 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.65252 (* 1 = 5.65252 loss)
I0826 16:36:57.637925 25446 sgd_solver.cpp:138] Iteration 20200, lr = 0.0001
I0826 16:36:59.696485 25446 solver.cpp:243] Iteration 20210, loss = 6.33199
I0826 16:36:59.696524 25446 solver.cpp:259]     Train net output #0: center_loss = 193.482 (* 0.008 = 1.54786 loss)
I0826 16:36:59.696530 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.78414 (* 1 = 4.78414 loss)
I0826 16:36:59.696534 25446 sgd_solver.cpp:138] Iteration 20210, lr = 0.0001
I0826 16:37:01.754773 25446 solver.cpp:243] Iteration 20220, loss = 6.58951
I0826 16:37:01.754797 25446 solver.cpp:259]     Train net output #0: center_loss = 191.004 (* 0.008 = 1.52803 loss)
I0826 16:37:01.754804 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.06147 (* 1 = 5.06147 loss)
I0826 16:37:01.754807 25446 sgd_solver.cpp:138] Iteration 20220, lr = 0.0001
I0826 16:37:03.814831 25446 solver.cpp:243] Iteration 20230, loss = 6.84729
I0826 16:37:03.814870 25446 solver.cpp:259]     Train net output #0: center_loss = 199.224 (* 0.008 = 1.59379 loss)
I0826 16:37:03.814877 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.2535 (* 1 = 5.2535 loss)
I0826 16:37:03.814879 25446 sgd_solver.cpp:138] Iteration 20230, lr = 0.0001
I0826 16:37:05.872773 25446 solver.cpp:243] Iteration 20240, loss = 6.75146
I0826 16:37:05.872812 25446 solver.cpp:259]     Train net output #0: center_loss = 184.212 (* 0.008 = 1.47369 loss)
I0826 16:37:05.872818 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.27777 (* 1 = 5.27777 loss)
I0826 16:37:05.872822 25446 sgd_solver.cpp:138] Iteration 20240, lr = 0.0001
I0826 16:37:07.930866 25446 solver.cpp:243] Iteration 20250, loss = 5.78183
I0826 16:37:07.930889 25446 solver.cpp:259]     Train net output #0: center_loss = 207.916 (* 0.008 = 1.66333 loss)
I0826 16:37:07.930910 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.1185 (* 1 = 4.1185 loss)
I0826 16:37:07.930914 25446 sgd_solver.cpp:138] Iteration 20250, lr = 0.0001
I0826 16:37:09.988991 25446 solver.cpp:243] Iteration 20260, loss = 6.07335
I0826 16:37:09.989030 25446 solver.cpp:259]     Train net output #0: center_loss = 211.19 (* 0.008 = 1.68952 loss)
I0826 16:37:09.989037 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.38383 (* 1 = 4.38383 loss)
I0826 16:37:09.989040 25446 sgd_solver.cpp:138] Iteration 20260, lr = 0.0001
I0826 16:37:12.045676 25446 solver.cpp:243] Iteration 20270, loss = 6.94658
I0826 16:37:12.045716 25446 solver.cpp:259]     Train net output #0: center_loss = 189.164 (* 0.008 = 1.51331 loss)
I0826 16:37:12.045722 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.43326 (* 1 = 5.43326 loss)
I0826 16:37:12.045725 25446 sgd_solver.cpp:138] Iteration 20270, lr = 0.0001
I0826 16:37:14.106828 25446 solver.cpp:243] Iteration 20280, loss = 6.02559
I0826 16:37:14.106868 25446 solver.cpp:259]     Train net output #0: center_loss = 215.351 (* 0.008 = 1.72281 loss)
I0826 16:37:14.106873 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.30278 (* 1 = 4.30278 loss)
I0826 16:37:14.106878 25446 sgd_solver.cpp:138] Iteration 20280, lr = 0.0001
I0826 16:37:16.167615 25446 solver.cpp:243] Iteration 20290, loss = 6.42012
I0826 16:37:16.167655 25446 solver.cpp:259]     Train net output #0: center_loss = 196.522 (* 0.008 = 1.57218 loss)
I0826 16:37:16.167661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.84795 (* 1 = 4.84795 loss)
I0826 16:37:16.167665 25446 sgd_solver.cpp:138] Iteration 20290, lr = 0.0001
I0826 16:37:18.230594 25446 solver.cpp:243] Iteration 20300, loss = 6.26776
I0826 16:37:18.230633 25446 solver.cpp:259]     Train net output #0: center_loss = 200.47 (* 0.008 = 1.60376 loss)
I0826 16:37:18.230639 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.66401 (* 1 = 4.66401 loss)
I0826 16:37:18.230643 25446 sgd_solver.cpp:138] Iteration 20300, lr = 0.0001
I0826 16:37:20.341614 25446 solver.cpp:243] Iteration 20310, loss = 5.62233
I0826 16:37:20.341640 25446 solver.cpp:259]     Train net output #0: center_loss = 215.447 (* 0.008 = 1.72357 loss)
I0826 16:37:20.341646 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.89875 (* 1 = 3.89875 loss)
I0826 16:37:20.341651 25446 sgd_solver.cpp:138] Iteration 20310, lr = 0.0001
I0826 16:37:22.620653 25446 solver.cpp:243] Iteration 20320, loss = 5.45204
I0826 16:37:22.620776 25446 solver.cpp:259]     Train net output #0: center_loss = 204.721 (* 0.008 = 1.63777 loss)
I0826 16:37:22.620797 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81428 (* 1 = 3.81428 loss)
I0826 16:37:22.620801 25446 sgd_solver.cpp:138] Iteration 20320, lr = 0.0001
I0826 16:37:24.715626 25446 solver.cpp:243] Iteration 20330, loss = 6.56984
I0826 16:37:24.715651 25446 solver.cpp:259]     Train net output #0: center_loss = 188.47 (* 0.008 = 1.50776 loss)
I0826 16:37:24.715656 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.06208 (* 1 = 5.06208 loss)
I0826 16:37:24.715662 25446 sgd_solver.cpp:138] Iteration 20330, lr = 0.0001
I0826 16:37:26.821566 25446 solver.cpp:243] Iteration 20340, loss = 5.42489
I0826 16:37:26.821591 25446 solver.cpp:259]     Train net output #0: center_loss = 212.501 (* 0.008 = 1.7 loss)
I0826 16:37:26.821597 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.72488 (* 1 = 3.72488 loss)
I0826 16:37:26.821601 25446 sgd_solver.cpp:138] Iteration 20340, lr = 0.0001
I0826 16:37:28.882740 25446 solver.cpp:243] Iteration 20350, loss = 5.57978
I0826 16:37:28.882763 25446 solver.cpp:259]     Train net output #0: center_loss = 190.692 (* 0.008 = 1.52553 loss)
I0826 16:37:28.882769 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.05424 (* 1 = 4.05424 loss)
I0826 16:37:28.882773 25446 sgd_solver.cpp:138] Iteration 20350, lr = 0.0001
I0826 16:37:30.943083 25446 solver.cpp:243] Iteration 20360, loss = 5.53129
I0826 16:37:30.943121 25446 solver.cpp:259]     Train net output #0: center_loss = 204.886 (* 0.008 = 1.63909 loss)
I0826 16:37:30.943127 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.8922 (* 1 = 3.8922 loss)
I0826 16:37:30.943131 25446 sgd_solver.cpp:138] Iteration 20360, lr = 0.0001
I0826 16:37:33.002804 25446 solver.cpp:243] Iteration 20370, loss = 5.82232
I0826 16:37:33.002842 25446 solver.cpp:259]     Train net output #0: center_loss = 189.65 (* 0.008 = 1.5172 loss)
I0826 16:37:33.002848 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.30513 (* 1 = 4.30513 loss)
I0826 16:37:33.002852 25446 sgd_solver.cpp:138] Iteration 20370, lr = 0.0001
I0826 16:37:35.064777 25446 solver.cpp:243] Iteration 20380, loss = 6.86928
I0826 16:37:35.064816 25446 solver.cpp:259]     Train net output #0: center_loss = 187.242 (* 0.008 = 1.49793 loss)
I0826 16:37:35.064821 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.37135 (* 1 = 5.37135 loss)
I0826 16:37:35.064826 25446 sgd_solver.cpp:138] Iteration 20380, lr = 0.0001
I0826 16:37:37.124459 25446 solver.cpp:243] Iteration 20390, loss = 6.40799
I0826 16:37:37.124500 25446 solver.cpp:259]     Train net output #0: center_loss = 197.899 (* 0.008 = 1.58319 loss)
I0826 16:37:37.124505 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82479 (* 1 = 4.82479 loss)
I0826 16:37:37.124509 25446 sgd_solver.cpp:138] Iteration 20390, lr = 0.0001
I0826 16:37:39.186339 25446 solver.cpp:243] Iteration 20400, loss = 5.49517
I0826 16:37:39.186378 25446 solver.cpp:259]     Train net output #0: center_loss = 197.593 (* 0.008 = 1.58074 loss)
I0826 16:37:39.186384 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91443 (* 1 = 3.91443 loss)
I0826 16:37:39.186388 25446 sgd_solver.cpp:138] Iteration 20400, lr = 0.0001
I0826 16:37:41.250000 25446 solver.cpp:243] Iteration 20410, loss = 5.27303
I0826 16:37:41.250036 25446 solver.cpp:259]     Train net output #0: center_loss = 201.036 (* 0.008 = 1.60829 loss)
I0826 16:37:41.250042 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.66474 (* 1 = 3.66474 loss)
I0826 16:37:41.250046 25446 sgd_solver.cpp:138] Iteration 20410, lr = 0.0001
I0826 16:37:43.420574 25446 solver.cpp:243] Iteration 20420, loss = 6.96919
I0826 16:37:43.420614 25446 solver.cpp:259]     Train net output #0: center_loss = 183.706 (* 0.008 = 1.46965 loss)
I0826 16:37:43.420620 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.49954 (* 1 = 5.49954 loss)
I0826 16:37:43.420624 25446 sgd_solver.cpp:138] Iteration 20420, lr = 0.0001
I0826 16:37:45.682003 25446 solver.cpp:243] Iteration 20430, loss = 5.41229
I0826 16:37:45.682029 25446 solver.cpp:259]     Train net output #0: center_loss = 214.291 (* 0.008 = 1.71433 loss)
I0826 16:37:45.682036 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.69796 (* 1 = 3.69796 loss)
I0826 16:37:45.682040 25446 sgd_solver.cpp:138] Iteration 20430, lr = 0.0001
I0826 16:37:47.748381 25446 solver.cpp:243] Iteration 20440, loss = 6.32461
I0826 16:37:47.748405 25446 solver.cpp:259]     Train net output #0: center_loss = 181.342 (* 0.008 = 1.45074 loss)
I0826 16:37:47.748411 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.87388 (* 1 = 4.87388 loss)
I0826 16:37:47.748415 25446 sgd_solver.cpp:138] Iteration 20440, lr = 0.0001
I0826 16:37:49.811209 25446 solver.cpp:243] Iteration 20450, loss = 6.41401
I0826 16:37:49.811234 25446 solver.cpp:259]     Train net output #0: center_loss = 174.738 (* 0.008 = 1.3979 loss)
I0826 16:37:49.811240 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.0161 (* 1 = 5.0161 loss)
I0826 16:37:49.811244 25446 sgd_solver.cpp:138] Iteration 20450, lr = 0.0001
I0826 16:37:51.874016 25446 solver.cpp:243] Iteration 20460, loss = 6.60477
I0826 16:37:51.874039 25446 solver.cpp:259]     Train net output #0: center_loss = 197.806 (* 0.008 = 1.58245 loss)
I0826 16:37:51.874044 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.02233 (* 1 = 5.02233 loss)
I0826 16:37:51.874048 25446 sgd_solver.cpp:138] Iteration 20460, lr = 0.0001
I0826 16:37:53.931982 25446 solver.cpp:243] Iteration 20470, loss = 5.32649
I0826 16:37:53.932093 25446 solver.cpp:259]     Train net output #0: center_loss = 214.918 (* 0.008 = 1.71935 loss)
I0826 16:37:53.932101 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.60714 (* 1 = 3.60714 loss)
I0826 16:37:53.932106 25446 sgd_solver.cpp:138] Iteration 20470, lr = 0.0001
I0826 16:37:55.988709 25446 solver.cpp:243] Iteration 20480, loss = 6.51468
I0826 16:37:55.988747 25446 solver.cpp:259]     Train net output #0: center_loss = 174.139 (* 0.008 = 1.39311 loss)
I0826 16:37:55.988754 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.12156 (* 1 = 5.12156 loss)
I0826 16:37:55.988759 25446 sgd_solver.cpp:138] Iteration 20480, lr = 0.0001
I0826 16:37:58.049958 25446 solver.cpp:243] Iteration 20490, loss = 5.48138
I0826 16:37:58.049996 25446 solver.cpp:259]     Train net output #0: center_loss = 238.262 (* 0.008 = 1.9061 loss)
I0826 16:37:58.050002 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.57528 (* 1 = 3.57528 loss)
I0826 16:37:58.050005 25446 sgd_solver.cpp:138] Iteration 20490, lr = 0.0001
I0826 16:38:00.112236 25446 solver.cpp:243] Iteration 20500, loss = 5.88358
I0826 16:38:00.112260 25446 solver.cpp:259]     Train net output #0: center_loss = 204.414 (* 0.008 = 1.63532 loss)
I0826 16:38:00.112267 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.24827 (* 1 = 4.24827 loss)
I0826 16:38:00.112272 25446 sgd_solver.cpp:138] Iteration 20500, lr = 0.0001
I0826 16:38:02.174772 25446 solver.cpp:243] Iteration 20510, loss = 5.62353
I0826 16:38:02.174810 25446 solver.cpp:259]     Train net output #0: center_loss = 216.931 (* 0.008 = 1.73545 loss)
I0826 16:38:02.174816 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.88809 (* 1 = 3.88809 loss)
I0826 16:38:02.174820 25446 sgd_solver.cpp:138] Iteration 20510, lr = 0.0001
I0826 16:38:04.238683 25446 solver.cpp:243] Iteration 20520, loss = 6.16952
I0826 16:38:04.238706 25446 solver.cpp:259]     Train net output #0: center_loss = 186.908 (* 0.008 = 1.49526 loss)
I0826 16:38:04.238713 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.67426 (* 1 = 4.67426 loss)
I0826 16:38:04.238716 25446 sgd_solver.cpp:138] Iteration 20520, lr = 0.0001
I0826 16:38:06.298012 25446 solver.cpp:243] Iteration 20530, loss = 6.2609
I0826 16:38:06.298035 25446 solver.cpp:259]     Train net output #0: center_loss = 183.73 (* 0.008 = 1.46984 loss)
I0826 16:38:06.298041 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79106 (* 1 = 4.79106 loss)
I0826 16:38:06.298045 25446 sgd_solver.cpp:138] Iteration 20530, lr = 0.0001
I0826 16:38:08.359084 25446 solver.cpp:243] Iteration 20540, loss = 5.22415
I0826 16:38:08.359124 25446 solver.cpp:259]     Train net output #0: center_loss = 223.278 (* 0.008 = 1.78623 loss)
I0826 16:38:08.359130 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.43793 (* 1 = 3.43793 loss)
I0826 16:38:08.359133 25446 sgd_solver.cpp:138] Iteration 20540, lr = 0.0001
I0826 16:38:10.422123 25446 solver.cpp:243] Iteration 20550, loss = 4.80816
I0826 16:38:10.422165 25446 solver.cpp:259]     Train net output #0: center_loss = 210.974 (* 0.008 = 1.68779 loss)
I0826 16:38:10.422171 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.12036 (* 1 = 3.12036 loss)
I0826 16:38:10.422175 25446 sgd_solver.cpp:138] Iteration 20550, lr = 0.0001
I0826 16:38:12.485710 25446 solver.cpp:243] Iteration 20560, loss = 7.22799
I0826 16:38:12.485751 25446 solver.cpp:259]     Train net output #0: center_loss = 186.765 (* 0.008 = 1.49412 loss)
I0826 16:38:12.485757 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.73386 (* 1 = 5.73386 loss)
I0826 16:38:12.485760 25446 sgd_solver.cpp:138] Iteration 20560, lr = 0.0001
I0826 16:38:14.548993 25446 solver.cpp:243] Iteration 20570, loss = 5.6761
I0826 16:38:14.549033 25446 solver.cpp:259]     Train net output #0: center_loss = 209.592 (* 0.008 = 1.67674 loss)
I0826 16:38:14.549039 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.99936 (* 1 = 3.99936 loss)
I0826 16:38:14.549043 25446 sgd_solver.cpp:138] Iteration 20570, lr = 0.0001
I0826 16:38:16.611476 25446 solver.cpp:243] Iteration 20580, loss = 6.75939
I0826 16:38:16.611515 25446 solver.cpp:259]     Train net output #0: center_loss = 204.564 (* 0.008 = 1.63651 loss)
I0826 16:38:16.611521 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.12288 (* 1 = 5.12288 loss)
I0826 16:38:16.611526 25446 sgd_solver.cpp:138] Iteration 20580, lr = 0.0001
I0826 16:38:18.672250 25446 solver.cpp:243] Iteration 20590, loss = 5.72366
I0826 16:38:18.672288 25446 solver.cpp:259]     Train net output #0: center_loss = 185.486 (* 0.008 = 1.48388 loss)
I0826 16:38:18.672294 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.23978 (* 1 = 4.23978 loss)
I0826 16:38:18.672297 25446 sgd_solver.cpp:138] Iteration 20590, lr = 0.0001
I0826 16:38:20.734143 25446 solver.cpp:243] Iteration 20600, loss = 6.81001
I0826 16:38:20.734166 25446 solver.cpp:259]     Train net output #0: center_loss = 188.416 (* 0.008 = 1.50733 loss)
I0826 16:38:20.734174 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.30268 (* 1 = 5.30268 loss)
I0826 16:38:20.734177 25446 sgd_solver.cpp:138] Iteration 20600, lr = 0.0001
I0826 16:38:22.793944 25446 solver.cpp:243] Iteration 20610, loss = 5.36295
I0826 16:38:22.793983 25446 solver.cpp:259]     Train net output #0: center_loss = 204.735 (* 0.008 = 1.63788 loss)
I0826 16:38:22.793989 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.72507 (* 1 = 3.72507 loss)
I0826 16:38:22.793992 25446 sgd_solver.cpp:138] Iteration 20610, lr = 0.0001
I0826 16:38:24.856251 25446 solver.cpp:243] Iteration 20620, loss = 5.93498
I0826 16:38:24.856379 25446 solver.cpp:259]     Train net output #0: center_loss = 198.848 (* 0.008 = 1.59079 loss)
I0826 16:38:24.856385 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.3442 (* 1 = 4.3442 loss)
I0826 16:38:24.856407 25446 sgd_solver.cpp:138] Iteration 20620, lr = 0.0001
I0826 16:38:26.914191 25446 solver.cpp:243] Iteration 20630, loss = 5.72351
I0826 16:38:26.914216 25446 solver.cpp:259]     Train net output #0: center_loss = 211.353 (* 0.008 = 1.69082 loss)
I0826 16:38:26.914222 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.03269 (* 1 = 4.03269 loss)
I0826 16:38:26.914224 25446 sgd_solver.cpp:138] Iteration 20630, lr = 0.0001
I0826 16:38:28.974041 25446 solver.cpp:243] Iteration 20640, loss = 5.51718
I0826 16:38:28.974081 25446 solver.cpp:259]     Train net output #0: center_loss = 224.01 (* 0.008 = 1.79208 loss)
I0826 16:38:28.974086 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.7251 (* 1 = 3.7251 loss)
I0826 16:38:28.974089 25446 sgd_solver.cpp:138] Iteration 20640, lr = 0.0001
I0826 16:38:31.038233 25446 solver.cpp:243] Iteration 20650, loss = 5.42884
I0826 16:38:31.038259 25446 solver.cpp:259]     Train net output #0: center_loss = 218.371 (* 0.008 = 1.74697 loss)
I0826 16:38:31.038265 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.68187 (* 1 = 3.68187 loss)
I0826 16:38:31.038269 25446 sgd_solver.cpp:138] Iteration 20650, lr = 0.0001
I0826 16:38:33.097820 25446 solver.cpp:243] Iteration 20660, loss = 6.801
I0826 16:38:33.097846 25446 solver.cpp:259]     Train net output #0: center_loss = 157.471 (* 0.008 = 1.25977 loss)
I0826 16:38:33.097854 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.54123 (* 1 = 5.54123 loss)
I0826 16:38:33.097858 25446 sgd_solver.cpp:138] Iteration 20660, lr = 0.0001
I0826 16:38:35.158779 25446 solver.cpp:243] Iteration 20670, loss = 6.39898
I0826 16:38:35.158802 25446 solver.cpp:259]     Train net output #0: center_loss = 182.463 (* 0.008 = 1.4597 loss)
I0826 16:38:35.158808 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.93928 (* 1 = 4.93928 loss)
I0826 16:38:35.158812 25446 sgd_solver.cpp:138] Iteration 20670, lr = 0.0001
I0826 16:38:37.218490 25446 solver.cpp:243] Iteration 20680, loss = 6.27646
I0826 16:38:37.218529 25446 solver.cpp:259]     Train net output #0: center_loss = 180.141 (* 0.008 = 1.44113 loss)
I0826 16:38:37.218535 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.83533 (* 1 = 4.83533 loss)
I0826 16:38:37.218539 25446 sgd_solver.cpp:138] Iteration 20680, lr = 0.0001
I0826 16:38:39.279590 25446 solver.cpp:243] Iteration 20690, loss = 6.6497
I0826 16:38:39.279613 25446 solver.cpp:259]     Train net output #0: center_loss = 190.585 (* 0.008 = 1.52468 loss)
I0826 16:38:39.279619 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.12502 (* 1 = 5.12502 loss)
I0826 16:38:39.279623 25446 sgd_solver.cpp:138] Iteration 20690, lr = 0.0001
I0826 16:38:41.341022 25446 solver.cpp:243] Iteration 20700, loss = 5.09235
I0826 16:38:41.341048 25446 solver.cpp:259]     Train net output #0: center_loss = 224.095 (* 0.008 = 1.79276 loss)
I0826 16:38:41.341053 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.29959 (* 1 = 3.29959 loss)
I0826 16:38:41.341058 25446 sgd_solver.cpp:138] Iteration 20700, lr = 0.0001
I0826 16:38:43.405709 25446 solver.cpp:243] Iteration 20710, loss = 6.70725
I0826 16:38:43.405735 25446 solver.cpp:259]     Train net output #0: center_loss = 200.051 (* 0.008 = 1.60041 loss)
I0826 16:38:43.405740 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.10684 (* 1 = 5.10684 loss)
I0826 16:38:43.405745 25446 sgd_solver.cpp:138] Iteration 20710, lr = 0.0001
I0826 16:38:45.462929 25446 solver.cpp:243] Iteration 20720, loss = 6.93136
I0826 16:38:45.462952 25446 solver.cpp:259]     Train net output #0: center_loss = 178.932 (* 0.008 = 1.43146 loss)
I0826 16:38:45.462958 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.4999 (* 1 = 5.4999 loss)
I0826 16:38:45.462962 25446 sgd_solver.cpp:138] Iteration 20720, lr = 0.0001
I0826 16:38:47.524920 25446 solver.cpp:243] Iteration 20730, loss = 5.78392
I0826 16:38:47.524945 25446 solver.cpp:259]     Train net output #0: center_loss = 197.458 (* 0.008 = 1.57967 loss)
I0826 16:38:47.524950 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.20426 (* 1 = 4.20426 loss)
I0826 16:38:47.524955 25446 sgd_solver.cpp:138] Iteration 20730, lr = 0.0001
I0826 16:38:49.585259 25446 solver.cpp:243] Iteration 20740, loss = 6.41115
I0826 16:38:49.585284 25446 solver.cpp:259]     Train net output #0: center_loss = 198.785 (* 0.008 = 1.59028 loss)
I0826 16:38:49.585290 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82087 (* 1 = 4.82087 loss)
I0826 16:38:49.585294 25446 sgd_solver.cpp:138] Iteration 20740, lr = 0.0001
I0826 16:38:51.647828 25446 solver.cpp:243] Iteration 20750, loss = 7.41188
I0826 16:38:51.647852 25446 solver.cpp:259]     Train net output #0: center_loss = 179.691 (* 0.008 = 1.43753 loss)
I0826 16:38:51.647858 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.97435 (* 1 = 5.97435 loss)
I0826 16:38:51.647862 25446 sgd_solver.cpp:138] Iteration 20750, lr = 0.0001
I0826 16:38:53.710232 25446 solver.cpp:243] Iteration 20760, loss = 6.19992
I0826 16:38:53.710259 25446 solver.cpp:259]     Train net output #0: center_loss = 204.104 (* 0.008 = 1.63284 loss)
I0826 16:38:53.710265 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.56709 (* 1 = 4.56709 loss)
I0826 16:38:53.710269 25446 sgd_solver.cpp:138] Iteration 20760, lr = 0.0001
I0826 16:38:55.772554 25446 solver.cpp:243] Iteration 20770, loss = 5.88121
I0826 16:38:55.772730 25446 solver.cpp:259]     Train net output #0: center_loss = 212.244 (* 0.008 = 1.69795 loss)
I0826 16:38:55.772737 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.18326 (* 1 = 4.18326 loss)
I0826 16:38:55.772754 25446 sgd_solver.cpp:138] Iteration 20770, lr = 0.0001
I0826 16:38:57.844278 25446 solver.cpp:243] Iteration 20780, loss = 5.00168
I0826 16:38:57.844303 25446 solver.cpp:259]     Train net output #0: center_loss = 232.015 (* 0.008 = 1.85612 loss)
I0826 16:38:57.844310 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.14556 (* 1 = 3.14556 loss)
I0826 16:38:57.844314 25446 sgd_solver.cpp:138] Iteration 20780, lr = 0.0001
I0826 16:39:00.018487 25446 solver.cpp:243] Iteration 20790, loss = 6.42216
I0826 16:39:00.018515 25446 solver.cpp:259]     Train net output #0: center_loss = 199.22 (* 0.008 = 1.59376 loss)
I0826 16:39:00.018522 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.8284 (* 1 = 4.8284 loss)
I0826 16:39:00.018527 25446 sgd_solver.cpp:138] Iteration 20790, lr = 0.0001
I0826 16:39:02.295536 25446 solver.cpp:243] Iteration 20800, loss = 6.6092
I0826 16:39:02.295562 25446 solver.cpp:259]     Train net output #0: center_loss = 184.693 (* 0.008 = 1.47754 loss)
I0826 16:39:02.295567 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.13166 (* 1 = 5.13166 loss)
I0826 16:39:02.295572 25446 sgd_solver.cpp:138] Iteration 20800, lr = 0.0001
I0826 16:39:04.487696 25446 solver.cpp:243] Iteration 20810, loss = 6.6745
I0826 16:39:04.487720 25446 solver.cpp:259]     Train net output #0: center_loss = 193.503 (* 0.008 = 1.54802 loss)
I0826 16:39:04.487726 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.12648 (* 1 = 5.12648 loss)
I0826 16:39:04.487730 25446 sgd_solver.cpp:138] Iteration 20810, lr = 0.0001
I0826 16:39:06.644137 25446 solver.cpp:243] Iteration 20820, loss = 5.93452
I0826 16:39:06.644177 25446 solver.cpp:259]     Train net output #0: center_loss = 199.987 (* 0.008 = 1.5999 loss)
I0826 16:39:06.644183 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.33462 (* 1 = 4.33462 loss)
I0826 16:39:06.644187 25446 sgd_solver.cpp:138] Iteration 20820, lr = 0.0001
I0826 16:39:08.707942 25446 solver.cpp:243] Iteration 20830, loss = 6.01235
I0826 16:39:08.707981 25446 solver.cpp:259]     Train net output #0: center_loss = 177.462 (* 0.008 = 1.41969 loss)
I0826 16:39:08.707988 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.59265 (* 1 = 4.59265 loss)
I0826 16:39:08.707991 25446 sgd_solver.cpp:138] Iteration 20830, lr = 0.0001
I0826 16:39:10.774142 25446 solver.cpp:243] Iteration 20840, loss = 5.37497
I0826 16:39:10.774179 25446 solver.cpp:259]     Train net output #0: center_loss = 234.127 (* 0.008 = 1.87301 loss)
I0826 16:39:10.774186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.50196 (* 1 = 3.50196 loss)
I0826 16:39:10.774190 25446 sgd_solver.cpp:138] Iteration 20840, lr = 0.0001
I0826 16:39:12.837641 25446 solver.cpp:243] Iteration 20850, loss = 5.56217
I0826 16:39:12.837679 25446 solver.cpp:259]     Train net output #0: center_loss = 216.053 (* 0.008 = 1.72842 loss)
I0826 16:39:12.837685 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83375 (* 1 = 3.83375 loss)
I0826 16:39:12.837689 25446 sgd_solver.cpp:138] Iteration 20850, lr = 0.0001
I0826 16:39:14.898433 25446 solver.cpp:243] Iteration 20860, loss = 6.11817
I0826 16:39:14.898458 25446 solver.cpp:259]     Train net output #0: center_loss = 205.68 (* 0.008 = 1.64544 loss)
I0826 16:39:14.898463 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47273 (* 1 = 4.47273 loss)
I0826 16:39:14.898466 25446 sgd_solver.cpp:138] Iteration 20860, lr = 0.0001
I0826 16:39:16.961799 25446 solver.cpp:243] Iteration 20870, loss = 5.27315
I0826 16:39:16.961823 25446 solver.cpp:259]     Train net output #0: center_loss = 207.361 (* 0.008 = 1.65889 loss)
I0826 16:39:16.961829 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.61427 (* 1 = 3.61427 loss)
I0826 16:39:16.961833 25446 sgd_solver.cpp:138] Iteration 20870, lr = 0.0001
I0826 16:39:19.025264 25446 solver.cpp:243] Iteration 20880, loss = 6.46878
I0826 16:39:19.025287 25446 solver.cpp:259]     Train net output #0: center_loss = 212.239 (* 0.008 = 1.69792 loss)
I0826 16:39:19.025293 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.77086 (* 1 = 4.77086 loss)
I0826 16:39:19.025297 25446 sgd_solver.cpp:138] Iteration 20880, lr = 0.0001
I0826 16:39:21.087802 25446 solver.cpp:243] Iteration 20890, loss = 5.50311
I0826 16:39:21.087827 25446 solver.cpp:259]     Train net output #0: center_loss = 210.622 (* 0.008 = 1.68498 loss)
I0826 16:39:21.087847 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81813 (* 1 = 3.81813 loss)
I0826 16:39:21.087852 25446 sgd_solver.cpp:138] Iteration 20890, lr = 0.0001
I0826 16:39:23.149703 25446 solver.cpp:243] Iteration 20900, loss = 6.60343
I0826 16:39:23.149725 25446 solver.cpp:259]     Train net output #0: center_loss = 182.942 (* 0.008 = 1.46353 loss)
I0826 16:39:23.149731 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.1399 (* 1 = 5.1399 loss)
I0826 16:39:23.149735 25446 sgd_solver.cpp:138] Iteration 20900, lr = 0.0001
I0826 16:39:25.211120 25446 solver.cpp:243] Iteration 20910, loss = 6.85174
I0826 16:39:25.211146 25446 solver.cpp:259]     Train net output #0: center_loss = 199.399 (* 0.008 = 1.59519 loss)
I0826 16:39:25.211153 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.25655 (* 1 = 5.25655 loss)
I0826 16:39:25.211155 25446 sgd_solver.cpp:138] Iteration 20910, lr = 0.0001
I0826 16:39:27.273021 25446 solver.cpp:243] Iteration 20920, loss = 5.9553
I0826 16:39:27.273159 25446 solver.cpp:259]     Train net output #0: center_loss = 196.958 (* 0.008 = 1.57566 loss)
I0826 16:39:27.273167 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.37964 (* 1 = 4.37964 loss)
I0826 16:39:27.273185 25446 sgd_solver.cpp:138] Iteration 20920, lr = 0.0001
I0826 16:39:29.336302 25446 solver.cpp:243] Iteration 20930, loss = 6.23845
I0826 16:39:29.336340 25446 solver.cpp:259]     Train net output #0: center_loss = 196.815 (* 0.008 = 1.57452 loss)
I0826 16:39:29.336347 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.66392 (* 1 = 4.66392 loss)
I0826 16:39:29.336351 25446 sgd_solver.cpp:138] Iteration 20930, lr = 0.0001
I0826 16:39:31.394310 25446 solver.cpp:243] Iteration 20940, loss = 5.38467
I0826 16:39:31.394335 25446 solver.cpp:259]     Train net output #0: center_loss = 203.624 (* 0.008 = 1.62899 loss)
I0826 16:39:31.394340 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.75568 (* 1 = 3.75568 loss)
I0826 16:39:31.394345 25446 sgd_solver.cpp:138] Iteration 20940, lr = 0.0001
I0826 16:39:33.455435 25446 solver.cpp:243] Iteration 20950, loss = 5.53528
I0826 16:39:33.455458 25446 solver.cpp:259]     Train net output #0: center_loss = 207.62 (* 0.008 = 1.66096 loss)
I0826 16:39:33.455464 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.87432 (* 1 = 3.87432 loss)
I0826 16:39:33.455468 25446 sgd_solver.cpp:138] Iteration 20950, lr = 0.0001
I0826 16:39:35.517323 25446 solver.cpp:243] Iteration 20960, loss = 7.15106
I0826 16:39:35.517361 25446 solver.cpp:259]     Train net output #0: center_loss = 191.49 (* 0.008 = 1.53192 loss)
I0826 16:39:35.517367 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.61914 (* 1 = 5.61914 loss)
I0826 16:39:35.517372 25446 sgd_solver.cpp:138] Iteration 20960, lr = 0.0001
I0826 16:39:37.581959 25446 solver.cpp:243] Iteration 20970, loss = 6.03488
I0826 16:39:37.581997 25446 solver.cpp:259]     Train net output #0: center_loss = 210.668 (* 0.008 = 1.68534 loss)
I0826 16:39:37.582003 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.34954 (* 1 = 4.34954 loss)
I0826 16:39:37.582007 25446 sgd_solver.cpp:138] Iteration 20970, lr = 0.0001
I0826 16:39:39.643148 25446 solver.cpp:243] Iteration 20980, loss = 5.39003
I0826 16:39:39.643172 25446 solver.cpp:259]     Train net output #0: center_loss = 212.54 (* 0.008 = 1.70032 loss)
I0826 16:39:39.643178 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.68971 (* 1 = 3.68971 loss)
I0826 16:39:39.643182 25446 sgd_solver.cpp:138] Iteration 20980, lr = 0.0001
I0826 16:39:41.776566 25446 solver.cpp:243] Iteration 20990, loss = 6.0451
I0826 16:39:41.776605 25446 solver.cpp:259]     Train net output #0: center_loss = 207.791 (* 0.008 = 1.66232 loss)
I0826 16:39:41.776612 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.38278 (* 1 = 4.38278 loss)
I0826 16:39:41.776615 25446 sgd_solver.cpp:138] Iteration 20990, lr = 0.0001
I0826 16:39:43.791160 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_21000.caffemodel
I0826 16:39:44.935921 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_21000.solverstate
I0826 16:39:45.268622 25446 solver.cpp:243] Iteration 21000, loss = 4.35363
I0826 16:39:45.268648 25446 solver.cpp:259]     Train net output #0: center_loss = 246.39 (* 0.008 = 1.97112 loss)
I0826 16:39:45.268654 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.38251 (* 1 = 2.38251 loss)
I0826 16:39:45.268658 25446 sgd_solver.cpp:138] Iteration 21000, lr = 0.0001
I0826 16:39:47.324415 25446 solver.cpp:243] Iteration 21010, loss = 7.07305
I0826 16:39:47.324438 25446 solver.cpp:259]     Train net output #0: center_loss = 190.146 (* 0.008 = 1.52117 loss)
I0826 16:39:47.324445 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.55188 (* 1 = 5.55188 loss)
I0826 16:39:47.324448 25446 sgd_solver.cpp:138] Iteration 21010, lr = 0.0001
I0826 16:39:49.381733 25446 solver.cpp:243] Iteration 21020, loss = 6.75125
I0826 16:39:49.381773 25446 solver.cpp:259]     Train net output #0: center_loss = 169.992 (* 0.008 = 1.35994 loss)
I0826 16:39:49.381816 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.39131 (* 1 = 5.39131 loss)
I0826 16:39:49.381821 25446 sgd_solver.cpp:138] Iteration 21020, lr = 0.0001
I0826 16:39:51.439903 25446 solver.cpp:243] Iteration 21030, loss = 6.9592
I0826 16:39:51.439927 25446 solver.cpp:259]     Train net output #0: center_loss = 176.289 (* 0.008 = 1.41031 loss)
I0826 16:39:51.439934 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.54889 (* 1 = 5.54889 loss)
I0826 16:39:51.439936 25446 sgd_solver.cpp:138] Iteration 21030, lr = 0.0001
I0826 16:39:53.498066 25446 solver.cpp:243] Iteration 21040, loss = 5.58634
I0826 16:39:53.498091 25446 solver.cpp:259]     Train net output #0: center_loss = 192.618 (* 0.008 = 1.54095 loss)
I0826 16:39:53.498097 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04539 (* 1 = 4.04539 loss)
I0826 16:39:53.498101 25446 sgd_solver.cpp:138] Iteration 21040, lr = 0.0001
I0826 16:39:55.553212 25446 solver.cpp:243] Iteration 21050, loss = 5.42318
I0826 16:39:55.553256 25446 solver.cpp:259]     Train net output #0: center_loss = 206.816 (* 0.008 = 1.65453 loss)
I0826 16:39:55.553277 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.76865 (* 1 = 3.76865 loss)
I0826 16:39:55.553282 25446 sgd_solver.cpp:138] Iteration 21050, lr = 0.0001
I0826 16:39:57.610430 25446 solver.cpp:243] Iteration 21060, loss = 5.53675
I0826 16:39:57.610555 25446 solver.cpp:259]     Train net output #0: center_loss = 214.849 (* 0.008 = 1.71879 loss)
I0826 16:39:57.610575 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81796 (* 1 = 3.81796 loss)
I0826 16:39:57.610579 25446 sgd_solver.cpp:138] Iteration 21060, lr = 0.0001
I0826 16:39:59.671005 25446 solver.cpp:243] Iteration 21070, loss = 5.28423
I0826 16:39:59.671046 25446 solver.cpp:259]     Train net output #0: center_loss = 227.412 (* 0.008 = 1.8193 loss)
I0826 16:39:59.671051 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.46493 (* 1 = 3.46493 loss)
I0826 16:39:59.671056 25446 sgd_solver.cpp:138] Iteration 21070, lr = 0.0001
I0826 16:40:01.733430 25446 solver.cpp:243] Iteration 21080, loss = 5.86153
I0826 16:40:01.733454 25446 solver.cpp:259]     Train net output #0: center_loss = 234.856 (* 0.008 = 1.87885 loss)
I0826 16:40:01.733460 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.98268 (* 1 = 3.98268 loss)
I0826 16:40:01.733464 25446 sgd_solver.cpp:138] Iteration 21080, lr = 0.0001
I0826 16:40:03.790546 25446 solver.cpp:243] Iteration 21090, loss = 6.14759
I0826 16:40:03.790586 25446 solver.cpp:259]     Train net output #0: center_loss = 217.14 (* 0.008 = 1.73712 loss)
I0826 16:40:03.790591 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.41048 (* 1 = 4.41048 loss)
I0826 16:40:03.790596 25446 sgd_solver.cpp:138] Iteration 21090, lr = 0.0001
I0826 16:40:05.851647 25446 solver.cpp:243] Iteration 21100, loss = 6.95611
I0826 16:40:05.851670 25446 solver.cpp:259]     Train net output #0: center_loss = 200.446 (* 0.008 = 1.60357 loss)
I0826 16:40:05.851676 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.35254 (* 1 = 5.35254 loss)
I0826 16:40:05.851680 25446 sgd_solver.cpp:138] Iteration 21100, lr = 0.0001
I0826 16:40:07.907994 25446 solver.cpp:243] Iteration 21110, loss = 4.94052
I0826 16:40:07.908017 25446 solver.cpp:259]     Train net output #0: center_loss = 241.966 (* 0.008 = 1.93573 loss)
I0826 16:40:07.908023 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.00479 (* 1 = 3.00479 loss)
I0826 16:40:07.908027 25446 sgd_solver.cpp:138] Iteration 21110, lr = 0.0001
I0826 16:40:10.079161 25446 solver.cpp:243] Iteration 21120, loss = 6.05401
I0826 16:40:10.079202 25446 solver.cpp:259]     Train net output #0: center_loss = 202.315 (* 0.008 = 1.61852 loss)
I0826 16:40:10.079208 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43549 (* 1 = 4.43549 loss)
I0826 16:40:10.079212 25446 sgd_solver.cpp:138] Iteration 21120, lr = 0.0001
I0826 16:40:12.349989 25446 solver.cpp:243] Iteration 21130, loss = 6.61678
I0826 16:40:12.350028 25446 solver.cpp:259]     Train net output #0: center_loss = 193.734 (* 0.008 = 1.54988 loss)
I0826 16:40:12.350033 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.0669 (* 1 = 5.0669 loss)
I0826 16:40:12.350039 25446 sgd_solver.cpp:138] Iteration 21130, lr = 0.0001
I0826 16:40:14.613696 25446 solver.cpp:243] Iteration 21140, loss = 5.51013
I0826 16:40:14.613720 25446 solver.cpp:259]     Train net output #0: center_loss = 192.053 (* 0.008 = 1.53642 loss)
I0826 16:40:14.613726 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97371 (* 1 = 3.97371 loss)
I0826 16:40:14.613746 25446 sgd_solver.cpp:138] Iteration 21140, lr = 0.0001
I0826 16:40:16.733264 25446 solver.cpp:243] Iteration 21150, loss = 5.33119
I0826 16:40:16.733292 25446 solver.cpp:259]     Train net output #0: center_loss = 234.549 (* 0.008 = 1.87639 loss)
I0826 16:40:16.733299 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.4548 (* 1 = 3.4548 loss)
I0826 16:40:16.733304 25446 sgd_solver.cpp:138] Iteration 21150, lr = 0.0001
I0826 16:40:18.818500 25446 solver.cpp:243] Iteration 21160, loss = 7.358
I0826 16:40:18.818524 25446 solver.cpp:259]     Train net output #0: center_loss = 171.708 (* 0.008 = 1.37366 loss)
I0826 16:40:18.818531 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.98434 (* 1 = 5.98434 loss)
I0826 16:40:18.818534 25446 sgd_solver.cpp:138] Iteration 21160, lr = 0.0001
I0826 16:40:20.875685 25446 solver.cpp:243] Iteration 21170, loss = 6.72734
I0826 16:40:20.875723 25446 solver.cpp:259]     Train net output #0: center_loss = 196.507 (* 0.008 = 1.57205 loss)
I0826 16:40:20.875730 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.15529 (* 1 = 5.15529 loss)
I0826 16:40:20.875733 25446 sgd_solver.cpp:138] Iteration 21170, lr = 0.0001
I0826 16:40:22.934106 25446 solver.cpp:243] Iteration 21180, loss = 6.08145
I0826 16:40:22.934130 25446 solver.cpp:259]     Train net output #0: center_loss = 192.643 (* 0.008 = 1.54114 loss)
I0826 16:40:22.934135 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.54031 (* 1 = 4.54031 loss)
I0826 16:40:22.934139 25446 sgd_solver.cpp:138] Iteration 21180, lr = 0.0001
I0826 16:40:24.994385 25446 solver.cpp:243] Iteration 21190, loss = 6.1614
I0826 16:40:24.994423 25446 solver.cpp:259]     Train net output #0: center_loss = 188.604 (* 0.008 = 1.50883 loss)
I0826 16:40:24.994429 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65257 (* 1 = 4.65257 loss)
I0826 16:40:24.994433 25446 sgd_solver.cpp:138] Iteration 21190, lr = 0.0001
I0826 16:40:27.056792 25446 solver.cpp:243] Iteration 21200, loss = 5.92985
I0826 16:40:27.056830 25446 solver.cpp:259]     Train net output #0: center_loss = 200.928 (* 0.008 = 1.60742 loss)
I0826 16:40:27.056836 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.32243 (* 1 = 4.32243 loss)
I0826 16:40:27.056840 25446 sgd_solver.cpp:138] Iteration 21200, lr = 0.0001
I0826 16:40:29.118300 25446 solver.cpp:243] Iteration 21210, loss = 6.02237
I0826 16:40:29.118432 25446 solver.cpp:259]     Train net output #0: center_loss = 187.234 (* 0.008 = 1.49787 loss)
I0826 16:40:29.118453 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52449 (* 1 = 4.52449 loss)
I0826 16:40:29.118469 25446 sgd_solver.cpp:138] Iteration 21210, lr = 0.0001
I0826 16:40:31.177604 25446 solver.cpp:243] Iteration 21220, loss = 5.37358
I0826 16:40:31.177645 25446 solver.cpp:259]     Train net output #0: center_loss = 183.028 (* 0.008 = 1.46422 loss)
I0826 16:40:31.177651 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.90936 (* 1 = 3.90936 loss)
I0826 16:40:31.177654 25446 sgd_solver.cpp:138] Iteration 21220, lr = 0.0001
I0826 16:40:33.237958 25446 solver.cpp:243] Iteration 21230, loss = 6.59668
I0826 16:40:33.237998 25446 solver.cpp:259]     Train net output #0: center_loss = 189.486 (* 0.008 = 1.51589 loss)
I0826 16:40:33.238005 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.08079 (* 1 = 5.08079 loss)
I0826 16:40:33.238009 25446 sgd_solver.cpp:138] Iteration 21230, lr = 0.0001
I0826 16:40:35.300040 25446 solver.cpp:243] Iteration 21240, loss = 6.16388
I0826 16:40:35.300065 25446 solver.cpp:259]     Train net output #0: center_loss = 177.299 (* 0.008 = 1.41839 loss)
I0826 16:40:35.300071 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.74549 (* 1 = 4.74549 loss)
I0826 16:40:35.300076 25446 sgd_solver.cpp:138] Iteration 21240, lr = 0.0001
I0826 16:40:37.359000 25446 solver.cpp:243] Iteration 21250, loss = 6.89025
I0826 16:40:37.359024 25446 solver.cpp:259]     Train net output #0: center_loss = 198.172 (* 0.008 = 1.58538 loss)
I0826 16:40:37.359045 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.30487 (* 1 = 5.30487 loss)
I0826 16:40:37.359048 25446 sgd_solver.cpp:138] Iteration 21250, lr = 0.0001
I0826 16:40:39.419270 25446 solver.cpp:243] Iteration 21260, loss = 6.51137
I0826 16:40:39.419309 25446 solver.cpp:259]     Train net output #0: center_loss = 191.669 (* 0.008 = 1.53335 loss)
I0826 16:40:39.419315 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.97802 (* 1 = 4.97802 loss)
I0826 16:40:39.419319 25446 sgd_solver.cpp:138] Iteration 21260, lr = 0.0001
I0826 16:40:41.481328 25446 solver.cpp:243] Iteration 21270, loss = 5.59754
I0826 16:40:41.481367 25446 solver.cpp:259]     Train net output #0: center_loss = 218.999 (* 0.008 = 1.75199 loss)
I0826 16:40:41.481374 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.84555 (* 1 = 3.84555 loss)
I0826 16:40:41.481376 25446 sgd_solver.cpp:138] Iteration 21270, lr = 0.0001
I0826 16:40:43.540753 25446 solver.cpp:243] Iteration 21280, loss = 6.72083
I0826 16:40:43.540792 25446 solver.cpp:259]     Train net output #0: center_loss = 180.955 (* 0.008 = 1.44764 loss)
I0826 16:40:43.540798 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.27319 (* 1 = 5.27319 loss)
I0826 16:40:43.540802 25446 sgd_solver.cpp:138] Iteration 21280, lr = 0.0001
I0826 16:40:45.604593 25446 solver.cpp:243] Iteration 21290, loss = 6.36048
I0826 16:40:45.604616 25446 solver.cpp:259]     Train net output #0: center_loss = 203.325 (* 0.008 = 1.6266 loss)
I0826 16:40:45.604622 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.73388 (* 1 = 4.73388 loss)
I0826 16:40:45.604626 25446 sgd_solver.cpp:138] Iteration 21290, lr = 0.0001
I0826 16:40:47.663283 25446 solver.cpp:243] Iteration 21300, loss = 6.21955
I0826 16:40:47.663307 25446 solver.cpp:259]     Train net output #0: center_loss = 220.923 (* 0.008 = 1.76739 loss)
I0826 16:40:47.663313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.45217 (* 1 = 4.45217 loss)
I0826 16:40:47.663317 25446 sgd_solver.cpp:138] Iteration 21300, lr = 0.0001
I0826 16:40:49.721491 25446 solver.cpp:243] Iteration 21310, loss = 6.59832
I0826 16:40:49.721515 25446 solver.cpp:259]     Train net output #0: center_loss = 214.095 (* 0.008 = 1.71276 loss)
I0826 16:40:49.721521 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.88556 (* 1 = 4.88556 loss)
I0826 16:40:49.721525 25446 sgd_solver.cpp:138] Iteration 21310, lr = 0.0001
I0826 16:40:51.782863 25446 solver.cpp:243] Iteration 21320, loss = 6.14903
I0826 16:40:51.782903 25446 solver.cpp:259]     Train net output #0: center_loss = 212.739 (* 0.008 = 1.70191 loss)
I0826 16:40:51.782909 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.44712 (* 1 = 4.44712 loss)
I0826 16:40:51.782913 25446 sgd_solver.cpp:138] Iteration 21320, lr = 0.0001
I0826 16:40:53.837757 25446 solver.cpp:243] Iteration 21330, loss = 4.89317
I0826 16:40:53.837781 25446 solver.cpp:259]     Train net output #0: center_loss = 213.076 (* 0.008 = 1.70461 loss)
I0826 16:40:53.837787 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.18856 (* 1 = 3.18856 loss)
I0826 16:40:53.837791 25446 sgd_solver.cpp:138] Iteration 21330, lr = 0.0001
I0826 16:40:55.898316 25446 solver.cpp:243] Iteration 21340, loss = 5.65242
I0826 16:40:55.898355 25446 solver.cpp:259]     Train net output #0: center_loss = 216.955 (* 0.008 = 1.73564 loss)
I0826 16:40:55.898362 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91678 (* 1 = 3.91678 loss)
I0826 16:40:55.898365 25446 sgd_solver.cpp:138] Iteration 21340, lr = 0.0001
I0826 16:40:57.957348 25446 solver.cpp:243] Iteration 21350, loss = 6.29432
I0826 16:40:57.957372 25446 solver.cpp:259]     Train net output #0: center_loss = 186.485 (* 0.008 = 1.49188 loss)
I0826 16:40:57.957377 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.80244 (* 1 = 4.80244 loss)
I0826 16:40:57.957381 25446 sgd_solver.cpp:138] Iteration 21350, lr = 0.0001
I0826 16:41:00.016693 25446 solver.cpp:243] Iteration 21360, loss = 6.94061
I0826 16:41:00.016868 25446 solver.cpp:259]     Train net output #0: center_loss = 171.006 (* 0.008 = 1.36805 loss)
I0826 16:41:00.016875 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.57256 (* 1 = 5.57256 loss)
I0826 16:41:00.016896 25446 sgd_solver.cpp:138] Iteration 21360, lr = 0.0001
I0826 16:41:02.073555 25446 solver.cpp:243] Iteration 21370, loss = 6.3715
I0826 16:41:02.073596 25446 solver.cpp:259]     Train net output #0: center_loss = 204.879 (* 0.008 = 1.63903 loss)
I0826 16:41:02.073601 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.73247 (* 1 = 4.73247 loss)
I0826 16:41:02.073606 25446 sgd_solver.cpp:138] Iteration 21370, lr = 0.0001
I0826 16:41:04.135159 25446 solver.cpp:243] Iteration 21380, loss = 7.72855
I0826 16:41:04.135197 25446 solver.cpp:259]     Train net output #0: center_loss = 166.962 (* 0.008 = 1.3357 loss)
I0826 16:41:04.135203 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.39285 (* 1 = 6.39285 loss)
I0826 16:41:04.135207 25446 sgd_solver.cpp:138] Iteration 21380, lr = 0.0001
I0826 16:41:06.190263 25446 solver.cpp:243] Iteration 21390, loss = 5.89877
I0826 16:41:06.190286 25446 solver.cpp:259]     Train net output #0: center_loss = 221.437 (* 0.008 = 1.7715 loss)
I0826 16:41:06.190292 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.12727 (* 1 = 4.12727 loss)
I0826 16:41:06.190295 25446 sgd_solver.cpp:138] Iteration 21390, lr = 0.0001
I0826 16:41:08.250700 25446 solver.cpp:243] Iteration 21400, loss = 5.44751
I0826 16:41:08.250741 25446 solver.cpp:259]     Train net output #0: center_loss = 210.106 (* 0.008 = 1.68085 loss)
I0826 16:41:08.250746 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.76666 (* 1 = 3.76666 loss)
I0826 16:41:08.250749 25446 sgd_solver.cpp:138] Iteration 21400, lr = 0.0001
I0826 16:41:10.322041 25446 solver.cpp:243] Iteration 21410, loss = 6.10121
I0826 16:41:10.322067 25446 solver.cpp:259]     Train net output #0: center_loss = 196.577 (* 0.008 = 1.57261 loss)
I0826 16:41:10.322072 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.5286 (* 1 = 4.5286 loss)
I0826 16:41:10.322077 25446 sgd_solver.cpp:138] Iteration 21410, lr = 0.0001
I0826 16:41:12.598732 25446 solver.cpp:243] Iteration 21420, loss = 5.57096
I0826 16:41:12.598773 25446 solver.cpp:259]     Train net output #0: center_loss = 201.354 (* 0.008 = 1.61083 loss)
I0826 16:41:12.598778 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.96013 (* 1 = 3.96013 loss)
I0826 16:41:12.598783 25446 sgd_solver.cpp:138] Iteration 21420, lr = 0.0001
I0826 16:41:14.706423 25446 solver.cpp:243] Iteration 21430, loss = 7.43913
I0826 16:41:14.706447 25446 solver.cpp:259]     Train net output #0: center_loss = 162.351 (* 0.008 = 1.29881 loss)
I0826 16:41:14.706454 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.14032 (* 1 = 6.14032 loss)
I0826 16:41:14.706459 25446 sgd_solver.cpp:138] Iteration 21430, lr = 0.0001
I0826 16:41:16.805253 25446 solver.cpp:243] Iteration 21440, loss = 6.30805
I0826 16:41:16.805279 25446 solver.cpp:259]     Train net output #0: center_loss = 199.191 (* 0.008 = 1.59353 loss)
I0826 16:41:16.805284 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.71452 (* 1 = 4.71452 loss)
I0826 16:41:16.805289 25446 sgd_solver.cpp:138] Iteration 21440, lr = 0.0001
I0826 16:41:18.863976 25446 solver.cpp:243] Iteration 21450, loss = 5.58351
I0826 16:41:18.864013 25446 solver.cpp:259]     Train net output #0: center_loss = 211.01 (* 0.008 = 1.68808 loss)
I0826 16:41:18.864020 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.89543 (* 1 = 3.89543 loss)
I0826 16:41:18.864024 25446 sgd_solver.cpp:138] Iteration 21450, lr = 0.0001
I0826 16:41:20.927034 25446 solver.cpp:243] Iteration 21460, loss = 6.60327
I0826 16:41:20.927074 25446 solver.cpp:259]     Train net output #0: center_loss = 186.193 (* 0.008 = 1.48954 loss)
I0826 16:41:20.927080 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.11373 (* 1 = 5.11373 loss)
I0826 16:41:20.927084 25446 sgd_solver.cpp:138] Iteration 21460, lr = 0.0001
I0826 16:41:22.986155 25446 solver.cpp:243] Iteration 21470, loss = 5.48439
I0826 16:41:22.986179 25446 solver.cpp:259]     Train net output #0: center_loss = 201.286 (* 0.008 = 1.61029 loss)
I0826 16:41:22.986186 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.87409 (* 1 = 3.87409 loss)
I0826 16:41:22.986189 25446 sgd_solver.cpp:138] Iteration 21470, lr = 0.0001
I0826 16:41:25.123734 25446 solver.cpp:243] Iteration 21480, loss = 5.73299
I0826 16:41:25.123773 25446 solver.cpp:259]     Train net output #0: center_loss = 203.058 (* 0.008 = 1.62446 loss)
I0826 16:41:25.123780 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.10853 (* 1 = 4.10853 loss)
I0826 16:41:25.123783 25446 sgd_solver.cpp:138] Iteration 21480, lr = 0.0001
I0826 16:41:27.402431 25446 solver.cpp:243] Iteration 21490, loss = 5.84942
I0826 16:41:27.402454 25446 solver.cpp:259]     Train net output #0: center_loss = 207.594 (* 0.008 = 1.66075 loss)
I0826 16:41:27.402462 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.18867 (* 1 = 4.18867 loss)
I0826 16:41:27.402467 25446 sgd_solver.cpp:138] Iteration 21490, lr = 0.0001
I0826 16:41:29.576226 25446 solver.cpp:243] Iteration 21500, loss = 5.01543
I0826 16:41:29.576267 25446 solver.cpp:259]     Train net output #0: center_loss = 210.327 (* 0.008 = 1.68261 loss)
I0826 16:41:29.576272 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.33282 (* 1 = 3.33282 loss)
I0826 16:41:29.576277 25446 sgd_solver.cpp:138] Iteration 21500, lr = 0.0001
I0826 16:41:31.636672 25446 solver.cpp:243] Iteration 21510, loss = 5.42997
I0826 16:41:31.636788 25446 solver.cpp:259]     Train net output #0: center_loss = 203.716 (* 0.008 = 1.62972 loss)
I0826 16:41:31.636795 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.80024 (* 1 = 3.80024 loss)
I0826 16:41:31.636799 25446 sgd_solver.cpp:138] Iteration 21510, lr = 0.0001
I0826 16:41:33.700549 25446 solver.cpp:243] Iteration 21520, loss = 6.02211
I0826 16:41:33.700590 25446 solver.cpp:259]     Train net output #0: center_loss = 207.629 (* 0.008 = 1.66103 loss)
I0826 16:41:33.700597 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.36108 (* 1 = 4.36108 loss)
I0826 16:41:33.700599 25446 sgd_solver.cpp:138] Iteration 21520, lr = 0.0001
I0826 16:41:35.762615 25446 solver.cpp:243] Iteration 21530, loss = 6.8654
I0826 16:41:35.762655 25446 solver.cpp:259]     Train net output #0: center_loss = 208.86 (* 0.008 = 1.67088 loss)
I0826 16:41:35.762661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.19452 (* 1 = 5.19452 loss)
I0826 16:41:35.762665 25446 sgd_solver.cpp:138] Iteration 21530, lr = 0.0001
I0826 16:41:37.823122 25446 solver.cpp:243] Iteration 21540, loss = 5.99664
I0826 16:41:37.823146 25446 solver.cpp:259]     Train net output #0: center_loss = 213.727 (* 0.008 = 1.70982 loss)
I0826 16:41:37.823153 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.28682 (* 1 = 4.28682 loss)
I0826 16:41:37.823156 25446 sgd_solver.cpp:138] Iteration 21540, lr = 0.0001
I0826 16:41:39.883654 25446 solver.cpp:243] Iteration 21550, loss = 6.52323
I0826 16:41:39.883678 25446 solver.cpp:259]     Train net output #0: center_loss = 191.63 (* 0.008 = 1.53304 loss)
I0826 16:41:39.883684 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.99019 (* 1 = 4.99019 loss)
I0826 16:41:39.883688 25446 sgd_solver.cpp:138] Iteration 21550, lr = 0.0001
I0826 16:41:41.944947 25446 solver.cpp:243] Iteration 21560, loss = 5.19669
I0826 16:41:41.944972 25446 solver.cpp:259]     Train net output #0: center_loss = 222.947 (* 0.008 = 1.78358 loss)
I0826 16:41:41.944977 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.41311 (* 1 = 3.41311 loss)
I0826 16:41:41.944981 25446 sgd_solver.cpp:138] Iteration 21560, lr = 0.0001
I0826 16:41:44.005268 25446 solver.cpp:243] Iteration 21570, loss = 5.75285
I0826 16:41:44.005292 25446 solver.cpp:259]     Train net output #0: center_loss = 221.09 (* 0.008 = 1.76872 loss)
I0826 16:41:44.005298 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.98413 (* 1 = 3.98413 loss)
I0826 16:41:44.005302 25446 sgd_solver.cpp:138] Iteration 21570, lr = 0.0001
I0826 16:41:46.066958 25446 solver.cpp:243] Iteration 21580, loss = 5.76417
I0826 16:41:46.066998 25446 solver.cpp:259]     Train net output #0: center_loss = 224.986 (* 0.008 = 1.79989 loss)
I0826 16:41:46.067004 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.96428 (* 1 = 3.96428 loss)
I0826 16:41:46.067008 25446 sgd_solver.cpp:138] Iteration 21580, lr = 0.0001
I0826 16:41:48.127539 25446 solver.cpp:243] Iteration 21590, loss = 4.92481
I0826 16:41:48.127564 25446 solver.cpp:259]     Train net output #0: center_loss = 217.456 (* 0.008 = 1.73965 loss)
I0826 16:41:48.127570 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.18516 (* 1 = 3.18516 loss)
I0826 16:41:48.127574 25446 sgd_solver.cpp:138] Iteration 21590, lr = 0.0001
I0826 16:41:50.185838 25446 solver.cpp:243] Iteration 21600, loss = 5.45271
I0826 16:41:50.185863 25446 solver.cpp:259]     Train net output #0: center_loss = 226.428 (* 0.008 = 1.81142 loss)
I0826 16:41:50.185869 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.64129 (* 1 = 3.64129 loss)
I0826 16:41:50.185873 25446 sgd_solver.cpp:138] Iteration 21600, lr = 0.0001
I0826 16:41:52.244204 25446 solver.cpp:243] Iteration 21610, loss = 6.20007
I0826 16:41:52.244228 25446 solver.cpp:259]     Train net output #0: center_loss = 209.162 (* 0.008 = 1.6733 loss)
I0826 16:41:52.244233 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52678 (* 1 = 4.52678 loss)
I0826 16:41:52.244238 25446 sgd_solver.cpp:138] Iteration 21610, lr = 0.0001
I0826 16:41:54.433115 25446 solver.cpp:243] Iteration 21620, loss = 7.01284
I0826 16:41:54.433153 25446 solver.cpp:259]     Train net output #0: center_loss = 188.925 (* 0.008 = 1.5114 loss)
I0826 16:41:54.433161 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.50144 (* 1 = 5.50144 loss)
I0826 16:41:54.433166 25446 sgd_solver.cpp:138] Iteration 21620, lr = 0.0001
I0826 16:41:56.608323 25446 solver.cpp:243] Iteration 21630, loss = 6.11957
I0826 16:41:56.608350 25446 solver.cpp:259]     Train net output #0: center_loss = 192.642 (* 0.008 = 1.54114 loss)
I0826 16:41:56.608356 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.57843 (* 1 = 4.57843 loss)
I0826 16:41:56.608361 25446 sgd_solver.cpp:138] Iteration 21630, lr = 0.0001
I0826 16:41:58.874817 25446 solver.cpp:243] Iteration 21640, loss = 6.15371
I0826 16:41:58.874841 25446 solver.cpp:259]     Train net output #0: center_loss = 197.239 (* 0.008 = 1.57792 loss)
I0826 16:41:58.874847 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.5758 (* 1 = 4.5758 loss)
I0826 16:41:58.874851 25446 sgd_solver.cpp:138] Iteration 21640, lr = 0.0001
I0826 16:42:01.100332 25446 solver.cpp:243] Iteration 21650, loss = 5.60101
I0826 16:42:01.100358 25446 solver.cpp:259]     Train net output #0: center_loss = 227.046 (* 0.008 = 1.81637 loss)
I0826 16:42:01.100365 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.78465 (* 1 = 3.78465 loss)
I0826 16:42:01.100370 25446 sgd_solver.cpp:138] Iteration 21650, lr = 0.0001
I0826 16:42:03.257298 25446 solver.cpp:243] Iteration 21660, loss = 5.82028
I0826 16:42:03.257413 25446 solver.cpp:259]     Train net output #0: center_loss = 199.214 (* 0.008 = 1.59371 loss)
I0826 16:42:03.257421 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.22657 (* 1 = 4.22657 loss)
I0826 16:42:03.257426 25446 sgd_solver.cpp:138] Iteration 21660, lr = 0.0001
I0826 16:42:05.448168 25446 solver.cpp:243] Iteration 21670, loss = 6.34212
I0826 16:42:05.448194 25446 solver.cpp:259]     Train net output #0: center_loss = 204.167 (* 0.008 = 1.63334 loss)
I0826 16:42:05.448199 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70878 (* 1 = 4.70878 loss)
I0826 16:42:05.448204 25446 sgd_solver.cpp:138] Iteration 21670, lr = 0.0001
I0826 16:42:07.583968 25446 solver.cpp:243] Iteration 21680, loss = 6.24014
I0826 16:42:07.583992 25446 solver.cpp:259]     Train net output #0: center_loss = 190.481 (* 0.008 = 1.52385 loss)
I0826 16:42:07.583999 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.71629 (* 1 = 4.71629 loss)
I0826 16:42:07.584002 25446 sgd_solver.cpp:138] Iteration 21680, lr = 0.0001
I0826 16:42:09.741869 25446 solver.cpp:243] Iteration 21690, loss = 6.04539
I0826 16:42:09.741894 25446 solver.cpp:259]     Train net output #0: center_loss = 184.739 (* 0.008 = 1.47791 loss)
I0826 16:42:09.741900 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.56748 (* 1 = 4.56748 loss)
I0826 16:42:09.741904 25446 sgd_solver.cpp:138] Iteration 21690, lr = 0.0001
I0826 16:42:11.801604 25446 solver.cpp:243] Iteration 21700, loss = 6.38376
I0826 16:42:11.801628 25446 solver.cpp:259]     Train net output #0: center_loss = 202.07 (* 0.008 = 1.61656 loss)
I0826 16:42:11.801635 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.7672 (* 1 = 4.7672 loss)
I0826 16:42:11.801653 25446 sgd_solver.cpp:138] Iteration 21700, lr = 0.0001
I0826 16:42:13.863651 25446 solver.cpp:243] Iteration 21710, loss = 5.61669
I0826 16:42:13.863674 25446 solver.cpp:259]     Train net output #0: center_loss = 214.596 (* 0.008 = 1.71677 loss)
I0826 16:42:13.863679 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.89992 (* 1 = 3.89992 loss)
I0826 16:42:13.863683 25446 sgd_solver.cpp:138] Iteration 21710, lr = 0.0001
I0826 16:42:15.929379 25446 solver.cpp:243] Iteration 21720, loss = 5.75176
I0826 16:42:15.929404 25446 solver.cpp:259]     Train net output #0: center_loss = 199.791 (* 0.008 = 1.59833 loss)
I0826 16:42:15.929409 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.15343 (* 1 = 4.15343 loss)
I0826 16:42:15.929414 25446 sgd_solver.cpp:138] Iteration 21720, lr = 0.0001
I0826 16:42:17.988600 25446 solver.cpp:243] Iteration 21730, loss = 5.40197
I0826 16:42:17.988623 25446 solver.cpp:259]     Train net output #0: center_loss = 184.913 (* 0.008 = 1.4793 loss)
I0826 16:42:17.988629 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.92267 (* 1 = 3.92267 loss)
I0826 16:42:17.988633 25446 sgd_solver.cpp:138] Iteration 21730, lr = 0.0001
I0826 16:42:20.047833 25446 solver.cpp:243] Iteration 21740, loss = 5.2148
I0826 16:42:20.047857 25446 solver.cpp:259]     Train net output #0: center_loss = 211.197 (* 0.008 = 1.68958 loss)
I0826 16:42:20.047863 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.52522 (* 1 = 3.52522 loss)
I0826 16:42:20.047866 25446 sgd_solver.cpp:138] Iteration 21740, lr = 0.0001
I0826 16:42:22.110414 25446 solver.cpp:243] Iteration 21750, loss = 6.8709
I0826 16:42:22.110440 25446 solver.cpp:259]     Train net output #0: center_loss = 186.222 (* 0.008 = 1.48978 loss)
I0826 16:42:22.110445 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.38112 (* 1 = 5.38112 loss)
I0826 16:42:22.110448 25446 sgd_solver.cpp:138] Iteration 21750, lr = 0.0001
I0826 16:42:24.166069 25446 solver.cpp:243] Iteration 21760, loss = 6.12658
I0826 16:42:24.166107 25446 solver.cpp:259]     Train net output #0: center_loss = 219.367 (* 0.008 = 1.75494 loss)
I0826 16:42:24.166113 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.37164 (* 1 = 4.37164 loss)
I0826 16:42:24.166117 25446 sgd_solver.cpp:138] Iteration 21760, lr = 0.0001
I0826 16:42:26.228914 25446 solver.cpp:243] Iteration 21770, loss = 5.73089
I0826 16:42:26.228955 25446 solver.cpp:259]     Train net output #0: center_loss = 221.212 (* 0.008 = 1.76969 loss)
I0826 16:42:26.228960 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9612 (* 1 = 3.9612 loss)
I0826 16:42:26.228963 25446 sgd_solver.cpp:138] Iteration 21770, lr = 0.0001
I0826 16:42:28.294473 25446 solver.cpp:243] Iteration 21780, loss = 5.6718
I0826 16:42:28.294498 25446 solver.cpp:259]     Train net output #0: center_loss = 209.631 (* 0.008 = 1.67705 loss)
I0826 16:42:28.294504 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.99475 (* 1 = 3.99475 loss)
I0826 16:42:28.294508 25446 sgd_solver.cpp:138] Iteration 21780, lr = 0.0001
I0826 16:42:30.359184 25446 solver.cpp:243] Iteration 21790, loss = 6.15106
I0826 16:42:30.359210 25446 solver.cpp:259]     Train net output #0: center_loss = 214.511 (* 0.008 = 1.71609 loss)
I0826 16:42:30.359216 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43497 (* 1 = 4.43497 loss)
I0826 16:42:30.359220 25446 sgd_solver.cpp:138] Iteration 21790, lr = 0.0001
I0826 16:42:32.639056 25446 solver.cpp:243] Iteration 21800, loss = 5.48301
I0826 16:42:32.639082 25446 solver.cpp:259]     Train net output #0: center_loss = 191.638 (* 0.008 = 1.53311 loss)
I0826 16:42:32.639088 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9499 (* 1 = 3.9499 loss)
I0826 16:42:32.639093 25446 sgd_solver.cpp:138] Iteration 21800, lr = 0.0001
I0826 16:42:34.859328 25446 solver.cpp:243] Iteration 21810, loss = 5.39306
I0826 16:42:34.859485 25446 solver.cpp:259]     Train net output #0: center_loss = 218.487 (* 0.008 = 1.74789 loss)
I0826 16:42:34.859493 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.64517 (* 1 = 3.64517 loss)
I0826 16:42:34.859498 25446 sgd_solver.cpp:138] Iteration 21810, lr = 0.0001
I0826 16:42:36.961397 25446 solver.cpp:243] Iteration 21820, loss = 5.80939
I0826 16:42:36.961436 25446 solver.cpp:259]     Train net output #0: center_loss = 214.182 (* 0.008 = 1.71346 loss)
I0826 16:42:36.961443 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.09593 (* 1 = 4.09593 loss)
I0826 16:42:36.961447 25446 sgd_solver.cpp:138] Iteration 21820, lr = 0.0001
I0826 16:42:39.024248 25446 solver.cpp:243] Iteration 21830, loss = 6.17763
I0826 16:42:39.024288 25446 solver.cpp:259]     Train net output #0: center_loss = 198.954 (* 0.008 = 1.59164 loss)
I0826 16:42:39.024294 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.586 (* 1 = 4.586 loss)
I0826 16:42:39.024298 25446 sgd_solver.cpp:138] Iteration 21830, lr = 0.0001
I0826 16:42:41.082973 25446 solver.cpp:243] Iteration 21840, loss = 5.863
I0826 16:42:41.083011 25446 solver.cpp:259]     Train net output #0: center_loss = 198.521 (* 0.008 = 1.58817 loss)
I0826 16:42:41.083017 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.27483 (* 1 = 4.27483 loss)
I0826 16:42:41.083020 25446 sgd_solver.cpp:138] Iteration 21840, lr = 0.0001
I0826 16:42:43.225514 25446 solver.cpp:243] Iteration 21850, loss = 6.26139
I0826 16:42:43.225538 25446 solver.cpp:259]     Train net output #0: center_loss = 195.488 (* 0.008 = 1.56391 loss)
I0826 16:42:43.225543 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.69748 (* 1 = 4.69748 loss)
I0826 16:42:43.225548 25446 sgd_solver.cpp:138] Iteration 21850, lr = 0.0001
I0826 16:42:45.365368 25446 solver.cpp:243] Iteration 21860, loss = 6.25708
I0826 16:42:45.365406 25446 solver.cpp:259]     Train net output #0: center_loss = 188.661 (* 0.008 = 1.50929 loss)
I0826 16:42:45.365412 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.74779 (* 1 = 4.74779 loss)
I0826 16:42:45.365417 25446 sgd_solver.cpp:138] Iteration 21860, lr = 0.0001
I0826 16:42:47.507814 25446 solver.cpp:243] Iteration 21870, loss = 5.5891
I0826 16:42:47.507853 25446 solver.cpp:259]     Train net output #0: center_loss = 192.49 (* 0.008 = 1.53992 loss)
I0826 16:42:47.507859 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04918 (* 1 = 4.04918 loss)
I0826 16:42:47.507863 25446 sgd_solver.cpp:138] Iteration 21870, lr = 0.0001
I0826 16:42:49.650336 25446 solver.cpp:243] Iteration 21880, loss = 6.52601
I0826 16:42:49.650377 25446 solver.cpp:259]     Train net output #0: center_loss = 179.373 (* 0.008 = 1.43498 loss)
I0826 16:42:49.650382 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.09103 (* 1 = 5.09103 loss)
I0826 16:42:49.650386 25446 sgd_solver.cpp:138] Iteration 21880, lr = 0.0001
I0826 16:42:51.792752 25446 solver.cpp:243] Iteration 21890, loss = 5.13673
I0826 16:42:51.792790 25446 solver.cpp:259]     Train net output #0: center_loss = 209.565 (* 0.008 = 1.67652 loss)
I0826 16:42:51.792796 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.46021 (* 1 = 3.46021 loss)
I0826 16:42:51.792800 25446 sgd_solver.cpp:138] Iteration 21890, lr = 0.0001
I0826 16:42:53.854730 25446 solver.cpp:243] Iteration 21900, loss = 5.17652
I0826 16:42:53.854769 25446 solver.cpp:259]     Train net output #0: center_loss = 244.272 (* 0.008 = 1.95418 loss)
I0826 16:42:53.854775 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.22234 (* 1 = 3.22234 loss)
I0826 16:42:53.854779 25446 sgd_solver.cpp:138] Iteration 21900, lr = 0.0001
I0826 16:42:55.917711 25446 solver.cpp:243] Iteration 21910, loss = 5.82723
I0826 16:42:55.917734 25446 solver.cpp:259]     Train net output #0: center_loss = 218.057 (* 0.008 = 1.74445 loss)
I0826 16:42:55.917740 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.08278 (* 1 = 4.08278 loss)
I0826 16:42:55.917744 25446 sgd_solver.cpp:138] Iteration 21910, lr = 0.0001
I0826 16:42:58.061445 25446 solver.cpp:243] Iteration 21920, loss = 5.67901
I0826 16:42:58.061484 25446 solver.cpp:259]     Train net output #0: center_loss = 201.388 (* 0.008 = 1.6111 loss)
I0826 16:42:58.061491 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.06791 (* 1 = 4.06791 loss)
I0826 16:42:58.061496 25446 sgd_solver.cpp:138] Iteration 21920, lr = 0.0001
I0826 16:43:00.220306 25446 solver.cpp:243] Iteration 21930, loss = 5.72623
I0826 16:43:00.220357 25446 solver.cpp:259]     Train net output #0: center_loss = 215.098 (* 0.008 = 1.72079 loss)
I0826 16:43:00.220365 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.00544 (* 1 = 4.00544 loss)
I0826 16:43:00.220368 25446 sgd_solver.cpp:138] Iteration 21930, lr = 0.0001
I0826 16:43:02.390512 25446 solver.cpp:243] Iteration 21940, loss = 5.64365
I0826 16:43:02.390537 25446 solver.cpp:259]     Train net output #0: center_loss = 205.321 (* 0.008 = 1.64257 loss)
I0826 16:43:02.390542 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.00108 (* 1 = 4.00108 loss)
I0826 16:43:02.390547 25446 sgd_solver.cpp:138] Iteration 21940, lr = 0.0001
I0826 16:43:04.451795 25446 solver.cpp:243] Iteration 21950, loss = 6.42214
I0826 16:43:04.451819 25446 solver.cpp:259]     Train net output #0: center_loss = 217.211 (* 0.008 = 1.73769 loss)
I0826 16:43:04.451825 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.68445 (* 1 = 4.68445 loss)
I0826 16:43:04.451829 25446 sgd_solver.cpp:138] Iteration 21950, lr = 0.0001
I0826 16:43:06.577311 25446 solver.cpp:243] Iteration 21960, loss = 5.67975
I0826 16:43:06.577442 25446 solver.cpp:259]     Train net output #0: center_loss = 214.712 (* 0.008 = 1.71769 loss)
I0826 16:43:06.577463 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.96205 (* 1 = 3.96205 loss)
I0826 16:43:06.577467 25446 sgd_solver.cpp:138] Iteration 21960, lr = 0.0001
I0826 16:43:08.716729 25446 solver.cpp:243] Iteration 21970, loss = 4.85796
I0826 16:43:08.716755 25446 solver.cpp:259]     Train net output #0: center_loss = 194.049 (* 0.008 = 1.55239 loss)
I0826 16:43:08.716761 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.30557 (* 1 = 3.30557 loss)
I0826 16:43:08.716765 25446 sgd_solver.cpp:138] Iteration 21970, lr = 0.0001
I0826 16:43:10.832181 25446 solver.cpp:243] Iteration 21980, loss = 5.94788
I0826 16:43:10.832207 25446 solver.cpp:259]     Train net output #0: center_loss = 215.733 (* 0.008 = 1.72587 loss)
I0826 16:43:10.832213 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.22201 (* 1 = 4.22201 loss)
I0826 16:43:10.832218 25446 sgd_solver.cpp:138] Iteration 21980, lr = 0.0001
I0826 16:43:13.002161 25446 solver.cpp:243] Iteration 21990, loss = 6.09213
I0826 16:43:13.002200 25446 solver.cpp:259]     Train net output #0: center_loss = 219.661 (* 0.008 = 1.75729 loss)
I0826 16:43:13.002207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.33485 (* 1 = 4.33485 loss)
I0826 16:43:13.002212 25446 sgd_solver.cpp:138] Iteration 21990, lr = 0.0001
I0826 16:43:14.942703 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_22000.caffemodel
I0826 16:43:16.076252 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_22000.solverstate
I0826 16:43:16.414081 25446 solver.cpp:243] Iteration 22000, loss = 6.54419
I0826 16:43:16.414106 25446 solver.cpp:259]     Train net output #0: center_loss = 191.184 (* 0.008 = 1.52947 loss)
I0826 16:43:16.414113 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.01472 (* 1 = 5.01472 loss)
I0826 16:43:16.414117 25446 sgd_solver.cpp:138] Iteration 22000, lr = 0.0001
I0826 16:43:18.528602 25446 solver.cpp:243] Iteration 22010, loss = 5.91488
I0826 16:43:18.528628 25446 solver.cpp:259]     Train net output #0: center_loss = 207.359 (* 0.008 = 1.65887 loss)
I0826 16:43:18.528635 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.25601 (* 1 = 4.25601 loss)
I0826 16:43:18.528640 25446 sgd_solver.cpp:138] Iteration 22010, lr = 0.0001
I0826 16:43:20.677834 25446 solver.cpp:243] Iteration 22020, loss = 5.50448
I0826 16:43:20.677860 25446 solver.cpp:259]     Train net output #0: center_loss = 223.152 (* 0.008 = 1.78522 loss)
I0826 16:43:20.677866 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.71926 (* 1 = 3.71926 loss)
I0826 16:43:20.677871 25446 sgd_solver.cpp:138] Iteration 22020, lr = 0.0001
I0826 16:43:22.830816 25446 solver.cpp:243] Iteration 22030, loss = 5.54804
I0826 16:43:22.830840 25446 solver.cpp:259]     Train net output #0: center_loss = 204.62 (* 0.008 = 1.63696 loss)
I0826 16:43:22.830847 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91108 (* 1 = 3.91108 loss)
I0826 16:43:22.830850 25446 sgd_solver.cpp:138] Iteration 22030, lr = 0.0001
I0826 16:43:24.990216 25446 solver.cpp:243] Iteration 22040, loss = 6.41842
I0826 16:43:24.990239 25446 solver.cpp:259]     Train net output #0: center_loss = 199.599 (* 0.008 = 1.59679 loss)
I0826 16:43:24.990245 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82163 (* 1 = 4.82163 loss)
I0826 16:43:24.990248 25446 sgd_solver.cpp:138] Iteration 22040, lr = 0.0001
I0826 16:43:27.141213 25446 solver.cpp:243] Iteration 22050, loss = 6.31235
I0826 16:43:27.141237 25446 solver.cpp:259]     Train net output #0: center_loss = 204.708 (* 0.008 = 1.63766 loss)
I0826 16:43:27.141244 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.67468 (* 1 = 4.67468 loss)
I0826 16:43:27.141252 25446 sgd_solver.cpp:138] Iteration 22050, lr = 0.0001
I0826 16:43:29.298202 25446 solver.cpp:243] Iteration 22060, loss = 6.54128
I0826 16:43:29.298269 25446 solver.cpp:259]     Train net output #0: center_loss = 212.923 (* 0.008 = 1.70338 loss)
I0826 16:43:29.298274 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.8379 (* 1 = 4.8379 loss)
I0826 16:43:29.298279 25446 sgd_solver.cpp:138] Iteration 22060, lr = 0.0001
I0826 16:43:31.550765 25446 solver.cpp:243] Iteration 22070, loss = 6.54859
I0826 16:43:31.550787 25446 solver.cpp:259]     Train net output #0: center_loss = 212.641 (* 0.008 = 1.70113 loss)
I0826 16:43:31.550793 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.84746 (* 1 = 4.84746 loss)
I0826 16:43:31.550797 25446 sgd_solver.cpp:138] Iteration 22070, lr = 0.0001
I0826 16:43:33.693217 25446 solver.cpp:243] Iteration 22080, loss = 5.5019
I0826 16:43:33.693243 25446 solver.cpp:259]     Train net output #0: center_loss = 203.586 (* 0.008 = 1.62868 loss)
I0826 16:43:33.693253 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.87322 (* 1 = 3.87322 loss)
I0826 16:43:33.693258 25446 sgd_solver.cpp:138] Iteration 22080, lr = 0.0001
I0826 16:43:35.755209 25446 solver.cpp:243] Iteration 22090, loss = 4.93006
I0826 16:43:35.755234 25446 solver.cpp:259]     Train net output #0: center_loss = 238.514 (* 0.008 = 1.90812 loss)
I0826 16:43:35.755239 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.02194 (* 1 = 3.02194 loss)
I0826 16:43:35.755244 25446 sgd_solver.cpp:138] Iteration 22090, lr = 0.0001
I0826 16:43:38.000655 25446 solver.cpp:243] Iteration 22100, loss = 6.05569
I0826 16:43:38.000826 25446 solver.cpp:259]     Train net output #0: center_loss = 211.77 (* 0.008 = 1.69416 loss)
I0826 16:43:38.000833 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.36153 (* 1 = 4.36153 loss)
I0826 16:43:38.000838 25446 sgd_solver.cpp:138] Iteration 22100, lr = 0.0001
I0826 16:43:40.120151 25446 solver.cpp:243] Iteration 22110, loss = 6.20285
I0826 16:43:40.120177 25446 solver.cpp:259]     Train net output #0: center_loss = 182.743 (* 0.008 = 1.46194 loss)
I0826 16:43:40.120183 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.74091 (* 1 = 4.74091 loss)
I0826 16:43:40.120188 25446 sgd_solver.cpp:138] Iteration 22110, lr = 0.0001
I0826 16:43:42.320407 25446 solver.cpp:243] Iteration 22120, loss = 6.18998
I0826 16:43:42.320448 25446 solver.cpp:259]     Train net output #0: center_loss = 203.176 (* 0.008 = 1.62541 loss)
I0826 16:43:42.320454 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.56457 (* 1 = 4.56457 loss)
I0826 16:43:42.320458 25446 sgd_solver.cpp:138] Iteration 22120, lr = 0.0001
I0826 16:43:44.452390 25446 solver.cpp:243] Iteration 22130, loss = 5.78208
I0826 16:43:44.452430 25446 solver.cpp:259]     Train net output #0: center_loss = 182.244 (* 0.008 = 1.45795 loss)
I0826 16:43:44.452436 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.32413 (* 1 = 4.32413 loss)
I0826 16:43:44.452440 25446 sgd_solver.cpp:138] Iteration 22130, lr = 0.0001
I0826 16:43:46.611033 25446 solver.cpp:243] Iteration 22140, loss = 6.84538
I0826 16:43:46.611057 25446 solver.cpp:259]     Train net output #0: center_loss = 183.276 (* 0.008 = 1.46621 loss)
I0826 16:43:46.611064 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.37918 (* 1 = 5.37918 loss)
I0826 16:43:46.611068 25446 sgd_solver.cpp:138] Iteration 22140, lr = 0.0001
I0826 16:43:48.672948 25446 solver.cpp:243] Iteration 22150, loss = 5.02385
I0826 16:43:48.672974 25446 solver.cpp:259]     Train net output #0: center_loss = 218.132 (* 0.008 = 1.74506 loss)
I0826 16:43:48.672979 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.27879 (* 1 = 3.27879 loss)
I0826 16:43:48.672983 25446 sgd_solver.cpp:138] Iteration 22150, lr = 0.0001
I0826 16:43:50.737234 25446 solver.cpp:243] Iteration 22160, loss = 5.80878
I0826 16:43:50.737277 25446 solver.cpp:259]     Train net output #0: center_loss = 200.707 (* 0.008 = 1.60565 loss)
I0826 16:43:50.737283 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.20312 (* 1 = 4.20312 loss)
I0826 16:43:50.737287 25446 sgd_solver.cpp:138] Iteration 22160, lr = 0.0001
I0826 16:43:52.801226 25446 solver.cpp:243] Iteration 22170, loss = 5.98851
I0826 16:43:52.801271 25446 solver.cpp:259]     Train net output #0: center_loss = 214.986 (* 0.008 = 1.71989 loss)
I0826 16:43:52.801277 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.26862 (* 1 = 4.26862 loss)
I0826 16:43:52.801281 25446 sgd_solver.cpp:138] Iteration 22170, lr = 0.0001
I0826 16:43:54.861634 25446 solver.cpp:243] Iteration 22180, loss = 5.83247
I0826 16:43:54.861672 25446 solver.cpp:259]     Train net output #0: center_loss = 192.859 (* 0.008 = 1.54287 loss)
I0826 16:43:54.861678 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.2896 (* 1 = 4.2896 loss)
I0826 16:43:54.861681 25446 sgd_solver.cpp:138] Iteration 22180, lr = 0.0001
I0826 16:43:56.918969 25446 solver.cpp:243] Iteration 22190, loss = 6.21864
I0826 16:43:56.918993 25446 solver.cpp:259]     Train net output #0: center_loss = 176.302 (* 0.008 = 1.41042 loss)
I0826 16:43:56.918998 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.80822 (* 1 = 4.80822 loss)
I0826 16:43:56.919003 25446 sgd_solver.cpp:138] Iteration 22190, lr = 0.0001
I0826 16:43:58.980144 25446 solver.cpp:243] Iteration 22200, loss = 6.33229
I0826 16:43:58.980181 25446 solver.cpp:259]     Train net output #0: center_loss = 201.381 (* 0.008 = 1.61105 loss)
I0826 16:43:58.980188 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.72124 (* 1 = 4.72124 loss)
I0826 16:43:58.980191 25446 sgd_solver.cpp:138] Iteration 22200, lr = 0.0001
I0826 16:44:01.045384 25446 solver.cpp:243] Iteration 22210, loss = 6.37063
I0826 16:44:01.045408 25446 solver.cpp:259]     Train net output #0: center_loss = 196.923 (* 0.008 = 1.57538 loss)
I0826 16:44:01.045414 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79525 (* 1 = 4.79525 loss)
I0826 16:44:01.045418 25446 sgd_solver.cpp:138] Iteration 22210, lr = 0.0001
I0826 16:44:03.104576 25446 solver.cpp:243] Iteration 22220, loss = 5.86289
I0826 16:44:03.104601 25446 solver.cpp:259]     Train net output #0: center_loss = 202.398 (* 0.008 = 1.61919 loss)
I0826 16:44:03.104607 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.2437 (* 1 = 4.2437 loss)
I0826 16:44:03.104610 25446 sgd_solver.cpp:138] Iteration 22220, lr = 0.0001
I0826 16:44:05.166208 25446 solver.cpp:243] Iteration 22230, loss = 6.43825
I0826 16:44:05.166232 25446 solver.cpp:259]     Train net output #0: center_loss = 217.718 (* 0.008 = 1.74174 loss)
I0826 16:44:05.166239 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.6965 (* 1 = 4.6965 loss)
I0826 16:44:05.166242 25446 sgd_solver.cpp:138] Iteration 22230, lr = 0.0001
I0826 16:44:07.223135 25446 solver.cpp:243] Iteration 22240, loss = 6.44046
I0826 16:44:07.223160 25446 solver.cpp:259]     Train net output #0: center_loss = 203.228 (* 0.008 = 1.62583 loss)
I0826 16:44:07.223167 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.81463 (* 1 = 4.81463 loss)
I0826 16:44:07.223171 25446 sgd_solver.cpp:138] Iteration 22240, lr = 0.0001
I0826 16:44:09.286986 25446 solver.cpp:243] Iteration 22250, loss = 5.92736
I0826 16:44:09.287103 25446 solver.cpp:259]     Train net output #0: center_loss = 218.429 (* 0.008 = 1.74744 loss)
I0826 16:44:09.287123 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.17992 (* 1 = 4.17992 loss)
I0826 16:44:09.287127 25446 sgd_solver.cpp:138] Iteration 22250, lr = 0.0001
I0826 16:44:11.346721 25446 solver.cpp:243] Iteration 22260, loss = 6.95302
I0826 16:44:11.346746 25446 solver.cpp:259]     Train net output #0: center_loss = 201.747 (* 0.008 = 1.61398 loss)
I0826 16:44:11.346752 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.33904 (* 1 = 5.33904 loss)
I0826 16:44:11.346756 25446 sgd_solver.cpp:138] Iteration 22260, lr = 0.0001
I0826 16:44:13.409915 25446 solver.cpp:243] Iteration 22270, loss = 6.28483
I0826 16:44:13.409940 25446 solver.cpp:259]     Train net output #0: center_loss = 187.939 (* 0.008 = 1.50351 loss)
I0826 16:44:13.409946 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.78132 (* 1 = 4.78132 loss)
I0826 16:44:13.409950 25446 sgd_solver.cpp:138] Iteration 22270, lr = 0.0001
I0826 16:44:15.471621 25446 solver.cpp:243] Iteration 22280, loss = 6.31161
I0826 16:44:15.471645 25446 solver.cpp:259]     Train net output #0: center_loss = 185.474 (* 0.008 = 1.48379 loss)
I0826 16:44:15.471650 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82782 (* 1 = 4.82782 loss)
I0826 16:44:15.471654 25446 sgd_solver.cpp:138] Iteration 22280, lr = 0.0001
I0826 16:44:17.531842 25446 solver.cpp:243] Iteration 22290, loss = 5.87394
I0826 16:44:17.531868 25446 solver.cpp:259]     Train net output #0: center_loss = 220.653 (* 0.008 = 1.76522 loss)
I0826 16:44:17.531874 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.10872 (* 1 = 4.10872 loss)
I0826 16:44:17.531878 25446 sgd_solver.cpp:138] Iteration 22290, lr = 0.0001
I0826 16:44:19.594439 25446 solver.cpp:243] Iteration 22300, loss = 5.81631
I0826 16:44:19.594462 25446 solver.cpp:259]     Train net output #0: center_loss = 190.761 (* 0.008 = 1.52609 loss)
I0826 16:44:19.594468 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29022 (* 1 = 4.29022 loss)
I0826 16:44:19.594472 25446 sgd_solver.cpp:138] Iteration 22300, lr = 0.0001
I0826 16:44:21.653219 25446 solver.cpp:243] Iteration 22310, loss = 5.32834
I0826 16:44:21.653244 25446 solver.cpp:259]     Train net output #0: center_loss = 204.14 (* 0.008 = 1.63312 loss)
I0826 16:44:21.653270 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.69522 (* 1 = 3.69522 loss)
I0826 16:44:21.653275 25446 sgd_solver.cpp:138] Iteration 22310, lr = 0.0001
I0826 16:44:23.718134 25446 solver.cpp:243] Iteration 22320, loss = 6.20194
I0826 16:44:23.718161 25446 solver.cpp:259]     Train net output #0: center_loss = 201.939 (* 0.008 = 1.61551 loss)
I0826 16:44:23.718168 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.58642 (* 1 = 4.58642 loss)
I0826 16:44:23.718173 25446 sgd_solver.cpp:138] Iteration 22320, lr = 0.0001
I0826 16:44:25.958688 25446 solver.cpp:243] Iteration 22330, loss = 6.15675
I0826 16:44:25.958725 25446 solver.cpp:259]     Train net output #0: center_loss = 202.769 (* 0.008 = 1.62215 loss)
I0826 16:44:25.958732 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.5346 (* 1 = 4.5346 loss)
I0826 16:44:25.958736 25446 sgd_solver.cpp:138] Iteration 22330, lr = 0.0001
I0826 16:44:28.118829 25446 solver.cpp:243] Iteration 22340, loss = 6.0549
I0826 16:44:28.118868 25446 solver.cpp:259]     Train net output #0: center_loss = 217.087 (* 0.008 = 1.7367 loss)
I0826 16:44:28.118875 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.3182 (* 1 = 4.3182 loss)
I0826 16:44:28.118878 25446 sgd_solver.cpp:138] Iteration 22340, lr = 0.0001
I0826 16:44:30.313680 25446 solver.cpp:243] Iteration 22350, loss = 5.43359
I0826 16:44:30.313720 25446 solver.cpp:259]     Train net output #0: center_loss = 214.534 (* 0.008 = 1.71627 loss)
I0826 16:44:30.313726 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.71731 (* 1 = 3.71731 loss)
I0826 16:44:30.313730 25446 sgd_solver.cpp:138] Iteration 22350, lr = 0.0001
I0826 16:44:32.587213 25446 solver.cpp:243] Iteration 22360, loss = 5.72772
I0826 16:44:32.587254 25446 solver.cpp:259]     Train net output #0: center_loss = 191.569 (* 0.008 = 1.53255 loss)
I0826 16:44:32.587260 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.19517 (* 1 = 4.19517 loss)
I0826 16:44:32.587263 25446 sgd_solver.cpp:138] Iteration 22360, lr = 0.0001
I0826 16:44:34.872341 25446 solver.cpp:243] Iteration 22370, loss = 6.62326
I0826 16:44:34.872366 25446 solver.cpp:259]     Train net output #0: center_loss = 188.081 (* 0.008 = 1.50465 loss)
I0826 16:44:34.872372 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.11862 (* 1 = 5.11862 loss)
I0826 16:44:34.872376 25446 sgd_solver.cpp:138] Iteration 22370, lr = 0.0001
I0826 16:44:37.029589 25446 solver.cpp:243] Iteration 22380, loss = 6.97962
I0826 16:44:37.029628 25446 solver.cpp:259]     Train net output #0: center_loss = 167.772 (* 0.008 = 1.34217 loss)
I0826 16:44:37.029635 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.63745 (* 1 = 5.63745 loss)
I0826 16:44:37.029639 25446 sgd_solver.cpp:138] Iteration 22380, lr = 0.0001
I0826 16:44:39.090668 25446 solver.cpp:243] Iteration 22390, loss = 4.81821
I0826 16:44:39.090693 25446 solver.cpp:259]     Train net output #0: center_loss = 237.747 (* 0.008 = 1.90198 loss)
I0826 16:44:39.090698 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.91623 (* 1 = 2.91623 loss)
I0826 16:44:39.090703 25446 sgd_solver.cpp:138] Iteration 22390, lr = 0.0001
I0826 16:44:41.281826 25446 solver.cpp:243] Iteration 22400, loss = 5.82932
I0826 16:44:41.281950 25446 solver.cpp:259]     Train net output #0: center_loss = 182.205 (* 0.008 = 1.45764 loss)
I0826 16:44:41.281957 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.37168 (* 1 = 4.37168 loss)
I0826 16:44:41.281962 25446 sgd_solver.cpp:138] Iteration 22400, lr = 0.0001
I0826 16:44:43.366443 25446 solver.cpp:243] Iteration 22410, loss = 6.00682
I0826 16:44:43.366469 25446 solver.cpp:259]     Train net output #0: center_loss = 196.537 (* 0.008 = 1.5723 loss)
I0826 16:44:43.366475 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43452 (* 1 = 4.43452 loss)
I0826 16:44:43.366479 25446 sgd_solver.cpp:138] Iteration 22410, lr = 0.0001
I0826 16:44:45.489522 25446 solver.cpp:243] Iteration 22420, loss = 6.14422
I0826 16:44:45.489547 25446 solver.cpp:259]     Train net output #0: center_loss = 207.844 (* 0.008 = 1.66275 loss)
I0826 16:44:45.489553 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.48146 (* 1 = 4.48146 loss)
I0826 16:44:45.489557 25446 sgd_solver.cpp:138] Iteration 22420, lr = 0.0001
I0826 16:44:47.600287 25446 solver.cpp:243] Iteration 22430, loss = 5.95941
I0826 16:44:47.600314 25446 solver.cpp:259]     Train net output #0: center_loss = 188.855 (* 0.008 = 1.51084 loss)
I0826 16:44:47.600319 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.44857 (* 1 = 4.44857 loss)
I0826 16:44:47.600324 25446 sgd_solver.cpp:138] Iteration 22430, lr = 0.0001
I0826 16:44:49.693491 25446 solver.cpp:243] Iteration 22440, loss = 5.93123
I0826 16:44:49.693531 25446 solver.cpp:259]     Train net output #0: center_loss = 210.607 (* 0.008 = 1.68485 loss)
I0826 16:44:49.693537 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.24637 (* 1 = 4.24637 loss)
I0826 16:44:49.693542 25446 sgd_solver.cpp:138] Iteration 22440, lr = 0.0001
I0826 16:44:51.776465 25446 solver.cpp:243] Iteration 22450, loss = 4.23699
I0826 16:44:51.776494 25446 solver.cpp:259]     Train net output #0: center_loss = 245.96 (* 0.008 = 1.96768 loss)
I0826 16:44:51.776499 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.26931 (* 1 = 2.26931 loss)
I0826 16:44:51.776504 25446 sgd_solver.cpp:138] Iteration 22450, lr = 0.0001
I0826 16:44:54.056546 25446 solver.cpp:243] Iteration 22460, loss = 5.7563
I0826 16:44:54.056586 25446 solver.cpp:259]     Train net output #0: center_loss = 208.574 (* 0.008 = 1.66859 loss)
I0826 16:44:54.056591 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.08771 (* 1 = 4.08771 loss)
I0826 16:44:54.056596 25446 sgd_solver.cpp:138] Iteration 22460, lr = 0.0001
I0826 16:44:56.196812 25446 solver.cpp:243] Iteration 22470, loss = 6.17806
I0826 16:44:56.196851 25446 solver.cpp:259]     Train net output #0: center_loss = 186.28 (* 0.008 = 1.49024 loss)
I0826 16:44:56.196858 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.68782 (* 1 = 4.68782 loss)
I0826 16:44:56.196862 25446 sgd_solver.cpp:138] Iteration 22470, lr = 0.0001
I0826 16:44:58.440973 25446 solver.cpp:243] Iteration 22480, loss = 6.52236
I0826 16:44:58.441000 25446 solver.cpp:259]     Train net output #0: center_loss = 191.96 (* 0.008 = 1.53568 loss)
I0826 16:44:58.441006 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.98669 (* 1 = 4.98669 loss)
I0826 16:44:58.441011 25446 sgd_solver.cpp:138] Iteration 22480, lr = 0.0001
I0826 16:45:00.636890 25446 solver.cpp:243] Iteration 22490, loss = 6.28543
I0826 16:45:00.636915 25446 solver.cpp:259]     Train net output #0: center_loss = 210.272 (* 0.008 = 1.68218 loss)
I0826 16:45:00.636921 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.60326 (* 1 = 4.60326 loss)
I0826 16:45:00.636925 25446 sgd_solver.cpp:138] Iteration 22490, lr = 0.0001
I0826 16:45:02.792840 25446 solver.cpp:243] Iteration 22500, loss = 6.15245
I0826 16:45:02.792865 25446 solver.cpp:259]     Train net output #0: center_loss = 216.63 (* 0.008 = 1.73304 loss)
I0826 16:45:02.792870 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.41941 (* 1 = 4.41941 loss)
I0826 16:45:02.792874 25446 sgd_solver.cpp:138] Iteration 22500, lr = 0.0001
I0826 16:45:04.855434 25446 solver.cpp:243] Iteration 22510, loss = 5.88799
I0826 16:45:04.855458 25446 solver.cpp:259]     Train net output #0: center_loss = 191.093 (* 0.008 = 1.52874 loss)
I0826 16:45:04.855464 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.35925 (* 1 = 4.35925 loss)
I0826 16:45:04.855468 25446 sgd_solver.cpp:138] Iteration 22510, lr = 0.0001
I0826 16:45:06.925681 25446 solver.cpp:243] Iteration 22520, loss = 6.08174
I0826 16:45:06.925705 25446 solver.cpp:259]     Train net output #0: center_loss = 201.275 (* 0.008 = 1.6102 loss)
I0826 16:45:06.925711 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47154 (* 1 = 4.47154 loss)
I0826 16:45:06.925715 25446 sgd_solver.cpp:138] Iteration 22520, lr = 0.0001
I0826 16:45:09.178804 25446 solver.cpp:243] Iteration 22530, loss = 5.53081
I0826 16:45:09.178845 25446 solver.cpp:259]     Train net output #0: center_loss = 212.257 (* 0.008 = 1.69806 loss)
I0826 16:45:09.178851 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83275 (* 1 = 3.83275 loss)
I0826 16:45:09.178856 25446 sgd_solver.cpp:138] Iteration 22530, lr = 0.0001
I0826 16:45:11.332006 25446 solver.cpp:243] Iteration 22540, loss = 5.42785
I0826 16:45:11.332159 25446 solver.cpp:259]     Train net output #0: center_loss = 227.24 (* 0.008 = 1.81792 loss)
I0826 16:45:11.332166 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.60993 (* 1 = 3.60993 loss)
I0826 16:45:11.332170 25446 sgd_solver.cpp:138] Iteration 22540, lr = 0.0001
I0826 16:45:13.615361 25446 solver.cpp:243] Iteration 22550, loss = 4.89557
I0826 16:45:13.615401 25446 solver.cpp:259]     Train net output #0: center_loss = 238.682 (* 0.008 = 1.90945 loss)
I0826 16:45:13.615407 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.98611 (* 1 = 2.98611 loss)
I0826 16:45:13.615411 25446 sgd_solver.cpp:138] Iteration 22550, lr = 0.0001
I0826 16:45:15.726485 25446 solver.cpp:243] Iteration 22560, loss = 6.31595
I0826 16:45:15.726511 25446 solver.cpp:259]     Train net output #0: center_loss = 236.207 (* 0.008 = 1.88966 loss)
I0826 16:45:15.726517 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.42629 (* 1 = 4.42629 loss)
I0826 16:45:15.726521 25446 sgd_solver.cpp:138] Iteration 22560, lr = 0.0001
I0826 16:45:17.844908 25446 solver.cpp:243] Iteration 22570, loss = 5.75308
I0826 16:45:17.844933 25446 solver.cpp:259]     Train net output #0: center_loss = 190.508 (* 0.008 = 1.52406 loss)
I0826 16:45:17.844939 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.22901 (* 1 = 4.22901 loss)
I0826 16:45:17.844943 25446 sgd_solver.cpp:138] Iteration 22570, lr = 0.0001
I0826 16:45:20.007262 25446 solver.cpp:243] Iteration 22580, loss = 6.27938
I0826 16:45:20.007302 25446 solver.cpp:259]     Train net output #0: center_loss = 205.211 (* 0.008 = 1.64169 loss)
I0826 16:45:20.007308 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.63769 (* 1 = 4.63769 loss)
I0826 16:45:20.007311 25446 sgd_solver.cpp:138] Iteration 22580, lr = 0.0001
I0826 16:45:22.148448 25446 solver.cpp:243] Iteration 22590, loss = 6.54083
I0826 16:45:22.148488 25446 solver.cpp:259]     Train net output #0: center_loss = 181.355 (* 0.008 = 1.45084 loss)
I0826 16:45:22.148494 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.08999 (* 1 = 5.08999 loss)
I0826 16:45:22.148497 25446 sgd_solver.cpp:138] Iteration 22590, lr = 0.0001
I0826 16:45:24.211621 25446 solver.cpp:243] Iteration 22600, loss = 5.41584
I0826 16:45:24.211660 25446 solver.cpp:259]     Train net output #0: center_loss = 207.794 (* 0.008 = 1.66235 loss)
I0826 16:45:24.211666 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.75348 (* 1 = 3.75348 loss)
I0826 16:45:24.211669 25446 sgd_solver.cpp:138] Iteration 22600, lr = 0.0001
I0826 16:45:26.274855 25446 solver.cpp:243] Iteration 22610, loss = 6.10977
I0826 16:45:26.274880 25446 solver.cpp:259]     Train net output #0: center_loss = 209.145 (* 0.008 = 1.67316 loss)
I0826 16:45:26.274886 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.43661 (* 1 = 4.43661 loss)
I0826 16:45:26.274890 25446 sgd_solver.cpp:138] Iteration 22610, lr = 0.0001
I0826 16:45:28.356683 25446 solver.cpp:243] Iteration 22620, loss = 5.9117
I0826 16:45:28.356709 25446 solver.cpp:259]     Train net output #0: center_loss = 205.953 (* 0.008 = 1.64762 loss)
I0826 16:45:28.356714 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.26408 (* 1 = 4.26408 loss)
I0826 16:45:28.356719 25446 sgd_solver.cpp:138] Iteration 22620, lr = 0.0001
I0826 16:45:30.511448 25446 solver.cpp:243] Iteration 22630, loss = 6.72678
I0826 16:45:30.511476 25446 solver.cpp:259]     Train net output #0: center_loss = 181.624 (* 0.008 = 1.453 loss)
I0826 16:45:30.511482 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.27378 (* 1 = 5.27378 loss)
I0826 16:45:30.511487 25446 sgd_solver.cpp:138] Iteration 22630, lr = 0.0001
I0826 16:45:32.668308 25446 solver.cpp:243] Iteration 22640, loss = 7.21243
I0826 16:45:32.668334 25446 solver.cpp:259]     Train net output #0: center_loss = 171.188 (* 0.008 = 1.3695 loss)
I0826 16:45:32.668339 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.84293 (* 1 = 5.84293 loss)
I0826 16:45:32.668344 25446 sgd_solver.cpp:138] Iteration 22640, lr = 0.0001
I0826 16:45:34.820780 25446 solver.cpp:243] Iteration 22650, loss = 4.98866
I0826 16:45:34.820806 25446 solver.cpp:259]     Train net output #0: center_loss = 208.839 (* 0.008 = 1.67071 loss)
I0826 16:45:34.820812 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.31795 (* 1 = 3.31795 loss)
I0826 16:45:34.820816 25446 sgd_solver.cpp:138] Iteration 22650, lr = 0.0001
I0826 16:45:36.910162 25446 solver.cpp:243] Iteration 22660, loss = 5.27759
I0826 16:45:36.910187 25446 solver.cpp:259]     Train net output #0: center_loss = 216.69 (* 0.008 = 1.73352 loss)
I0826 16:45:36.910193 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.54407 (* 1 = 3.54407 loss)
I0826 16:45:36.910197 25446 sgd_solver.cpp:138] Iteration 22660, lr = 0.0001
I0826 16:45:38.975021 25446 solver.cpp:243] Iteration 22670, loss = 5.39067
I0826 16:45:38.975059 25446 solver.cpp:259]     Train net output #0: center_loss = 228.067 (* 0.008 = 1.82454 loss)
I0826 16:45:38.975065 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.56614 (* 1 = 3.56614 loss)
I0826 16:45:38.975069 25446 sgd_solver.cpp:138] Iteration 22670, lr = 0.0001
I0826 16:45:41.175873 25446 solver.cpp:243] Iteration 22680, loss = 6.41855
I0826 16:45:41.175911 25446 solver.cpp:259]     Train net output #0: center_loss = 204.14 (* 0.008 = 1.63312 loss)
I0826 16:45:41.175920 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.78543 (* 1 = 4.78543 loss)
I0826 16:45:41.175925 25446 sgd_solver.cpp:138] Iteration 22680, lr = 0.0001
I0826 16:45:43.320710 25446 solver.cpp:243] Iteration 22690, loss = 5.33994
I0826 16:45:43.320829 25446 solver.cpp:259]     Train net output #0: center_loss = 210.439 (* 0.008 = 1.68351 loss)
I0826 16:45:43.320837 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.65642 (* 1 = 3.65642 loss)
I0826 16:45:43.320842 25446 sgd_solver.cpp:138] Iteration 22690, lr = 0.0001
I0826 16:45:45.459431 25446 solver.cpp:243] Iteration 22700, loss = 6.61355
I0826 16:45:45.459471 25446 solver.cpp:259]     Train net output #0: center_loss = 179.612 (* 0.008 = 1.4369 loss)
I0826 16:45:45.459477 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.17666 (* 1 = 5.17666 loss)
I0826 16:45:45.459481 25446 sgd_solver.cpp:138] Iteration 22700, lr = 0.0001
I0826 16:45:47.523526 25446 solver.cpp:243] Iteration 22710, loss = 5.95686
I0826 16:45:47.523566 25446 solver.cpp:259]     Train net output #0: center_loss = 222.19 (* 0.008 = 1.77752 loss)
I0826 16:45:47.523571 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.17934 (* 1 = 4.17934 loss)
I0826 16:45:47.523576 25446 sgd_solver.cpp:138] Iteration 22710, lr = 0.0001
I0826 16:45:49.584430 25446 solver.cpp:243] Iteration 22720, loss = 6.64334
I0826 16:45:49.584455 25446 solver.cpp:259]     Train net output #0: center_loss = 194.392 (* 0.008 = 1.55513 loss)
I0826 16:45:49.584460 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.08821 (* 1 = 5.08821 loss)
I0826 16:45:49.584465 25446 sgd_solver.cpp:138] Iteration 22720, lr = 0.0001
I0826 16:45:51.644165 25446 solver.cpp:243] Iteration 22730, loss = 4.80605
I0826 16:45:51.644204 25446 solver.cpp:259]     Train net output #0: center_loss = 217.339 (* 0.008 = 1.73871 loss)
I0826 16:45:51.644210 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.06733 (* 1 = 3.06733 loss)
I0826 16:45:51.644214 25446 sgd_solver.cpp:138] Iteration 22730, lr = 0.0001
I0826 16:45:53.704160 25446 solver.cpp:243] Iteration 22740, loss = 6.49248
I0826 16:45:53.704185 25446 solver.cpp:259]     Train net output #0: center_loss = 172.871 (* 0.008 = 1.38297 loss)
I0826 16:45:53.704190 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.10952 (* 1 = 5.10952 loss)
I0826 16:45:53.704195 25446 sgd_solver.cpp:138] Iteration 22740, lr = 0.0001
I0826 16:45:55.765084 25446 solver.cpp:243] Iteration 22750, loss = 6.24665
I0826 16:45:55.765123 25446 solver.cpp:259]     Train net output #0: center_loss = 172.327 (* 0.008 = 1.37862 loss)
I0826 16:45:55.765130 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.86804 (* 1 = 4.86804 loss)
I0826 16:45:55.765133 25446 sgd_solver.cpp:138] Iteration 22750, lr = 0.0001
I0826 16:45:57.826808 25446 solver.cpp:243] Iteration 22760, loss = 5.57398
I0826 16:45:57.826833 25446 solver.cpp:259]     Train net output #0: center_loss = 225.133 (* 0.008 = 1.80107 loss)
I0826 16:45:57.826838 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77291 (* 1 = 3.77291 loss)
I0826 16:45:57.826843 25446 sgd_solver.cpp:138] Iteration 22760, lr = 0.0001
I0826 16:45:59.886678 25446 solver.cpp:243] Iteration 22770, loss = 6.11043
I0826 16:45:59.886701 25446 solver.cpp:259]     Train net output #0: center_loss = 210.598 (* 0.008 = 1.68478 loss)
I0826 16:45:59.886708 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.42564 (* 1 = 4.42564 loss)
I0826 16:45:59.886711 25446 sgd_solver.cpp:138] Iteration 22770, lr = 0.0001
I0826 16:46:01.949023 25446 solver.cpp:243] Iteration 22780, loss = 6.23739
I0826 16:46:01.949046 25446 solver.cpp:259]     Train net output #0: center_loss = 211.492 (* 0.008 = 1.69194 loss)
I0826 16:46:01.949052 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.54546 (* 1 = 4.54546 loss)
I0826 16:46:01.949056 25446 sgd_solver.cpp:138] Iteration 22780, lr = 0.0001
I0826 16:46:04.156615 25446 solver.cpp:243] Iteration 22790, loss = 5.68081
I0826 16:46:04.156638 25446 solver.cpp:259]     Train net output #0: center_loss = 191.875 (* 0.008 = 1.535 loss)
I0826 16:46:04.156646 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.14581 (* 1 = 4.14581 loss)
I0826 16:46:04.156649 25446 sgd_solver.cpp:138] Iteration 22790, lr = 0.0001
I0826 16:46:06.442728 25446 solver.cpp:243] Iteration 22800, loss = 5.30231
I0826 16:46:06.442754 25446 solver.cpp:259]     Train net output #0: center_loss = 196.176 (* 0.008 = 1.56941 loss)
I0826 16:46:06.442760 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.7329 (* 1 = 3.7329 loss)
I0826 16:46:06.442765 25446 sgd_solver.cpp:138] Iteration 22800, lr = 0.0001
I0826 16:46:08.725023 25446 solver.cpp:243] Iteration 22810, loss = 5.11804
I0826 16:46:08.725062 25446 solver.cpp:259]     Train net output #0: center_loss = 212.373 (* 0.008 = 1.69899 loss)
I0826 16:46:08.725069 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.41905 (* 1 = 3.41905 loss)
I0826 16:46:08.725072 25446 sgd_solver.cpp:138] Iteration 22810, lr = 0.0001
I0826 16:46:10.976665 25446 solver.cpp:243] Iteration 22820, loss = 5.54953
I0826 16:46:10.976688 25446 solver.cpp:259]     Train net output #0: center_loss = 217.349 (* 0.008 = 1.73879 loss)
I0826 16:46:10.976694 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81074 (* 1 = 3.81074 loss)
I0826 16:46:10.976698 25446 sgd_solver.cpp:138] Iteration 22820, lr = 0.0001
I0826 16:46:13.114971 25446 solver.cpp:243] Iteration 22830, loss = 5.89569
I0826 16:46:13.114998 25446 solver.cpp:259]     Train net output #0: center_loss = 209.223 (* 0.008 = 1.67378 loss)
I0826 16:46:13.115005 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.22191 (* 1 = 4.22191 loss)
I0826 16:46:13.115010 25446 sgd_solver.cpp:138] Iteration 22830, lr = 0.0001
I0826 16:46:15.177677 25446 solver.cpp:243] Iteration 22840, loss = 6.28908
I0826 16:46:15.177780 25446 solver.cpp:259]     Train net output #0: center_loss = 189.097 (* 0.008 = 1.51278 loss)
I0826 16:46:15.177800 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.7763 (* 1 = 4.7763 loss)
I0826 16:46:15.177804 25446 sgd_solver.cpp:138] Iteration 22840, lr = 0.0001
I0826 16:46:17.240424 25446 solver.cpp:243] Iteration 22850, loss = 6.06604
I0826 16:46:17.240464 25446 solver.cpp:259]     Train net output #0: center_loss = 227.184 (* 0.008 = 1.81747 loss)
I0826 16:46:17.240470 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.24857 (* 1 = 4.24857 loss)
I0826 16:46:17.240474 25446 sgd_solver.cpp:138] Iteration 22850, lr = 0.0001
I0826 16:46:19.301825 25446 solver.cpp:243] Iteration 22860, loss = 5.24639
I0826 16:46:19.301848 25446 solver.cpp:259]     Train net output #0: center_loss = 214.786 (* 0.008 = 1.71829 loss)
I0826 16:46:19.301854 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.5281 (* 1 = 3.5281 loss)
I0826 16:46:19.301858 25446 sgd_solver.cpp:138] Iteration 22860, lr = 0.0001
I0826 16:46:21.362844 25446 solver.cpp:243] Iteration 22870, loss = 6.18172
I0826 16:46:21.362885 25446 solver.cpp:259]     Train net output #0: center_loss = 187.28 (* 0.008 = 1.49824 loss)
I0826 16:46:21.362892 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.68348 (* 1 = 4.68348 loss)
I0826 16:46:21.362896 25446 sgd_solver.cpp:138] Iteration 22870, lr = 0.0001
I0826 16:46:23.423641 25446 solver.cpp:243] Iteration 22880, loss = 5.15347
I0826 16:46:23.423681 25446 solver.cpp:259]     Train net output #0: center_loss = 220.926 (* 0.008 = 1.76741 loss)
I0826 16:46:23.423687 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.38606 (* 1 = 3.38606 loss)
I0826 16:46:23.423691 25446 sgd_solver.cpp:138] Iteration 22880, lr = 0.0001
I0826 16:46:25.487011 25446 solver.cpp:243] Iteration 22890, loss = 5.22553
I0826 16:46:25.487035 25446 solver.cpp:259]     Train net output #0: center_loss = 190.493 (* 0.008 = 1.52395 loss)
I0826 16:46:25.487041 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.70158 (* 1 = 3.70158 loss)
I0826 16:46:25.487046 25446 sgd_solver.cpp:138] Iteration 22890, lr = 0.0001
I0826 16:46:27.628304 25446 solver.cpp:243] Iteration 22900, loss = 5.60583
I0826 16:46:27.628343 25446 solver.cpp:259]     Train net output #0: center_loss = 212.084 (* 0.008 = 1.69668 loss)
I0826 16:46:27.628350 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.90916 (* 1 = 3.90916 loss)
I0826 16:46:27.628353 25446 sgd_solver.cpp:138] Iteration 22900, lr = 0.0001
I0826 16:46:29.838075 25446 solver.cpp:243] Iteration 22910, loss = 7.12453
I0826 16:46:29.838114 25446 solver.cpp:259]     Train net output #0: center_loss = 196.758 (* 0.008 = 1.57407 loss)
I0826 16:46:29.838120 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.55047 (* 1 = 5.55047 loss)
I0826 16:46:29.838124 25446 sgd_solver.cpp:138] Iteration 22910, lr = 0.0001
I0826 16:46:31.992282 25446 solver.cpp:243] Iteration 22920, loss = 7.88233
I0826 16:46:31.992310 25446 solver.cpp:259]     Train net output #0: center_loss = 174.275 (* 0.008 = 1.3942 loss)
I0826 16:46:31.992316 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.48813 (* 1 = 6.48813 loss)
I0826 16:46:31.992321 25446 sgd_solver.cpp:138] Iteration 22920, lr = 0.0001
I0826 16:46:34.068018 25446 solver.cpp:243] Iteration 22930, loss = 6.00713
I0826 16:46:34.068042 25446 solver.cpp:259]     Train net output #0: center_loss = 200.608 (* 0.008 = 1.60487 loss)
I0826 16:46:34.068048 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40226 (* 1 = 4.40226 loss)
I0826 16:46:34.068051 25446 sgd_solver.cpp:138] Iteration 22930, lr = 0.0001
I0826 16:46:36.299542 25446 solver.cpp:243] Iteration 22940, loss = 5.97817
I0826 16:46:36.299582 25446 solver.cpp:259]     Train net output #0: center_loss = 187.076 (* 0.008 = 1.4966 loss)
I0826 16:46:36.299588 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.48157 (* 1 = 4.48157 loss)
I0826 16:46:36.299593 25446 sgd_solver.cpp:138] Iteration 22940, lr = 0.0001
I0826 16:46:38.587606 25446 solver.cpp:243] Iteration 22950, loss = 5.2759
I0826 16:46:38.587647 25446 solver.cpp:259]     Train net output #0: center_loss = 231.751 (* 0.008 = 1.85401 loss)
I0826 16:46:38.587653 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.42189 (* 1 = 3.42189 loss)
I0826 16:46:38.587657 25446 sgd_solver.cpp:138] Iteration 22950, lr = 0.0001
I0826 16:46:40.715301 25446 solver.cpp:243] Iteration 22960, loss = 6.68712
I0826 16:46:40.715328 25446 solver.cpp:259]     Train net output #0: center_loss = 197.34 (* 0.008 = 1.57872 loss)
I0826 16:46:40.715334 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.1084 (* 1 = 5.1084 loss)
I0826 16:46:40.715339 25446 sgd_solver.cpp:138] Iteration 22960, lr = 0.0001
I0826 16:46:42.901937 25446 solver.cpp:243] Iteration 22970, loss = 5.93505
I0826 16:46:42.901960 25446 solver.cpp:259]     Train net output #0: center_loss = 213.298 (* 0.008 = 1.70639 loss)
I0826 16:46:42.901966 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.22866 (* 1 = 4.22866 loss)
I0826 16:46:42.901970 25446 sgd_solver.cpp:138] Iteration 22970, lr = 0.0001
I0826 16:46:45.040338 25446 solver.cpp:243] Iteration 22980, loss = 5.07734
I0826 16:46:45.040362 25446 solver.cpp:259]     Train net output #0: center_loss = 231.334 (* 0.008 = 1.85067 loss)
I0826 16:46:45.040369 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.22666 (* 1 = 3.22666 loss)
I0826 16:46:45.040372 25446 sgd_solver.cpp:138] Iteration 22980, lr = 0.0001
I0826 16:46:47.105100 25446 solver.cpp:243] Iteration 22990, loss = 6.3169
I0826 16:46:47.105242 25446 solver.cpp:259]     Train net output #0: center_loss = 185.959 (* 0.008 = 1.48767 loss)
I0826 16:46:47.105283 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.82923 (* 1 = 4.82923 loss)
I0826 16:46:47.105286 25446 sgd_solver.cpp:138] Iteration 22990, lr = 0.0001
I0826 16:46:48.961339 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_23000.caffemodel
I0826 16:46:50.082597 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_23000.solverstate
I0826 16:46:50.411787 25446 solver.cpp:243] Iteration 23000, loss = 5.21123
I0826 16:46:50.411834 25446 solver.cpp:259]     Train net output #0: center_loss = 239.569 (* 0.008 = 1.91655 loss)
I0826 16:46:50.411841 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.29467 (* 1 = 3.29467 loss)
I0826 16:46:50.411845 25446 sgd_solver.cpp:138] Iteration 23000, lr = 0.0001
I0826 16:46:52.474411 25446 solver.cpp:243] Iteration 23010, loss = 4.88575
I0826 16:46:52.474436 25446 solver.cpp:259]     Train net output #0: center_loss = 221.69 (* 0.008 = 1.77352 loss)
I0826 16:46:52.474442 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.11222 (* 1 = 3.11222 loss)
I0826 16:46:52.474447 25446 sgd_solver.cpp:138] Iteration 23010, lr = 0.0001
I0826 16:46:54.534647 25446 solver.cpp:243] Iteration 23020, loss = 5.1291
I0826 16:46:54.534685 25446 solver.cpp:259]     Train net output #0: center_loss = 224.963 (* 0.008 = 1.79971 loss)
I0826 16:46:54.534691 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.32939 (* 1 = 3.32939 loss)
I0826 16:46:54.534695 25446 sgd_solver.cpp:138] Iteration 23020, lr = 0.0001
I0826 16:46:56.596947 25446 solver.cpp:243] Iteration 23030, loss = 5.61602
I0826 16:46:56.596988 25446 solver.cpp:259]     Train net output #0: center_loss = 202.64 (* 0.008 = 1.62112 loss)
I0826 16:46:56.596994 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9949 (* 1 = 3.9949 loss)
I0826 16:46:56.596997 25446 sgd_solver.cpp:138] Iteration 23030, lr = 0.0001
I0826 16:46:58.659330 25446 solver.cpp:243] Iteration 23040, loss = 6.36992
I0826 16:46:58.659354 25446 solver.cpp:259]     Train net output #0: center_loss = 222.736 (* 0.008 = 1.78189 loss)
I0826 16:46:58.659360 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.58803 (* 1 = 4.58803 loss)
I0826 16:46:58.659364 25446 sgd_solver.cpp:138] Iteration 23040, lr = 0.0001
I0826 16:47:00.722919 25446 solver.cpp:243] Iteration 23050, loss = 5.90344
I0826 16:47:00.722944 25446 solver.cpp:259]     Train net output #0: center_loss = 211.497 (* 0.008 = 1.69198 loss)
I0826 16:47:00.722949 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.21146 (* 1 = 4.21146 loss)
I0826 16:47:00.722954 25446 sgd_solver.cpp:138] Iteration 23050, lr = 0.0001
I0826 16:47:02.783702 25446 solver.cpp:243] Iteration 23060, loss = 6.06319
I0826 16:47:02.783740 25446 solver.cpp:259]     Train net output #0: center_loss = 219.849 (* 0.008 = 1.75879 loss)
I0826 16:47:02.783747 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.30439 (* 1 = 4.30439 loss)
I0826 16:47:02.783751 25446 sgd_solver.cpp:138] Iteration 23060, lr = 0.0001
I0826 16:47:04.847803 25446 solver.cpp:243] Iteration 23070, loss = 5.90033
I0826 16:47:04.847828 25446 solver.cpp:259]     Train net output #0: center_loss = 198.528 (* 0.008 = 1.58822 loss)
I0826 16:47:04.847834 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.31211 (* 1 = 4.31211 loss)
I0826 16:47:04.847838 25446 sgd_solver.cpp:138] Iteration 23070, lr = 0.0001
I0826 16:47:06.909660 25446 solver.cpp:243] Iteration 23080, loss = 6.09963
I0826 16:47:06.909684 25446 solver.cpp:259]     Train net output #0: center_loss = 199.056 (* 0.008 = 1.59245 loss)
I0826 16:47:06.909690 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50718 (* 1 = 4.50718 loss)
I0826 16:47:06.909694 25446 sgd_solver.cpp:138] Iteration 23080, lr = 0.0001
I0826 16:47:08.971212 25446 solver.cpp:243] Iteration 23090, loss = 5.57739
I0826 16:47:08.971235 25446 solver.cpp:259]     Train net output #0: center_loss = 215.334 (* 0.008 = 1.72267 loss)
I0826 16:47:08.971282 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.85471 (* 1 = 3.85471 loss)
I0826 16:47:08.971285 25446 sgd_solver.cpp:138] Iteration 23090, lr = 0.0001
I0826 16:47:11.033478 25446 solver.cpp:243] Iteration 23100, loss = 6.13548
I0826 16:47:11.033515 25446 solver.cpp:259]     Train net output #0: center_loss = 219.898 (* 0.008 = 1.75919 loss)
I0826 16:47:11.033521 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.3763 (* 1 = 4.3763 loss)
I0826 16:47:11.033525 25446 sgd_solver.cpp:138] Iteration 23100, lr = 0.0001
I0826 16:47:13.096778 25446 solver.cpp:243] Iteration 23110, loss = 5.86101
I0826 16:47:13.096817 25446 solver.cpp:259]     Train net output #0: center_loss = 212.364 (* 0.008 = 1.69891 loss)
I0826 16:47:13.096824 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.1621 (* 1 = 4.1621 loss)
I0826 16:47:13.096827 25446 sgd_solver.cpp:138] Iteration 23110, lr = 0.0001
I0826 16:47:15.160984 25446 solver.cpp:243] Iteration 23120, loss = 5.62051
I0826 16:47:15.161022 25446 solver.cpp:259]     Train net output #0: center_loss = 208.261 (* 0.008 = 1.66609 loss)
I0826 16:47:15.161028 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.95442 (* 1 = 3.95442 loss)
I0826 16:47:15.161032 25446 sgd_solver.cpp:138] Iteration 23120, lr = 0.0001
I0826 16:47:17.221810 25446 solver.cpp:243] Iteration 23130, loss = 5.42003
I0826 16:47:17.221979 25446 solver.cpp:259]     Train net output #0: center_loss = 203.428 (* 0.008 = 1.62743 loss)
I0826 16:47:17.221987 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.7926 (* 1 = 3.7926 loss)
I0826 16:47:17.222002 25446 sgd_solver.cpp:138] Iteration 23130, lr = 0.0001
I0826 16:47:19.285856 25446 solver.cpp:243] Iteration 23140, loss = 5.09758
I0826 16:47:19.285879 25446 solver.cpp:259]     Train net output #0: center_loss = 227.677 (* 0.008 = 1.82142 loss)
I0826 16:47:19.285885 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.27617 (* 1 = 3.27617 loss)
I0826 16:47:19.285889 25446 sgd_solver.cpp:138] Iteration 23140, lr = 0.0001
I0826 16:47:21.348626 25446 solver.cpp:243] Iteration 23150, loss = 6.06935
I0826 16:47:21.348666 25446 solver.cpp:259]     Train net output #0: center_loss = 230.869 (* 0.008 = 1.84695 loss)
I0826 16:47:21.348672 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.2224 (* 1 = 4.2224 loss)
I0826 16:47:21.348675 25446 sgd_solver.cpp:138] Iteration 23150, lr = 0.0001
I0826 16:47:23.412933 25446 solver.cpp:243] Iteration 23160, loss = 6.04037
I0826 16:47:23.412961 25446 solver.cpp:259]     Train net output #0: center_loss = 173.488 (* 0.008 = 1.38791 loss)
I0826 16:47:23.412967 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65246 (* 1 = 4.65246 loss)
I0826 16:47:23.412971 25446 sgd_solver.cpp:138] Iteration 23160, lr = 0.0001
I0826 16:47:25.477103 25446 solver.cpp:243] Iteration 23170, loss = 5.82005
I0826 16:47:25.477144 25446 solver.cpp:259]     Train net output #0: center_loss = 193.021 (* 0.008 = 1.54417 loss)
I0826 16:47:25.477149 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.27588 (* 1 = 4.27588 loss)
I0826 16:47:25.477154 25446 sgd_solver.cpp:138] Iteration 23170, lr = 0.0001
I0826 16:47:27.541143 25446 solver.cpp:243] Iteration 23180, loss = 5.95369
I0826 16:47:27.541182 25446 solver.cpp:259]     Train net output #0: center_loss = 186.511 (* 0.008 = 1.49209 loss)
I0826 16:47:27.541188 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.4616 (* 1 = 4.4616 loss)
I0826 16:47:27.541191 25446 sgd_solver.cpp:138] Iteration 23180, lr = 0.0001
I0826 16:47:29.601285 25446 solver.cpp:243] Iteration 23190, loss = 5.45232
I0826 16:47:29.601310 25446 solver.cpp:259]     Train net output #0: center_loss = 202.509 (* 0.008 = 1.62007 loss)
I0826 16:47:29.601315 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83224 (* 1 = 3.83224 loss)
I0826 16:47:29.601320 25446 sgd_solver.cpp:138] Iteration 23190, lr = 0.0001
I0826 16:47:31.662137 25446 solver.cpp:243] Iteration 23200, loss = 6.24893
I0826 16:47:31.662161 25446 solver.cpp:259]     Train net output #0: center_loss = 201.516 (* 0.008 = 1.61213 loss)
I0826 16:47:31.662168 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.6368 (* 1 = 4.6368 loss)
I0826 16:47:31.662171 25446 sgd_solver.cpp:138] Iteration 23200, lr = 0.0001
I0826 16:47:33.725520 25446 solver.cpp:243] Iteration 23210, loss = 5.86188
I0826 16:47:33.725544 25446 solver.cpp:259]     Train net output #0: center_loss = 207.33 (* 0.008 = 1.65864 loss)
I0826 16:47:33.725550 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.20323 (* 1 = 4.20323 loss)
I0826 16:47:33.725554 25446 sgd_solver.cpp:138] Iteration 23210, lr = 0.0001
I0826 16:47:35.788400 25446 solver.cpp:243] Iteration 23220, loss = 6.06072
I0826 16:47:35.788424 25446 solver.cpp:259]     Train net output #0: center_loss = 213.507 (* 0.008 = 1.70806 loss)
I0826 16:47:35.788430 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.35266 (* 1 = 4.35266 loss)
I0826 16:47:35.788434 25446 sgd_solver.cpp:138] Iteration 23220, lr = 0.0001
I0826 16:47:37.850710 25446 solver.cpp:243] Iteration 23230, loss = 6.16703
I0826 16:47:37.850733 25446 solver.cpp:259]     Train net output #0: center_loss = 207.21 (* 0.008 = 1.65768 loss)
I0826 16:47:37.850754 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50935 (* 1 = 4.50935 loss)
I0826 16:47:37.850757 25446 sgd_solver.cpp:138] Iteration 23230, lr = 0.0001
I0826 16:47:39.910709 25446 solver.cpp:243] Iteration 23240, loss = 6.96256
I0826 16:47:39.910759 25446 solver.cpp:259]     Train net output #0: center_loss = 204.366 (* 0.008 = 1.63493 loss)
I0826 16:47:39.910765 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.32763 (* 1 = 5.32763 loss)
I0826 16:47:39.910769 25446 sgd_solver.cpp:138] Iteration 23240, lr = 0.0001
I0826 16:47:41.970556 25446 solver.cpp:243] Iteration 23250, loss = 6.10053
I0826 16:47:41.970595 25446 solver.cpp:259]     Train net output #0: center_loss = 196.739 (* 0.008 = 1.57391 loss)
I0826 16:47:41.970603 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52662 (* 1 = 4.52662 loss)
I0826 16:47:41.970607 25446 sgd_solver.cpp:138] Iteration 23250, lr = 0.0001
I0826 16:47:44.034312 25446 solver.cpp:243] Iteration 23260, loss = 5.31571
I0826 16:47:44.034335 25446 solver.cpp:259]     Train net output #0: center_loss = 216.098 (* 0.008 = 1.72878 loss)
I0826 16:47:44.034341 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.58693 (* 1 = 3.58693 loss)
I0826 16:47:44.034344 25446 sgd_solver.cpp:138] Iteration 23260, lr = 0.0001
I0826 16:47:46.095435 25446 solver.cpp:243] Iteration 23270, loss = 6.23832
I0826 16:47:46.095474 25446 solver.cpp:259]     Train net output #0: center_loss = 196.266 (* 0.008 = 1.57013 loss)
I0826 16:47:46.095479 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.66819 (* 1 = 4.66819 loss)
I0826 16:47:46.095484 25446 sgd_solver.cpp:138] Iteration 23270, lr = 0.0001
I0826 16:47:48.153317 25446 solver.cpp:243] Iteration 23280, loss = 5.8932
I0826 16:47:48.153497 25446 solver.cpp:259]     Train net output #0: center_loss = 201.977 (* 0.008 = 1.61582 loss)
I0826 16:47:48.153506 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.27738 (* 1 = 4.27738 loss)
I0826 16:47:48.153508 25446 sgd_solver.cpp:138] Iteration 23280, lr = 0.0001
I0826 16:47:50.214591 25446 solver.cpp:243] Iteration 23290, loss = 6.18652
I0826 16:47:50.214630 25446 solver.cpp:259]     Train net output #0: center_loss = 198.149 (* 0.008 = 1.58519 loss)
I0826 16:47:50.214637 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.60133 (* 1 = 4.60133 loss)
I0826 16:47:50.214640 25446 sgd_solver.cpp:138] Iteration 23290, lr = 0.0001
I0826 16:47:52.273409 25446 solver.cpp:243] Iteration 23300, loss = 6.2033
I0826 16:47:52.273449 25446 solver.cpp:259]     Train net output #0: center_loss = 201.318 (* 0.008 = 1.61054 loss)
I0826 16:47:52.273455 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.59275 (* 1 = 4.59275 loss)
I0826 16:47:52.273459 25446 sgd_solver.cpp:138] Iteration 23300, lr = 0.0001
I0826 16:47:54.334990 25446 solver.cpp:243] Iteration 23310, loss = 6.21997
I0826 16:47:54.335013 25446 solver.cpp:259]     Train net output #0: center_loss = 215.388 (* 0.008 = 1.7231 loss)
I0826 16:47:54.335019 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.49687 (* 1 = 4.49687 loss)
I0826 16:47:54.335023 25446 sgd_solver.cpp:138] Iteration 23310, lr = 0.0001
I0826 16:47:56.397130 25446 solver.cpp:243] Iteration 23320, loss = 4.96529
I0826 16:47:56.397153 25446 solver.cpp:259]     Train net output #0: center_loss = 220.705 (* 0.008 = 1.76564 loss)
I0826 16:47:56.397159 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.19965 (* 1 = 3.19965 loss)
I0826 16:47:56.397164 25446 sgd_solver.cpp:138] Iteration 23320, lr = 0.0001
I0826 16:47:58.457471 25446 solver.cpp:243] Iteration 23330, loss = 5.56236
I0826 16:47:58.457495 25446 solver.cpp:259]     Train net output #0: center_loss = 222.385 (* 0.008 = 1.77908 loss)
I0826 16:47:58.457501 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.78328 (* 1 = 3.78328 loss)
I0826 16:47:58.457505 25446 sgd_solver.cpp:138] Iteration 23330, lr = 0.0001
I0826 16:48:00.523866 25446 solver.cpp:243] Iteration 23340, loss = 5.05878
I0826 16:48:00.523892 25446 solver.cpp:259]     Train net output #0: center_loss = 211.445 (* 0.008 = 1.69156 loss)
I0826 16:48:00.523898 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.36721 (* 1 = 3.36721 loss)
I0826 16:48:00.523903 25446 sgd_solver.cpp:138] Iteration 23340, lr = 0.0001
I0826 16:48:02.586949 25446 solver.cpp:243] Iteration 23350, loss = 5.81224
I0826 16:48:02.586988 25446 solver.cpp:259]     Train net output #0: center_loss = 202.453 (* 0.008 = 1.61963 loss)
I0826 16:48:02.586995 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.19262 (* 1 = 4.19262 loss)
I0826 16:48:02.586999 25446 sgd_solver.cpp:138] Iteration 23350, lr = 0.0001
I0826 16:48:04.651613 25446 solver.cpp:243] Iteration 23360, loss = 6.10406
I0826 16:48:04.651652 25446 solver.cpp:259]     Train net output #0: center_loss = 216.383 (* 0.008 = 1.73107 loss)
I0826 16:48:04.651659 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.373 (* 1 = 4.373 loss)
I0826 16:48:04.651662 25446 sgd_solver.cpp:138] Iteration 23360, lr = 0.0001
I0826 16:48:06.713297 25446 solver.cpp:243] Iteration 23370, loss = 6.57174
I0826 16:48:06.713336 25446 solver.cpp:259]     Train net output #0: center_loss = 187.151 (* 0.008 = 1.49721 loss)
I0826 16:48:06.713342 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.07453 (* 1 = 5.07453 loss)
I0826 16:48:06.713346 25446 sgd_solver.cpp:138] Iteration 23370, lr = 0.0001
I0826 16:48:08.776280 25446 solver.cpp:243] Iteration 23380, loss = 5.53148
I0826 16:48:08.776340 25446 solver.cpp:259]     Train net output #0: center_loss = 195.211 (* 0.008 = 1.56169 loss)
I0826 16:48:08.776345 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.96979 (* 1 = 3.96979 loss)
I0826 16:48:08.776350 25446 sgd_solver.cpp:138] Iteration 23380, lr = 0.0001
I0826 16:48:10.840318 25446 solver.cpp:243] Iteration 23390, loss = 6.93565
I0826 16:48:10.840356 25446 solver.cpp:259]     Train net output #0: center_loss = 169.167 (* 0.008 = 1.35334 loss)
I0826 16:48:10.840363 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.58231 (* 1 = 5.58231 loss)
I0826 16:48:10.840366 25446 sgd_solver.cpp:138] Iteration 23390, lr = 0.0001
I0826 16:48:12.899271 25446 solver.cpp:243] Iteration 23400, loss = 6.23619
I0826 16:48:12.899309 25446 solver.cpp:259]     Train net output #0: center_loss = 189.502 (* 0.008 = 1.51602 loss)
I0826 16:48:12.899317 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.72017 (* 1 = 4.72017 loss)
I0826 16:48:12.899320 25446 sgd_solver.cpp:138] Iteration 23400, lr = 0.0001
I0826 16:48:14.961726 25446 solver.cpp:243] Iteration 23410, loss = 5.01237
I0826 16:48:14.961764 25446 solver.cpp:259]     Train net output #0: center_loss = 232.852 (* 0.008 = 1.86281 loss)
I0826 16:48:14.961771 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.14956 (* 1 = 3.14956 loss)
I0826 16:48:14.961773 25446 sgd_solver.cpp:138] Iteration 23410, lr = 0.0001
I0826 16:48:17.020817 25446 solver.cpp:243] Iteration 23420, loss = 5.737
I0826 16:48:17.020855 25446 solver.cpp:259]     Train net output #0: center_loss = 204.679 (* 0.008 = 1.63743 loss)
I0826 16:48:17.020862 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.09956 (* 1 = 4.09956 loss)
I0826 16:48:17.020866 25446 sgd_solver.cpp:138] Iteration 23420, lr = 0.0001
I0826 16:48:19.084326 25446 solver.cpp:243] Iteration 23430, loss = 5.79903
I0826 16:48:19.084440 25446 solver.cpp:259]     Train net output #0: center_loss = 223.924 (* 0.008 = 1.79139 loss)
I0826 16:48:19.084447 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.00764 (* 1 = 4.00764 loss)
I0826 16:48:19.084451 25446 sgd_solver.cpp:138] Iteration 23430, lr = 0.0001
I0826 16:48:21.144748 25446 solver.cpp:243] Iteration 23440, loss = 5.59603
I0826 16:48:21.144786 25446 solver.cpp:259]     Train net output #0: center_loss = 202.807 (* 0.008 = 1.62245 loss)
I0826 16:48:21.144793 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97358 (* 1 = 3.97358 loss)
I0826 16:48:21.144796 25446 sgd_solver.cpp:138] Iteration 23440, lr = 0.0001
I0826 16:48:23.207839 25446 solver.cpp:243] Iteration 23450, loss = 5.739
I0826 16:48:23.207878 25446 solver.cpp:259]     Train net output #0: center_loss = 220.596 (* 0.008 = 1.76477 loss)
I0826 16:48:23.207885 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97424 (* 1 = 3.97424 loss)
I0826 16:48:23.207888 25446 sgd_solver.cpp:138] Iteration 23450, lr = 0.0001
I0826 16:48:25.273154 25446 solver.cpp:243] Iteration 23460, loss = 6.65523
I0826 16:48:25.273193 25446 solver.cpp:259]     Train net output #0: center_loss = 210.367 (* 0.008 = 1.68294 loss)
I0826 16:48:25.273200 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.97229 (* 1 = 4.97229 loss)
I0826 16:48:25.273203 25446 sgd_solver.cpp:138] Iteration 23460, lr = 0.0001
I0826 16:48:27.333788 25446 solver.cpp:243] Iteration 23470, loss = 4.91772
I0826 16:48:27.333827 25446 solver.cpp:259]     Train net output #0: center_loss = 222.639 (* 0.008 = 1.78111 loss)
I0826 16:48:27.333832 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.13661 (* 1 = 3.13661 loss)
I0826 16:48:27.333837 25446 sgd_solver.cpp:138] Iteration 23470, lr = 0.0001
I0826 16:48:29.397991 25446 solver.cpp:243] Iteration 23480, loss = 5.12285
I0826 16:48:29.398015 25446 solver.cpp:259]     Train net output #0: center_loss = 202.78 (* 0.008 = 1.62224 loss)
I0826 16:48:29.398021 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.50061 (* 1 = 3.50061 loss)
I0826 16:48:29.398025 25446 sgd_solver.cpp:138] Iteration 23480, lr = 0.0001
I0826 16:48:31.459342 25446 solver.cpp:243] Iteration 23490, loss = 5.29163
I0826 16:48:31.459379 25446 solver.cpp:259]     Train net output #0: center_loss = 219.098 (* 0.008 = 1.75279 loss)
I0826 16:48:31.459385 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.53884 (* 1 = 3.53884 loss)
I0826 16:48:31.459389 25446 sgd_solver.cpp:138] Iteration 23490, lr = 0.0001
I0826 16:48:33.520774 25446 solver.cpp:243] Iteration 23500, loss = 4.70585
I0826 16:48:33.520798 25446 solver.cpp:259]     Train net output #0: center_loss = 220.523 (* 0.008 = 1.76419 loss)
I0826 16:48:33.520805 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.94166 (* 1 = 2.94166 loss)
I0826 16:48:33.520808 25446 sgd_solver.cpp:138] Iteration 23500, lr = 0.0001
I0826 16:48:35.586062 25446 solver.cpp:243] Iteration 23510, loss = 6.1046
I0826 16:48:35.586086 25446 solver.cpp:259]     Train net output #0: center_loss = 181.956 (* 0.008 = 1.45564 loss)
I0826 16:48:35.586107 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64895 (* 1 = 4.64895 loss)
I0826 16:48:35.586112 25446 sgd_solver.cpp:138] Iteration 23510, lr = 0.0001
I0826 16:48:37.652552 25446 solver.cpp:243] Iteration 23520, loss = 6.15965
I0826 16:48:37.652592 25446 solver.cpp:259]     Train net output #0: center_loss = 210.712 (* 0.008 = 1.68569 loss)
I0826 16:48:37.652598 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47396 (* 1 = 4.47396 loss)
I0826 16:48:37.652602 25446 sgd_solver.cpp:138] Iteration 23520, lr = 0.0001
I0826 16:48:39.718009 25446 solver.cpp:243] Iteration 23530, loss = 5.49836
I0826 16:48:39.718047 25446 solver.cpp:259]     Train net output #0: center_loss = 211.348 (* 0.008 = 1.69078 loss)
I0826 16:48:39.718055 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.80758 (* 1 = 3.80758 loss)
I0826 16:48:39.718057 25446 sgd_solver.cpp:138] Iteration 23530, lr = 0.0001
I0826 16:48:41.778846 25446 solver.cpp:243] Iteration 23540, loss = 5.9465
I0826 16:48:41.778872 25446 solver.cpp:259]     Train net output #0: center_loss = 177.275 (* 0.008 = 1.4182 loss)
I0826 16:48:41.778877 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52829 (* 1 = 4.52829 loss)
I0826 16:48:41.778880 25446 sgd_solver.cpp:138] Iteration 23540, lr = 0.0001
I0826 16:48:43.843518 25446 solver.cpp:243] Iteration 23550, loss = 5.34571
I0826 16:48:43.843556 25446 solver.cpp:259]     Train net output #0: center_loss = 199.75 (* 0.008 = 1.598 loss)
I0826 16:48:43.843562 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.74771 (* 1 = 3.74771 loss)
I0826 16:48:43.843565 25446 sgd_solver.cpp:138] Iteration 23550, lr = 0.0001
I0826 16:48:45.904198 25446 solver.cpp:243] Iteration 23560, loss = 5.88713
I0826 16:48:45.904222 25446 solver.cpp:259]     Train net output #0: center_loss = 194.833 (* 0.008 = 1.55866 loss)
I0826 16:48:45.904227 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.32847 (* 1 = 4.32847 loss)
I0826 16:48:45.904232 25446 sgd_solver.cpp:138] Iteration 23560, lr = 0.0001
I0826 16:48:47.969688 25446 solver.cpp:243] Iteration 23570, loss = 5.48466
I0826 16:48:47.969712 25446 solver.cpp:259]     Train net output #0: center_loss = 221.308 (* 0.008 = 1.77047 loss)
I0826 16:48:47.969717 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.71419 (* 1 = 3.71419 loss)
I0826 16:48:47.969722 25446 sgd_solver.cpp:138] Iteration 23570, lr = 0.0001
I0826 16:48:50.036005 25446 solver.cpp:243] Iteration 23580, loss = 5.85303
I0826 16:48:50.036157 25446 solver.cpp:259]     Train net output #0: center_loss = 220.86 (* 0.008 = 1.76688 loss)
I0826 16:48:50.036164 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.08615 (* 1 = 4.08615 loss)
I0826 16:48:50.036183 25446 sgd_solver.cpp:138] Iteration 23580, lr = 0.0001
I0826 16:48:52.100001 25446 solver.cpp:243] Iteration 23590, loss = 5.14501
I0826 16:48:52.100040 25446 solver.cpp:259]     Train net output #0: center_loss = 231.369 (* 0.008 = 1.85095 loss)
I0826 16:48:52.100046 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.29406 (* 1 = 3.29406 loss)
I0826 16:48:52.100050 25446 sgd_solver.cpp:138] Iteration 23590, lr = 0.0001
I0826 16:48:54.160362 25446 solver.cpp:243] Iteration 23600, loss = 5.75722
I0826 16:48:54.160384 25446 solver.cpp:259]     Train net output #0: center_loss = 196.163 (* 0.008 = 1.5693 loss)
I0826 16:48:54.160390 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.18791 (* 1 = 4.18791 loss)
I0826 16:48:54.160393 25446 sgd_solver.cpp:138] Iteration 23600, lr = 0.0001
I0826 16:48:56.221540 25446 solver.cpp:243] Iteration 23610, loss = 6.28074
I0826 16:48:56.221562 25446 solver.cpp:259]     Train net output #0: center_loss = 196.804 (* 0.008 = 1.57443 loss)
I0826 16:48:56.221568 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70631 (* 1 = 4.70631 loss)
I0826 16:48:56.221572 25446 sgd_solver.cpp:138] Iteration 23610, lr = 0.0001
I0826 16:48:58.285696 25446 solver.cpp:243] Iteration 23620, loss = 5.29921
I0826 16:48:58.285719 25446 solver.cpp:259]     Train net output #0: center_loss = 241.83 (* 0.008 = 1.93464 loss)
I0826 16:48:58.285725 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.36457 (* 1 = 3.36457 loss)
I0826 16:48:58.285729 25446 sgd_solver.cpp:138] Iteration 23620, lr = 0.0001
I0826 16:49:00.348984 25446 solver.cpp:243] Iteration 23630, loss = 5.99731
I0826 16:49:00.349022 25446 solver.cpp:259]     Train net output #0: center_loss = 211.237 (* 0.008 = 1.6899 loss)
I0826 16:49:00.349028 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.30741 (* 1 = 4.30741 loss)
I0826 16:49:00.349032 25446 sgd_solver.cpp:138] Iteration 23630, lr = 0.0001
I0826 16:49:02.415227 25446 solver.cpp:243] Iteration 23640, loss = 5.28198
I0826 16:49:02.415266 25446 solver.cpp:259]     Train net output #0: center_loss = 215.049 (* 0.008 = 1.72039 loss)
I0826 16:49:02.415272 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.56158 (* 1 = 3.56158 loss)
I0826 16:49:02.415277 25446 sgd_solver.cpp:138] Iteration 23640, lr = 0.0001
I0826 16:49:04.478333 25446 solver.cpp:243] Iteration 23650, loss = 6.45228
I0826 16:49:04.478372 25446 solver.cpp:259]     Train net output #0: center_loss = 179.172 (* 0.008 = 1.43338 loss)
I0826 16:49:04.478379 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.0189 (* 1 = 5.0189 loss)
I0826 16:49:04.478384 25446 sgd_solver.cpp:138] Iteration 23650, lr = 0.0001
I0826 16:49:06.541291 25446 solver.cpp:243] Iteration 23660, loss = 5.23923
I0826 16:49:06.541316 25446 solver.cpp:259]     Train net output #0: center_loss = 235.304 (* 0.008 = 1.88243 loss)
I0826 16:49:06.541322 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.35679 (* 1 = 3.35679 loss)
I0826 16:49:06.541326 25446 sgd_solver.cpp:138] Iteration 23660, lr = 0.0001
I0826 16:49:08.599488 25446 solver.cpp:243] Iteration 23670, loss = 5.88261
I0826 16:49:08.599527 25446 solver.cpp:259]     Train net output #0: center_loss = 198.668 (* 0.008 = 1.58935 loss)
I0826 16:49:08.599534 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29327 (* 1 = 4.29327 loss)
I0826 16:49:08.599537 25446 sgd_solver.cpp:138] Iteration 23670, lr = 0.0001
I0826 16:49:10.660943 25446 solver.cpp:243] Iteration 23680, loss = 5.01696
I0826 16:49:10.660982 25446 solver.cpp:259]     Train net output #0: center_loss = 223.868 (* 0.008 = 1.79095 loss)
I0826 16:49:10.660989 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.22601 (* 1 = 3.22601 loss)
I0826 16:49:10.660992 25446 sgd_solver.cpp:138] Iteration 23680, lr = 0.0001
I0826 16:49:12.726054 25446 solver.cpp:243] Iteration 23690, loss = 5.50846
I0826 16:49:12.726078 25446 solver.cpp:259]     Train net output #0: center_loss = 207.9 (* 0.008 = 1.6632 loss)
I0826 16:49:12.726084 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.84527 (* 1 = 3.84527 loss)
I0826 16:49:12.726089 25446 sgd_solver.cpp:138] Iteration 23690, lr = 0.0001
I0826 16:49:14.784824 25446 solver.cpp:243] Iteration 23700, loss = 6.06942
I0826 16:49:14.784864 25446 solver.cpp:259]     Train net output #0: center_loss = 208.82 (* 0.008 = 1.67056 loss)
I0826 16:49:14.784870 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.39886 (* 1 = 4.39886 loss)
I0826 16:49:14.784874 25446 sgd_solver.cpp:138] Iteration 23700, lr = 0.0001
I0826 16:49:16.849794 25446 solver.cpp:243] Iteration 23710, loss = 5.56751
I0826 16:49:16.849833 25446 solver.cpp:259]     Train net output #0: center_loss = 208.385 (* 0.008 = 1.66708 loss)
I0826 16:49:16.849839 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.90043 (* 1 = 3.90043 loss)
I0826 16:49:16.849843 25446 sgd_solver.cpp:138] Iteration 23710, lr = 0.0001
I0826 16:49:18.915163 25446 solver.cpp:243] Iteration 23720, loss = 5.00791
I0826 16:49:18.915185 25446 solver.cpp:259]     Train net output #0: center_loss = 204.617 (* 0.008 = 1.63694 loss)
I0826 16:49:18.915191 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.37098 (* 1 = 3.37098 loss)
I0826 16:49:18.915195 25446 sgd_solver.cpp:138] Iteration 23720, lr = 0.0001
I0826 16:49:20.980967 25446 solver.cpp:243] Iteration 23730, loss = 5.46226
I0826 16:49:20.981122 25446 solver.cpp:259]     Train net output #0: center_loss = 215.567 (* 0.008 = 1.72454 loss)
I0826 16:49:20.981129 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.73773 (* 1 = 3.73773 loss)
I0826 16:49:20.981145 25446 sgd_solver.cpp:138] Iteration 23730, lr = 0.0001
I0826 16:49:23.043519 25446 solver.cpp:243] Iteration 23740, loss = 7.01131
I0826 16:49:23.043555 25446 solver.cpp:259]     Train net output #0: center_loss = 196.959 (* 0.008 = 1.57567 loss)
I0826 16:49:23.043562 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.43563 (* 1 = 5.43563 loss)
I0826 16:49:23.043566 25446 sgd_solver.cpp:138] Iteration 23740, lr = 0.0001
I0826 16:49:25.103813 25446 solver.cpp:243] Iteration 23750, loss = 4.90661
I0826 16:49:25.103853 25446 solver.cpp:259]     Train net output #0: center_loss = 216.749 (* 0.008 = 1.734 loss)
I0826 16:49:25.103859 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.17262 (* 1 = 3.17262 loss)
I0826 16:49:25.103876 25446 sgd_solver.cpp:138] Iteration 23750, lr = 0.0001
I0826 16:49:27.164876 25446 solver.cpp:243] Iteration 23760, loss = 5.31119
I0826 16:49:27.164916 25446 solver.cpp:259]     Train net output #0: center_loss = 219.563 (* 0.008 = 1.75651 loss)
I0826 16:49:27.164923 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.55468 (* 1 = 3.55468 loss)
I0826 16:49:27.164927 25446 sgd_solver.cpp:138] Iteration 23760, lr = 0.0001
I0826 16:49:29.226385 25446 solver.cpp:243] Iteration 23770, loss = 5.84565
I0826 16:49:29.226408 25446 solver.cpp:259]     Train net output #0: center_loss = 200.159 (* 0.008 = 1.60127 loss)
I0826 16:49:29.226414 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.24438 (* 1 = 4.24438 loss)
I0826 16:49:29.226418 25446 sgd_solver.cpp:138] Iteration 23770, lr = 0.0001
I0826 16:49:31.283205 25446 solver.cpp:243] Iteration 23780, loss = 7.07812
I0826 16:49:31.283244 25446 solver.cpp:259]     Train net output #0: center_loss = 211.587 (* 0.008 = 1.69269 loss)
I0826 16:49:31.283251 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.38542 (* 1 = 5.38542 loss)
I0826 16:49:31.283253 25446 sgd_solver.cpp:138] Iteration 23780, lr = 0.0001
I0826 16:49:33.425434 25446 solver.cpp:243] Iteration 23790, loss = 4.6627
I0826 16:49:33.425460 25446 solver.cpp:259]     Train net output #0: center_loss = 226.223 (* 0.008 = 1.80979 loss)
I0826 16:49:33.425467 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.85291 (* 1 = 2.85291 loss)
I0826 16:49:33.425472 25446 sgd_solver.cpp:138] Iteration 23790, lr = 0.0001
I0826 16:49:35.566138 25446 solver.cpp:243] Iteration 23800, loss = 5.80762
I0826 16:49:35.566177 25446 solver.cpp:259]     Train net output #0: center_loss = 208.989 (* 0.008 = 1.67191 loss)
I0826 16:49:35.566182 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.13571 (* 1 = 4.13571 loss)
I0826 16:49:35.566187 25446 sgd_solver.cpp:138] Iteration 23800, lr = 0.0001
I0826 16:49:37.713513 25446 solver.cpp:243] Iteration 23810, loss = 5.6216
I0826 16:49:37.713537 25446 solver.cpp:259]     Train net output #0: center_loss = 211.307 (* 0.008 = 1.69046 loss)
I0826 16:49:37.713543 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.93114 (* 1 = 3.93114 loss)
I0826 16:49:37.713548 25446 sgd_solver.cpp:138] Iteration 23810, lr = 0.0001
I0826 16:49:39.896513 25446 solver.cpp:243] Iteration 23820, loss = 5.64085
I0826 16:49:39.896536 25446 solver.cpp:259]     Train net output #0: center_loss = 215.995 (* 0.008 = 1.72796 loss)
I0826 16:49:39.896543 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91288 (* 1 = 3.91288 loss)
I0826 16:49:39.896548 25446 sgd_solver.cpp:138] Iteration 23820, lr = 0.0001
I0826 16:49:42.143784 25446 solver.cpp:243] Iteration 23830, loss = 5.32107
I0826 16:49:42.143810 25446 solver.cpp:259]     Train net output #0: center_loss = 221.278 (* 0.008 = 1.77023 loss)
I0826 16:49:42.143815 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.55085 (* 1 = 3.55085 loss)
I0826 16:49:42.143820 25446 sgd_solver.cpp:138] Iteration 23830, lr = 0.0001
I0826 16:49:44.426426 25446 solver.cpp:243] Iteration 23840, loss = 6.44524
I0826 16:49:44.426450 25446 solver.cpp:259]     Train net output #0: center_loss = 197.641 (* 0.008 = 1.58113 loss)
I0826 16:49:44.426456 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.86411 (* 1 = 4.86411 loss)
I0826 16:49:44.426460 25446 sgd_solver.cpp:138] Iteration 23840, lr = 0.0001
I0826 16:49:46.708920 25446 solver.cpp:243] Iteration 23850, loss = 5.59403
I0826 16:49:46.708959 25446 solver.cpp:259]     Train net output #0: center_loss = 200.303 (* 0.008 = 1.60242 loss)
I0826 16:49:46.708966 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.99161 (* 1 = 3.99161 loss)
I0826 16:49:46.708971 25446 sgd_solver.cpp:138] Iteration 23850, lr = 0.0001
I0826 16:49:48.877821 25446 solver.cpp:243] Iteration 23860, loss = 6.47409
I0826 16:49:48.877861 25446 solver.cpp:259]     Train net output #0: center_loss = 193.354 (* 0.008 = 1.54683 loss)
I0826 16:49:48.877868 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.92726 (* 1 = 4.92726 loss)
I0826 16:49:48.877871 25446 sgd_solver.cpp:138] Iteration 23860, lr = 0.0001
I0826 16:49:51.033144 25446 solver.cpp:243] Iteration 23870, loss = 6.50871
I0826 16:49:51.033262 25446 solver.cpp:259]     Train net output #0: center_loss = 206.772 (* 0.008 = 1.65418 loss)
I0826 16:49:51.033269 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.85454 (* 1 = 4.85454 loss)
I0826 16:49:51.033273 25446 sgd_solver.cpp:138] Iteration 23870, lr = 0.0001
I0826 16:49:53.096719 25446 solver.cpp:243] Iteration 23880, loss = 5.03674
I0826 16:49:53.096742 25446 solver.cpp:259]     Train net output #0: center_loss = 229.116 (* 0.008 = 1.83293 loss)
I0826 16:49:53.096748 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.20381 (* 1 = 3.20381 loss)
I0826 16:49:53.096752 25446 sgd_solver.cpp:138] Iteration 23880, lr = 0.0001
I0826 16:49:55.160465 25446 solver.cpp:243] Iteration 23890, loss = 6.12613
I0826 16:49:55.160490 25446 solver.cpp:259]     Train net output #0: center_loss = 199.885 (* 0.008 = 1.59908 loss)
I0826 16:49:55.160496 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52706 (* 1 = 4.52706 loss)
I0826 16:49:55.160501 25446 sgd_solver.cpp:138] Iteration 23890, lr = 0.0001
I0826 16:49:57.224684 25446 solver.cpp:243] Iteration 23900, loss = 6.45599
I0826 16:49:57.224709 25446 solver.cpp:259]     Train net output #0: center_loss = 192.852 (* 0.008 = 1.54282 loss)
I0826 16:49:57.224714 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.91318 (* 1 = 4.91318 loss)
I0826 16:49:57.224719 25446 sgd_solver.cpp:138] Iteration 23900, lr = 0.0001
I0826 16:49:59.289474 25446 solver.cpp:243] Iteration 23910, loss = 6.73163
I0826 16:49:59.289499 25446 solver.cpp:259]     Train net output #0: center_loss = 170.512 (* 0.008 = 1.36409 loss)
I0826 16:49:59.289507 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.36754 (* 1 = 5.36754 loss)
I0826 16:49:59.289511 25446 sgd_solver.cpp:138] Iteration 23910, lr = 0.0001
I0826 16:50:01.354022 25446 solver.cpp:243] Iteration 23920, loss = 5.86956
I0826 16:50:01.354063 25446 solver.cpp:259]     Train net output #0: center_loss = 204.793 (* 0.008 = 1.63835 loss)
I0826 16:50:01.354068 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.23122 (* 1 = 4.23122 loss)
I0826 16:50:01.354073 25446 sgd_solver.cpp:138] Iteration 23920, lr = 0.0001
I0826 16:50:03.413460 25446 solver.cpp:243] Iteration 23930, loss = 6.24057
I0826 16:50:03.413486 25446 solver.cpp:259]     Train net output #0: center_loss = 219.816 (* 0.008 = 1.75853 loss)
I0826 16:50:03.413506 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.48204 (* 1 = 4.48204 loss)
I0826 16:50:03.413511 25446 sgd_solver.cpp:138] Iteration 23930, lr = 0.0001
I0826 16:50:05.475343 25446 solver.cpp:243] Iteration 23940, loss = 5.35646
I0826 16:50:05.475368 25446 solver.cpp:259]     Train net output #0: center_loss = 250.939 (* 0.008 = 2.00751 loss)
I0826 16:50:05.475373 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.34894 (* 1 = 3.34894 loss)
I0826 16:50:05.475378 25446 sgd_solver.cpp:138] Iteration 23940, lr = 0.0001
I0826 16:50:07.539723 25446 solver.cpp:243] Iteration 23950, loss = 5.44529
I0826 16:50:07.539763 25446 solver.cpp:259]     Train net output #0: center_loss = 198.819 (* 0.008 = 1.59055 loss)
I0826 16:50:07.539769 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.85474 (* 1 = 3.85474 loss)
I0826 16:50:07.539773 25446 sgd_solver.cpp:138] Iteration 23950, lr = 0.0001
I0826 16:50:09.603330 25446 solver.cpp:243] Iteration 23960, loss = 5.4159
I0826 16:50:09.603358 25446 solver.cpp:259]     Train net output #0: center_loss = 233.278 (* 0.008 = 1.86622 loss)
I0826 16:50:09.603366 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.54967 (* 1 = 3.54967 loss)
I0826 16:50:09.603370 25446 sgd_solver.cpp:138] Iteration 23960, lr = 0.0001
I0826 16:50:11.665722 25446 solver.cpp:243] Iteration 23970, loss = 5.33349
I0826 16:50:11.665746 25446 solver.cpp:259]     Train net output #0: center_loss = 220.863 (* 0.008 = 1.7669 loss)
I0826 16:50:11.665752 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.56659 (* 1 = 3.56659 loss)
I0826 16:50:11.665756 25446 sgd_solver.cpp:138] Iteration 23970, lr = 0.0001
I0826 16:50:13.725709 25446 solver.cpp:243] Iteration 23980, loss = 6.88519
I0826 16:50:13.725749 25446 solver.cpp:259]     Train net output #0: center_loss = 188.663 (* 0.008 = 1.50931 loss)
I0826 16:50:13.725755 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.37588 (* 1 = 5.37588 loss)
I0826 16:50:13.725759 25446 sgd_solver.cpp:138] Iteration 23980, lr = 0.0001
I0826 16:50:15.785301 25446 solver.cpp:243] Iteration 23990, loss = 5.42138
I0826 16:50:15.785326 25446 solver.cpp:259]     Train net output #0: center_loss = 237.45 (* 0.008 = 1.8996 loss)
I0826 16:50:15.785331 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.52178 (* 1 = 3.52178 loss)
I0826 16:50:15.785336 25446 sgd_solver.cpp:138] Iteration 23990, lr = 0.0001
I0826 16:50:17.638892 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_24000.caffemodel
I0826 16:50:18.759758 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_24000.solverstate
I0826 16:50:19.086916 25446 solver.cpp:243] Iteration 24000, loss = 6.5607
I0826 16:50:19.086943 25446 solver.cpp:259]     Train net output #0: center_loss = 197.806 (* 0.008 = 1.58245 loss)
I0826 16:50:19.086949 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.97825 (* 1 = 4.97825 loss)
I0826 16:50:19.086953 25446 sgd_solver.cpp:47] MultiStep Status: Iteration 24000, step = 2
I0826 16:50:19.086956 25446 sgd_solver.cpp:138] Iteration 24000, lr = 1e-05
I0826 16:50:21.142915 25446 solver.cpp:243] Iteration 24010, loss = 5.87284
I0826 16:50:21.143054 25446 solver.cpp:259]     Train net output #0: center_loss = 213.241 (* 0.008 = 1.70593 loss)
I0826 16:50:21.143060 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.16691 (* 1 = 4.16691 loss)
I0826 16:50:21.143064 25446 sgd_solver.cpp:138] Iteration 24010, lr = 1e-05
I0826 16:50:23.199612 25446 solver.cpp:243] Iteration 24020, loss = 6.23756
I0826 16:50:23.199636 25446 solver.cpp:259]     Train net output #0: center_loss = 214.724 (* 0.008 = 1.71779 loss)
I0826 16:50:23.199642 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.51976 (* 1 = 4.51976 loss)
I0826 16:50:23.199646 25446 sgd_solver.cpp:138] Iteration 24020, lr = 1e-05
I0826 16:50:25.261371 25446 solver.cpp:243] Iteration 24030, loss = 5.13259
I0826 16:50:25.261409 25446 solver.cpp:259]     Train net output #0: center_loss = 219.241 (* 0.008 = 1.75393 loss)
I0826 16:50:25.261415 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.37867 (* 1 = 3.37867 loss)
I0826 16:50:25.261418 25446 sgd_solver.cpp:138] Iteration 24030, lr = 1e-05
I0826 16:50:27.322677 25446 solver.cpp:243] Iteration 24040, loss = 6.12264
I0826 16:50:27.322701 25446 solver.cpp:259]     Train net output #0: center_loss = 188.952 (* 0.008 = 1.51162 loss)
I0826 16:50:27.322707 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.61102 (* 1 = 4.61102 loss)
I0826 16:50:27.322711 25446 sgd_solver.cpp:138] Iteration 24040, lr = 1e-05
I0826 16:50:29.386401 25446 solver.cpp:243] Iteration 24050, loss = 5.86488
I0826 16:50:29.386425 25446 solver.cpp:259]     Train net output #0: center_loss = 212.558 (* 0.008 = 1.70046 loss)
I0826 16:50:29.386430 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.16442 (* 1 = 4.16442 loss)
I0826 16:50:29.386435 25446 sgd_solver.cpp:138] Iteration 24050, lr = 1e-05
I0826 16:50:31.445659 25446 solver.cpp:243] Iteration 24060, loss = 6.21967
I0826 16:50:31.445683 25446 solver.cpp:259]     Train net output #0: center_loss = 196.455 (* 0.008 = 1.57164 loss)
I0826 16:50:31.445688 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64803 (* 1 = 4.64803 loss)
I0826 16:50:31.445693 25446 sgd_solver.cpp:138] Iteration 24060, lr = 1e-05
I0826 16:50:33.510843 25446 solver.cpp:243] Iteration 24070, loss = 6.26211
I0826 16:50:33.510869 25446 solver.cpp:259]     Train net output #0: center_loss = 188.81 (* 0.008 = 1.51048 loss)
I0826 16:50:33.510875 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.75163 (* 1 = 4.75163 loss)
I0826 16:50:33.510879 25446 sgd_solver.cpp:138] Iteration 24070, lr = 1e-05
I0826 16:50:35.574563 25446 solver.cpp:243] Iteration 24080, loss = 5.47726
I0826 16:50:35.574589 25446 solver.cpp:259]     Train net output #0: center_loss = 197.952 (* 0.008 = 1.58362 loss)
I0826 16:50:35.574594 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.89364 (* 1 = 3.89364 loss)
I0826 16:50:35.574597 25446 sgd_solver.cpp:138] Iteration 24080, lr = 1e-05
I0826 16:50:37.637244 25446 solver.cpp:243] Iteration 24090, loss = 5.61017
I0826 16:50:37.637295 25446 solver.cpp:259]     Train net output #0: center_loss = 229.866 (* 0.008 = 1.83893 loss)
I0826 16:50:37.637313 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77124 (* 1 = 3.77124 loss)
I0826 16:50:37.637316 25446 sgd_solver.cpp:138] Iteration 24090, lr = 1e-05
I0826 16:50:39.700240 25446 solver.cpp:243] Iteration 24100, loss = 5.52704
I0826 16:50:39.700264 25446 solver.cpp:259]     Train net output #0: center_loss = 232.426 (* 0.008 = 1.8594 loss)
I0826 16:50:39.700269 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.66764 (* 1 = 3.66764 loss)
I0826 16:50:39.700273 25446 sgd_solver.cpp:138] Iteration 24100, lr = 1e-05
I0826 16:50:41.852573 25446 solver.cpp:243] Iteration 24110, loss = 5.91799
I0826 16:50:41.852597 25446 solver.cpp:259]     Train net output #0: center_loss = 199.517 (* 0.008 = 1.59614 loss)
I0826 16:50:41.852603 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.32185 (* 1 = 4.32185 loss)
I0826 16:50:41.852608 25446 sgd_solver.cpp:138] Iteration 24110, lr = 1e-05
I0826 16:50:44.073999 25446 solver.cpp:243] Iteration 24120, loss = 5.85434
I0826 16:50:44.074038 25446 solver.cpp:259]     Train net output #0: center_loss = 220.792 (* 0.008 = 1.76634 loss)
I0826 16:50:44.074043 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.08801 (* 1 = 4.08801 loss)
I0826 16:50:44.074048 25446 sgd_solver.cpp:138] Iteration 24120, lr = 1e-05
I0826 16:50:46.213826 25446 solver.cpp:243] Iteration 24130, loss = 4.42927
I0826 16:50:46.213850 25446 solver.cpp:259]     Train net output #0: center_loss = 215.424 (* 0.008 = 1.72339 loss)
I0826 16:50:46.213856 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.70588 (* 1 = 2.70588 loss)
I0826 16:50:46.213860 25446 sgd_solver.cpp:138] Iteration 24130, lr = 1e-05
I0826 16:50:48.277648 25446 solver.cpp:243] Iteration 24140, loss = 5.8713
I0826 16:50:48.277675 25446 solver.cpp:259]     Train net output #0: center_loss = 200.084 (* 0.008 = 1.60067 loss)
I0826 16:50:48.277681 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.27063 (* 1 = 4.27063 loss)
I0826 16:50:48.277685 25446 sgd_solver.cpp:138] Iteration 24140, lr = 1e-05
I0826 16:50:50.431836 25446 solver.cpp:243] Iteration 24150, loss = 6.47517
I0826 16:50:50.431861 25446 solver.cpp:259]     Train net output #0: center_loss = 166.033 (* 0.008 = 1.32827 loss)
I0826 16:50:50.431867 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.14691 (* 1 = 5.14691 loss)
I0826 16:50:50.431872 25446 sgd_solver.cpp:138] Iteration 24150, lr = 1e-05
I0826 16:50:52.562399 25446 solver.cpp:243] Iteration 24160, loss = 6.69088
I0826 16:50:52.562544 25446 solver.cpp:259]     Train net output #0: center_loss = 192.463 (* 0.008 = 1.53971 loss)
I0826 16:50:52.562564 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.15117 (* 1 = 5.15117 loss)
I0826 16:50:52.562568 25446 sgd_solver.cpp:138] Iteration 24160, lr = 1e-05
I0826 16:50:54.627586 25446 solver.cpp:243] Iteration 24170, loss = 5.55045
I0826 16:50:54.627625 25446 solver.cpp:259]     Train net output #0: center_loss = 219.197 (* 0.008 = 1.75358 loss)
I0826 16:50:54.627631 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.79687 (* 1 = 3.79687 loss)
I0826 16:50:54.627635 25446 sgd_solver.cpp:138] Iteration 24170, lr = 1e-05
I0826 16:50:56.693138 25446 solver.cpp:243] Iteration 24180, loss = 5.10034
I0826 16:50:56.693163 25446 solver.cpp:259]     Train net output #0: center_loss = 215.049 (* 0.008 = 1.72039 loss)
I0826 16:50:56.693169 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.37995 (* 1 = 3.37995 loss)
I0826 16:50:56.693173 25446 sgd_solver.cpp:138] Iteration 24180, lr = 1e-05
I0826 16:50:58.801391 25446 solver.cpp:243] Iteration 24190, loss = 6.00029
I0826 16:50:58.801417 25446 solver.cpp:259]     Train net output #0: center_loss = 206.502 (* 0.008 = 1.65202 loss)
I0826 16:50:58.801437 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.34827 (* 1 = 4.34827 loss)
I0826 16:50:58.801442 25446 sgd_solver.cpp:138] Iteration 24190, lr = 1e-05
I0826 16:51:00.955440 25446 solver.cpp:243] Iteration 24200, loss = 4.91319
I0826 16:51:00.955466 25446 solver.cpp:259]     Train net output #0: center_loss = 229.688 (* 0.008 = 1.8375 loss)
I0826 16:51:00.955471 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.07569 (* 1 = 3.07569 loss)
I0826 16:51:00.955476 25446 sgd_solver.cpp:138] Iteration 24200, lr = 1e-05
I0826 16:51:03.035850 25446 solver.cpp:243] Iteration 24210, loss = 5.48206
I0826 16:51:03.035888 25446 solver.cpp:259]     Train net output #0: center_loss = 210.173 (* 0.008 = 1.68138 loss)
I0826 16:51:03.035894 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.80068 (* 1 = 3.80068 loss)
I0826 16:51:03.035898 25446 sgd_solver.cpp:138] Iteration 24210, lr = 1e-05
I0826 16:51:05.098721 25446 solver.cpp:243] Iteration 24220, loss = 5.637
I0826 16:51:05.098744 25446 solver.cpp:259]     Train net output #0: center_loss = 215.835 (* 0.008 = 1.72668 loss)
I0826 16:51:05.098750 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91032 (* 1 = 3.91032 loss)
I0826 16:51:05.098754 25446 sgd_solver.cpp:138] Iteration 24220, lr = 1e-05
I0826 16:51:07.236090 25446 solver.cpp:243] Iteration 24230, loss = 5.29341
I0826 16:51:07.236115 25446 solver.cpp:259]     Train net output #0: center_loss = 206.248 (* 0.008 = 1.64998 loss)
I0826 16:51:07.236121 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.64343 (* 1 = 3.64343 loss)
I0826 16:51:07.236126 25446 sgd_solver.cpp:138] Iteration 24230, lr = 1e-05
I0826 16:51:09.387440 25446 solver.cpp:243] Iteration 24240, loss = 5.3662
I0826 16:51:09.387466 25446 solver.cpp:259]     Train net output #0: center_loss = 201.283 (* 0.008 = 1.61027 loss)
I0826 16:51:09.387473 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.75593 (* 1 = 3.75593 loss)
I0826 16:51:09.387477 25446 sgd_solver.cpp:138] Iteration 24240, lr = 1e-05
I0826 16:51:11.509625 25446 solver.cpp:243] Iteration 24250, loss = 5.62583
I0826 16:51:11.509651 25446 solver.cpp:259]     Train net output #0: center_loss = 215.329 (* 0.008 = 1.72263 loss)
I0826 16:51:11.509658 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9032 (* 1 = 3.9032 loss)
I0826 16:51:11.509662 25446 sgd_solver.cpp:138] Iteration 24250, lr = 1e-05
I0826 16:51:13.664510 25446 solver.cpp:243] Iteration 24260, loss = 5.36018
I0826 16:51:13.664549 25446 solver.cpp:259]     Train net output #0: center_loss = 206.734 (* 0.008 = 1.65387 loss)
I0826 16:51:13.664556 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.70631 (* 1 = 3.70631 loss)
I0826 16:51:13.664561 25446 sgd_solver.cpp:138] Iteration 24260, lr = 1e-05
I0826 16:51:15.742516 25446 solver.cpp:243] Iteration 24270, loss = 5.71296
I0826 16:51:15.742540 25446 solver.cpp:259]     Train net output #0: center_loss = 204.869 (* 0.008 = 1.63895 loss)
I0826 16:51:15.742561 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.07401 (* 1 = 4.07401 loss)
I0826 16:51:15.742564 25446 sgd_solver.cpp:138] Iteration 24270, lr = 1e-05
I0826 16:51:17.805830 25446 solver.cpp:243] Iteration 24280, loss = 5.61958
I0826 16:51:17.805855 25446 solver.cpp:259]     Train net output #0: center_loss = 202.568 (* 0.008 = 1.62054 loss)
I0826 16:51:17.805861 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.99904 (* 1 = 3.99904 loss)
I0826 16:51:17.805866 25446 sgd_solver.cpp:138] Iteration 24280, lr = 1e-05
I0826 16:51:19.868373 25446 solver.cpp:243] Iteration 24290, loss = 5.12598
I0826 16:51:19.868396 25446 solver.cpp:259]     Train net output #0: center_loss = 218.502 (* 0.008 = 1.74801 loss)
I0826 16:51:19.868402 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.37797 (* 1 = 3.37797 loss)
I0826 16:51:19.868407 25446 sgd_solver.cpp:138] Iteration 24290, lr = 1e-05
I0826 16:51:21.927639 25446 solver.cpp:243] Iteration 24300, loss = 5.63442
I0826 16:51:21.927661 25446 solver.cpp:259]     Train net output #0: center_loss = 206.34 (* 0.008 = 1.65072 loss)
I0826 16:51:21.927667 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9837 (* 1 = 3.9837 loss)
I0826 16:51:21.927671 25446 sgd_solver.cpp:138] Iteration 24300, lr = 1e-05
I0826 16:51:24.091241 25446 solver.cpp:243] Iteration 24310, loss = 4.93381
I0826 16:51:24.091382 25446 solver.cpp:259]     Train net output #0: center_loss = 205.217 (* 0.008 = 1.64174 loss)
I0826 16:51:24.091389 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.29207 (* 1 = 3.29207 loss)
I0826 16:51:24.091408 25446 sgd_solver.cpp:138] Iteration 24310, lr = 1e-05
I0826 16:51:26.381130 25446 solver.cpp:243] Iteration 24320, loss = 5.4477
I0826 16:51:26.381155 25446 solver.cpp:259]     Train net output #0: center_loss = 215.248 (* 0.008 = 1.72198 loss)
I0826 16:51:26.381161 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.72572 (* 1 = 3.72572 loss)
I0826 16:51:26.381165 25446 sgd_solver.cpp:138] Iteration 24320, lr = 1e-05
I0826 16:51:28.585461 25446 solver.cpp:243] Iteration 24330, loss = 6.63172
I0826 16:51:28.585485 25446 solver.cpp:259]     Train net output #0: center_loss = 207.826 (* 0.008 = 1.6626 loss)
I0826 16:51:28.585491 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.96912 (* 1 = 4.96912 loss)
I0826 16:51:28.585495 25446 sgd_solver.cpp:138] Iteration 24330, lr = 1e-05
I0826 16:51:30.728680 25446 solver.cpp:243] Iteration 24340, loss = 5.20638
I0826 16:51:30.728704 25446 solver.cpp:259]     Train net output #0: center_loss = 220.454 (* 0.008 = 1.76363 loss)
I0826 16:51:30.728710 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.44275 (* 1 = 3.44275 loss)
I0826 16:51:30.728715 25446 sgd_solver.cpp:138] Iteration 24340, lr = 1e-05
I0826 16:51:32.797377 25446 solver.cpp:243] Iteration 24350, loss = 6.1376
I0826 16:51:32.797402 25446 solver.cpp:259]     Train net output #0: center_loss = 177.479 (* 0.008 = 1.41983 loss)
I0826 16:51:32.797408 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.71777 (* 1 = 4.71777 loss)
I0826 16:51:32.797412 25446 sgd_solver.cpp:138] Iteration 24350, lr = 1e-05
I0826 16:51:34.860002 25446 solver.cpp:243] Iteration 24360, loss = 6.90899
I0826 16:51:34.860026 25446 solver.cpp:259]     Train net output #0: center_loss = 176.778 (* 0.008 = 1.41422 loss)
I0826 16:51:34.860033 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.49477 (* 1 = 5.49477 loss)
I0826 16:51:34.860036 25446 sgd_solver.cpp:138] Iteration 24360, lr = 1e-05
I0826 16:51:36.923920 25446 solver.cpp:243] Iteration 24370, loss = 5.67332
I0826 16:51:36.923959 25446 solver.cpp:259]     Train net output #0: center_loss = 212.603 (* 0.008 = 1.70082 loss)
I0826 16:51:36.923964 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9725 (* 1 = 3.9725 loss)
I0826 16:51:36.923969 25446 sgd_solver.cpp:138] Iteration 24370, lr = 1e-05
I0826 16:51:38.984172 25446 solver.cpp:243] Iteration 24380, loss = 4.94294
I0826 16:51:38.984211 25446 solver.cpp:259]     Train net output #0: center_loss = 208.921 (* 0.008 = 1.67137 loss)
I0826 16:51:38.984216 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.27157 (* 1 = 3.27157 loss)
I0826 16:51:38.984220 25446 sgd_solver.cpp:138] Iteration 24380, lr = 1e-05
I0826 16:51:41.045465 25446 solver.cpp:243] Iteration 24390, loss = 4.98408
I0826 16:51:41.045503 25446 solver.cpp:259]     Train net output #0: center_loss = 221.232 (* 0.008 = 1.76986 loss)
I0826 16:51:41.045509 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.21422 (* 1 = 3.21422 loss)
I0826 16:51:41.045513 25446 sgd_solver.cpp:138] Iteration 24390, lr = 1e-05
I0826 16:51:43.105136 25446 solver.cpp:243] Iteration 24400, loss = 5.27732
I0826 16:51:43.105175 25446 solver.cpp:259]     Train net output #0: center_loss = 224.394 (* 0.008 = 1.79515 loss)
I0826 16:51:43.105181 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.48216 (* 1 = 3.48216 loss)
I0826 16:51:43.105185 25446 sgd_solver.cpp:138] Iteration 24400, lr = 1e-05
I0826 16:51:45.166473 25446 solver.cpp:243] Iteration 24410, loss = 6.73475
I0826 16:51:45.166510 25446 solver.cpp:259]     Train net output #0: center_loss = 206.858 (* 0.008 = 1.65486 loss)
I0826 16:51:45.166517 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.07989 (* 1 = 5.07989 loss)
I0826 16:51:45.166520 25446 sgd_solver.cpp:138] Iteration 24410, lr = 1e-05
I0826 16:51:47.227705 25446 solver.cpp:243] Iteration 24420, loss = 5.74294
I0826 16:51:47.227730 25446 solver.cpp:259]     Train net output #0: center_loss = 225.557 (* 0.008 = 1.80445 loss)
I0826 16:51:47.227735 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.93848 (* 1 = 3.93848 loss)
I0826 16:51:47.227739 25446 sgd_solver.cpp:138] Iteration 24420, lr = 1e-05
I0826 16:51:49.291302 25446 solver.cpp:243] Iteration 24430, loss = 5.7715
I0826 16:51:49.291326 25446 solver.cpp:259]     Train net output #0: center_loss = 227.991 (* 0.008 = 1.82393 loss)
I0826 16:51:49.291332 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.94758 (* 1 = 3.94758 loss)
I0826 16:51:49.291335 25446 sgd_solver.cpp:138] Iteration 24430, lr = 1e-05
I0826 16:51:51.354321 25446 solver.cpp:243] Iteration 24440, loss = 5.83181
I0826 16:51:51.354359 25446 solver.cpp:259]     Train net output #0: center_loss = 223.306 (* 0.008 = 1.78645 loss)
I0826 16:51:51.354365 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04536 (* 1 = 4.04536 loss)
I0826 16:51:51.354369 25446 sgd_solver.cpp:138] Iteration 24440, lr = 1e-05
I0826 16:51:53.413448 25446 solver.cpp:243] Iteration 24450, loss = 5.02342
I0826 16:51:53.413473 25446 solver.cpp:259]     Train net output #0: center_loss = 211.045 (* 0.008 = 1.68836 loss)
I0826 16:51:53.413492 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.33505 (* 1 = 3.33505 loss)
I0826 16:51:53.413496 25446 sgd_solver.cpp:138] Iteration 24450, lr = 1e-05
I0826 16:51:55.476016 25446 solver.cpp:243] Iteration 24460, loss = 4.88067
I0826 16:51:55.476158 25446 solver.cpp:259]     Train net output #0: center_loss = 226.221 (* 0.008 = 1.80977 loss)
I0826 16:51:55.476179 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.0709 (* 1 = 3.0709 loss)
I0826 16:51:55.476183 25446 sgd_solver.cpp:138] Iteration 24460, lr = 1e-05
I0826 16:51:57.538450 25446 solver.cpp:243] Iteration 24470, loss = 5.80045
I0826 16:51:57.538475 25446 solver.cpp:259]     Train net output #0: center_loss = 210.074 (* 0.008 = 1.68059 loss)
I0826 16:51:57.538480 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.11986 (* 1 = 4.11986 loss)
I0826 16:51:57.538484 25446 sgd_solver.cpp:138] Iteration 24470, lr = 1e-05
I0826 16:51:59.603184 25446 solver.cpp:243] Iteration 24480, loss = 5.46036
I0826 16:51:59.603209 25446 solver.cpp:259]     Train net output #0: center_loss = 220.969 (* 0.008 = 1.76775 loss)
I0826 16:51:59.603215 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.69261 (* 1 = 3.69261 loss)
I0826 16:51:59.603219 25446 sgd_solver.cpp:138] Iteration 24480, lr = 1e-05
I0826 16:52:01.666334 25446 solver.cpp:243] Iteration 24490, loss = 5.45439
I0826 16:52:01.666373 25446 solver.cpp:259]     Train net output #0: center_loss = 220.607 (* 0.008 = 1.76485 loss)
I0826 16:52:01.666378 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.68953 (* 1 = 3.68953 loss)
I0826 16:52:01.666395 25446 sgd_solver.cpp:138] Iteration 24490, lr = 1e-05
I0826 16:52:03.728036 25446 solver.cpp:243] Iteration 24500, loss = 5.17858
I0826 16:52:03.728061 25446 solver.cpp:259]     Train net output #0: center_loss = 210.159 (* 0.008 = 1.68127 loss)
I0826 16:52:03.728067 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.49731 (* 1 = 3.49731 loss)
I0826 16:52:03.728071 25446 sgd_solver.cpp:138] Iteration 24500, lr = 1e-05
I0826 16:52:05.791656 25446 solver.cpp:243] Iteration 24510, loss = 5.42149
I0826 16:52:05.791680 25446 solver.cpp:259]     Train net output #0: center_loss = 202.498 (* 0.008 = 1.61998 loss)
I0826 16:52:05.791687 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.80151 (* 1 = 3.80151 loss)
I0826 16:52:05.791690 25446 sgd_solver.cpp:138] Iteration 24510, lr = 1e-05
I0826 16:52:07.854655 25446 solver.cpp:243] Iteration 24520, loss = 6.77015
I0826 16:52:07.854679 25446 solver.cpp:259]     Train net output #0: center_loss = 178.015 (* 0.008 = 1.42412 loss)
I0826 16:52:07.854686 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.34603 (* 1 = 5.34603 loss)
I0826 16:52:07.854689 25446 sgd_solver.cpp:138] Iteration 24520, lr = 1e-05
I0826 16:52:09.917484 25446 solver.cpp:243] Iteration 24530, loss = 5.18267
I0826 16:52:09.917507 25446 solver.cpp:259]     Train net output #0: center_loss = 217.475 (* 0.008 = 1.7398 loss)
I0826 16:52:09.917513 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.44287 (* 1 = 3.44287 loss)
I0826 16:52:09.917517 25446 sgd_solver.cpp:138] Iteration 24530, lr = 1e-05
I0826 16:52:11.980268 25446 solver.cpp:243] Iteration 24540, loss = 5.23841
I0826 16:52:11.980293 25446 solver.cpp:259]     Train net output #0: center_loss = 249.802 (* 0.008 = 1.99842 loss)
I0826 16:52:11.980298 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.23999 (* 1 = 3.23999 loss)
I0826 16:52:11.980302 25446 sgd_solver.cpp:138] Iteration 24540, lr = 1e-05
I0826 16:52:14.043833 25446 solver.cpp:243] Iteration 24550, loss = 6.24508
I0826 16:52:14.043856 25446 solver.cpp:259]     Train net output #0: center_loss = 200.012 (* 0.008 = 1.60009 loss)
I0826 16:52:14.043862 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64498 (* 1 = 4.64498 loss)
I0826 16:52:14.043866 25446 sgd_solver.cpp:138] Iteration 24550, lr = 1e-05
I0826 16:52:16.107272 25446 solver.cpp:243] Iteration 24560, loss = 6.80392
I0826 16:52:16.107296 25446 solver.cpp:259]     Train net output #0: center_loss = 195.82 (* 0.008 = 1.56656 loss)
I0826 16:52:16.107302 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.23736 (* 1 = 5.23736 loss)
I0826 16:52:16.107306 25446 sgd_solver.cpp:138] Iteration 24560, lr = 1e-05
I0826 16:52:18.168764 25446 solver.cpp:243] Iteration 24570, loss = 5.98535
I0826 16:52:18.168788 25446 solver.cpp:259]     Train net output #0: center_loss = 213.698 (* 0.008 = 1.70958 loss)
I0826 16:52:18.168794 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.27577 (* 1 = 4.27577 loss)
I0826 16:52:18.168797 25446 sgd_solver.cpp:138] Iteration 24570, lr = 1e-05
I0826 16:52:20.230844 25446 solver.cpp:243] Iteration 24580, loss = 5.61541
I0826 16:52:20.230866 25446 solver.cpp:259]     Train net output #0: center_loss = 195.873 (* 0.008 = 1.56698 loss)
I0826 16:52:20.230872 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04843 (* 1 = 4.04843 loss)
I0826 16:52:20.230876 25446 sgd_solver.cpp:138] Iteration 24580, lr = 1e-05
I0826 16:52:22.295718 25446 solver.cpp:243] Iteration 24590, loss = 5.97398
I0826 16:52:22.295743 25446 solver.cpp:259]     Train net output #0: center_loss = 205.051 (* 0.008 = 1.64041 loss)
I0826 16:52:22.295749 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.33357 (* 1 = 4.33357 loss)
I0826 16:52:22.295753 25446 sgd_solver.cpp:138] Iteration 24590, lr = 1e-05
I0826 16:52:24.358021 25446 solver.cpp:243] Iteration 24600, loss = 4.99937
I0826 16:52:24.358045 25446 solver.cpp:259]     Train net output #0: center_loss = 213.727 (* 0.008 = 1.70982 loss)
I0826 16:52:24.358052 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.28955 (* 1 = 3.28955 loss)
I0826 16:52:24.358054 25446 sgd_solver.cpp:138] Iteration 24600, lr = 1e-05
I0826 16:52:26.420416 25446 solver.cpp:243] Iteration 24610, loss = 6.0562
I0826 16:52:26.420563 25446 solver.cpp:259]     Train net output #0: center_loss = 198.129 (* 0.008 = 1.58503 loss)
I0826 16:52:26.420583 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47117 (* 1 = 4.47117 loss)
I0826 16:52:26.420588 25446 sgd_solver.cpp:138] Iteration 24610, lr = 1e-05
I0826 16:52:28.480226 25446 solver.cpp:243] Iteration 24620, loss = 6.15411
I0826 16:52:28.480250 25446 solver.cpp:259]     Train net output #0: center_loss = 212.49 (* 0.008 = 1.69992 loss)
I0826 16:52:28.480257 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.45419 (* 1 = 4.45419 loss)
I0826 16:52:28.480260 25446 sgd_solver.cpp:138] Iteration 24620, lr = 1e-05
I0826 16:52:30.543298 25446 solver.cpp:243] Iteration 24630, loss = 5.81439
I0826 16:52:30.543320 25446 solver.cpp:259]     Train net output #0: center_loss = 199.838 (* 0.008 = 1.59871 loss)
I0826 16:52:30.543328 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.21568 (* 1 = 4.21568 loss)
I0826 16:52:30.543330 25446 sgd_solver.cpp:138] Iteration 24630, lr = 1e-05
I0826 16:52:32.605420 25446 solver.cpp:243] Iteration 24640, loss = 6.16355
I0826 16:52:32.605444 25446 solver.cpp:259]     Train net output #0: center_loss = 208.989 (* 0.008 = 1.67191 loss)
I0826 16:52:32.605451 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.49164 (* 1 = 4.49164 loss)
I0826 16:52:32.605454 25446 sgd_solver.cpp:138] Iteration 24640, lr = 1e-05
I0826 16:52:34.668608 25446 solver.cpp:243] Iteration 24650, loss = 5.33363
I0826 16:52:34.668632 25446 solver.cpp:259]     Train net output #0: center_loss = 188.575 (* 0.008 = 1.5086 loss)
I0826 16:52:34.668638 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.82503 (* 1 = 3.82503 loss)
I0826 16:52:34.668642 25446 sgd_solver.cpp:138] Iteration 24650, lr = 1e-05
I0826 16:52:36.729961 25446 solver.cpp:243] Iteration 24660, loss = 5.6338
I0826 16:52:36.729986 25446 solver.cpp:259]     Train net output #0: center_loss = 207.012 (* 0.008 = 1.65609 loss)
I0826 16:52:36.729992 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97771 (* 1 = 3.97771 loss)
I0826 16:52:36.729996 25446 sgd_solver.cpp:138] Iteration 24660, lr = 1e-05
I0826 16:52:38.793454 25446 solver.cpp:243] Iteration 24670, loss = 7.08492
I0826 16:52:38.793478 25446 solver.cpp:259]     Train net output #0: center_loss = 180.426 (* 0.008 = 1.44341 loss)
I0826 16:52:38.793484 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.64152 (* 1 = 5.64152 loss)
I0826 16:52:38.793488 25446 sgd_solver.cpp:138] Iteration 24670, lr = 1e-05
I0826 16:52:40.857283 25446 solver.cpp:243] Iteration 24680, loss = 5.46116
I0826 16:52:40.857306 25446 solver.cpp:259]     Train net output #0: center_loss = 205.163 (* 0.008 = 1.6413 loss)
I0826 16:52:40.857311 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81986 (* 1 = 3.81986 loss)
I0826 16:52:40.857316 25446 sgd_solver.cpp:138] Iteration 24680, lr = 1e-05
I0826 16:52:42.920656 25446 solver.cpp:243] Iteration 24690, loss = 6.24971
I0826 16:52:42.920680 25446 solver.cpp:259]     Train net output #0: center_loss = 211.342 (* 0.008 = 1.69073 loss)
I0826 16:52:42.920686 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.55898 (* 1 = 4.55898 loss)
I0826 16:52:42.920691 25446 sgd_solver.cpp:138] Iteration 24690, lr = 1e-05
I0826 16:52:45.049717 25446 solver.cpp:243] Iteration 24700, loss = 6.0351
I0826 16:52:45.049746 25446 solver.cpp:259]     Train net output #0: center_loss = 208.145 (* 0.008 = 1.66516 loss)
I0826 16:52:45.049751 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.36995 (* 1 = 4.36995 loss)
I0826 16:52:45.049757 25446 sgd_solver.cpp:138] Iteration 24700, lr = 1e-05
I0826 16:52:47.338989 25446 solver.cpp:243] Iteration 24710, loss = 4.85725
I0826 16:52:47.339015 25446 solver.cpp:259]     Train net output #0: center_loss = 231.576 (* 0.008 = 1.85261 loss)
I0826 16:52:47.339021 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.00464 (* 1 = 3.00464 loss)
I0826 16:52:47.339026 25446 sgd_solver.cpp:138] Iteration 24710, lr = 1e-05
I0826 16:52:49.443807 25446 solver.cpp:243] Iteration 24720, loss = 4.83421
I0826 16:52:49.443831 25446 solver.cpp:259]     Train net output #0: center_loss = 236.5 (* 0.008 = 1.892 loss)
I0826 16:52:49.443837 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.94222 (* 1 = 2.94222 loss)
I0826 16:52:49.443841 25446 sgd_solver.cpp:138] Iteration 24720, lr = 1e-05
I0826 16:52:51.512847 25446 solver.cpp:243] Iteration 24730, loss = 6.4786
I0826 16:52:51.512872 25446 solver.cpp:259]     Train net output #0: center_loss = 207.469 (* 0.008 = 1.65975 loss)
I0826 16:52:51.512878 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.81885 (* 1 = 4.81885 loss)
I0826 16:52:51.512882 25446 sgd_solver.cpp:138] Iteration 24730, lr = 1e-05
I0826 16:52:53.579480 25446 solver.cpp:243] Iteration 24740, loss = 7.57874
I0826 16:52:53.579520 25446 solver.cpp:259]     Train net output #0: center_loss = 167.694 (* 0.008 = 1.34156 loss)
I0826 16:52:53.579527 25446 solver.cpp:259]     Train net output #1: softmax_loss = 6.23719 (* 1 = 6.23719 loss)
I0826 16:52:53.579530 25446 sgd_solver.cpp:138] Iteration 24740, lr = 1e-05
I0826 16:52:55.653756 25446 solver.cpp:243] Iteration 24750, loss = 5.15222
I0826 16:52:55.653795 25446 solver.cpp:259]     Train net output #0: center_loss = 230.565 (* 0.008 = 1.84452 loss)
I0826 16:52:55.653801 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.3077 (* 1 = 3.3077 loss)
I0826 16:52:55.653806 25446 sgd_solver.cpp:138] Iteration 24750, lr = 1e-05
I0826 16:52:57.801450 25446 solver.cpp:243] Iteration 24760, loss = 4.7295
I0826 16:52:57.801585 25446 solver.cpp:259]     Train net output #0: center_loss = 216.358 (* 0.008 = 1.73086 loss)
I0826 16:52:57.801594 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.99864 (* 1 = 2.99864 loss)
I0826 16:52:57.801599 25446 sgd_solver.cpp:138] Iteration 24760, lr = 1e-05
I0826 16:52:59.899348 25446 solver.cpp:243] Iteration 24770, loss = 5.65938
I0826 16:52:59.899371 25446 solver.cpp:259]     Train net output #0: center_loss = 219.767 (* 0.008 = 1.75814 loss)
I0826 16:52:59.899377 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.90124 (* 1 = 3.90124 loss)
I0826 16:52:59.899381 25446 sgd_solver.cpp:138] Iteration 24770, lr = 1e-05
I0826 16:53:01.977239 25446 solver.cpp:243] Iteration 24780, loss = 4.65775
I0826 16:53:01.977282 25446 solver.cpp:259]     Train net output #0: center_loss = 233.382 (* 0.008 = 1.86706 loss)
I0826 16:53:01.977288 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.79069 (* 1 = 2.79069 loss)
I0826 16:53:01.977291 25446 sgd_solver.cpp:138] Iteration 24780, lr = 1e-05
I0826 16:53:04.049557 25446 solver.cpp:243] Iteration 24790, loss = 6.40945
I0826 16:53:04.049582 25446 solver.cpp:259]     Train net output #0: center_loss = 205.218 (* 0.008 = 1.64175 loss)
I0826 16:53:04.049587 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.76771 (* 1 = 4.76771 loss)
I0826 16:53:04.049592 25446 sgd_solver.cpp:138] Iteration 24790, lr = 1e-05
I0826 16:53:06.114437 25446 solver.cpp:243] Iteration 24800, loss = 4.85254
I0826 16:53:06.114461 25446 solver.cpp:259]     Train net output #0: center_loss = 243.511 (* 0.008 = 1.94809 loss)
I0826 16:53:06.114467 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.90445 (* 1 = 2.90445 loss)
I0826 16:53:06.114471 25446 sgd_solver.cpp:138] Iteration 24800, lr = 1e-05
I0826 16:53:08.185636 25446 solver.cpp:243] Iteration 24810, loss = 5.30476
I0826 16:53:08.185659 25446 solver.cpp:259]     Train net output #0: center_loss = 226.282 (* 0.008 = 1.81026 loss)
I0826 16:53:08.185665 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.4945 (* 1 = 3.4945 loss)
I0826 16:53:08.185670 25446 sgd_solver.cpp:138] Iteration 24810, lr = 1e-05
I0826 16:53:10.259047 25446 solver.cpp:243] Iteration 24820, loss = 5.56985
I0826 16:53:10.259071 25446 solver.cpp:259]     Train net output #0: center_loss = 198.209 (* 0.008 = 1.58567 loss)
I0826 16:53:10.259078 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.98418 (* 1 = 3.98418 loss)
I0826 16:53:10.259083 25446 sgd_solver.cpp:138] Iteration 24820, lr = 1e-05
I0826 16:53:12.339933 25446 solver.cpp:243] Iteration 24830, loss = 5.42352
I0826 16:53:12.339957 25446 solver.cpp:259]     Train net output #0: center_loss = 223.859 (* 0.008 = 1.79087 loss)
I0826 16:53:12.339963 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.63265 (* 1 = 3.63265 loss)
I0826 16:53:12.339967 25446 sgd_solver.cpp:138] Iteration 24830, lr = 1e-05
I0826 16:53:14.409948 25446 solver.cpp:243] Iteration 24840, loss = 5.13823
I0826 16:53:14.409987 25446 solver.cpp:259]     Train net output #0: center_loss = 220.447 (* 0.008 = 1.76358 loss)
I0826 16:53:14.409993 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.37466 (* 1 = 3.37466 loss)
I0826 16:53:14.409997 25446 sgd_solver.cpp:138] Iteration 24840, lr = 1e-05
I0826 16:53:16.486510 25446 solver.cpp:243] Iteration 24850, loss = 4.99779
I0826 16:53:16.486536 25446 solver.cpp:259]     Train net output #0: center_loss = 235.693 (* 0.008 = 1.88554 loss)
I0826 16:53:16.486542 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.11224 (* 1 = 3.11224 loss)
I0826 16:53:16.486546 25446 sgd_solver.cpp:138] Iteration 24850, lr = 1e-05
I0826 16:53:18.559033 25446 solver.cpp:243] Iteration 24860, loss = 6.04552
I0826 16:53:18.559073 25446 solver.cpp:259]     Train net output #0: center_loss = 199.536 (* 0.008 = 1.59629 loss)
I0826 16:53:18.559079 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.44923 (* 1 = 4.44923 loss)
I0826 16:53:18.559083 25446 sgd_solver.cpp:138] Iteration 24860, lr = 1e-05
I0826 16:53:20.633111 25446 solver.cpp:243] Iteration 24870, loss = 6.03364
I0826 16:53:20.633134 25446 solver.cpp:259]     Train net output #0: center_loss = 206.107 (* 0.008 = 1.64885 loss)
I0826 16:53:20.633141 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.38479 (* 1 = 4.38479 loss)
I0826 16:53:20.633157 25446 sgd_solver.cpp:138] Iteration 24870, lr = 1e-05
I0826 16:53:22.717325 25446 solver.cpp:243] Iteration 24880, loss = 4.80119
I0826 16:53:22.717350 25446 solver.cpp:259]     Train net output #0: center_loss = 212.29 (* 0.008 = 1.69832 loss)
I0826 16:53:22.717355 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.10287 (* 1 = 3.10287 loss)
I0826 16:53:22.717360 25446 sgd_solver.cpp:138] Iteration 24880, lr = 1e-05
I0826 16:53:24.793387 25446 solver.cpp:243] Iteration 24890, loss = 4.70259
I0826 16:53:24.793411 25446 solver.cpp:259]     Train net output #0: center_loss = 224.784 (* 0.008 = 1.79827 loss)
I0826 16:53:24.793417 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.90432 (* 1 = 2.90432 loss)
I0826 16:53:24.793422 25446 sgd_solver.cpp:138] Iteration 24890, lr = 1e-05
I0826 16:53:26.874511 25446 solver.cpp:243] Iteration 24900, loss = 5.8336
I0826 16:53:26.874536 25446 solver.cpp:259]     Train net output #0: center_loss = 223.919 (* 0.008 = 1.79135 loss)
I0826 16:53:26.874541 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04225 (* 1 = 4.04225 loss)
I0826 16:53:26.874547 25446 sgd_solver.cpp:138] Iteration 24900, lr = 1e-05
I0826 16:53:28.947273 25446 solver.cpp:243] Iteration 24910, loss = 5.61781
I0826 16:53:28.947407 25446 solver.cpp:259]     Train net output #0: center_loss = 204.935 (* 0.008 = 1.63948 loss)
I0826 16:53:28.947427 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97833 (* 1 = 3.97833 loss)
I0826 16:53:28.947430 25446 sgd_solver.cpp:138] Iteration 24910, lr = 1e-05
I0826 16:53:31.028978 25446 solver.cpp:243] Iteration 24920, loss = 6.23249
I0826 16:53:31.029002 25446 solver.cpp:259]     Train net output #0: center_loss = 193.908 (* 0.008 = 1.55126 loss)
I0826 16:53:31.029008 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.68123 (* 1 = 4.68123 loss)
I0826 16:53:31.029013 25446 sgd_solver.cpp:138] Iteration 24920, lr = 1e-05
I0826 16:53:33.109141 25446 solver.cpp:243] Iteration 24930, loss = 5.83678
I0826 16:53:33.109165 25446 solver.cpp:259]     Train net output #0: center_loss = 213.26 (* 0.008 = 1.70608 loss)
I0826 16:53:33.109171 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.1307 (* 1 = 4.1307 loss)
I0826 16:53:33.109176 25446 sgd_solver.cpp:138] Iteration 24930, lr = 1e-05
I0826 16:53:35.179750 25446 solver.cpp:243] Iteration 24940, loss = 5.55224
I0826 16:53:35.179790 25446 solver.cpp:259]     Train net output #0: center_loss = 208.43 (* 0.008 = 1.66744 loss)
I0826 16:53:35.179795 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.8848 (* 1 = 3.8848 loss)
I0826 16:53:35.179800 25446 sgd_solver.cpp:138] Iteration 24940, lr = 1e-05
I0826 16:53:37.247655 25446 solver.cpp:243] Iteration 24950, loss = 5.00975
I0826 16:53:37.247678 25446 solver.cpp:259]     Train net output #0: center_loss = 229.805 (* 0.008 = 1.83844 loss)
I0826 16:53:37.247684 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.17131 (* 1 = 3.17131 loss)
I0826 16:53:37.247687 25446 sgd_solver.cpp:138] Iteration 24950, lr = 1e-05
I0826 16:53:39.316931 25446 solver.cpp:243] Iteration 24960, loss = 5.73621
I0826 16:53:39.316959 25446 solver.cpp:259]     Train net output #0: center_loss = 223.799 (* 0.008 = 1.79039 loss)
I0826 16:53:39.316967 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.94582 (* 1 = 3.94582 loss)
I0826 16:53:39.316972 25446 sgd_solver.cpp:138] Iteration 24960, lr = 1e-05
I0826 16:53:41.384403 25446 solver.cpp:243] Iteration 24970, loss = 6.14232
I0826 16:53:41.384428 25446 solver.cpp:259]     Train net output #0: center_loss = 204.788 (* 0.008 = 1.6383 loss)
I0826 16:53:41.384434 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.50402 (* 1 = 4.50402 loss)
I0826 16:53:41.384438 25446 sgd_solver.cpp:138] Iteration 24970, lr = 1e-05
I0826 16:53:43.454679 25446 solver.cpp:243] Iteration 24980, loss = 5.40847
I0826 16:53:43.454716 25446 solver.cpp:259]     Train net output #0: center_loss = 205.731 (* 0.008 = 1.64584 loss)
I0826 16:53:43.454722 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.76262 (* 1 = 3.76262 loss)
I0826 16:53:43.454727 25446 sgd_solver.cpp:138] Iteration 24980, lr = 1e-05
I0826 16:53:45.516047 25446 solver.cpp:243] Iteration 24990, loss = 5.05536
I0826 16:53:45.516085 25446 solver.cpp:259]     Train net output #0: center_loss = 230.812 (* 0.008 = 1.8465 loss)
I0826 16:53:45.516091 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.20886 (* 1 = 3.20886 loss)
I0826 16:53:45.516095 25446 sgd_solver.cpp:138] Iteration 24990, lr = 1e-05
I0826 16:53:47.374367 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_25000.caffemodel
I0826 16:53:48.504642 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_25000.solverstate
I0826 16:53:48.833740 25446 solver.cpp:243] Iteration 25000, loss = 5.30351
I0826 16:53:48.833768 25446 solver.cpp:259]     Train net output #0: center_loss = 208.999 (* 0.008 = 1.67199 loss)
I0826 16:53:48.833775 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.63152 (* 1 = 3.63152 loss)
I0826 16:53:48.833779 25446 sgd_solver.cpp:138] Iteration 25000, lr = 1e-05
I0826 16:53:50.901016 25446 solver.cpp:243] Iteration 25010, loss = 5.38602
I0826 16:53:50.901054 25446 solver.cpp:259]     Train net output #0: center_loss = 230.038 (* 0.008 = 1.84031 loss)
I0826 16:53:50.901101 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.54572 (* 1 = 3.54572 loss)
I0826 16:53:50.901105 25446 sgd_solver.cpp:138] Iteration 25010, lr = 1e-05
I0826 16:53:52.988934 25446 solver.cpp:243] Iteration 25020, loss = 5.53721
I0826 16:53:52.988972 25446 solver.cpp:259]     Train net output #0: center_loss = 200.516 (* 0.008 = 1.60413 loss)
I0826 16:53:52.988978 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.93308 (* 1 = 3.93308 loss)
I0826 16:53:52.988982 25446 sgd_solver.cpp:138] Iteration 25020, lr = 1e-05
I0826 16:53:55.080057 25446 solver.cpp:243] Iteration 25030, loss = 6.34686
I0826 16:53:55.080080 25446 solver.cpp:259]     Train net output #0: center_loss = 205.368 (* 0.008 = 1.64294 loss)
I0826 16:53:55.080111 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70391 (* 1 = 4.70391 loss)
I0826 16:53:55.080116 25446 sgd_solver.cpp:138] Iteration 25030, lr = 1e-05
I0826 16:53:57.148185 25446 solver.cpp:243] Iteration 25040, loss = 5.76959
I0826 16:53:57.148223 25446 solver.cpp:259]     Train net output #0: center_loss = 227.977 (* 0.008 = 1.82381 loss)
I0826 16:53:57.148229 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.94577 (* 1 = 3.94577 loss)
I0826 16:53:57.148233 25446 sgd_solver.cpp:138] Iteration 25040, lr = 1e-05
I0826 16:53:59.218428 25446 solver.cpp:243] Iteration 25050, loss = 5.37456
I0826 16:53:59.218605 25446 solver.cpp:259]     Train net output #0: center_loss = 210.603 (* 0.008 = 1.68483 loss)
I0826 16:53:59.218613 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.68974 (* 1 = 3.68974 loss)
I0826 16:53:59.218617 25446 sgd_solver.cpp:138] Iteration 25050, lr = 1e-05
I0826 16:54:01.288861 25446 solver.cpp:243] Iteration 25060, loss = 5.77629
I0826 16:54:01.288885 25446 solver.cpp:259]     Train net output #0: center_loss = 205.678 (* 0.008 = 1.64542 loss)
I0826 16:54:01.288892 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.13087 (* 1 = 4.13087 loss)
I0826 16:54:01.288895 25446 sgd_solver.cpp:138] Iteration 25060, lr = 1e-05
I0826 16:54:03.357064 25446 solver.cpp:243] Iteration 25070, loss = 5.72979
I0826 16:54:03.357087 25446 solver.cpp:259]     Train net output #0: center_loss = 220.291 (* 0.008 = 1.76233 loss)
I0826 16:54:03.357093 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.96746 (* 1 = 3.96746 loss)
I0826 16:54:03.357097 25446 sgd_solver.cpp:138] Iteration 25070, lr = 1e-05
I0826 16:54:05.422467 25446 solver.cpp:243] Iteration 25080, loss = 5.27206
I0826 16:54:05.422507 25446 solver.cpp:259]     Train net output #0: center_loss = 216.993 (* 0.008 = 1.73594 loss)
I0826 16:54:05.422513 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.53612 (* 1 = 3.53612 loss)
I0826 16:54:05.422518 25446 sgd_solver.cpp:138] Iteration 25080, lr = 1e-05
I0826 16:54:07.491770 25446 solver.cpp:243] Iteration 25090, loss = 6.18803
I0826 16:54:07.491793 25446 solver.cpp:259]     Train net output #0: center_loss = 192.553 (* 0.008 = 1.54042 loss)
I0826 16:54:07.491799 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.64761 (* 1 = 4.64761 loss)
I0826 16:54:07.491803 25446 sgd_solver.cpp:138] Iteration 25090, lr = 1e-05
I0826 16:54:09.560284 25446 solver.cpp:243] Iteration 25100, loss = 5.66121
I0826 16:54:09.560308 25446 solver.cpp:259]     Train net output #0: center_loss = 205.131 (* 0.008 = 1.64104 loss)
I0826 16:54:09.560315 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.02017 (* 1 = 4.02017 loss)
I0826 16:54:09.560319 25446 sgd_solver.cpp:138] Iteration 25100, lr = 1e-05
I0826 16:54:11.629444 25446 solver.cpp:243] Iteration 25110, loss = 4.58346
I0826 16:54:11.629468 25446 solver.cpp:259]     Train net output #0: center_loss = 217.366 (* 0.008 = 1.73893 loss)
I0826 16:54:11.629474 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.84453 (* 1 = 2.84453 loss)
I0826 16:54:11.629479 25446 sgd_solver.cpp:138] Iteration 25110, lr = 1e-05
I0826 16:54:13.693992 25446 solver.cpp:243] Iteration 25120, loss = 5.17364
I0826 16:54:13.694032 25446 solver.cpp:259]     Train net output #0: center_loss = 218.907 (* 0.008 = 1.75126 loss)
I0826 16:54:13.694038 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.42239 (* 1 = 3.42239 loss)
I0826 16:54:13.694042 25446 sgd_solver.cpp:138] Iteration 25120, lr = 1e-05
I0826 16:54:15.762550 25446 solver.cpp:243] Iteration 25130, loss = 6.47381
I0826 16:54:15.762573 25446 solver.cpp:259]     Train net output #0: center_loss = 188.879 (* 0.008 = 1.51103 loss)
I0826 16:54:15.762579 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.96277 (* 1 = 4.96277 loss)
I0826 16:54:15.762583 25446 sgd_solver.cpp:138] Iteration 25130, lr = 1e-05
I0826 16:54:17.827682 25446 solver.cpp:243] Iteration 25140, loss = 5.00393
I0826 16:54:17.827720 25446 solver.cpp:259]     Train net output #0: center_loss = 213.998 (* 0.008 = 1.71198 loss)
I0826 16:54:17.827726 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.29195 (* 1 = 3.29195 loss)
I0826 16:54:17.827730 25446 sgd_solver.cpp:138] Iteration 25140, lr = 1e-05
I0826 16:54:19.893124 25446 solver.cpp:243] Iteration 25150, loss = 4.94738
I0826 16:54:19.893163 25446 solver.cpp:259]     Train net output #0: center_loss = 213.961 (* 0.008 = 1.71169 loss)
I0826 16:54:19.893170 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.23569 (* 1 = 3.23569 loss)
I0826 16:54:19.893174 25446 sgd_solver.cpp:138] Iteration 25150, lr = 1e-05
I0826 16:54:21.961578 25446 solver.cpp:243] Iteration 25160, loss = 5.65887
I0826 16:54:21.961617 25446 solver.cpp:259]     Train net output #0: center_loss = 210.188 (* 0.008 = 1.68151 loss)
I0826 16:54:21.961623 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97737 (* 1 = 3.97737 loss)
I0826 16:54:21.961627 25446 sgd_solver.cpp:138] Iteration 25160, lr = 1e-05
I0826 16:54:24.032488 25446 solver.cpp:243] Iteration 25170, loss = 5.40493
I0826 16:54:24.032526 25446 solver.cpp:259]     Train net output #0: center_loss = 210.213 (* 0.008 = 1.68171 loss)
I0826 16:54:24.032532 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.72322 (* 1 = 3.72322 loss)
I0826 16:54:24.032537 25446 sgd_solver.cpp:138] Iteration 25170, lr = 1e-05
I0826 16:54:26.097643 25446 solver.cpp:243] Iteration 25180, loss = 6.09795
I0826 16:54:26.097667 25446 solver.cpp:259]     Train net output #0: center_loss = 202.39 (* 0.008 = 1.61912 loss)
I0826 16:54:26.097673 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47883 (* 1 = 4.47883 loss)
I0826 16:54:26.097678 25446 sgd_solver.cpp:138] Iteration 25180, lr = 1e-05
I0826 16:54:28.164161 25446 solver.cpp:243] Iteration 25190, loss = 4.74636
I0826 16:54:28.164199 25446 solver.cpp:259]     Train net output #0: center_loss = 215.212 (* 0.008 = 1.72169 loss)
I0826 16:54:28.164206 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.02466 (* 1 = 3.02466 loss)
I0826 16:54:28.164211 25446 sgd_solver.cpp:138] Iteration 25190, lr = 1e-05
I0826 16:54:30.228629 25446 solver.cpp:243] Iteration 25200, loss = 5.93016
I0826 16:54:30.228760 25446 solver.cpp:259]     Train net output #0: center_loss = 220.502 (* 0.008 = 1.76402 loss)
I0826 16:54:30.228767 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.16614 (* 1 = 4.16614 loss)
I0826 16:54:30.228785 25446 sgd_solver.cpp:138] Iteration 25200, lr = 1e-05
I0826 16:54:32.296066 25446 solver.cpp:243] Iteration 25210, loss = 5.28888
I0826 16:54:32.296088 25446 solver.cpp:259]     Train net output #0: center_loss = 204.766 (* 0.008 = 1.63813 loss)
I0826 16:54:32.296094 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.65075 (* 1 = 3.65075 loss)
I0826 16:54:32.296099 25446 sgd_solver.cpp:138] Iteration 25210, lr = 1e-05
I0826 16:54:34.366101 25446 solver.cpp:243] Iteration 25220, loss = 5.38037
I0826 16:54:34.366123 25446 solver.cpp:259]     Train net output #0: center_loss = 235.66 (* 0.008 = 1.88528 loss)
I0826 16:54:34.366130 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.49509 (* 1 = 3.49509 loss)
I0826 16:54:34.366134 25446 sgd_solver.cpp:138] Iteration 25220, lr = 1e-05
I0826 16:54:36.439273 25446 solver.cpp:243] Iteration 25230, loss = 5.81641
I0826 16:54:36.439312 25446 solver.cpp:259]     Train net output #0: center_loss = 223.113 (* 0.008 = 1.78491 loss)
I0826 16:54:36.439319 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.03151 (* 1 = 4.03151 loss)
I0826 16:54:36.439323 25446 sgd_solver.cpp:138] Iteration 25230, lr = 1e-05
I0826 16:54:38.508292 25446 solver.cpp:243] Iteration 25240, loss = 6.42838
I0826 16:54:38.508316 25446 solver.cpp:259]     Train net output #0: center_loss = 203.806 (* 0.008 = 1.63045 loss)
I0826 16:54:38.508322 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.79794 (* 1 = 4.79794 loss)
I0826 16:54:38.508327 25446 sgd_solver.cpp:138] Iteration 25240, lr = 1e-05
I0826 16:54:40.576997 25446 solver.cpp:243] Iteration 25250, loss = 4.79992
I0826 16:54:40.577021 25446 solver.cpp:259]     Train net output #0: center_loss = 226.23 (* 0.008 = 1.80984 loss)
I0826 16:54:40.577028 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.99008 (* 1 = 2.99008 loss)
I0826 16:54:40.577031 25446 sgd_solver.cpp:138] Iteration 25250, lr = 1e-05
I0826 16:54:42.643618 25446 solver.cpp:243] Iteration 25260, loss = 6.40518
I0826 16:54:42.643643 25446 solver.cpp:259]     Train net output #0: center_loss = 206.323 (* 0.008 = 1.65058 loss)
I0826 16:54:42.643649 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.7546 (* 1 = 4.7546 loss)
I0826 16:54:42.643653 25446 sgd_solver.cpp:138] Iteration 25260, lr = 1e-05
I0826 16:54:44.739012 25446 solver.cpp:243] Iteration 25270, loss = 5.79445
I0826 16:54:44.739053 25446 solver.cpp:259]     Train net output #0: center_loss = 183.49 (* 0.008 = 1.46792 loss)
I0826 16:54:44.739059 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.32653 (* 1 = 4.32653 loss)
I0826 16:54:44.739063 25446 sgd_solver.cpp:138] Iteration 25270, lr = 1e-05
I0826 16:54:46.935184 25446 solver.cpp:243] Iteration 25280, loss = 6.25746
I0826 16:54:46.935207 25446 solver.cpp:259]     Train net output #0: center_loss = 194.28 (* 0.008 = 1.55424 loss)
I0826 16:54:46.935214 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.70322 (* 1 = 4.70322 loss)
I0826 16:54:46.935218 25446 sgd_solver.cpp:138] Iteration 25280, lr = 1e-05
I0826 16:54:49.074329 25446 solver.cpp:243] Iteration 25290, loss = 6.2281
I0826 16:54:49.074355 25446 solver.cpp:259]     Train net output #0: center_loss = 203.592 (* 0.008 = 1.62874 loss)
I0826 16:54:49.074362 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.59936 (* 1 = 4.59936 loss)
I0826 16:54:49.074367 25446 sgd_solver.cpp:138] Iteration 25290, lr = 1e-05
I0826 16:54:51.206373 25446 solver.cpp:243] Iteration 25300, loss = 7.23756
I0826 16:54:51.206411 25446 solver.cpp:259]     Train net output #0: center_loss = 212.841 (* 0.008 = 1.70273 loss)
I0826 16:54:51.206418 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.53484 (* 1 = 5.53484 loss)
I0826 16:54:51.206421 25446 sgd_solver.cpp:138] Iteration 25300, lr = 1e-05
I0826 16:54:53.267104 25446 solver.cpp:243] Iteration 25310, loss = 5.43035
I0826 16:54:53.267127 25446 solver.cpp:259]     Train net output #0: center_loss = 207.061 (* 0.008 = 1.65649 loss)
I0826 16:54:53.267134 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77386 (* 1 = 3.77386 loss)
I0826 16:54:53.267138 25446 sgd_solver.cpp:138] Iteration 25310, lr = 1e-05
I0826 16:54:55.329546 25446 solver.cpp:243] Iteration 25320, loss = 5.3145
I0826 16:54:55.329586 25446 solver.cpp:259]     Train net output #0: center_loss = 211.13 (* 0.008 = 1.68904 loss)
I0826 16:54:55.329592 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.62546 (* 1 = 3.62546 loss)
I0826 16:54:55.329596 25446 sgd_solver.cpp:138] Iteration 25320, lr = 1e-05
I0826 16:54:57.385761 25446 solver.cpp:243] Iteration 25330, loss = 4.25975
I0826 16:54:57.385785 25446 solver.cpp:259]     Train net output #0: center_loss = 204.674 (* 0.008 = 1.63739 loss)
I0826 16:54:57.385792 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.62237 (* 1 = 2.62237 loss)
I0826 16:54:57.385795 25446 sgd_solver.cpp:138] Iteration 25330, lr = 1e-05
I0826 16:54:59.444205 25446 solver.cpp:243] Iteration 25340, loss = 4.47653
I0826 16:54:59.444229 25446 solver.cpp:259]     Train net output #0: center_loss = 208.897 (* 0.008 = 1.67118 loss)
I0826 16:54:59.444236 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.80535 (* 1 = 2.80535 loss)
I0826 16:54:59.444239 25446 sgd_solver.cpp:138] Iteration 25340, lr = 1e-05
I0826 16:55:01.506523 25446 solver.cpp:243] Iteration 25350, loss = 5.11889
I0826 16:55:01.506649 25446 solver.cpp:259]     Train net output #0: center_loss = 214.623 (* 0.008 = 1.71698 loss)
I0826 16:55:01.506656 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.4019 (* 1 = 3.4019 loss)
I0826 16:55:01.506660 25446 sgd_solver.cpp:138] Iteration 25350, lr = 1e-05
I0826 16:55:03.568902 25446 solver.cpp:243] Iteration 25360, loss = 4.71295
I0826 16:55:03.568943 25446 solver.cpp:259]     Train net output #0: center_loss = 235.574 (* 0.008 = 1.88459 loss)
I0826 16:55:03.568948 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.82837 (* 1 = 2.82837 loss)
I0826 16:55:03.568951 25446 sgd_solver.cpp:138] Iteration 25360, lr = 1e-05
I0826 16:55:05.631486 25446 solver.cpp:243] Iteration 25370, loss = 6.21256
I0826 16:55:05.631510 25446 solver.cpp:259]     Train net output #0: center_loss = 192.709 (* 0.008 = 1.54167 loss)
I0826 16:55:05.631516 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.67089 (* 1 = 4.67089 loss)
I0826 16:55:05.631520 25446 sgd_solver.cpp:138] Iteration 25370, lr = 1e-05
I0826 16:55:07.692736 25446 solver.cpp:243] Iteration 25380, loss = 4.74425
I0826 16:55:07.692761 25446 solver.cpp:259]     Train net output #0: center_loss = 210.536 (* 0.008 = 1.68429 loss)
I0826 16:55:07.692767 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.05996 (* 1 = 3.05996 loss)
I0826 16:55:07.692770 25446 sgd_solver.cpp:138] Iteration 25380, lr = 1e-05
I0826 16:55:09.753334 25446 solver.cpp:243] Iteration 25390, loss = 5.09299
I0826 16:55:09.753372 25446 solver.cpp:259]     Train net output #0: center_loss = 217.272 (* 0.008 = 1.73817 loss)
I0826 16:55:09.753378 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.35481 (* 1 = 3.35481 loss)
I0826 16:55:09.753382 25446 sgd_solver.cpp:138] Iteration 25390, lr = 1e-05
I0826 16:55:11.816892 25446 solver.cpp:243] Iteration 25400, loss = 5.51047
I0826 16:55:11.816916 25446 solver.cpp:259]     Train net output #0: center_loss = 218.674 (* 0.008 = 1.74939 loss)
I0826 16:55:11.816922 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.76108 (* 1 = 3.76108 loss)
I0826 16:55:11.816926 25446 sgd_solver.cpp:138] Iteration 25400, lr = 1e-05
I0826 16:55:14.024705 25446 solver.cpp:243] Iteration 25410, loss = 5.26434
I0826 16:55:14.024729 25446 solver.cpp:259]     Train net output #0: center_loss = 206.617 (* 0.008 = 1.65293 loss)
I0826 16:55:14.024735 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.6114 (* 1 = 3.6114 loss)
I0826 16:55:14.024740 25446 sgd_solver.cpp:138] Iteration 25410, lr = 1e-05
I0826 16:55:16.269331 25446 solver.cpp:243] Iteration 25420, loss = 5.61617
I0826 16:55:16.269359 25446 solver.cpp:259]     Train net output #0: center_loss = 198.802 (* 0.008 = 1.59041 loss)
I0826 16:55:16.269366 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.02576 (* 1 = 4.02576 loss)
I0826 16:55:16.269371 25446 sgd_solver.cpp:138] Iteration 25420, lr = 1e-05
I0826 16:55:18.469310 25446 solver.cpp:243] Iteration 25430, loss = 5.20823
I0826 16:55:18.469338 25446 solver.cpp:259]     Train net output #0: center_loss = 220.344 (* 0.008 = 1.76275 loss)
I0826 16:55:18.469344 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.44547 (* 1 = 3.44547 loss)
I0826 16:55:18.469349 25446 sgd_solver.cpp:138] Iteration 25430, lr = 1e-05
I0826 16:55:20.561760 25446 solver.cpp:243] Iteration 25440, loss = 5.93501
I0826 16:55:20.561800 25446 solver.cpp:259]     Train net output #0: center_loss = 228.389 (* 0.008 = 1.82711 loss)
I0826 16:55:20.561807 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.1079 (* 1 = 4.1079 loss)
I0826 16:55:20.561811 25446 sgd_solver.cpp:138] Iteration 25440, lr = 1e-05
I0826 16:55:22.668337 25446 solver.cpp:243] Iteration 25450, loss = 5.30754
I0826 16:55:22.668365 25446 solver.cpp:259]     Train net output #0: center_loss = 242.533 (* 0.008 = 1.94026 loss)
I0826 16:55:22.668372 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.36727 (* 1 = 3.36727 loss)
I0826 16:55:22.668377 25446 sgd_solver.cpp:138] Iteration 25450, lr = 1e-05
I0826 16:55:24.788352 25446 solver.cpp:243] Iteration 25460, loss = 4.82947
I0826 16:55:24.788375 25446 solver.cpp:259]     Train net output #0: center_loss = 222.927 (* 0.008 = 1.78341 loss)
I0826 16:55:24.788381 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.04606 (* 1 = 3.04606 loss)
I0826 16:55:24.788386 25446 sgd_solver.cpp:138] Iteration 25460, lr = 1e-05
I0826 16:55:26.852928 25446 solver.cpp:243] Iteration 25470, loss = 5.32171
I0826 16:55:26.852952 25446 solver.cpp:259]     Train net output #0: center_loss = 200.654 (* 0.008 = 1.60524 loss)
I0826 16:55:26.852958 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.71647 (* 1 = 3.71647 loss)
I0826 16:55:26.852962 25446 sgd_solver.cpp:138] Iteration 25470, lr = 1e-05
I0826 16:55:28.933877 25446 solver.cpp:243] Iteration 25480, loss = 5.65812
I0826 16:55:28.933902 25446 solver.cpp:259]     Train net output #0: center_loss = 227.41 (* 0.008 = 1.81928 loss)
I0826 16:55:28.933909 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83883 (* 1 = 3.83883 loss)
I0826 16:55:28.933913 25446 sgd_solver.cpp:138] Iteration 25480, lr = 1e-05
I0826 16:55:30.998803 25446 solver.cpp:243] Iteration 25490, loss = 5.28257
I0826 16:55:30.998826 25446 solver.cpp:259]     Train net output #0: center_loss = 233.128 (* 0.008 = 1.86503 loss)
I0826 16:55:30.998833 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.41754 (* 1 = 3.41754 loss)
I0826 16:55:30.998837 25446 sgd_solver.cpp:138] Iteration 25490, lr = 1e-05
I0826 16:55:33.092754 25446 solver.cpp:243] Iteration 25500, loss = 6.10239
I0826 16:55:33.092865 25446 solver.cpp:259]     Train net output #0: center_loss = 210.29 (* 0.008 = 1.68232 loss)
I0826 16:55:33.092872 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.42007 (* 1 = 4.42007 loss)
I0826 16:55:33.092877 25446 sgd_solver.cpp:138] Iteration 25500, lr = 1e-05
I0826 16:55:35.227562 25446 solver.cpp:243] Iteration 25510, loss = 5.54027
I0826 16:55:35.227586 25446 solver.cpp:259]     Train net output #0: center_loss = 214.183 (* 0.008 = 1.71347 loss)
I0826 16:55:35.227592 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.82681 (* 1 = 3.82681 loss)
I0826 16:55:35.227596 25446 sgd_solver.cpp:138] Iteration 25510, lr = 1e-05
I0826 16:55:37.294698 25446 solver.cpp:243] Iteration 25520, loss = 5.93722
I0826 16:55:37.294726 25446 solver.cpp:259]     Train net output #0: center_loss = 193.871 (* 0.008 = 1.55097 loss)
I0826 16:55:37.294733 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.38625 (* 1 = 4.38625 loss)
I0826 16:55:37.294737 25446 sgd_solver.cpp:138] Iteration 25520, lr = 1e-05
I0826 16:55:39.371222 25446 solver.cpp:243] Iteration 25530, loss = 5.23441
I0826 16:55:39.371246 25446 solver.cpp:259]     Train net output #0: center_loss = 208.133 (* 0.008 = 1.66506 loss)
I0826 16:55:39.371253 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.56935 (* 1 = 3.56935 loss)
I0826 16:55:39.371256 25446 sgd_solver.cpp:138] Iteration 25530, lr = 1e-05
I0826 16:55:41.447769 25446 solver.cpp:243] Iteration 25540, loss = 5.88891
I0826 16:55:41.447793 25446 solver.cpp:259]     Train net output #0: center_loss = 204.85 (* 0.008 = 1.6388 loss)
I0826 16:55:41.447799 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.25011 (* 1 = 4.25011 loss)
I0826 16:55:41.447804 25446 sgd_solver.cpp:138] Iteration 25540, lr = 1e-05
I0826 16:55:43.524806 25446 solver.cpp:243] Iteration 25550, loss = 4.83558
I0826 16:55:43.524830 25446 solver.cpp:259]     Train net output #0: center_loss = 233.598 (* 0.008 = 1.86878 loss)
I0826 16:55:43.524837 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.96679 (* 1 = 2.96679 loss)
I0826 16:55:43.524840 25446 sgd_solver.cpp:138] Iteration 25550, lr = 1e-05
I0826 16:55:45.673257 25446 solver.cpp:243] Iteration 25560, loss = 4.88521
I0826 16:55:45.673283 25446 solver.cpp:259]     Train net output #0: center_loss = 222.862 (* 0.008 = 1.7829 loss)
I0826 16:55:45.673290 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.10231 (* 1 = 3.10231 loss)
I0826 16:55:45.673295 25446 sgd_solver.cpp:138] Iteration 25560, lr = 1e-05
I0826 16:55:47.794634 25446 solver.cpp:243] Iteration 25570, loss = 5.58165
I0826 16:55:47.794656 25446 solver.cpp:259]     Train net output #0: center_loss = 224.746 (* 0.008 = 1.79797 loss)
I0826 16:55:47.794662 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.78368 (* 1 = 3.78368 loss)
I0826 16:55:47.794667 25446 sgd_solver.cpp:138] Iteration 25570, lr = 1e-05
I0826 16:55:49.865290 25446 solver.cpp:243] Iteration 25580, loss = 5.6416
I0826 16:55:49.865312 25446 solver.cpp:259]     Train net output #0: center_loss = 223.725 (* 0.008 = 1.7898 loss)
I0826 16:55:49.865319 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.8518 (* 1 = 3.8518 loss)
I0826 16:55:49.865322 25446 sgd_solver.cpp:138] Iteration 25580, lr = 1e-05
I0826 16:55:51.928607 25446 solver.cpp:243] Iteration 25590, loss = 5.98172
I0826 16:55:51.928645 25446 solver.cpp:259]     Train net output #0: center_loss = 210.867 (* 0.008 = 1.68693 loss)
I0826 16:55:51.928653 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29479 (* 1 = 4.29479 loss)
I0826 16:55:51.928656 25446 sgd_solver.cpp:138] Iteration 25590, lr = 1e-05
I0826 16:55:54.009690 25446 solver.cpp:243] Iteration 25600, loss = 6.29681
I0826 16:55:54.009714 25446 solver.cpp:259]     Train net output #0: center_loss = 212.959 (* 0.008 = 1.70367 loss)
I0826 16:55:54.009721 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.59314 (* 1 = 4.59314 loss)
I0826 16:55:54.009726 25446 sgd_solver.cpp:138] Iteration 25600, lr = 1e-05
I0826 16:55:56.075167 25446 solver.cpp:243] Iteration 25610, loss = 6.61577
I0826 16:55:56.075206 25446 solver.cpp:259]     Train net output #0: center_loss = 202.193 (* 0.008 = 1.61755 loss)
I0826 16:55:56.075213 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.99823 (* 1 = 4.99823 loss)
I0826 16:55:56.075217 25446 sgd_solver.cpp:138] Iteration 25610, lr = 1e-05
I0826 16:55:58.160755 25446 solver.cpp:243] Iteration 25620, loss = 5.81668
I0826 16:55:58.160786 25446 solver.cpp:259]     Train net output #0: center_loss = 215.9 (* 0.008 = 1.7272 loss)
I0826 16:55:58.160794 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.08948 (* 1 = 4.08948 loss)
I0826 16:55:58.160799 25446 sgd_solver.cpp:138] Iteration 25620, lr = 1e-05
I0826 16:56:00.326308 25446 solver.cpp:243] Iteration 25630, loss = 5.16114
I0826 16:56:00.326346 25446 solver.cpp:259]     Train net output #0: center_loss = 245.397 (* 0.008 = 1.96318 loss)
I0826 16:56:00.326354 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.19797 (* 1 = 3.19797 loss)
I0826 16:56:00.326370 25446 sgd_solver.cpp:138] Iteration 25630, lr = 1e-05
I0826 16:56:02.416625 25446 solver.cpp:243] Iteration 25640, loss = 5.38218
I0826 16:56:02.416651 25446 solver.cpp:259]     Train net output #0: center_loss = 228.391 (* 0.008 = 1.82713 loss)
I0826 16:56:02.416656 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.55505 (* 1 = 3.55505 loss)
I0826 16:56:02.416661 25446 sgd_solver.cpp:138] Iteration 25640, lr = 1e-05
I0826 16:56:04.482538 25446 solver.cpp:243] Iteration 25650, loss = 6.3036
I0826 16:56:04.482679 25446 solver.cpp:259]     Train net output #0: center_loss = 236.772 (* 0.008 = 1.89418 loss)
I0826 16:56:04.482699 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40942 (* 1 = 4.40942 loss)
I0826 16:56:04.482703 25446 sgd_solver.cpp:138] Iteration 25650, lr = 1e-05
I0826 16:56:06.621258 25446 solver.cpp:243] Iteration 25660, loss = 5.50378
I0826 16:56:06.621284 25446 solver.cpp:259]     Train net output #0: center_loss = 197.236 (* 0.008 = 1.57789 loss)
I0826 16:56:06.621290 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9259 (* 1 = 3.9259 loss)
I0826 16:56:06.621295 25446 sgd_solver.cpp:138] Iteration 25660, lr = 1e-05
I0826 16:56:08.833657 25446 solver.cpp:243] Iteration 25670, loss = 5.17903
I0826 16:56:08.833683 25446 solver.cpp:259]     Train net output #0: center_loss = 210.296 (* 0.008 = 1.68237 loss)
I0826 16:56:08.833688 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.49666 (* 1 = 3.49666 loss)
I0826 16:56:08.833693 25446 sgd_solver.cpp:138] Iteration 25670, lr = 1e-05
I0826 16:56:10.947034 25446 solver.cpp:243] Iteration 25680, loss = 6.88335
I0826 16:56:10.947059 25446 solver.cpp:259]     Train net output #0: center_loss = 192.912 (* 0.008 = 1.54329 loss)
I0826 16:56:10.947067 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.34005 (* 1 = 5.34005 loss)
I0826 16:56:10.947072 25446 sgd_solver.cpp:138] Iteration 25680, lr = 1e-05
I0826 16:56:13.051579 25446 solver.cpp:243] Iteration 25690, loss = 4.74961
I0826 16:56:13.051602 25446 solver.cpp:259]     Train net output #0: center_loss = 236.459 (* 0.008 = 1.89167 loss)
I0826 16:56:13.051609 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.85794 (* 1 = 2.85794 loss)
I0826 16:56:13.051614 25446 sgd_solver.cpp:138] Iteration 25690, lr = 1e-05
I0826 16:56:15.138561 25446 solver.cpp:243] Iteration 25700, loss = 6.34051
I0826 16:56:15.138586 25446 solver.cpp:259]     Train net output #0: center_loss = 184.435 (* 0.008 = 1.47548 loss)
I0826 16:56:15.138592 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.86503 (* 1 = 4.86503 loss)
I0826 16:56:15.138597 25446 sgd_solver.cpp:138] Iteration 25700, lr = 1e-05
I0826 16:56:17.237198 25446 solver.cpp:243] Iteration 25710, loss = 5.17035
I0826 16:56:17.237221 25446 solver.cpp:259]     Train net output #0: center_loss = 219.842 (* 0.008 = 1.75874 loss)
I0826 16:56:17.237227 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.41162 (* 1 = 3.41162 loss)
I0826 16:56:17.237231 25446 sgd_solver.cpp:138] Iteration 25710, lr = 1e-05
I0826 16:56:19.336055 25446 solver.cpp:243] Iteration 25720, loss = 5.93849
I0826 16:56:19.336078 25446 solver.cpp:259]     Train net output #0: center_loss = 199.243 (* 0.008 = 1.59394 loss)
I0826 16:56:19.336084 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.34454 (* 1 = 4.34454 loss)
I0826 16:56:19.336089 25446 sgd_solver.cpp:138] Iteration 25720, lr = 1e-05
I0826 16:56:21.408294 25446 solver.cpp:243] Iteration 25730, loss = 5.15081
I0826 16:56:21.408334 25446 solver.cpp:259]     Train net output #0: center_loss = 233.155 (* 0.008 = 1.86524 loss)
I0826 16:56:21.408339 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.28557 (* 1 = 3.28557 loss)
I0826 16:56:21.408344 25446 sgd_solver.cpp:138] Iteration 25730, lr = 1e-05
I0826 16:56:23.475387 25446 solver.cpp:243] Iteration 25740, loss = 5.29971
I0826 16:56:23.475411 25446 solver.cpp:259]     Train net output #0: center_loss = 219.247 (* 0.008 = 1.75398 loss)
I0826 16:56:23.475417 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.54573 (* 1 = 3.54573 loss)
I0826 16:56:23.475421 25446 sgd_solver.cpp:138] Iteration 25740, lr = 1e-05
I0826 16:56:25.706970 25446 solver.cpp:243] Iteration 25750, loss = 5.17356
I0826 16:56:25.706996 25446 solver.cpp:259]     Train net output #0: center_loss = 224.123 (* 0.008 = 1.79299 loss)
I0826 16:56:25.707003 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.38057 (* 1 = 3.38057 loss)
I0826 16:56:25.707008 25446 sgd_solver.cpp:138] Iteration 25750, lr = 1e-05
I0826 16:56:27.851435 25446 solver.cpp:243] Iteration 25760, loss = 5.35665
I0826 16:56:27.851474 25446 solver.cpp:259]     Train net output #0: center_loss = 204.379 (* 0.008 = 1.63503 loss)
I0826 16:56:27.851480 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.72162 (* 1 = 3.72162 loss)
I0826 16:56:27.851485 25446 sgd_solver.cpp:138] Iteration 25760, lr = 1e-05
I0826 16:56:29.961714 25446 solver.cpp:243] Iteration 25770, loss = 5.75489
I0826 16:56:29.961740 25446 solver.cpp:259]     Train net output #0: center_loss = 207.601 (* 0.008 = 1.66081 loss)
I0826 16:56:29.961746 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.09408 (* 1 = 4.09408 loss)
I0826 16:56:29.961751 25446 sgd_solver.cpp:138] Iteration 25770, lr = 1e-05
I0826 16:56:32.024446 25446 solver.cpp:243] Iteration 25780, loss = 5.29305
I0826 16:56:32.024485 25446 solver.cpp:259]     Train net output #0: center_loss = 202.887 (* 0.008 = 1.62309 loss)
I0826 16:56:32.024492 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.66995 (* 1 = 3.66995 loss)
I0826 16:56:32.024495 25446 sgd_solver.cpp:138] Iteration 25780, lr = 1e-05
I0826 16:56:34.090874 25446 solver.cpp:243] Iteration 25790, loss = 6.3061
I0826 16:56:34.090898 25446 solver.cpp:259]     Train net output #0: center_loss = 180.177 (* 0.008 = 1.44142 loss)
I0826 16:56:34.090903 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.86468 (* 1 = 4.86468 loss)
I0826 16:56:34.090907 25446 sgd_solver.cpp:138] Iteration 25790, lr = 1e-05
I0826 16:56:36.245596 25446 solver.cpp:243] Iteration 25800, loss = 6.30637
I0826 16:56:36.245704 25446 solver.cpp:259]     Train net output #0: center_loss = 204.098 (* 0.008 = 1.63278 loss)
I0826 16:56:36.245712 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.67359 (* 1 = 4.67359 loss)
I0826 16:56:36.245728 25446 sgd_solver.cpp:138] Iteration 25800, lr = 1e-05
I0826 16:56:38.308915 25446 solver.cpp:243] Iteration 25810, loss = 6.12977
I0826 16:56:38.308954 25446 solver.cpp:259]     Train net output #0: center_loss = 206.64 (* 0.008 = 1.65312 loss)
I0826 16:56:38.308961 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.47665 (* 1 = 4.47665 loss)
I0826 16:56:38.308965 25446 sgd_solver.cpp:138] Iteration 25810, lr = 1e-05
I0826 16:56:40.383158 25446 solver.cpp:243] Iteration 25820, loss = 5.60198
I0826 16:56:40.383185 25446 solver.cpp:259]     Train net output #0: center_loss = 204.124 (* 0.008 = 1.63299 loss)
I0826 16:56:40.383193 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.96899 (* 1 = 3.96899 loss)
I0826 16:56:40.383196 25446 sgd_solver.cpp:138] Iteration 25820, lr = 1e-05
I0826 16:56:42.486333 25446 solver.cpp:243] Iteration 25830, loss = 5.30969
I0826 16:56:42.486357 25446 solver.cpp:259]     Train net output #0: center_loss = 214.867 (* 0.008 = 1.71893 loss)
I0826 16:56:42.486363 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.59076 (* 1 = 3.59076 loss)
I0826 16:56:42.486367 25446 sgd_solver.cpp:138] Iteration 25830, lr = 1e-05
I0826 16:56:44.603673 25446 solver.cpp:243] Iteration 25840, loss = 5.10195
I0826 16:56:44.603698 25446 solver.cpp:259]     Train net output #0: center_loss = 190.514 (* 0.008 = 1.52411 loss)
I0826 16:56:44.603704 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.57783 (* 1 = 3.57783 loss)
I0826 16:56:44.603708 25446 sgd_solver.cpp:138] Iteration 25840, lr = 1e-05
I0826 16:56:46.737017 25446 solver.cpp:243] Iteration 25850, loss = 4.91956
I0826 16:56:46.737041 25446 solver.cpp:259]     Train net output #0: center_loss = 211.779 (* 0.008 = 1.69423 loss)
I0826 16:56:46.737047 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.22533 (* 1 = 3.22533 loss)
I0826 16:56:46.737052 25446 sgd_solver.cpp:138] Iteration 25850, lr = 1e-05
I0826 16:56:48.875088 25446 solver.cpp:243] Iteration 25860, loss = 5.81266
I0826 16:56:48.875128 25446 solver.cpp:259]     Train net output #0: center_loss = 215.423 (* 0.008 = 1.72339 loss)
I0826 16:56:48.875133 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.08928 (* 1 = 4.08928 loss)
I0826 16:56:48.875138 25446 sgd_solver.cpp:138] Iteration 25860, lr = 1e-05
I0826 16:56:50.938097 25446 solver.cpp:243] Iteration 25870, loss = 6.19877
I0826 16:56:50.938135 25446 solver.cpp:259]     Train net output #0: center_loss = 208.49 (* 0.008 = 1.66792 loss)
I0826 16:56:50.938141 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.53086 (* 1 = 4.53086 loss)
I0826 16:56:50.938144 25446 sgd_solver.cpp:138] Iteration 25870, lr = 1e-05
I0826 16:56:53.004456 25446 solver.cpp:243] Iteration 25880, loss = 5.79586
I0826 16:56:53.004495 25446 solver.cpp:259]     Train net output #0: center_loss = 219.55 (* 0.008 = 1.7564 loss)
I0826 16:56:53.004503 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.03946 (* 1 = 4.03946 loss)
I0826 16:56:53.004506 25446 sgd_solver.cpp:138] Iteration 25880, lr = 1e-05
I0826 16:56:55.090553 25446 solver.cpp:243] Iteration 25890, loss = 5.25479
I0826 16:56:55.090592 25446 solver.cpp:259]     Train net output #0: center_loss = 216.874 (* 0.008 = 1.735 loss)
I0826 16:56:55.090598 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.51979 (* 1 = 3.51979 loss)
I0826 16:56:55.090602 25446 sgd_solver.cpp:138] Iteration 25890, lr = 1e-05
I0826 16:56:57.154657 25446 solver.cpp:243] Iteration 25900, loss = 5.72022
I0826 16:56:57.154680 25446 solver.cpp:259]     Train net output #0: center_loss = 191.292 (* 0.008 = 1.53034 loss)
I0826 16:56:57.154701 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.18988 (* 1 = 4.18988 loss)
I0826 16:56:57.154706 25446 sgd_solver.cpp:138] Iteration 25900, lr = 1e-05
I0826 16:56:59.277333 25446 solver.cpp:243] Iteration 25910, loss = 4.74542
I0826 16:56:59.277356 25446 solver.cpp:259]     Train net output #0: center_loss = 236.475 (* 0.008 = 1.8918 loss)
I0826 16:56:59.277362 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.85362 (* 1 = 2.85362 loss)
I0826 16:56:59.277367 25446 sgd_solver.cpp:138] Iteration 25910, lr = 1e-05
I0826 16:57:01.356763 25446 solver.cpp:243] Iteration 25920, loss = 6.5095
I0826 16:57:01.356788 25446 solver.cpp:259]     Train net output #0: center_loss = 191.26 (* 0.008 = 1.53008 loss)
I0826 16:57:01.356794 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.97942 (* 1 = 4.97942 loss)
I0826 16:57:01.356799 25446 sgd_solver.cpp:138] Iteration 25920, lr = 1e-05
I0826 16:57:03.455319 25446 solver.cpp:243] Iteration 25930, loss = 5.50838
I0826 16:57:03.455343 25446 solver.cpp:259]     Train net output #0: center_loss = 216.71 (* 0.008 = 1.73368 loss)
I0826 16:57:03.455349 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.7747 (* 1 = 3.7747 loss)
I0826 16:57:03.455353 25446 sgd_solver.cpp:138] Iteration 25930, lr = 1e-05
I0826 16:57:05.578935 25446 solver.cpp:243] Iteration 25940, loss = 5.16532
I0826 16:57:05.578959 25446 solver.cpp:259]     Train net output #0: center_loss = 227.835 (* 0.008 = 1.82268 loss)
I0826 16:57:05.578966 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.34263 (* 1 = 3.34263 loss)
I0826 16:57:05.578970 25446 sgd_solver.cpp:138] Iteration 25940, lr = 1e-05
I0826 16:57:07.650933 25446 solver.cpp:243] Iteration 25950, loss = 5.57277
I0826 16:57:07.651069 25446 solver.cpp:259]     Train net output #0: center_loss = 224.239 (* 0.008 = 1.79391 loss)
I0826 16:57:07.651077 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77886 (* 1 = 3.77886 loss)
I0826 16:57:07.651094 25446 sgd_solver.cpp:138] Iteration 25950, lr = 1e-05
I0826 16:57:09.720129 25446 solver.cpp:243] Iteration 25960, loss = 5.07817
I0826 16:57:09.720154 25446 solver.cpp:259]     Train net output #0: center_loss = 192.302 (* 0.008 = 1.53841 loss)
I0826 16:57:09.720172 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.53975 (* 1 = 3.53975 loss)
I0826 16:57:09.720175 25446 sgd_solver.cpp:138] Iteration 25960, lr = 1e-05
I0826 16:57:11.795096 25446 solver.cpp:243] Iteration 25970, loss = 6.48905
I0826 16:57:11.795120 25446 solver.cpp:259]     Train net output #0: center_loss = 189.588 (* 0.008 = 1.51671 loss)
I0826 16:57:11.795127 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.97234 (* 1 = 4.97234 loss)
I0826 16:57:11.795131 25446 sgd_solver.cpp:138] Iteration 25970, lr = 1e-05
I0826 16:57:13.859270 25446 solver.cpp:243] Iteration 25980, loss = 6.04065
I0826 16:57:13.859293 25446 solver.cpp:259]     Train net output #0: center_loss = 201.717 (* 0.008 = 1.61373 loss)
I0826 16:57:13.859299 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.42691 (* 1 = 4.42691 loss)
I0826 16:57:13.859302 25446 sgd_solver.cpp:138] Iteration 25980, lr = 1e-05
I0826 16:57:15.999366 25446 solver.cpp:243] Iteration 25990, loss = 5.62484
I0826 16:57:15.999397 25446 solver.cpp:259]     Train net output #0: center_loss = 213.972 (* 0.008 = 1.71178 loss)
I0826 16:57:15.999404 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91306 (* 1 = 3.91306 loss)
I0826 16:57:15.999408 25446 sgd_solver.cpp:138] Iteration 25990, lr = 1e-05
I0826 16:57:17.967200 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_26000.caffemodel
I0826 16:57:19.127929 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_26000.solverstate
I0826 16:57:19.465309 25446 solver.cpp:243] Iteration 26000, loss = 5.98533
I0826 16:57:19.465338 25446 solver.cpp:259]     Train net output #0: center_loss = 230 (* 0.008 = 1.84 loss)
I0826 16:57:19.465344 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.14533 (* 1 = 4.14533 loss)
I0826 16:57:19.465350 25446 sgd_solver.cpp:138] Iteration 26000, lr = 1e-05
I0826 16:57:21.552067 25446 solver.cpp:243] Iteration 26010, loss = 5.88512
I0826 16:57:21.552094 25446 solver.cpp:259]     Train net output #0: center_loss = 235.341 (* 0.008 = 1.88273 loss)
I0826 16:57:21.552101 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.00239 (* 1 = 4.00239 loss)
I0826 16:57:21.552106 25446 sgd_solver.cpp:138] Iteration 26010, lr = 1e-05
I0826 16:57:23.690537 25446 solver.cpp:243] Iteration 26020, loss = 6.43733
I0826 16:57:23.690565 25446 solver.cpp:259]     Train net output #0: center_loss = 194.655 (* 0.008 = 1.55724 loss)
I0826 16:57:23.690572 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.88009 (* 1 = 4.88009 loss)
I0826 16:57:23.690577 25446 sgd_solver.cpp:138] Iteration 26020, lr = 1e-05
I0826 16:57:25.883316 25446 solver.cpp:243] Iteration 26030, loss = 5.70602
I0826 16:57:25.883339 25446 solver.cpp:259]     Train net output #0: center_loss = 211.833 (* 0.008 = 1.69466 loss)
I0826 16:57:25.883345 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.01136 (* 1 = 4.01136 loss)
I0826 16:57:25.883349 25446 sgd_solver.cpp:138] Iteration 26030, lr = 1e-05
I0826 16:57:28.015866 25446 solver.cpp:243] Iteration 26040, loss = 5.82216
I0826 16:57:28.015897 25446 solver.cpp:259]     Train net output #0: center_loss = 192.012 (* 0.008 = 1.5361 loss)
I0826 16:57:28.015902 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.28607 (* 1 = 4.28607 loss)
I0826 16:57:28.015908 25446 sgd_solver.cpp:138] Iteration 26040, lr = 1e-05
I0826 16:57:30.152328 25446 solver.cpp:243] Iteration 26050, loss = 4.88758
I0826 16:57:30.152354 25446 solver.cpp:259]     Train net output #0: center_loss = 219.787 (* 0.008 = 1.7583 loss)
I0826 16:57:30.152387 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.12928 (* 1 = 3.12928 loss)
I0826 16:57:30.152392 25446 sgd_solver.cpp:138] Iteration 26050, lr = 1e-05
I0826 16:57:32.243597 25446 solver.cpp:243] Iteration 26060, loss = 5.74596
I0826 16:57:32.243620 25446 solver.cpp:259]     Train net output #0: center_loss = 211.149 (* 0.008 = 1.68919 loss)
I0826 16:57:32.243626 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.05677 (* 1 = 4.05677 loss)
I0826 16:57:32.243631 25446 sgd_solver.cpp:138] Iteration 26060, lr = 1e-05
I0826 16:57:34.338807 25446 solver.cpp:243] Iteration 26070, loss = 4.93689
I0826 16:57:34.338835 25446 solver.cpp:259]     Train net output #0: center_loss = 230.026 (* 0.008 = 1.84021 loss)
I0826 16:57:34.338840 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.09668 (* 1 = 3.09668 loss)
I0826 16:57:34.338845 25446 sgd_solver.cpp:138] Iteration 26070, lr = 1e-05
I0826 16:57:36.448526 25446 solver.cpp:243] Iteration 26080, loss = 6.3277
I0826 16:57:36.448585 25446 solver.cpp:259]     Train net output #0: center_loss = 206.518 (* 0.008 = 1.65215 loss)
I0826 16:57:36.448602 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.67555 (* 1 = 4.67555 loss)
I0826 16:57:36.448607 25446 sgd_solver.cpp:138] Iteration 26080, lr = 1e-05
I0826 16:57:38.543917 25446 solver.cpp:243] Iteration 26090, loss = 5.36574
I0826 16:57:38.544024 25446 solver.cpp:259]     Train net output #0: center_loss = 245.506 (* 0.008 = 1.96405 loss)
I0826 16:57:38.544031 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.40169 (* 1 = 3.40169 loss)
I0826 16:57:38.544049 25446 sgd_solver.cpp:138] Iteration 26090, lr = 1e-05
I0826 16:57:40.650257 25446 solver.cpp:243] Iteration 26100, loss = 5.48859
I0826 16:57:40.650285 25446 solver.cpp:259]     Train net output #0: center_loss = 214.742 (* 0.008 = 1.71794 loss)
I0826 16:57:40.650291 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77065 (* 1 = 3.77065 loss)
I0826 16:57:40.650295 25446 sgd_solver.cpp:138] Iteration 26100, lr = 1e-05
I0826 16:57:42.799387 25446 solver.cpp:243] Iteration 26110, loss = 6.11185
I0826 16:57:42.799412 25446 solver.cpp:259]     Train net output #0: center_loss = 215.985 (* 0.008 = 1.72788 loss)
I0826 16:57:42.799418 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.38397 (* 1 = 4.38397 loss)
I0826 16:57:42.799422 25446 sgd_solver.cpp:138] Iteration 26110, lr = 1e-05
I0826 16:57:44.865371 25446 solver.cpp:243] Iteration 26120, loss = 5.09019
I0826 16:57:44.865394 25446 solver.cpp:259]     Train net output #0: center_loss = 217.102 (* 0.008 = 1.73682 loss)
I0826 16:57:44.865401 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.35337 (* 1 = 3.35337 loss)
I0826 16:57:44.865406 25446 sgd_solver.cpp:138] Iteration 26120, lr = 1e-05
I0826 16:57:46.930881 25446 solver.cpp:243] Iteration 26130, loss = 5.17253
I0826 16:57:46.930905 25446 solver.cpp:259]     Train net output #0: center_loss = 224.866 (* 0.008 = 1.79893 loss)
I0826 16:57:46.930912 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.3736 (* 1 = 3.3736 loss)
I0826 16:57:46.930915 25446 sgd_solver.cpp:138] Iteration 26130, lr = 1e-05
I0826 16:57:49.001046 25446 solver.cpp:243] Iteration 26140, loss = 5.86973
I0826 16:57:49.001070 25446 solver.cpp:259]     Train net output #0: center_loss = 221.097 (* 0.008 = 1.76878 loss)
I0826 16:57:49.001091 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.10096 (* 1 = 4.10096 loss)
I0826 16:57:49.001097 25446 sgd_solver.cpp:138] Iteration 26140, lr = 1e-05
I0826 16:57:51.115393 25446 solver.cpp:243] Iteration 26150, loss = 4.90365
I0826 16:57:51.115417 25446 solver.cpp:259]     Train net output #0: center_loss = 223.81 (* 0.008 = 1.79048 loss)
I0826 16:57:51.115423 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.11317 (* 1 = 3.11317 loss)
I0826 16:57:51.115428 25446 sgd_solver.cpp:138] Iteration 26150, lr = 1e-05
I0826 16:57:53.188458 25446 solver.cpp:243] Iteration 26160, loss = 4.92897
I0826 16:57:53.188488 25446 solver.cpp:259]     Train net output #0: center_loss = 217.909 (* 0.008 = 1.74327 loss)
I0826 16:57:53.188493 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.1857 (* 1 = 3.1857 loss)
I0826 16:57:53.188498 25446 sgd_solver.cpp:138] Iteration 26160, lr = 1e-05
I0826 16:57:55.365561 25446 solver.cpp:243] Iteration 26170, loss = 4.44313
I0826 16:57:55.365587 25446 solver.cpp:259]     Train net output #0: center_loss = 216.225 (* 0.008 = 1.7298 loss)
I0826 16:57:55.365594 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.71333 (* 1 = 2.71333 loss)
I0826 16:57:55.365598 25446 sgd_solver.cpp:138] Iteration 26170, lr = 1e-05
I0826 16:57:57.587249 25446 solver.cpp:243] Iteration 26180, loss = 5.38906
I0826 16:57:57.587273 25446 solver.cpp:259]     Train net output #0: center_loss = 226.102 (* 0.008 = 1.80882 loss)
I0826 16:57:57.587280 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.58024 (* 1 = 3.58024 loss)
I0826 16:57:57.587285 25446 sgd_solver.cpp:138] Iteration 26180, lr = 1e-05
I0826 16:57:59.751149 25446 solver.cpp:243] Iteration 26190, loss = 4.91988
I0826 16:57:59.751173 25446 solver.cpp:259]     Train net output #0: center_loss = 233.458 (* 0.008 = 1.86766 loss)
I0826 16:57:59.751179 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.05222 (* 1 = 3.05222 loss)
I0826 16:57:59.751183 25446 sgd_solver.cpp:138] Iteration 26190, lr = 1e-05
I0826 16:58:01.819038 25446 solver.cpp:243] Iteration 26200, loss = 6.18879
I0826 16:58:01.819064 25446 solver.cpp:259]     Train net output #0: center_loss = 198.745 (* 0.008 = 1.58996 loss)
I0826 16:58:01.819070 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.59884 (* 1 = 4.59884 loss)
I0826 16:58:01.819074 25446 sgd_solver.cpp:138] Iteration 26200, lr = 1e-05
I0826 16:58:03.975432 25446 solver.cpp:243] Iteration 26210, loss = 5.60499
I0826 16:58:03.975456 25446 solver.cpp:259]     Train net output #0: center_loss = 203.974 (* 0.008 = 1.63179 loss)
I0826 16:58:03.975463 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.9732 (* 1 = 3.9732 loss)
I0826 16:58:03.975467 25446 sgd_solver.cpp:138] Iteration 26210, lr = 1e-05
I0826 16:58:06.090116 25446 solver.cpp:243] Iteration 26220, loss = 6.01804
I0826 16:58:06.090139 25446 solver.cpp:259]     Train net output #0: center_loss = 184.009 (* 0.008 = 1.47207 loss)
I0826 16:58:06.090145 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.54596 (* 1 = 4.54596 loss)
I0826 16:58:06.090149 25446 sgd_solver.cpp:138] Iteration 26220, lr = 1e-05
I0826 16:58:08.182040 25446 solver.cpp:243] Iteration 26230, loss = 6.25593
I0826 16:58:08.182065 25446 solver.cpp:259]     Train net output #0: center_loss = 199.621 (* 0.008 = 1.59697 loss)
I0826 16:58:08.182071 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65896 (* 1 = 4.65896 loss)
I0826 16:58:08.182075 25446 sgd_solver.cpp:138] Iteration 26230, lr = 1e-05
I0826 16:58:10.270795 25446 solver.cpp:243] Iteration 26240, loss = 5.41286
I0826 16:58:10.270951 25446 solver.cpp:259]     Train net output #0: center_loss = 210.378 (* 0.008 = 1.68303 loss)
I0826 16:58:10.270958 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.72983 (* 1 = 3.72983 loss)
I0826 16:58:10.270962 25446 sgd_solver.cpp:138] Iteration 26240, lr = 1e-05
I0826 16:58:12.356676 25446 solver.cpp:243] Iteration 26250, loss = 4.97337
I0826 16:58:12.356701 25446 solver.cpp:259]     Train net output #0: center_loss = 215.706 (* 0.008 = 1.72565 loss)
I0826 16:58:12.356707 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.24772 (* 1 = 3.24772 loss)
I0826 16:58:12.356712 25446 sgd_solver.cpp:138] Iteration 26250, lr = 1e-05
I0826 16:58:14.437466 25446 solver.cpp:243] Iteration 26260, loss = 4.91576
I0826 16:58:14.437495 25446 solver.cpp:259]     Train net output #0: center_loss = 217.579 (* 0.008 = 1.74063 loss)
I0826 16:58:14.437501 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.17513 (* 1 = 3.17513 loss)
I0826 16:58:14.437506 25446 sgd_solver.cpp:138] Iteration 26260, lr = 1e-05
I0826 16:58:16.539007 25446 solver.cpp:243] Iteration 26270, loss = 5.03971
I0826 16:58:16.539033 25446 solver.cpp:259]     Train net output #0: center_loss = 225.022 (* 0.008 = 1.80018 loss)
I0826 16:58:16.539039 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.23953 (* 1 = 3.23953 loss)
I0826 16:58:16.539044 25446 sgd_solver.cpp:138] Iteration 26270, lr = 1e-05
I0826 16:58:18.626713 25446 solver.cpp:243] Iteration 26280, loss = 5.67038
I0826 16:58:18.626737 25446 solver.cpp:259]     Train net output #0: center_loss = 186.823 (* 0.008 = 1.49458 loss)
I0826 16:58:18.626744 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.1758 (* 1 = 4.1758 loss)
I0826 16:58:18.626747 25446 sgd_solver.cpp:138] Iteration 26280, lr = 1e-05
I0826 16:58:20.698202 25446 solver.cpp:243] Iteration 26290, loss = 5.1017
I0826 16:58:20.698227 25446 solver.cpp:259]     Train net output #0: center_loss = 216.427 (* 0.008 = 1.73141 loss)
I0826 16:58:20.698233 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.37029 (* 1 = 3.37029 loss)
I0826 16:58:20.698238 25446 sgd_solver.cpp:138] Iteration 26290, lr = 1e-05
I0826 16:58:22.801501 25446 solver.cpp:243] Iteration 26300, loss = 5.29748
I0826 16:58:22.801528 25446 solver.cpp:259]     Train net output #0: center_loss = 224.003 (* 0.008 = 1.79202 loss)
I0826 16:58:22.801535 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.50545 (* 1 = 3.50545 loss)
I0826 16:58:22.801540 25446 sgd_solver.cpp:138] Iteration 26300, lr = 1e-05
I0826 16:58:24.915376 25446 solver.cpp:243] Iteration 26310, loss = 5.89193
I0826 16:58:24.915405 25446 solver.cpp:259]     Train net output #0: center_loss = 199.965 (* 0.008 = 1.59972 loss)
I0826 16:58:24.915411 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29221 (* 1 = 4.29221 loss)
I0826 16:58:24.915416 25446 sgd_solver.cpp:138] Iteration 26310, lr = 1e-05
I0826 16:58:27.058562 25446 solver.cpp:243] Iteration 26320, loss = 5.77354
I0826 16:58:27.058588 25446 solver.cpp:259]     Train net output #0: center_loss = 217.162 (* 0.008 = 1.73729 loss)
I0826 16:58:27.058594 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.03625 (* 1 = 4.03625 loss)
I0826 16:58:27.058599 25446 sgd_solver.cpp:138] Iteration 26320, lr = 1e-05
I0826 16:58:29.231679 25446 solver.cpp:243] Iteration 26330, loss = 5.8737
I0826 16:58:29.231709 25446 solver.cpp:259]     Train net output #0: center_loss = 210.586 (* 0.008 = 1.68469 loss)
I0826 16:58:29.231714 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.18901 (* 1 = 4.18901 loss)
I0826 16:58:29.231719 25446 sgd_solver.cpp:138] Iteration 26330, lr = 1e-05
I0826 16:58:31.308233 25446 solver.cpp:243] Iteration 26340, loss = 5.54505
I0826 16:58:31.308257 25446 solver.cpp:259]     Train net output #0: center_loss = 208.004 (* 0.008 = 1.66403 loss)
I0826 16:58:31.308264 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.88102 (* 1 = 3.88102 loss)
I0826 16:58:31.308267 25446 sgd_solver.cpp:138] Iteration 26340, lr = 1e-05
I0826 16:58:33.387550 25446 solver.cpp:243] Iteration 26350, loss = 4.93272
I0826 16:58:33.387574 25446 solver.cpp:259]     Train net output #0: center_loss = 204.694 (* 0.008 = 1.63755 loss)
I0826 16:58:33.387581 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.29517 (* 1 = 3.29517 loss)
I0826 16:58:33.387585 25446 sgd_solver.cpp:138] Iteration 26350, lr = 1e-05
I0826 16:58:35.452745 25446 solver.cpp:243] Iteration 26360, loss = 4.38449
I0826 16:58:35.452785 25446 solver.cpp:259]     Train net output #0: center_loss = 215.295 (* 0.008 = 1.72236 loss)
I0826 16:58:35.452791 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.66213 (* 1 = 2.66213 loss)
I0826 16:58:35.452795 25446 sgd_solver.cpp:138] Iteration 26360, lr = 1e-05
I0826 16:58:37.517254 25446 solver.cpp:243] Iteration 26370, loss = 5.79692
I0826 16:58:37.517279 25446 solver.cpp:259]     Train net output #0: center_loss = 203.837 (* 0.008 = 1.63069 loss)
I0826 16:58:37.517285 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.16622 (* 1 = 4.16622 loss)
I0826 16:58:37.517289 25446 sgd_solver.cpp:138] Iteration 26370, lr = 1e-05
I0826 16:58:39.584765 25446 solver.cpp:243] Iteration 26380, loss = 5.42645
I0826 16:58:39.584805 25446 solver.cpp:259]     Train net output #0: center_loss = 198.792 (* 0.008 = 1.59033 loss)
I0826 16:58:39.584811 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83612 (* 1 = 3.83612 loss)
I0826 16:58:39.584815 25446 sgd_solver.cpp:138] Iteration 26380, lr = 1e-05
I0826 16:58:41.712169 25446 solver.cpp:243] Iteration 26390, loss = 5.42811
I0826 16:58:41.712318 25446 solver.cpp:259]     Train net output #0: center_loss = 202.832 (* 0.008 = 1.62266 loss)
I0826 16:58:41.712339 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.80545 (* 1 = 3.80545 loss)
I0826 16:58:41.712344 25446 sgd_solver.cpp:138] Iteration 26390, lr = 1e-05
I0826 16:58:43.803982 25446 solver.cpp:243] Iteration 26400, loss = 5.08129
I0826 16:58:43.804023 25446 solver.cpp:259]     Train net output #0: center_loss = 214.451 (* 0.008 = 1.71561 loss)
I0826 16:58:43.804029 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.36568 (* 1 = 3.36568 loss)
I0826 16:58:43.804033 25446 sgd_solver.cpp:138] Iteration 26400, lr = 1e-05
I0826 16:58:45.936605 25446 solver.cpp:243] Iteration 26410, loss = 4.42204
I0826 16:58:45.936635 25446 solver.cpp:259]     Train net output #0: center_loss = 238.346 (* 0.008 = 1.90677 loss)
I0826 16:58:45.936640 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.51527 (* 1 = 2.51527 loss)
I0826 16:58:45.936645 25446 sgd_solver.cpp:138] Iteration 26410, lr = 1e-05
I0826 16:58:48.162856 25446 solver.cpp:243] Iteration 26420, loss = 5.67458
I0826 16:58:48.162895 25446 solver.cpp:259]     Train net output #0: center_loss = 199.821 (* 0.008 = 1.59857 loss)
I0826 16:58:48.162901 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.07601 (* 1 = 4.07601 loss)
I0826 16:58:48.162905 25446 sgd_solver.cpp:138] Iteration 26420, lr = 1e-05
I0826 16:58:50.327183 25446 solver.cpp:243] Iteration 26430, loss = 4.90667
I0826 16:58:50.327208 25446 solver.cpp:259]     Train net output #0: center_loss = 226.354 (* 0.008 = 1.81083 loss)
I0826 16:58:50.327214 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.09584 (* 1 = 3.09584 loss)
I0826 16:58:50.327219 25446 sgd_solver.cpp:138] Iteration 26430, lr = 1e-05
I0826 16:58:52.404772 25446 solver.cpp:243] Iteration 26440, loss = 4.49731
I0826 16:58:52.404810 25446 solver.cpp:259]     Train net output #0: center_loss = 231.505 (* 0.008 = 1.85204 loss)
I0826 16:58:52.404816 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.64527 (* 1 = 2.64527 loss)
I0826 16:58:52.404820 25446 sgd_solver.cpp:138] Iteration 26440, lr = 1e-05
I0826 16:58:54.480355 25446 solver.cpp:243] Iteration 26450, loss = 4.93397
I0826 16:58:54.480379 25446 solver.cpp:259]     Train net output #0: center_loss = 228.179 (* 0.008 = 1.82543 loss)
I0826 16:58:54.480386 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.10854 (* 1 = 3.10854 loss)
I0826 16:58:54.480391 25446 sgd_solver.cpp:138] Iteration 26450, lr = 1e-05
I0826 16:58:56.556063 25446 solver.cpp:243] Iteration 26460, loss = 5.65741
I0826 16:58:56.556102 25446 solver.cpp:259]     Train net output #0: center_loss = 201.595 (* 0.008 = 1.61276 loss)
I0826 16:58:56.556108 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04466 (* 1 = 4.04466 loss)
I0826 16:58:56.556113 25446 sgd_solver.cpp:138] Iteration 26460, lr = 1e-05
I0826 16:58:58.627930 25446 solver.cpp:243] Iteration 26470, loss = 5.24658
I0826 16:58:58.627954 25446 solver.cpp:259]     Train net output #0: center_loss = 206.757 (* 0.008 = 1.65406 loss)
I0826 16:58:58.627959 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.59252 (* 1 = 3.59252 loss)
I0826 16:58:58.627964 25446 sgd_solver.cpp:138] Iteration 26470, lr = 1e-05
I0826 16:59:00.701203 25446 solver.cpp:243] Iteration 26480, loss = 5.32086
I0826 16:59:00.701228 25446 solver.cpp:259]     Train net output #0: center_loss = 198.388 (* 0.008 = 1.58711 loss)
I0826 16:59:00.701270 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.73375 (* 1 = 3.73375 loss)
I0826 16:59:00.701274 25446 sgd_solver.cpp:138] Iteration 26480, lr = 1e-05
I0826 16:59:02.777376 25446 solver.cpp:243] Iteration 26490, loss = 5.25966
I0826 16:59:02.777400 25446 solver.cpp:259]     Train net output #0: center_loss = 229.311 (* 0.008 = 1.83449 loss)
I0826 16:59:02.777406 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.42517 (* 1 = 3.42517 loss)
I0826 16:59:02.777410 25446 sgd_solver.cpp:138] Iteration 26490, lr = 1e-05
I0826 16:59:04.846469 25446 solver.cpp:243] Iteration 26500, loss = 5.07356
I0826 16:59:04.846508 25446 solver.cpp:259]     Train net output #0: center_loss = 215.072 (* 0.008 = 1.72058 loss)
I0826 16:59:04.846514 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.35298 (* 1 = 3.35298 loss)
I0826 16:59:04.846518 25446 sgd_solver.cpp:138] Iteration 26500, lr = 1e-05
I0826 16:59:06.915007 25446 solver.cpp:243] Iteration 26510, loss = 4.24255
I0826 16:59:06.915030 25446 solver.cpp:259]     Train net output #0: center_loss = 222.871 (* 0.008 = 1.78296 loss)
I0826 16:59:06.915037 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.45958 (* 1 = 2.45958 loss)
I0826 16:59:06.915042 25446 sgd_solver.cpp:138] Iteration 26510, lr = 1e-05
I0826 16:59:08.987619 25446 solver.cpp:243] Iteration 26520, loss = 6.08069
I0826 16:59:08.987643 25446 solver.cpp:259]     Train net output #0: center_loss = 209.285 (* 0.008 = 1.67428 loss)
I0826 16:59:08.987649 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.40641 (* 1 = 4.40641 loss)
I0826 16:59:08.987653 25446 sgd_solver.cpp:138] Iteration 26520, lr = 1e-05
I0826 16:59:11.061091 25446 solver.cpp:243] Iteration 26530, loss = 5.54174
I0826 16:59:11.061115 25446 solver.cpp:259]     Train net output #0: center_loss = 187.592 (* 0.008 = 1.50074 loss)
I0826 16:59:11.061121 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.041 (* 1 = 4.041 loss)
I0826 16:59:11.061125 25446 sgd_solver.cpp:138] Iteration 26530, lr = 1e-05
I0826 16:59:13.131503 25446 solver.cpp:243] Iteration 26540, loss = 4.85948
I0826 16:59:13.131649 25446 solver.cpp:259]     Train net output #0: center_loss = 217.245 (* 0.008 = 1.73796 loss)
I0826 16:59:13.131656 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.12152 (* 1 = 3.12152 loss)
I0826 16:59:13.131673 25446 sgd_solver.cpp:138] Iteration 26540, lr = 1e-05
I0826 16:59:15.202373 25446 solver.cpp:243] Iteration 26550, loss = 5.99249
I0826 16:59:15.202411 25446 solver.cpp:259]     Train net output #0: center_loss = 206.865 (* 0.008 = 1.65492 loss)
I0826 16:59:15.202417 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.33757 (* 1 = 4.33757 loss)
I0826 16:59:15.202421 25446 sgd_solver.cpp:138] Iteration 26550, lr = 1e-05
I0826 16:59:17.272684 25446 solver.cpp:243] Iteration 26560, loss = 4.5862
I0826 16:59:17.272723 25446 solver.cpp:259]     Train net output #0: center_loss = 218.329 (* 0.008 = 1.74663 loss)
I0826 16:59:17.272729 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.83957 (* 1 = 2.83957 loss)
I0826 16:59:17.272733 25446 sgd_solver.cpp:138] Iteration 26560, lr = 1e-05
I0826 16:59:19.347995 25446 solver.cpp:243] Iteration 26570, loss = 5.4979
I0826 16:59:19.348018 25446 solver.cpp:259]     Train net output #0: center_loss = 205.913 (* 0.008 = 1.6473 loss)
I0826 16:59:19.348026 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.8506 (* 1 = 3.8506 loss)
I0826 16:59:19.348029 25446 sgd_solver.cpp:138] Iteration 26570, lr = 1e-05
I0826 16:59:21.420255 25446 solver.cpp:243] Iteration 26580, loss = 4.57023
I0826 16:59:21.420280 25446 solver.cpp:259]     Train net output #0: center_loss = 229.856 (* 0.008 = 1.83885 loss)
I0826 16:59:21.420286 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.73138 (* 1 = 2.73138 loss)
I0826 16:59:21.420290 25446 sgd_solver.cpp:138] Iteration 26580, lr = 1e-05
I0826 16:59:23.499100 25446 solver.cpp:243] Iteration 26590, loss = 5.33464
I0826 16:59:23.499140 25446 solver.cpp:259]     Train net output #0: center_loss = 224.763 (* 0.008 = 1.7981 loss)
I0826 16:59:23.499146 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.53654 (* 1 = 3.53654 loss)
I0826 16:59:23.499150 25446 sgd_solver.cpp:138] Iteration 26590, lr = 1e-05
I0826 16:59:25.571333 25446 solver.cpp:243] Iteration 26600, loss = 5.075
I0826 16:59:25.571357 25446 solver.cpp:259]     Train net output #0: center_loss = 224.557 (* 0.008 = 1.79645 loss)
I0826 16:59:25.571362 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.27855 (* 1 = 3.27855 loss)
I0826 16:59:25.571367 25446 sgd_solver.cpp:138] Iteration 26600, lr = 1e-05
I0826 16:59:27.643952 25446 solver.cpp:243] Iteration 26610, loss = 5.68702
I0826 16:59:27.643976 25446 solver.cpp:259]     Train net output #0: center_loss = 212.125 (* 0.008 = 1.697 loss)
I0826 16:59:27.643982 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.99002 (* 1 = 3.99002 loss)
I0826 16:59:27.643986 25446 sgd_solver.cpp:138] Iteration 26610, lr = 1e-05
I0826 16:59:29.719878 25446 solver.cpp:243] Iteration 26620, loss = 5.84168
I0826 16:59:29.719918 25446 solver.cpp:259]     Train net output #0: center_loss = 201.951 (* 0.008 = 1.61561 loss)
I0826 16:59:29.719923 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.22607 (* 1 = 4.22607 loss)
I0826 16:59:29.719928 25446 sgd_solver.cpp:138] Iteration 26620, lr = 1e-05
I0826 16:59:31.791429 25446 solver.cpp:243] Iteration 26630, loss = 5.10147
I0826 16:59:31.791474 25446 solver.cpp:259]     Train net output #0: center_loss = 199.869 (* 0.008 = 1.59895 loss)
I0826 16:59:31.791481 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.50252 (* 1 = 3.50252 loss)
I0826 16:59:31.791486 25446 sgd_solver.cpp:138] Iteration 26630, lr = 1e-05
I0826 16:59:33.862192 25446 solver.cpp:243] Iteration 26640, loss = 5.18309
I0826 16:59:33.862216 25446 solver.cpp:259]     Train net output #0: center_loss = 216.999 (* 0.008 = 1.73599 loss)
I0826 16:59:33.862222 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.4471 (* 1 = 3.4471 loss)
I0826 16:59:33.862227 25446 sgd_solver.cpp:138] Iteration 26640, lr = 1e-05
I0826 16:59:35.936002 25446 solver.cpp:243] Iteration 26650, loss = 5.16088
I0826 16:59:35.936025 25446 solver.cpp:259]     Train net output #0: center_loss = 222.983 (* 0.008 = 1.78386 loss)
I0826 16:59:35.936031 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.37702 (* 1 = 3.37702 loss)
I0826 16:59:35.936035 25446 sgd_solver.cpp:138] Iteration 26650, lr = 1e-05
I0826 16:59:38.009130 25446 solver.cpp:243] Iteration 26660, loss = 4.3849
I0826 16:59:38.009155 25446 solver.cpp:259]     Train net output #0: center_loss = 222.744 (* 0.008 = 1.78195 loss)
I0826 16:59:38.009160 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.60295 (* 1 = 2.60295 loss)
I0826 16:59:38.009166 25446 sgd_solver.cpp:138] Iteration 26660, lr = 1e-05
I0826 16:59:40.081284 25446 solver.cpp:243] Iteration 26670, loss = 5.40571
I0826 16:59:40.081308 25446 solver.cpp:259]     Train net output #0: center_loss = 198.244 (* 0.008 = 1.58595 loss)
I0826 16:59:40.081315 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81976 (* 1 = 3.81976 loss)
I0826 16:59:40.081318 25446 sgd_solver.cpp:138] Iteration 26670, lr = 1e-05
I0826 16:59:42.155653 25446 solver.cpp:243] Iteration 26680, loss = 5.19205
I0826 16:59:42.155692 25446 solver.cpp:259]     Train net output #0: center_loss = 221.445 (* 0.008 = 1.77156 loss)
I0826 16:59:42.155699 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.42049 (* 1 = 3.42049 loss)
I0826 16:59:42.155702 25446 sgd_solver.cpp:138] Iteration 26680, lr = 1e-05
I0826 16:59:44.225385 25446 solver.cpp:243] Iteration 26690, loss = 5.70675
I0826 16:59:44.225502 25446 solver.cpp:259]     Train net output #0: center_loss = 236.221 (* 0.008 = 1.88977 loss)
I0826 16:59:44.225522 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81699 (* 1 = 3.81699 loss)
I0826 16:59:44.225527 25446 sgd_solver.cpp:138] Iteration 26690, lr = 1e-05
I0826 16:59:46.297192 25446 solver.cpp:243] Iteration 26700, loss = 5.1495
I0826 16:59:46.297232 25446 solver.cpp:259]     Train net output #0: center_loss = 213.546 (* 0.008 = 1.70836 loss)
I0826 16:59:46.297238 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.44113 (* 1 = 3.44113 loss)
I0826 16:59:46.297242 25446 sgd_solver.cpp:138] Iteration 26700, lr = 1e-05
I0826 16:59:48.366616 25446 solver.cpp:243] Iteration 26710, loss = 4.14817
I0826 16:59:48.366639 25446 solver.cpp:259]     Train net output #0: center_loss = 247.083 (* 0.008 = 1.97666 loss)
I0826 16:59:48.366645 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.17151 (* 1 = 2.17151 loss)
I0826 16:59:48.366649 25446 sgd_solver.cpp:138] Iteration 26710, lr = 1e-05
I0826 16:59:50.441411 25446 solver.cpp:243] Iteration 26720, loss = 5.03304
I0826 16:59:50.441450 25446 solver.cpp:259]     Train net output #0: center_loss = 228.7 (* 0.008 = 1.8296 loss)
I0826 16:59:50.441457 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.20344 (* 1 = 3.20344 loss)
I0826 16:59:50.441462 25446 sgd_solver.cpp:138] Iteration 26720, lr = 1e-05
I0826 16:59:52.514523 25446 solver.cpp:243] Iteration 26730, loss = 4.89703
I0826 16:59:52.514561 25446 solver.cpp:259]     Train net output #0: center_loss = 225.232 (* 0.008 = 1.80186 loss)
I0826 16:59:52.514569 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.09517 (* 1 = 3.09517 loss)
I0826 16:59:52.514572 25446 sgd_solver.cpp:138] Iteration 26730, lr = 1e-05
I0826 16:59:54.666105 25446 solver.cpp:243] Iteration 26740, loss = 4.4912
I0826 16:59:54.666129 25446 solver.cpp:259]     Train net output #0: center_loss = 228.94 (* 0.008 = 1.83152 loss)
I0826 16:59:54.666136 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.65967 (* 1 = 2.65967 loss)
I0826 16:59:54.666141 25446 sgd_solver.cpp:138] Iteration 26740, lr = 1e-05
I0826 16:59:56.804605 25446 solver.cpp:243] Iteration 26750, loss = 4.03067
I0826 16:59:56.804646 25446 solver.cpp:259]     Train net output #0: center_loss = 237.084 (* 0.008 = 1.89667 loss)
I0826 16:59:56.804651 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.134 (* 1 = 2.134 loss)
I0826 16:59:56.804656 25446 sgd_solver.cpp:138] Iteration 26750, lr = 1e-05
I0826 16:59:58.874341 25446 solver.cpp:243] Iteration 26760, loss = 5.52307
I0826 16:59:58.874382 25446 solver.cpp:259]     Train net output #0: center_loss = 213.462 (* 0.008 = 1.70769 loss)
I0826 16:59:58.874388 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81538 (* 1 = 3.81538 loss)
I0826 16:59:58.874392 25446 sgd_solver.cpp:138] Iteration 26760, lr = 1e-05
I0826 17:00:00.952759 25446 solver.cpp:243] Iteration 26770, loss = 5.20235
I0826 17:00:00.952798 25446 solver.cpp:259]     Train net output #0: center_loss = 217.04 (* 0.008 = 1.73632 loss)
I0826 17:00:00.952805 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.46603 (* 1 = 3.46603 loss)
I0826 17:00:00.952808 25446 sgd_solver.cpp:138] Iteration 26770, lr = 1e-05
I0826 17:00:03.026827 25446 solver.cpp:243] Iteration 26780, loss = 4.60984
I0826 17:00:03.026867 25446 solver.cpp:259]     Train net output #0: center_loss = 226.348 (* 0.008 = 1.81078 loss)
I0826 17:00:03.026873 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.79906 (* 1 = 2.79906 loss)
I0826 17:00:03.026878 25446 sgd_solver.cpp:138] Iteration 26780, lr = 1e-05
I0826 17:00:05.099584 25446 solver.cpp:243] Iteration 26790, loss = 5.72729
I0826 17:00:05.099608 25446 solver.cpp:259]     Train net output #0: center_loss = 205.299 (* 0.008 = 1.64239 loss)
I0826 17:00:05.099614 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.0849 (* 1 = 4.0849 loss)
I0826 17:00:05.099618 25446 sgd_solver.cpp:138] Iteration 26790, lr = 1e-05
I0826 17:00:07.175586 25446 solver.cpp:243] Iteration 26800, loss = 5.53129
I0826 17:00:07.175611 25446 solver.cpp:259]     Train net output #0: center_loss = 202.081 (* 0.008 = 1.61665 loss)
I0826 17:00:07.175616 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91464 (* 1 = 3.91464 loss)
I0826 17:00:07.175621 25446 sgd_solver.cpp:138] Iteration 26800, lr = 1e-05
I0826 17:00:09.247956 25446 solver.cpp:243] Iteration 26810, loss = 4.74556
I0826 17:00:09.247995 25446 solver.cpp:259]     Train net output #0: center_loss = 214.051 (* 0.008 = 1.7124 loss)
I0826 17:00:09.248001 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.03315 (* 1 = 3.03315 loss)
I0826 17:00:09.248005 25446 sgd_solver.cpp:138] Iteration 26810, lr = 1e-05
I0826 17:00:11.320557 25446 solver.cpp:243] Iteration 26820, loss = 4.77268
I0826 17:00:11.320582 25446 solver.cpp:259]     Train net output #0: center_loss = 228.413 (* 0.008 = 1.8273 loss)
I0826 17:00:11.320590 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.94538 (* 1 = 2.94538 loss)
I0826 17:00:11.320593 25446 sgd_solver.cpp:138] Iteration 26820, lr = 1e-05
I0826 17:00:13.391623 25446 solver.cpp:243] Iteration 26830, loss = 5.50734
I0826 17:00:13.391647 25446 solver.cpp:259]     Train net output #0: center_loss = 208.687 (* 0.008 = 1.6695 loss)
I0826 17:00:13.391654 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83785 (* 1 = 3.83785 loss)
I0826 17:00:13.391657 25446 sgd_solver.cpp:138] Iteration 26830, lr = 1e-05
I0826 17:00:15.463568 25446 solver.cpp:243] Iteration 26840, loss = 6.40698
I0826 17:00:15.463719 25446 solver.cpp:259]     Train net output #0: center_loss = 218.883 (* 0.008 = 1.75107 loss)
I0826 17:00:15.463727 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.65592 (* 1 = 4.65592 loss)
I0826 17:00:15.463732 25446 sgd_solver.cpp:138] Iteration 26840, lr = 1e-05
I0826 17:00:17.532066 25446 solver.cpp:243] Iteration 26850, loss = 4.94967
I0826 17:00:17.532105 25446 solver.cpp:259]     Train net output #0: center_loss = 233.547 (* 0.008 = 1.86838 loss)
I0826 17:00:17.532112 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.08129 (* 1 = 3.08129 loss)
I0826 17:00:17.532116 25446 sgd_solver.cpp:138] Iteration 26850, lr = 1e-05
I0826 17:00:19.602797 25446 solver.cpp:243] Iteration 26860, loss = 5.86458
I0826 17:00:19.602821 25446 solver.cpp:259]     Train net output #0: center_loss = 196.098 (* 0.008 = 1.56879 loss)
I0826 17:00:19.602828 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.29579 (* 1 = 4.29579 loss)
I0826 17:00:19.602833 25446 sgd_solver.cpp:138] Iteration 26860, lr = 1e-05
I0826 17:00:21.676373 25446 solver.cpp:243] Iteration 26870, loss = 6.11052
I0826 17:00:21.676396 25446 solver.cpp:259]     Train net output #0: center_loss = 198.167 (* 0.008 = 1.58533 loss)
I0826 17:00:21.676403 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.52518 (* 1 = 4.52518 loss)
I0826 17:00:21.676406 25446 sgd_solver.cpp:138] Iteration 26870, lr = 1e-05
I0826 17:00:23.746814 25446 solver.cpp:243] Iteration 26880, loss = 5.69884
I0826 17:00:23.746853 25446 solver.cpp:259]     Train net output #0: center_loss = 198.449 (* 0.008 = 1.58759 loss)
I0826 17:00:23.746860 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.11125 (* 1 = 4.11125 loss)
I0826 17:00:23.746865 25446 sgd_solver.cpp:138] Iteration 26880, lr = 1e-05
I0826 17:00:25.820842 25446 solver.cpp:243] Iteration 26890, loss = 4.50914
I0826 17:00:25.820869 25446 solver.cpp:259]     Train net output #0: center_loss = 221.601 (* 0.008 = 1.77281 loss)
I0826 17:00:25.820875 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.73633 (* 1 = 2.73633 loss)
I0826 17:00:25.820895 25446 sgd_solver.cpp:138] Iteration 26890, lr = 1e-05
I0826 17:00:27.894052 25446 solver.cpp:243] Iteration 26900, loss = 6.78302
I0826 17:00:27.894076 25446 solver.cpp:259]     Train net output #0: center_loss = 190.643 (* 0.008 = 1.52514 loss)
I0826 17:00:27.894083 25446 solver.cpp:259]     Train net output #1: softmax_loss = 5.25788 (* 1 = 5.25788 loss)
I0826 17:00:27.894088 25446 sgd_solver.cpp:138] Iteration 26900, lr = 1e-05
I0826 17:00:29.963951 25446 solver.cpp:243] Iteration 26910, loss = 5.05519
I0826 17:00:29.963974 25446 solver.cpp:259]     Train net output #0: center_loss = 226.729 (* 0.008 = 1.81384 loss)
I0826 17:00:29.963981 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.24135 (* 1 = 3.24135 loss)
I0826 17:00:29.963986 25446 sgd_solver.cpp:138] Iteration 26910, lr = 1e-05
I0826 17:00:32.035185 25446 solver.cpp:243] Iteration 26920, loss = 5.22401
I0826 17:00:32.035210 25446 solver.cpp:259]     Train net output #0: center_loss = 209.203 (* 0.008 = 1.67363 loss)
I0826 17:00:32.035217 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.55038 (* 1 = 3.55038 loss)
I0826 17:00:32.035221 25446 sgd_solver.cpp:138] Iteration 26920, lr = 1e-05
I0826 17:00:34.104249 25446 solver.cpp:243] Iteration 26930, loss = 5.17127
I0826 17:00:34.104288 25446 solver.cpp:259]     Train net output #0: center_loss = 202.626 (* 0.008 = 1.62101 loss)
I0826 17:00:34.104295 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.55026 (* 1 = 3.55026 loss)
I0826 17:00:34.104298 25446 sgd_solver.cpp:138] Iteration 26930, lr = 1e-05
I0826 17:00:36.256438 25446 solver.cpp:243] Iteration 26940, loss = 4.90648
I0826 17:00:36.256477 25446 solver.cpp:259]     Train net output #0: center_loss = 204.642 (* 0.008 = 1.63714 loss)
I0826 17:00:36.256484 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.26934 (* 1 = 3.26934 loss)
I0826 17:00:36.256487 25446 sgd_solver.cpp:138] Iteration 26940, lr = 1e-05
I0826 17:00:38.418432 25446 solver.cpp:243] Iteration 26950, loss = 5.22411
I0826 17:00:38.418457 25446 solver.cpp:259]     Train net output #0: center_loss = 241.98 (* 0.008 = 1.93584 loss)
I0826 17:00:38.418463 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.28827 (* 1 = 3.28827 loss)
I0826 17:00:38.418467 25446 sgd_solver.cpp:138] Iteration 26950, lr = 1e-05
I0826 17:00:40.568404 25446 solver.cpp:243] Iteration 26960, loss = 5.57478
I0826 17:00:40.568430 25446 solver.cpp:259]     Train net output #0: center_loss = 212.926 (* 0.008 = 1.70341 loss)
I0826 17:00:40.568436 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.87137 (* 1 = 3.87137 loss)
I0826 17:00:40.568441 25446 sgd_solver.cpp:138] Iteration 26960, lr = 1e-05
I0826 17:00:42.635664 25446 solver.cpp:243] Iteration 26970, loss = 4.91644
I0826 17:00:42.635704 25446 solver.cpp:259]     Train net output #0: center_loss = 219.231 (* 0.008 = 1.75385 loss)
I0826 17:00:42.635710 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.16259 (* 1 = 3.16259 loss)
I0826 17:00:42.635713 25446 sgd_solver.cpp:138] Iteration 26970, lr = 1e-05
I0826 17:00:44.710157 25446 solver.cpp:243] Iteration 26980, loss = 6.14712
I0826 17:00:44.710196 25446 solver.cpp:259]     Train net output #0: center_loss = 211.83 (* 0.008 = 1.69464 loss)
I0826 17:00:44.710202 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.45249 (* 1 = 4.45249 loss)
I0826 17:00:44.710206 25446 sgd_solver.cpp:138] Iteration 26980, lr = 1e-05
I0826 17:00:46.782510 25446 solver.cpp:243] Iteration 26990, loss = 5.64467
I0826 17:00:46.782675 25446 solver.cpp:259]     Train net output #0: center_loss = 222.436 (* 0.008 = 1.77949 loss)
I0826 17:00:46.782682 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.86518 (* 1 = 3.86518 loss)
I0826 17:00:46.782686 25446 sgd_solver.cpp:138] Iteration 26990, lr = 1e-05
I0826 17:00:48.650061 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_27000.caffemodel
I0826 17:00:49.790896 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_27000.solverstate
I0826 17:00:50.124472 25446 solver.cpp:243] Iteration 27000, loss = 5.05988
I0826 17:00:50.124497 25446 solver.cpp:259]     Train net output #0: center_loss = 216.835 (* 0.008 = 1.73468 loss)
I0826 17:00:50.124503 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.32521 (* 1 = 3.32521 loss)
I0826 17:00:50.124507 25446 sgd_solver.cpp:138] Iteration 27000, lr = 1e-05
I0826 17:00:52.192544 25446 solver.cpp:243] Iteration 27010, loss = 5.78482
I0826 17:00:52.192584 25446 solver.cpp:259]     Train net output #0: center_loss = 217.555 (* 0.008 = 1.74044 loss)
I0826 17:00:52.192589 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.04438 (* 1 = 4.04438 loss)
I0826 17:00:52.192593 25446 sgd_solver.cpp:138] Iteration 27010, lr = 1e-05
I0826 17:00:54.263886 25446 solver.cpp:243] Iteration 27020, loss = 6.16733
I0826 17:00:54.263926 25446 solver.cpp:259]     Train net output #0: center_loss = 196.644 (* 0.008 = 1.57315 loss)
I0826 17:00:54.263933 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.59418 (* 1 = 4.59418 loss)
I0826 17:00:54.263937 25446 sgd_solver.cpp:138] Iteration 27020, lr = 1e-05
I0826 17:00:56.336004 25446 solver.cpp:243] Iteration 27030, loss = 5.31152
I0826 17:00:56.336028 25446 solver.cpp:259]     Train net output #0: center_loss = 202.272 (* 0.008 = 1.61817 loss)
I0826 17:00:56.336035 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.69335 (* 1 = 3.69335 loss)
I0826 17:00:56.336037 25446 sgd_solver.cpp:138] Iteration 27030, lr = 1e-05
I0826 17:00:58.408383 25446 solver.cpp:243] Iteration 27040, loss = 5.30109
I0826 17:00:58.408421 25446 solver.cpp:259]     Train net output #0: center_loss = 211.928 (* 0.008 = 1.69542 loss)
I0826 17:00:58.408428 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.60567 (* 1 = 3.60567 loss)
I0826 17:00:58.408432 25446 sgd_solver.cpp:138] Iteration 27040, lr = 1e-05
I0826 17:01:00.483623 25446 solver.cpp:243] Iteration 27050, loss = 5.17612
I0826 17:01:00.483646 25446 solver.cpp:259]     Train net output #0: center_loss = 217.901 (* 0.008 = 1.74321 loss)
I0826 17:01:00.483652 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.43291 (* 1 = 3.43291 loss)
I0826 17:01:00.483656 25446 sgd_solver.cpp:138] Iteration 27050, lr = 1e-05
I0826 17:01:02.555136 25446 solver.cpp:243] Iteration 27060, loss = 5.13856
I0826 17:01:02.555176 25446 solver.cpp:259]     Train net output #0: center_loss = 221.72 (* 0.008 = 1.77376 loss)
I0826 17:01:02.555182 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.36481 (* 1 = 3.36481 loss)
I0826 17:01:02.555186 25446 sgd_solver.cpp:138] Iteration 27060, lr = 1e-05
I0826 17:01:04.628751 25446 solver.cpp:243] Iteration 27070, loss = 5.39793
I0826 17:01:04.628789 25446 solver.cpp:259]     Train net output #0: center_loss = 213.528 (* 0.008 = 1.70822 loss)
I0826 17:01:04.628795 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.6897 (* 1 = 3.6897 loss)
I0826 17:01:04.628800 25446 sgd_solver.cpp:138] Iteration 27070, lr = 1e-05
I0826 17:01:06.697646 25446 solver.cpp:243] Iteration 27080, loss = 5.32292
I0826 17:01:06.697669 25446 solver.cpp:259]     Train net output #0: center_loss = 218.936 (* 0.008 = 1.75149 loss)
I0826 17:01:06.697675 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.57143 (* 1 = 3.57143 loss)
I0826 17:01:06.697680 25446 sgd_solver.cpp:138] Iteration 27080, lr = 1e-05
I0826 17:01:08.767966 25446 solver.cpp:243] Iteration 27090, loss = 4.98443
I0826 17:01:08.767990 25446 solver.cpp:259]     Train net output #0: center_loss = 226.303 (* 0.008 = 1.81042 loss)
I0826 17:01:08.768023 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.17401 (* 1 = 3.17401 loss)
I0826 17:01:08.768026 25446 sgd_solver.cpp:138] Iteration 27090, lr = 1e-05
I0826 17:01:10.843046 25446 solver.cpp:243] Iteration 27100, loss = 5.3766
I0826 17:01:10.843070 25446 solver.cpp:259]     Train net output #0: center_loss = 187.676 (* 0.008 = 1.50141 loss)
I0826 17:01:10.843077 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.87519 (* 1 = 3.87519 loss)
I0826 17:01:10.843081 25446 sgd_solver.cpp:138] Iteration 27100, lr = 1e-05
I0826 17:01:12.913437 25446 solver.cpp:243] Iteration 27110, loss = 5.58305
I0826 17:01:12.913460 25446 solver.cpp:259]     Train net output #0: center_loss = 206.237 (* 0.008 = 1.6499 loss)
I0826 17:01:12.913466 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.93315 (* 1 = 3.93315 loss)
I0826 17:01:12.913470 25446 sgd_solver.cpp:138] Iteration 27110, lr = 1e-05
I0826 17:01:14.989044 25446 solver.cpp:243] Iteration 27120, loss = 5.37058
I0826 17:01:14.989068 25446 solver.cpp:259]     Train net output #0: center_loss = 224.43 (* 0.008 = 1.79544 loss)
I0826 17:01:14.989074 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.57514 (* 1 = 3.57514 loss)
I0826 17:01:14.989078 25446 sgd_solver.cpp:138] Iteration 27120, lr = 1e-05
I0826 17:01:17.061547 25446 solver.cpp:243] Iteration 27130, loss = 5.82585
I0826 17:01:17.061709 25446 solver.cpp:259]     Train net output #0: center_loss = 210.745 (* 0.008 = 1.68596 loss)
I0826 17:01:17.061730 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.13989 (* 1 = 4.13989 loss)
I0826 17:01:17.061734 25446 sgd_solver.cpp:138] Iteration 27130, lr = 1e-05
I0826 17:01:19.136003 25446 solver.cpp:243] Iteration 27140, loss = 4.9655
I0826 17:01:19.136042 25446 solver.cpp:259]     Train net output #0: center_loss = 233.103 (* 0.008 = 1.86482 loss)
I0826 17:01:19.136049 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.10068 (* 1 = 3.10068 loss)
I0826 17:01:19.136052 25446 sgd_solver.cpp:138] Iteration 27140, lr = 1e-05
I0826 17:01:21.209280 25446 solver.cpp:243] Iteration 27150, loss = 5.91724
I0826 17:01:21.209316 25446 solver.cpp:259]     Train net output #0: center_loss = 205.743 (* 0.008 = 1.64595 loss)
I0826 17:01:21.209337 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.27129 (* 1 = 4.27129 loss)
I0826 17:01:21.209342 25446 sgd_solver.cpp:138] Iteration 27150, lr = 1e-05
I0826 17:01:23.281451 25446 solver.cpp:243] Iteration 27160, loss = 4.98544
I0826 17:01:23.281489 25446 solver.cpp:259]     Train net output #0: center_loss = 220.748 (* 0.008 = 1.76599 loss)
I0826 17:01:23.281496 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.21945 (* 1 = 3.21945 loss)
I0826 17:01:23.281499 25446 sgd_solver.cpp:138] Iteration 27160, lr = 1e-05
I0826 17:01:25.350242 25446 solver.cpp:243] Iteration 27170, loss = 5.60372
I0826 17:01:25.350283 25446 solver.cpp:259]     Train net output #0: center_loss = 220.641 (* 0.008 = 1.76513 loss)
I0826 17:01:25.350289 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83859 (* 1 = 3.83859 loss)
I0826 17:01:25.350293 25446 sgd_solver.cpp:138] Iteration 27170, lr = 1e-05
I0826 17:01:27.420442 25446 solver.cpp:243] Iteration 27180, loss = 4.64504
I0826 17:01:27.420481 25446 solver.cpp:259]     Train net output #0: center_loss = 226.309 (* 0.008 = 1.81047 loss)
I0826 17:01:27.420487 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.83457 (* 1 = 2.83457 loss)
I0826 17:01:27.420491 25446 sgd_solver.cpp:138] Iteration 27180, lr = 1e-05
I0826 17:01:29.490984 25446 solver.cpp:243] Iteration 27190, loss = 4.60978
I0826 17:01:29.491022 25446 solver.cpp:259]     Train net output #0: center_loss = 232.291 (* 0.008 = 1.85833 loss)
I0826 17:01:29.491029 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.75145 (* 1 = 2.75145 loss)
I0826 17:01:29.491032 25446 sgd_solver.cpp:138] Iteration 27190, lr = 1e-05
I0826 17:01:31.565656 25446 solver.cpp:243] Iteration 27200, loss = 5.28554
I0826 17:01:31.565681 25446 solver.cpp:259]     Train net output #0: center_loss = 228.085 (* 0.008 = 1.82468 loss)
I0826 17:01:31.565688 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.46086 (* 1 = 3.46086 loss)
I0826 17:01:31.565692 25446 sgd_solver.cpp:138] Iteration 27200, lr = 1e-05
I0826 17:01:33.635288 25446 solver.cpp:243] Iteration 27210, loss = 4.8845
I0826 17:01:33.635327 25446 solver.cpp:259]     Train net output #0: center_loss = 218.584 (* 0.008 = 1.74867 loss)
I0826 17:01:33.635334 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.13582 (* 1 = 3.13582 loss)
I0826 17:01:33.635339 25446 sgd_solver.cpp:138] Iteration 27210, lr = 1e-05
I0826 17:01:35.705147 25446 solver.cpp:243] Iteration 27220, loss = 4.74001
I0826 17:01:35.705173 25446 solver.cpp:259]     Train net output #0: center_loss = 224.332 (* 0.008 = 1.79465 loss)
I0826 17:01:35.705179 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.94536 (* 1 = 2.94536 loss)
I0826 17:01:35.705183 25446 sgd_solver.cpp:138] Iteration 27220, lr = 1e-05
I0826 17:01:37.775285 25446 solver.cpp:243] Iteration 27230, loss = 6.13766
I0826 17:01:37.775310 25446 solver.cpp:259]     Train net output #0: center_loss = 200.384 (* 0.008 = 1.60308 loss)
I0826 17:01:37.775316 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.53458 (* 1 = 4.53458 loss)
I0826 17:01:37.775321 25446 sgd_solver.cpp:138] Iteration 27230, lr = 1e-05
I0826 17:01:39.852412 25446 solver.cpp:243] Iteration 27240, loss = 4.84335
I0826 17:01:39.852435 25446 solver.cpp:259]     Train net output #0: center_loss = 210.204 (* 0.008 = 1.68164 loss)
I0826 17:01:39.852442 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.16171 (* 1 = 3.16171 loss)
I0826 17:01:39.852445 25446 sgd_solver.cpp:138] Iteration 27240, lr = 1e-05
I0826 17:01:41.923130 25446 solver.cpp:243] Iteration 27250, loss = 5.68745
I0826 17:01:41.923154 25446 solver.cpp:259]     Train net output #0: center_loss = 214.484 (* 0.008 = 1.71587 loss)
I0826 17:01:41.923161 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97158 (* 1 = 3.97158 loss)
I0826 17:01:41.923166 25446 sgd_solver.cpp:138] Iteration 27250, lr = 1e-05
I0826 17:01:43.994204 25446 solver.cpp:243] Iteration 27260, loss = 5.93622
I0826 17:01:43.994243 25446 solver.cpp:259]     Train net output #0: center_loss = 208.576 (* 0.008 = 1.66861 loss)
I0826 17:01:43.994249 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.26761 (* 1 = 4.26761 loss)
I0826 17:01:43.994253 25446 sgd_solver.cpp:138] Iteration 27260, lr = 1e-05
I0826 17:01:46.067983 25446 solver.cpp:243] Iteration 27270, loss = 5.20544
I0826 17:01:46.068008 25446 solver.cpp:259]     Train net output #0: center_loss = 245.105 (* 0.008 = 1.96084 loss)
I0826 17:01:46.068014 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.24461 (* 1 = 3.24461 loss)
I0826 17:01:46.068018 25446 sgd_solver.cpp:138] Iteration 27270, lr = 1e-05
I0826 17:01:48.137751 25446 solver.cpp:243] Iteration 27280, loss = 5.19814
I0826 17:01:48.137861 25446 solver.cpp:259]     Train net output #0: center_loss = 224.992 (* 0.008 = 1.79994 loss)
I0826 17:01:48.137881 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.3982 (* 1 = 3.3982 loss)
I0826 17:01:48.137886 25446 sgd_solver.cpp:138] Iteration 27280, lr = 1e-05
I0826 17:01:50.210309 25446 solver.cpp:243] Iteration 27290, loss = 5.42028
I0826 17:01:50.210348 25446 solver.cpp:259]     Train net output #0: center_loss = 224.205 (* 0.008 = 1.79364 loss)
I0826 17:01:50.210355 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.62665 (* 1 = 3.62665 loss)
I0826 17:01:50.210359 25446 sgd_solver.cpp:138] Iteration 27290, lr = 1e-05
I0826 17:01:52.281213 25446 solver.cpp:243] Iteration 27300, loss = 5.33038
I0826 17:01:52.281255 25446 solver.cpp:259]     Train net output #0: center_loss = 234.485 (* 0.008 = 1.87588 loss)
I0826 17:01:52.281275 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.4545 (* 1 = 3.4545 loss)
I0826 17:01:52.281280 25446 sgd_solver.cpp:138] Iteration 27300, lr = 1e-05
I0826 17:01:54.353597 25446 solver.cpp:243] Iteration 27310, loss = 4.66541
I0826 17:01:54.353636 25446 solver.cpp:259]     Train net output #0: center_loss = 225.497 (* 0.008 = 1.80398 loss)
I0826 17:01:54.353642 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.86143 (* 1 = 2.86143 loss)
I0826 17:01:54.353646 25446 sgd_solver.cpp:138] Iteration 27310, lr = 1e-05
I0826 17:01:56.425978 25446 solver.cpp:243] Iteration 27320, loss = 4.76975
I0826 17:01:56.426017 25446 solver.cpp:259]     Train net output #0: center_loss = 200.953 (* 0.008 = 1.60762 loss)
I0826 17:01:56.426023 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.16213 (* 1 = 3.16213 loss)
I0826 17:01:56.426028 25446 sgd_solver.cpp:138] Iteration 27320, lr = 1e-05
I0826 17:01:58.497439 25446 solver.cpp:243] Iteration 27330, loss = 3.79389
I0826 17:01:58.497478 25446 solver.cpp:259]     Train net output #0: center_loss = 240.664 (* 0.008 = 1.92531 loss)
I0826 17:01:58.497484 25446 solver.cpp:259]     Train net output #1: softmax_loss = 1.86858 (* 1 = 1.86858 loss)
I0826 17:01:58.497488 25446 sgd_solver.cpp:138] Iteration 27330, lr = 1e-05
I0826 17:02:00.570194 25446 solver.cpp:243] Iteration 27340, loss = 6.12194
I0826 17:02:00.570216 25446 solver.cpp:259]     Train net output #0: center_loss = 209.889 (* 0.008 = 1.67911 loss)
I0826 17:02:00.570222 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.44283 (* 1 = 4.44283 loss)
I0826 17:02:00.570226 25446 sgd_solver.cpp:138] Iteration 27340, lr = 1e-05
I0826 17:02:02.644510 25446 solver.cpp:243] Iteration 27350, loss = 4.82987
I0826 17:02:02.644534 25446 solver.cpp:259]     Train net output #0: center_loss = 236.362 (* 0.008 = 1.89089 loss)
I0826 17:02:02.644541 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.93898 (* 1 = 2.93898 loss)
I0826 17:02:02.644544 25446 sgd_solver.cpp:138] Iteration 27350, lr = 1e-05
I0826 17:02:04.721704 25446 solver.cpp:243] Iteration 27360, loss = 4.56588
I0826 17:02:04.721726 25446 solver.cpp:259]     Train net output #0: center_loss = 211.238 (* 0.008 = 1.6899 loss)
I0826 17:02:04.721734 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.87597 (* 1 = 2.87597 loss)
I0826 17:02:04.721737 25446 sgd_solver.cpp:138] Iteration 27360, lr = 1e-05
I0826 17:02:06.791980 25446 solver.cpp:243] Iteration 27370, loss = 5.90292
I0826 17:02:06.792001 25446 solver.cpp:259]     Train net output #0: center_loss = 204.983 (* 0.008 = 1.63986 loss)
I0826 17:02:06.792008 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.26306 (* 1 = 4.26306 loss)
I0826 17:02:06.792012 25446 sgd_solver.cpp:138] Iteration 27370, lr = 1e-05
I0826 17:02:08.865141 25446 solver.cpp:243] Iteration 27380, loss = 5.13944
I0826 17:02:08.865166 25446 solver.cpp:259]     Train net output #0: center_loss = 202.21 (* 0.008 = 1.61768 loss)
I0826 17:02:08.865172 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.52177 (* 1 = 3.52177 loss)
I0826 17:02:08.865176 25446 sgd_solver.cpp:138] Iteration 27380, lr = 1e-05
I0826 17:02:10.939628 25446 solver.cpp:243] Iteration 27390, loss = 5.01863
I0826 17:02:10.939653 25446 solver.cpp:259]     Train net output #0: center_loss = 213.075 (* 0.008 = 1.7046 loss)
I0826 17:02:10.939661 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.31403 (* 1 = 3.31403 loss)
I0826 17:02:10.939664 25446 sgd_solver.cpp:138] Iteration 27390, lr = 1e-05
I0826 17:02:13.014957 25446 solver.cpp:243] Iteration 27400, loss = 4.76921
I0826 17:02:13.014981 25446 solver.cpp:259]     Train net output #0: center_loss = 225.644 (* 0.008 = 1.80516 loss)
I0826 17:02:13.014987 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.96405 (* 1 = 2.96405 loss)
I0826 17:02:13.014992 25446 sgd_solver.cpp:138] Iteration 27400, lr = 1e-05
I0826 17:02:15.083585 25446 solver.cpp:243] Iteration 27410, loss = 6.16057
I0826 17:02:15.083609 25446 solver.cpp:259]     Train net output #0: center_loss = 213.384 (* 0.008 = 1.70707 loss)
I0826 17:02:15.083616 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.4535 (* 1 = 4.4535 loss)
I0826 17:02:15.083621 25446 sgd_solver.cpp:138] Iteration 27410, lr = 1e-05
I0826 17:02:17.154768 25446 solver.cpp:243] Iteration 27420, loss = 4.32351
I0826 17:02:17.154793 25446 solver.cpp:259]     Train net output #0: center_loss = 238.392 (* 0.008 = 1.90714 loss)
I0826 17:02:17.154799 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.41637 (* 1 = 2.41637 loss)
I0826 17:02:17.154803 25446 sgd_solver.cpp:138] Iteration 27420, lr = 1e-05
I0826 17:02:19.227288 25446 solver.cpp:243] Iteration 27430, loss = 5.37356
I0826 17:02:19.227414 25446 solver.cpp:259]     Train net output #0: center_loss = 191.443 (* 0.008 = 1.53154 loss)
I0826 17:02:19.227421 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.84202 (* 1 = 3.84202 loss)
I0826 17:02:19.227439 25446 sgd_solver.cpp:138] Iteration 27430, lr = 1e-05
I0826 17:02:21.299351 25446 solver.cpp:243] Iteration 27440, loss = 5.01533
I0826 17:02:21.299374 25446 solver.cpp:259]     Train net output #0: center_loss = 226.149 (* 0.008 = 1.80919 loss)
I0826 17:02:21.299381 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.20614 (* 1 = 3.20614 loss)
I0826 17:02:21.299386 25446 sgd_solver.cpp:138] Iteration 27440, lr = 1e-05
I0826 17:02:23.373236 25446 solver.cpp:243] Iteration 27450, loss = 4.77197
I0826 17:02:23.373265 25446 solver.cpp:259]     Train net output #0: center_loss = 221.491 (* 0.008 = 1.77193 loss)
I0826 17:02:23.373271 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.00004 (* 1 = 3.00004 loss)
I0826 17:02:23.373275 25446 sgd_solver.cpp:138] Iteration 27450, lr = 1e-05
I0826 17:02:25.445003 25446 solver.cpp:243] Iteration 27460, loss = 5.67973
I0826 17:02:25.445026 25446 solver.cpp:259]     Train net output #0: center_loss = 215.451 (* 0.008 = 1.7236 loss)
I0826 17:02:25.445032 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.95612 (* 1 = 3.95612 loss)
I0826 17:02:25.445036 25446 sgd_solver.cpp:138] Iteration 27460, lr = 1e-05
I0826 17:02:27.518929 25446 solver.cpp:243] Iteration 27470, loss = 4.54752
I0826 17:02:27.518952 25446 solver.cpp:259]     Train net output #0: center_loss = 230.897 (* 0.008 = 1.84718 loss)
I0826 17:02:27.518959 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.70035 (* 1 = 2.70035 loss)
I0826 17:02:27.518962 25446 sgd_solver.cpp:138] Iteration 27470, lr = 1e-05
I0826 17:02:29.588992 25446 solver.cpp:243] Iteration 27480, loss = 5.53388
I0826 17:02:29.589017 25446 solver.cpp:259]     Train net output #0: center_loss = 219.326 (* 0.008 = 1.75461 loss)
I0826 17:02:29.589023 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77927 (* 1 = 3.77927 loss)
I0826 17:02:29.589027 25446 sgd_solver.cpp:138] Iteration 27480, lr = 1e-05
I0826 17:02:31.663055 25446 solver.cpp:243] Iteration 27490, loss = 4.31788
I0826 17:02:31.663079 25446 solver.cpp:259]     Train net output #0: center_loss = 214.103 (* 0.008 = 1.71282 loss)
I0826 17:02:31.663085 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.60506 (* 1 = 2.60506 loss)
I0826 17:02:31.663090 25446 sgd_solver.cpp:138] Iteration 27490, lr = 1e-05
I0826 17:02:33.736953 25446 solver.cpp:243] Iteration 27500, loss = 5.02754
I0826 17:02:33.736976 25446 solver.cpp:259]     Train net output #0: center_loss = 218.403 (* 0.008 = 1.74722 loss)
I0826 17:02:33.736982 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.28032 (* 1 = 3.28032 loss)
I0826 17:02:33.736986 25446 sgd_solver.cpp:138] Iteration 27500, lr = 1e-05
I0826 17:02:35.809569 25446 solver.cpp:243] Iteration 27510, loss = 5.53189
I0826 17:02:35.809597 25446 solver.cpp:259]     Train net output #0: center_loss = 202.005 (* 0.008 = 1.61604 loss)
I0826 17:02:35.809603 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.91585 (* 1 = 3.91585 loss)
I0826 17:02:35.809607 25446 sgd_solver.cpp:138] Iteration 27510, lr = 1e-05
I0826 17:02:37.885426 25446 solver.cpp:243] Iteration 27520, loss = 4.72682
I0826 17:02:37.885452 25446 solver.cpp:259]     Train net output #0: center_loss = 205.508 (* 0.008 = 1.64406 loss)
I0826 17:02:37.885457 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.08276 (* 1 = 3.08276 loss)
I0826 17:02:37.885462 25446 sgd_solver.cpp:138] Iteration 27520, lr = 1e-05
I0826 17:02:39.956856 25446 solver.cpp:243] Iteration 27530, loss = 4.5683
I0826 17:02:39.956881 25446 solver.cpp:259]     Train net output #0: center_loss = 224.253 (* 0.008 = 1.79402 loss)
I0826 17:02:39.956888 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.77428 (* 1 = 2.77428 loss)
I0826 17:02:39.956893 25446 sgd_solver.cpp:138] Iteration 27530, lr = 1e-05
I0826 17:02:42.029541 25446 solver.cpp:243] Iteration 27540, loss = 4.98589
I0826 17:02:42.029564 25446 solver.cpp:259]     Train net output #0: center_loss = 224.413 (* 0.008 = 1.79531 loss)
I0826 17:02:42.029572 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.19058 (* 1 = 3.19058 loss)
I0826 17:02:42.029575 25446 sgd_solver.cpp:138] Iteration 27540, lr = 1e-05
I0826 17:02:44.102385 25446 solver.cpp:243] Iteration 27550, loss = 5.46189
I0826 17:02:44.102408 25446 solver.cpp:259]     Train net output #0: center_loss = 207.542 (* 0.008 = 1.66034 loss)
I0826 17:02:44.102414 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.80156 (* 1 = 3.80156 loss)
I0826 17:02:44.102418 25446 sgd_solver.cpp:138] Iteration 27550, lr = 1e-05
I0826 17:02:46.175549 25446 solver.cpp:243] Iteration 27560, loss = 5.65034
I0826 17:02:46.175575 25446 solver.cpp:259]     Train net output #0: center_loss = 209.525 (* 0.008 = 1.6762 loss)
I0826 17:02:46.175596 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.97414 (* 1 = 3.97414 loss)
I0826 17:02:46.175601 25446 sgd_solver.cpp:138] Iteration 27560, lr = 1e-05
I0826 17:02:48.247458 25446 solver.cpp:243] Iteration 27570, loss = 5.26323
I0826 17:02:48.247483 25446 solver.cpp:259]     Train net output #0: center_loss = 213.649 (* 0.008 = 1.70919 loss)
I0826 17:02:48.247489 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.55404 (* 1 = 3.55404 loss)
I0826 17:02:48.247493 25446 sgd_solver.cpp:138] Iteration 27570, lr = 1e-05
I0826 17:02:50.321292 25446 solver.cpp:243] Iteration 27580, loss = 5.57737
I0826 17:02:50.321439 25446 solver.cpp:259]     Train net output #0: center_loss = 215.381 (* 0.008 = 1.72304 loss)
I0826 17:02:50.321460 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.85433 (* 1 = 3.85433 loss)
I0826 17:02:50.321465 25446 sgd_solver.cpp:138] Iteration 27580, lr = 1e-05
I0826 17:02:52.522182 25446 solver.cpp:243] Iteration 27590, loss = 3.82698
I0826 17:02:52.522207 25446 solver.cpp:259]     Train net output #0: center_loss = 224.719 (* 0.008 = 1.79775 loss)
I0826 17:02:52.522213 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.02923 (* 1 = 2.02923 loss)
I0826 17:02:52.522217 25446 sgd_solver.cpp:138] Iteration 27590, lr = 1e-05
I0826 17:02:54.802469 25446 solver.cpp:243] Iteration 27600, loss = 4.18986
I0826 17:02:54.802508 25446 solver.cpp:259]     Train net output #0: center_loss = 233.226 (* 0.008 = 1.86581 loss)
I0826 17:02:54.802515 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.32406 (* 1 = 2.32406 loss)
I0826 17:02:54.802518 25446 sgd_solver.cpp:138] Iteration 27600, lr = 1e-05
I0826 17:02:57.090314 25446 solver.cpp:243] Iteration 27610, loss = 5.60335
I0826 17:02:57.090363 25446 solver.cpp:259]     Train net output #0: center_loss = 216.106 (* 0.008 = 1.72885 loss)
I0826 17:02:57.090370 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.87451 (* 1 = 3.87451 loss)
I0826 17:02:57.090375 25446 sgd_solver.cpp:138] Iteration 27610, lr = 1e-05
I0826 17:02:59.325165 25446 solver.cpp:243] Iteration 27620, loss = 5.27624
I0826 17:02:59.325191 25446 solver.cpp:259]     Train net output #0: center_loss = 204.775 (* 0.008 = 1.6382 loss)
I0826 17:02:59.325197 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.63804 (* 1 = 3.63804 loss)
I0826 17:02:59.325202 25446 sgd_solver.cpp:138] Iteration 27620, lr = 1e-05
I0826 17:03:01.524238 25446 solver.cpp:243] Iteration 27630, loss = 4.91036
I0826 17:03:01.524277 25446 solver.cpp:259]     Train net output #0: center_loss = 242.634 (* 0.008 = 1.94107 loss)
I0826 17:03:01.524284 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.96929 (* 1 = 2.96929 loss)
I0826 17:03:01.524289 25446 sgd_solver.cpp:138] Iteration 27630, lr = 1e-05
I0826 17:03:03.735821 25446 solver.cpp:243] Iteration 27640, loss = 4.55283
I0826 17:03:03.735862 25446 solver.cpp:259]     Train net output #0: center_loss = 226.498 (* 0.008 = 1.81199 loss)
I0826 17:03:03.735867 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.74085 (* 1 = 2.74085 loss)
I0826 17:03:03.735872 25446 sgd_solver.cpp:138] Iteration 27640, lr = 1e-05
I0826 17:03:05.969044 25446 solver.cpp:243] Iteration 27650, loss = 5.47978
I0826 17:03:05.969067 25446 solver.cpp:259]     Train net output #0: center_loss = 213.313 (* 0.008 = 1.70651 loss)
I0826 17:03:05.969074 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.77327 (* 1 = 3.77327 loss)
I0826 17:03:05.969076 25446 sgd_solver.cpp:138] Iteration 27650, lr = 1e-05
I0826 17:03:08.110117 25446 solver.cpp:243] Iteration 27660, loss = 5.81983
I0826 17:03:08.110141 25446 solver.cpp:259]     Train net output #0: center_loss = 210.974 (* 0.008 = 1.68779 loss)
I0826 17:03:08.110147 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.13205 (* 1 = 4.13205 loss)
I0826 17:03:08.110152 25446 sgd_solver.cpp:138] Iteration 27660, lr = 1e-05
I0826 17:03:10.174522 25446 solver.cpp:243] Iteration 27670, loss = 4.63077
I0826 17:03:10.174546 25446 solver.cpp:259]     Train net output #0: center_loss = 214.89 (* 0.008 = 1.71912 loss)
I0826 17:03:10.174552 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.91165 (* 1 = 2.91165 loss)
I0826 17:03:10.174556 25446 sgd_solver.cpp:138] Iteration 27670, lr = 1e-05
I0826 17:03:12.235379 25446 solver.cpp:243] Iteration 27680, loss = 5.19696
I0826 17:03:12.235404 25446 solver.cpp:259]     Train net output #0: center_loss = 213.941 (* 0.008 = 1.71153 loss)
I0826 17:03:12.235409 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.48543 (* 1 = 3.48543 loss)
I0826 17:03:12.235414 25446 sgd_solver.cpp:138] Iteration 27680, lr = 1e-05
I0826 17:03:14.296631 25446 solver.cpp:243] Iteration 27690, loss = 4.56896
I0826 17:03:14.296671 25446 solver.cpp:259]     Train net output #0: center_loss = 219.419 (* 0.008 = 1.75535 loss)
I0826 17:03:14.296676 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.81361 (* 1 = 2.81361 loss)
I0826 17:03:14.296680 25446 sgd_solver.cpp:138] Iteration 27690, lr = 1e-05
I0826 17:03:16.360510 25446 solver.cpp:243] Iteration 27700, loss = 4.9934
I0826 17:03:16.360535 25446 solver.cpp:259]     Train net output #0: center_loss = 218.224 (* 0.008 = 1.74579 loss)
I0826 17:03:16.360541 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.24761 (* 1 = 3.24761 loss)
I0826 17:03:16.360545 25446 sgd_solver.cpp:138] Iteration 27700, lr = 1e-05
I0826 17:03:18.420120 25446 solver.cpp:243] Iteration 27710, loss = 4.70148
I0826 17:03:18.420145 25446 solver.cpp:259]     Train net output #0: center_loss = 197.082 (* 0.008 = 1.57666 loss)
I0826 17:03:18.420150 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.12482 (* 1 = 3.12482 loss)
I0826 17:03:18.420154 25446 sgd_solver.cpp:138] Iteration 27710, lr = 1e-05
I0826 17:03:20.480626 25446 solver.cpp:243] Iteration 27720, loss = 5.53335
I0826 17:03:20.480763 25446 solver.cpp:259]     Train net output #0: center_loss = 213.577 (* 0.008 = 1.70862 loss)
I0826 17:03:20.480772 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.82473 (* 1 = 3.82473 loss)
I0826 17:03:20.480788 25446 sgd_solver.cpp:138] Iteration 27720, lr = 1e-05
I0826 17:03:22.544608 25446 solver.cpp:243] Iteration 27730, loss = 5.2546
I0826 17:03:22.544646 25446 solver.cpp:259]     Train net output #0: center_loss = 211.936 (* 0.008 = 1.69549 loss)
I0826 17:03:22.544652 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.55911 (* 1 = 3.55911 loss)
I0826 17:03:22.544656 25446 sgd_solver.cpp:138] Iteration 27730, lr = 1e-05
I0826 17:03:24.605684 25446 solver.cpp:243] Iteration 27740, loss = 5.66884
I0826 17:03:24.605722 25446 solver.cpp:259]     Train net output #0: center_loss = 195.555 (* 0.008 = 1.56444 loss)
I0826 17:03:24.605728 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.10441 (* 1 = 4.10441 loss)
I0826 17:03:24.605732 25446 sgd_solver.cpp:138] Iteration 27740, lr = 1e-05
I0826 17:03:26.670742 25446 solver.cpp:243] Iteration 27750, loss = 5.11493
I0826 17:03:26.670766 25446 solver.cpp:259]     Train net output #0: center_loss = 212.17 (* 0.008 = 1.69736 loss)
I0826 17:03:26.670773 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.41756 (* 1 = 3.41756 loss)
I0826 17:03:26.670776 25446 sgd_solver.cpp:138] Iteration 27750, lr = 1e-05
I0826 17:03:28.731182 25446 solver.cpp:243] Iteration 27760, loss = 4.59091
I0826 17:03:28.731235 25446 solver.cpp:259]     Train net output #0: center_loss = 206.787 (* 0.008 = 1.6543 loss)
I0826 17:03:28.731240 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.93661 (* 1 = 2.93661 loss)
I0826 17:03:28.731259 25446 sgd_solver.cpp:138] Iteration 27760, lr = 1e-05
I0826 17:03:30.791854 25446 solver.cpp:243] Iteration 27770, loss = 4.72049
I0826 17:03:30.791878 25446 solver.cpp:259]     Train net output #0: center_loss = 228.532 (* 0.008 = 1.82825 loss)
I0826 17:03:30.791883 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.89224 (* 1 = 2.89224 loss)
I0826 17:03:30.791888 25446 sgd_solver.cpp:138] Iteration 27770, lr = 1e-05
I0826 17:03:32.855007 25446 solver.cpp:243] Iteration 27780, loss = 5.27882
I0826 17:03:32.855031 25446 solver.cpp:259]     Train net output #0: center_loss = 208.214 (* 0.008 = 1.66571 loss)
I0826 17:03:32.855037 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.61311 (* 1 = 3.61311 loss)
I0826 17:03:32.855041 25446 sgd_solver.cpp:138] Iteration 27780, lr = 1e-05
I0826 17:03:34.943071 25446 solver.cpp:243] Iteration 27790, loss = 5.56257
I0826 17:03:34.943099 25446 solver.cpp:259]     Train net output #0: center_loss = 216.007 (* 0.008 = 1.72805 loss)
I0826 17:03:34.943104 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.83452 (* 1 = 3.83452 loss)
I0826 17:03:34.943109 25446 sgd_solver.cpp:138] Iteration 27790, lr = 1e-05
I0826 17:03:37.224783 25446 solver.cpp:243] Iteration 27800, loss = 5.26304
I0826 17:03:37.224809 25446 solver.cpp:259]     Train net output #0: center_loss = 216.619 (* 0.008 = 1.73295 loss)
I0826 17:03:37.224815 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.53009 (* 1 = 3.53009 loss)
I0826 17:03:37.224819 25446 sgd_solver.cpp:138] Iteration 27800, lr = 1e-05
I0826 17:03:39.473563 25446 solver.cpp:243] Iteration 27810, loss = 5.40014
I0826 17:03:39.473603 25446 solver.cpp:259]     Train net output #0: center_loss = 237.329 (* 0.008 = 1.89864 loss)
I0826 17:03:39.473609 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.50151 (* 1 = 3.50151 loss)
I0826 17:03:39.473613 25446 sgd_solver.cpp:138] Iteration 27810, lr = 1e-05
I0826 17:03:41.705868 25446 solver.cpp:243] Iteration 27820, loss = 4.89614
I0826 17:03:41.705893 25446 solver.cpp:259]     Train net output #0: center_loss = 218.14 (* 0.008 = 1.74512 loss)
I0826 17:03:41.705899 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.15102 (* 1 = 3.15102 loss)
I0826 17:03:41.705904 25446 sgd_solver.cpp:138] Iteration 27820, lr = 1e-05
I0826 17:03:43.948521 25446 solver.cpp:243] Iteration 27830, loss = 3.9994
I0826 17:03:43.948546 25446 solver.cpp:259]     Train net output #0: center_loss = 212.223 (* 0.008 = 1.69778 loss)
I0826 17:03:43.948552 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.30162 (* 1 = 2.30162 loss)
I0826 17:03:43.948556 25446 sgd_solver.cpp:138] Iteration 27830, lr = 1e-05
I0826 17:03:46.193457 25446 solver.cpp:243] Iteration 27840, loss = 5.2497
I0826 17:03:46.193485 25446 solver.cpp:259]     Train net output #0: center_loss = 225.835 (* 0.008 = 1.80668 loss)
I0826 17:03:46.193491 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.44302 (* 1 = 3.44302 loss)
I0826 17:03:46.193496 25446 sgd_solver.cpp:138] Iteration 27840, lr = 1e-05
I0826 17:03:48.442225 25446 solver.cpp:243] Iteration 27850, loss = 5.05076
I0826 17:03:48.442250 25446 solver.cpp:259]     Train net output #0: center_loss = 231.786 (* 0.008 = 1.85428 loss)
I0826 17:03:48.442270 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.19647 (* 1 = 3.19647 loss)
I0826 17:03:48.442275 25446 sgd_solver.cpp:138] Iteration 27850, lr = 1e-05
I0826 17:03:50.736840 25446 solver.cpp:243] Iteration 27860, loss = 5.44183
I0826 17:03:50.736958 25446 solver.cpp:259]     Train net output #0: center_loss = 203.774 (* 0.008 = 1.63019 loss)
I0826 17:03:50.736968 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.81163 (* 1 = 3.81163 loss)
I0826 17:03:50.736971 25446 sgd_solver.cpp:138] Iteration 27860, lr = 1e-05
I0826 17:03:52.925720 25446 solver.cpp:243] Iteration 27870, loss = 4.78252
I0826 17:03:52.925745 25446 solver.cpp:259]     Train net output #0: center_loss = 229.123 (* 0.008 = 1.83298 loss)
I0826 17:03:52.925752 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.94954 (* 1 = 2.94954 loss)
I0826 17:03:52.925756 25446 sgd_solver.cpp:138] Iteration 27870, lr = 1e-05
I0826 17:03:55.087676 25446 solver.cpp:243] Iteration 27880, loss = 5.21649
I0826 17:03:55.087702 25446 solver.cpp:259]     Train net output #0: center_loss = 205.362 (* 0.008 = 1.64289 loss)
I0826 17:03:55.087708 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.57359 (* 1 = 3.57359 loss)
I0826 17:03:55.087713 25446 sgd_solver.cpp:138] Iteration 27880, lr = 1e-05
I0826 17:03:57.250344 25446 solver.cpp:243] Iteration 27890, loss = 5.04992
I0826 17:03:57.250370 25446 solver.cpp:259]     Train net output #0: center_loss = 216.243 (* 0.008 = 1.72994 loss)
I0826 17:03:57.250375 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.31998 (* 1 = 3.31998 loss)
I0826 17:03:57.250380 25446 sgd_solver.cpp:138] Iteration 27890, lr = 1e-05
I0826 17:03:59.481021 25446 solver.cpp:243] Iteration 27900, loss = 3.89008
I0826 17:03:59.481060 25446 solver.cpp:259]     Train net output #0: center_loss = 227.775 (* 0.008 = 1.8222 loss)
I0826 17:03:59.481066 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.06788 (* 1 = 2.06788 loss)
I0826 17:03:59.481070 25446 sgd_solver.cpp:138] Iteration 27900, lr = 1e-05
I0826 17:04:01.622545 25446 solver.cpp:243] Iteration 27910, loss = 5.09892
I0826 17:04:01.622570 25446 solver.cpp:259]     Train net output #0: center_loss = 216.802 (* 0.008 = 1.73441 loss)
I0826 17:04:01.622576 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.36451 (* 1 = 3.36451 loss)
I0826 17:04:01.622581 25446 sgd_solver.cpp:138] Iteration 27910, lr = 1e-05
I0826 17:04:03.685622 25446 solver.cpp:243] Iteration 27920, loss = 5.27232
I0826 17:04:03.685647 25446 solver.cpp:259]     Train net output #0: center_loss = 214.615 (* 0.008 = 1.71692 loss)
I0826 17:04:03.685652 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.5554 (* 1 = 3.5554 loss)
I0826 17:04:03.685657 25446 sgd_solver.cpp:138] Iteration 27920, lr = 1e-05
I0826 17:04:05.748941 25446 solver.cpp:243] Iteration 27930, loss = 5.29265
I0826 17:04:05.748966 25446 solver.cpp:259]     Train net output #0: center_loss = 212.231 (* 0.008 = 1.69785 loss)
I0826 17:04:05.748972 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.5948 (* 1 = 3.5948 loss)
I0826 17:04:05.748976 25446 sgd_solver.cpp:138] Iteration 27930, lr = 1e-05
I0826 17:04:07.814003 25446 solver.cpp:243] Iteration 27940, loss = 5.13462
I0826 17:04:07.814026 25446 solver.cpp:259]     Train net output #0: center_loss = 212.615 (* 0.008 = 1.70092 loss)
I0826 17:04:07.814033 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.43371 (* 1 = 3.43371 loss)
I0826 17:04:07.814036 25446 sgd_solver.cpp:138] Iteration 27940, lr = 1e-05
I0826 17:04:09.875177 25446 solver.cpp:243] Iteration 27950, loss = 4.95334
I0826 17:04:09.875201 25446 solver.cpp:259]     Train net output #0: center_loss = 220.559 (* 0.008 = 1.76447 loss)
I0826 17:04:09.875207 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.18887 (* 1 = 3.18887 loss)
I0826 17:04:09.875211 25446 sgd_solver.cpp:138] Iteration 27950, lr = 1e-05
I0826 17:04:11.940794 25446 solver.cpp:243] Iteration 27960, loss = 6.00657
I0826 17:04:11.940819 25446 solver.cpp:259]     Train net output #0: center_loss = 181.734 (* 0.008 = 1.45387 loss)
I0826 17:04:11.940824 25446 solver.cpp:259]     Train net output #1: softmax_loss = 4.5527 (* 1 = 4.5527 loss)
I0826 17:04:11.940827 25446 sgd_solver.cpp:138] Iteration 27960, lr = 1e-05
I0826 17:04:14.000470 25446 solver.cpp:243] Iteration 27970, loss = 4.24537
I0826 17:04:14.000509 25446 solver.cpp:259]     Train net output #0: center_loss = 226.85 (* 0.008 = 1.8148 loss)
I0826 17:04:14.000514 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.43057 (* 1 = 2.43057 loss)
I0826 17:04:14.000517 25446 sgd_solver.cpp:138] Iteration 27970, lr = 1e-05
I0826 17:04:16.063592 25446 solver.cpp:243] Iteration 27980, loss = 4.89861
I0826 17:04:16.063630 25446 solver.cpp:259]     Train net output #0: center_loss = 222.44 (* 0.008 = 1.77952 loss)
I0826 17:04:16.063637 25446 solver.cpp:259]     Train net output #1: softmax_loss = 3.11908 (* 1 = 3.11908 loss)
I0826 17:04:16.063640 25446 sgd_solver.cpp:138] Iteration 27980, lr = 1e-05
I0826 17:04:18.125522 25446 solver.cpp:243] Iteration 27990, loss = 4.7312
I0826 17:04:18.125561 25446 solver.cpp:259]     Train net output #0: center_loss = 235.554 (* 0.008 = 1.88443 loss)
I0826 17:04:18.125568 25446 solver.cpp:259]     Train net output #1: softmax_loss = 2.84676 (* 1 = 2.84676 loss)
I0826 17:04:18.125587 25446 sgd_solver.cpp:138] Iteration 27990, lr = 1e-05
I0826 17:04:19.981124 25446 solver.cpp:596] Snapshotting to binary proto file face_snapshot/face_train_test_iter_28000.caffemodel
I0826 17:04:21.112709 25446 sgd_solver.cpp:307] Snapshotting solver state to binary proto file face_snapshot/face_train_test_iter_28000.solverstate
I0826 17:04:21.435452 25446 solver.cpp:332] Iteration 28000, loss = 5.36372
I0826 17:04:21.435472 25446 solver.cpp:337] Optimization Done.
I0826 17:04:21.435489 25446 caffe.cpp:254] Optimization Done.
